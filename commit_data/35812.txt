commit cde34780b7a0bbd162321a34c41fc8a6268e2c09
Author: Alberto Donizetti <alb.donizetti@gmail.com>
Date:   Thu Mar 8 17:43:55 2018 +0100

    test/codegen: port math/bits.RotateLeft tests to codegen
    
    Only RotateLeft{64,32} were tested, and just for ppc64. This CL adds
    tests for RotateLeft{64,32,16,8} on arm64 and amd64/386, for the cases
    where the calls are actually instrinsified.
    
    RotateLeft tests (the last ones for math/bits functions) are deleted
    from asm_test.
    
    This CL also adds a space between the "//" and the arch name in the
    comments, to uniform this file to the style used in all the other
    files.
    
    Change-Id: Ifc2a27261d70bcc294b4ec64490d8367f62d2b89
    Reviewed-on: https://go-review.googlesource.com/99596
    Reviewed-by: Giovanni Bajo <rasky@develer.com>
---
 src/cmd/compile/internal/gc/asm_test.go |  24 +----
 test/codegen/mathbits.go                | 164 +++++++++++++++++++-------------
 2 files changed, 99 insertions(+), 89 deletions(-)

diff --git a/src/cmd/compile/internal/gc/asm_test.go b/src/cmd/compile/internal/gc/asm_test.go
index 1e3cbfe16f..96d0bc0d08 100644
--- a/src/cmd/compile/internal/gc/asm_test.go
+++ b/src/cmd/compile/internal/gc/asm_test.go
@@ -259,10 +259,9 @@ var allAsmTests = []*asmTests{
 		tests: linuxMIPS64Tests,
 	},
 	{
-		arch:    "ppc64le",
-		os:      "linux",
-		imports: []string{"math/bits"},
-		tests:   linuxPPC64LETests,
+		arch:  "ppc64le",
+		os:    "linux",
+		tests: linuxPPC64LETests,
 	},
 	{
 		arch:  "amd64",
@@ -1701,23 +1700,6 @@ var linuxPPC64LETests = []*asmTest{
 		`,
 		pos: []string{"\tROTL\t"},
 	},
-	{
-		fn: `
-		func f10(a uint32) uint32 {
-			return bits.RotateLeft32(a, 9)
-		}
-		`,
-		pos: []string{"\tROTLW\t"},
-	},
-	{
-		fn: `
-		func f11(a uint64) uint64 {
-			return bits.RotateLeft64(a, 37)
-		}
-		`,
-		pos: []string{"\tROTL\t"},
-	},
-
 	{
 		// check that stack store is optimized away
 		fn: `
diff --git a/test/codegen/mathbits.go b/test/codegen/mathbits.go
index 2185b535b9..964949e33c 100644
--- a/test/codegen/mathbits.go
+++ b/test/codegen/mathbits.go
@@ -13,42 +13,42 @@ import "math/bits"
 // ----------------------- //
 
 func LeadingZeros(n uint) int {
-	//amd64:"BSRQ"
-	//s390x:"FLOGR"
-	//arm:"CLZ" arm64:"CLZ"
-	//mips:"CLZ"
+	// amd64:"BSRQ"
+	// s390x:"FLOGR"
+	// arm:"CLZ" arm64:"CLZ"
+	// mips:"CLZ"
 	return bits.LeadingZeros(n)
 }
 
 func LeadingZeros64(n uint64) int {
-	//amd64:"BSRQ"
-	//s390x:"FLOGR"
-	//arm:"CLZ" arm64:"CLZ"
-	//mips:"CLZ"
+	// amd64:"BSRQ"
+	// s390x:"FLOGR"
+	// arm:"CLZ" arm64:"CLZ"
+	// mips:"CLZ"
 	return bits.LeadingZeros64(n)
 }
 
 func LeadingZeros32(n uint32) int {
-	//amd64:"BSRQ"
-	//s390x:"FLOGR"
-	//arm:"CLZ" arm64:"CLZ"
-	//mips:"CLZ"
+	// amd64:"BSRQ"
+	// s390x:"FLOGR"
+	// arm:"CLZ" arm64:"CLZ"
+	// mips:"CLZ"
 	return bits.LeadingZeros32(n)
 }
 
 func LeadingZeros16(n uint16) int {
-	//amd64:"BSRQ"
-	//s390x:"FLOGR"
-	//arm:"CLZ" arm64:"CLZ"
-	//mips:"CLZ"
+	// amd64:"BSRQ"
+	// s390x:"FLOGR"
+	// arm:"CLZ" arm64:"CLZ"
+	// mips:"CLZ"
 	return bits.LeadingZeros16(n)
 }
 
 func LeadingZeros8(n uint8) int {
-	//amd64 LeadingZeros8 not intrinsified (see ssa.go)
-	//s390x:"FLOGR"
-	//arm:"CLZ" arm64:"CLZ"
-	//mips:"CLZ"
+	// amd64 LeadingZeros8 not intrinsified (see ssa.go)
+	// s390x:"FLOGR"
+	// arm:"CLZ" arm64:"CLZ"
+	// mips:"CLZ"
 	return bits.LeadingZeros8(n)
 }
 
@@ -57,42 +57,42 @@ func LeadingZeros8(n uint8) int {
 // --------------- //
 
 func Len(n uint) int {
-	//amd64:"BSRQ"
-	//s390x:"FLOGR"
-	//arm:"CLZ" arm64:"CLZ"
-	//mips:"CLZ"
+	// amd64:"BSRQ"
+	// s390x:"FLOGR"
+	// arm:"CLZ" arm64:"CLZ"
+	// mips:"CLZ"
 	return bits.Len(n)
 }
 
 func Len64(n uint64) int {
-	//amd64:"BSRQ"
-	//s390x:"FLOGR"
-	//arm:"CLZ" arm64:"CLZ"
-	//mips:"CLZ"
+	// amd64:"BSRQ"
+	// s390x:"FLOGR"
+	// arm:"CLZ" arm64:"CLZ"
+	// mips:"CLZ"
 	return bits.Len64(n)
 }
 
 func Len32(n uint32) int {
-	//amd64:"BSRQ"
-	//s390x:"FLOGR"
-	//arm:"CLZ" arm64:"CLZ"
-	//mips:"CLZ"
+	// amd64:"BSRQ"
+	// s390x:"FLOGR"
+	// arm:"CLZ" arm64:"CLZ"
+	// mips:"CLZ"
 	return bits.Len32(n)
 }
 
 func Len16(n uint16) int {
-	//amd64:"BSRQ"
-	//s390x:"FLOGR"
-	//arm:"CLZ" arm64:"CLZ"
-	//mips:"CLZ"
+	// amd64:"BSRQ"
+	// s390x:"FLOGR"
+	// arm:"CLZ" arm64:"CLZ"
+	// mips:"CLZ"
 	return bits.Len16(n)
 }
 
 func Len8(n uint8) int {
-	//amd64 Len8 not intrisified (see ssa.go)
-	//s390x:"FLOGR"
-	//arm:"CLZ" arm64:"CLZ"
-	//mips:"CLZ"
+	// amd64 Len8 not intrisified (see ssa.go)
+	// s390x:"FLOGR"
+	// arm:"CLZ" arm64:"CLZ"
+	// mips:"CLZ"
 	return bits.Len8(n)
 }
 
@@ -101,26 +101,26 @@ func Len8(n uint8) int {
 // -------------------- //
 
 func OnesCount(n uint) int {
-	//amd64:"POPCNTQ",".*support_popcnt"
-	//arm64:"VCNT","VUADDLV"
+	// amd64:"POPCNTQ",".*support_popcnt"
+	// arm64:"VCNT","VUADDLV"
 	return bits.OnesCount(n)
 }
 
 func OnesCount64(n uint64) int {
-	//amd64:"POPCNTQ",".*support_popcnt"
-	//arm64:"VCNT","VUADDLV"
+	// amd64:"POPCNTQ",".*support_popcnt"
+	// arm64:"VCNT","VUADDLV"
 	return bits.OnesCount64(n)
 }
 
 func OnesCount32(n uint32) int {
-	//amd64:"POPCNTL",".*support_popcnt"
-	//arm64:"VCNT","VUADDLV"
+	// amd64:"POPCNTL",".*support_popcnt"
+	// arm64:"VCNT","VUADDLV"
 	return bits.OnesCount32(n)
 }
 
 func OnesCount16(n uint16) int {
-	//amd64:"POPCNTL",".*support_popcnt"
-	//arm64:"VCNT","VUADDLV"
+	// amd64:"POPCNTL",".*support_popcnt"
+	// arm64:"VCNT","VUADDLV"
 	return bits.OnesCount16(n)
 }
 
@@ -129,61 +129,89 @@ func OnesCount16(n uint16) int {
 // ----------------------- //
 
 func ReverseBytes(n uint) uint {
-	//amd64:"BSWAPQ"
-	//s390x:"MOVDBR"
-	//arm64:"REV"
+	// amd64:"BSWAPQ"
+	// s390x:"MOVDBR"
+	// arm64:"REV"
 	return bits.ReverseBytes(n)
 }
 
 func ReverseBytes64(n uint64) uint64 {
-	//amd64:"BSWAPQ"
-	//s390x:"MOVDBR"
-	//arm64:"REV"
+	// amd64:"BSWAPQ"
+	// s390x:"MOVDBR"
+	// arm64:"REV"
 	return bits.ReverseBytes64(n)
 }
 
 func ReverseBytes32(n uint32) uint32 {
-	//amd64:"BSWAPL"
-	//s390x:"MOVWBR"
-	//arm64:"REVW"
+	// amd64:"BSWAPL"
+	// s390x:"MOVWBR"
+	// arm64:"REVW"
 	return bits.ReverseBytes32(n)
 }
 
 func ReverseBytes16(n uint16) uint16 {
-	//amd64:"ROLW"
+	// amd64:"ROLW"
 	return bits.ReverseBytes16(n)
 }
 
+// --------------------- //
+//    bits.RotateLeft    //
+// --------------------- //
+
+func RotateLeft64(n uint64) uint64 {
+	// amd64:"ROLQ"
+	// arm64:"ROR"
+	// ppc64:"ROTL"
+	return bits.RotateLeft64(n, 37)
+}
+
+func RotateLeft32(n uint32) uint32 {
+	// amd64:"ROLL" 386:"ROLL"
+	// arm64:"RORW"
+	// ppc64:"ROTLW"
+	return bits.RotateLeft32(n, 9)
+}
+
+func RotateLeft16(n uint16) uint16 {
+	// amd64:"ROLW" 386:"ROLW"
+	return bits.RotateLeft16(n, 5)
+}
+
+func RotateLeft8(n uint8) uint8 {
+	// amd64:"ROLB" 386:"ROLB"
+	return bits.RotateLeft8(n, 5)
+}
+
 // ------------------------ //
 //    bits.TrailingZeros    //
 // ------------------------ //
 
 func TrailingZeros(n uint) int {
-	//amd64:"BSFQ","MOVL\t\\$64","CMOVQEQ"
-	//s390x:"FLOGR"
+	// amd64:"BSFQ","MOVL\t\\$64","CMOVQEQ"
+	// s390x:"FLOGR"
 	return bits.TrailingZeros(n)
 }
 
 func TrailingZeros64(n uint64) int {
-	//amd64:"BSFQ","MOVL\t\\$64","CMOVQEQ"
-	//s390x:"FLOGR"
+	// amd64:"BSFQ","MOVL\t\\$64","CMOVQEQ"
+	// s390x:"FLOGR"
 	return bits.TrailingZeros64(n)
 }
 
 func TrailingZeros32(n uint32) int {
-	//amd64:"MOVQ\t\\$4294967296","ORQ\t[^$]","BSFQ"
-	//s390x:"FLOGR","MOVWZ"
+	// amd64:"MOVQ\t\\$4294967296","ORQ\t[^$]","BSFQ"
+	// s390x:"FLOGR","MOVWZ"
 	return bits.TrailingZeros32(n)
 }
 
 func TrailingZeros16(n uint16) int {
-	//amd64:"BSFQ","ORQ\t\\$65536"
-	//s390x:"FLOGR","OR\t\\$65536"
+	// amd64:"BSFQ","ORQ\t\\$65536"
+	// s390x:"FLOGR","OR\t\\$65536"
 	return bits.TrailingZeros16(n)
 }
 
 func TrailingZeros8(n uint8) int {
-	//amd64:"BSFQ","ORQ\t\\$256"
-	//s390x:"FLOGR","OR\t\\$256"
+	// amd64:"BSFQ","ORQ\t\\$256"
+	// s390x:"FLOGR","OR\t\\$256"
 	return bits.TrailingZeros8(n)
 }
