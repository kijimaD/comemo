commit 02fb9b8ca90874085173d6bd900038573ef4a4c3
Author: Michael Pratt <mpratt@google.com>
Date:   Fri Jul 15 14:27:48 2022 -0400

    runtime: convert gcController.maxStackScan to atomic type
    
    For #53821.
    
    Change-Id: I1bd23cdbc371011ec2331fb0a37482ecf99a063b
    Reviewed-on: https://go-review.googlesource.com/c/go/+/417778
    Run-TryBot: Michael Pratt <mpratt@google.com>
    Reviewed-by: Austin Clements <austin@google.com>
    TryBot-Result: Gopher Robot <gobot@golang.org>
---
 src/runtime/align_runtime_test.go |  1 -
 src/runtime/export_test.go        |  2 +-
 src/runtime/mgc.go                |  2 +-
 src/runtime/mgcpacer.go           | 10 ++++------
 4 files changed, 6 insertions(+), 9 deletions(-)

diff --git a/src/runtime/align_runtime_test.go b/src/runtime/align_runtime_test.go
index 03309a22d0..9fe7b61c44 100644
--- a/src/runtime/align_runtime_test.go
+++ b/src/runtime/align_runtime_test.go
@@ -22,7 +22,6 @@ var AtomicFields = []uintptr{
 	unsafe.Offsetof(schedt{}.pollUntil),
 	unsafe.Offsetof(schedt{}.timeToRun),
 	unsafe.Offsetof(gcControllerState{}.bgScanCredit),
-	unsafe.Offsetof(gcControllerState{}.maxStackScan),
 	unsafe.Offsetof(gcControllerState{}.dedicatedMarkTime),
 	unsafe.Offsetof(gcControllerState{}.dedicatedMarkWorkersNeeded),
 	unsafe.Offsetof(gcControllerState{}.fractionalMarkTime),
diff --git a/src/runtime/export_test.go b/src/runtime/export_test.go
index 1018875651..4736163673 100644
--- a/src/runtime/export_test.go
+++ b/src/runtime/export_test.go
@@ -1322,7 +1322,7 @@ func (c *GCController) StartCycle(stackSize, globalsSize uint64, scannableFrac f
 	if c.heapMarked > trigger {
 		trigger = c.heapMarked
 	}
-	c.maxStackScan = stackSize
+	c.maxStackScan.Store(stackSize)
 	c.globalsScan = globalsSize
 	c.heapLive.Store(trigger)
 	c.heapScan.Add(int64(float64(trigger-c.heapMarked) * scannableFrac))
diff --git a/src/runtime/mgc.go b/src/runtime/mgc.go
index c35e9af05b..b1657482a0 100644
--- a/src/runtime/mgc.go
+++ b/src/runtime/mgc.go
@@ -1120,7 +1120,7 @@ func gcMarkTermination() {
 		print(" ms cpu, ",
 			work.heap0>>20, "->", work.heap1>>20, "->", work.heap2>>20, " MB, ",
 			gcController.lastHeapGoal>>20, " MB goal, ",
-			atomic.Load64(&gcController.maxStackScan)>>20, " MB stacks, ",
+			gcController.maxStackScan.Load()>>20, " MB stacks, ",
 			gcController.globalsScan>>20, " MB globals, ",
 			work.maxprocs, " P")
 		if work.userForced {
diff --git a/src/runtime/mgcpacer.go b/src/runtime/mgcpacer.go
index bc4946d46f..fe31d6fbd8 100644
--- a/src/runtime/mgcpacer.go
+++ b/src/runtime/mgcpacer.go
@@ -227,9 +227,7 @@ type gcControllerState struct {
 	// goroutine stack space is much harder to measure cheaply. By using
 	// allocated space, we make an overestimate; this is OK, it's better
 	// to conservatively overcount than undercount.
-	//
-	// Read and updated atomically.
-	maxStackScan uint64
+	maxStackScan atomic.Uint64
 
 	// globalsScan is the total amount of global variable space
 	// that is scannable.
@@ -563,7 +561,7 @@ func (c *gcControllerState) revise() {
 	// needs to be performed in this GC cycle. Specifically, it represents
 	// the case where *all* scannable memory turns out to be live, and
 	// *all* allocated stack space is scannable.
-	maxStackScan := atomic.Load64(&c.maxStackScan)
+	maxStackScan := c.maxStackScan.Load()
 	maxScanWork := int64(scan + maxStackScan + c.globalsScan)
 	if work > scanWorkExpected {
 		// We've already done more scan work than expected. Because our expectation
@@ -944,12 +942,12 @@ func (c *gcControllerState) update(dHeapLive, dHeapScan int64) {
 
 func (c *gcControllerState) addScannableStack(pp *p, amount int64) {
 	if pp == nil {
-		atomic.Xadd64(&c.maxStackScan, amount)
+		c.maxStackScan.Add(amount)
 		return
 	}
 	pp.maxStackScanDelta += amount
 	if pp.maxStackScanDelta >= maxStackScanSlack || pp.maxStackScanDelta <= -maxStackScanSlack {
-		atomic.Xadd64(&c.maxStackScan, pp.maxStackScanDelta)
+		c.maxStackScan.Add(pp.maxStackScanDelta)
 		pp.maxStackScanDelta = 0
 	}
 }
