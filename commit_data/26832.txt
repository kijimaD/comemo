commit ff274210674e407ab7c44585a097259cd029dced
Author: Joe Tsai <joetsai@digital-static.net>
Date:   Tue Dec 8 18:26:22 2015 -0800

    compress/bzip2: fix benchmark to actually measure decompression rate
    
    Motivation:
    * Previously, the size of the compressed data was used for metrics,
    rather than the uncompressed size. This causes the library to appear
    to perform poorly relative to C or other implementation. Switch it
    to use the uncompressed size so that it matches how decompression
    benchmarks are usually done (like in compress/flate). This also makes
    it easier to compare bzip2 rates to other algorithms since they measure
    performance in this way.
    * Also, reset the timer after doing initialization work.
    
    Change-Id: I32112c2ee8e7391e658c9cf31039f70a689d9b9d
    Reviewed-on: https://go-review.googlesource.com/17611
    Reviewed-by: Brad Fitzpatrick <bradfitz@golang.org>
    Run-TryBot: Brad Fitzpatrick <bradfitz@golang.org>
    TryBot-Result: Gobot Gobot <gobot@golang.org>
---
 src/compress/bzip2/bzip2_test.go | 12 +++++++++++-
 1 file changed, 11 insertions(+), 1 deletion(-)

diff --git a/src/compress/bzip2/bzip2_test.go b/src/compress/bzip2/bzip2_test.go
index 2a2136df4d..2acf40290c 100644
--- a/src/compress/bzip2/bzip2_test.go
+++ b/src/compress/bzip2/bzip2_test.go
@@ -194,7 +194,17 @@ func benchmarkDecode(b *testing.B, testfile int) {
 	if err != nil {
 		b.Fatal(err)
 	}
-	b.SetBytes(int64(len(compressed)))
+
+	// Determine the uncompressed size of testfile.
+	uncompressedSize, err := io.Copy(ioutil.Discard, NewReader(bytes.NewReader(compressed)))
+	if err != nil {
+		b.Fatal(err)
+	}
+
+	b.SetBytes(uncompressedSize)
+	b.ReportAllocs()
+	b.ResetTimer()
+
 	for i := 0; i < b.N; i++ {
 		r := bytes.NewReader(compressed)
 		io.Copy(ioutil.Discard, NewReader(r))
