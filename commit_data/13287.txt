commit 09f48db3e17c71e2ab709efb760e2a305c67aace
Author: Dave Cheney <dave@cheney.net>
Date:   Tue Jun 5 18:55:14 2012 +1000

    runtime: use uintptr for block length in scanblock
    
    Using an int64 for a block size doesn't make
    sense on 32bit platforms but extracts a performance
    penalty dealing with double word quantities on Arm.
    
    linux/arm
    
    benchmark                 old ns/op    new ns/op    delta
    BenchmarkGobDecode        155401600    144589300   -6.96%
    BenchmarkGobEncode         72772220     62460940  -14.17%
    BenchmarkGzip               5822632      2604797  -55.26%
    BenchmarkGunzip              326321       151721  -53.51%
    
    benchmark                  old MB/s     new MB/s  speedup
    BenchmarkGobDecode             4.94         5.31    1.07x
    BenchmarkGobEncode            10.55        12.29    1.16x
    
    R=golang-dev, rsc, bradfitz
    CC=golang-dev
    https://golang.org/cl/6272047
---
 src/pkg/runtime/mgc0.c | 14 +++++++-------
 1 file changed, 7 insertions(+), 7 deletions(-)

diff --git a/src/pkg/runtime/mgc0.c b/src/pkg/runtime/mgc0.c
index 5f3d20b05b..5f1bff2c46 100644
--- a/src/pkg/runtime/mgc0.c
+++ b/src/pkg/runtime/mgc0.c
@@ -148,7 +148,7 @@ static struct {
 // body.  Keeping an explicit work list is easier on the stack allocator and
 // more efficient.
 static void
-scanblock(byte *b, int64 n)
+scanblock(byte *b, uintptr n)
 {
 	byte *obj, *arena_start, *arena_used, *p;
 	void **vp;
@@ -159,8 +159,8 @@ scanblock(byte *b, int64 n)
 	Workbuf *wbuf;
 	bool keepworking;
 
-	if((int64)(uintptr)n != n || n < 0) {
-		runtime·printf("scanblock %p %D\n", b, n);
+	if((intptr)n < 0) {
+		runtime·printf("scanblock %p %D\n", b, (int64)n);
 		runtime·throw("scanblock");
 	}
 
@@ -191,7 +191,7 @@ scanblock(byte *b, int64 n)
 		// Each iteration scans the block b of length n, queueing pointers in
 		// the work buffer.
 		if(Debug > 1)
-			runtime·printf("scanblock %p %D\n", b, n);
+			runtime·printf("scanblock %p %D\n", b, (int64)n);
 
 		vp = (void**)b;
 		n >>= (2+PtrSize/8);  /* n /= PtrSize (4 or 8) */
@@ -339,7 +339,7 @@ scanblock(byte *b, int64 n)
 // it is simpler, slower, single-threaded, recursive,
 // and uses bitSpecial as the mark bit.
 static void
-debug_scanblock(byte *b, int64 n)
+debug_scanblock(byte *b, uintptr n)
 {
 	byte *obj, *p;
 	void **vp;
@@ -349,8 +349,8 @@ debug_scanblock(byte *b, int64 n)
 	if(!DebugMark)
 		runtime·throw("debug_scanblock without DebugMark");
 
-	if((int64)(uintptr)n != n || n < 0) {
-		runtime·printf("debug_scanblock %p %D\n", b, n);
+	if((intptr)n < 0) {
+		runtime·printf("debug_scanblock %p %D\n", b, (int64)n);
 		runtime·throw("debug_scanblock");
 	}
 
