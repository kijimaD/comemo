commit ea33523877e4c7a136f2db94a8b5bc4e40220be2
Author: Xiangdong Ji <xiangdong.ji@arm.com>
Date:   Tue Sep 8 09:55:20 2020 +0000

    cmd/compile: rewrite some ARM64 rules to use typed aux
    
    Passes toolstash-check -all.
    
    Change-Id: I7ec36bc048f3031c8201107e6fc5d1257271dbf1
    Reviewed-on: https://go-review.googlesource.com/c/go/+/234379
    Run-TryBot: Alberto Donizetti <alb.donizetti@gmail.com>
    TryBot-Result: Go Bot <gobot@golang.org>
    Trust: Alberto Donizetti <alb.donizetti@gmail.com>
    Reviewed-by: Keith Randall <khr@golang.org>
---
 src/cmd/compile/internal/ssa/gen/ARM64.rules | 496 +++++++--------
 src/cmd/compile/internal/ssa/rewriteARM64.go | 912 +++++++++++++--------------
 2 files changed, 704 insertions(+), 704 deletions(-)

diff --git a/src/cmd/compile/internal/ssa/gen/ARM64.rules b/src/cmd/compile/internal/ssa/gen/ARM64.rules
index 311067e87a..c4a3532632 100644
--- a/src/cmd/compile/internal/ssa/gen/ARM64.rules
+++ b/src/cmd/compile/internal/ssa/gen/ARM64.rules
@@ -1116,280 +1116,280 @@
 
 // if a register move has only 1 use, just use the same register without emitting instruction
 // MOVDnop doesn't emit instruction, only for ensuring the type.
-(MOVDreg x) && x.Uses == 1 -> (MOVDnop x)
+(MOVDreg x) && x.Uses == 1 => (MOVDnop x)
 
 // fold constant into arithmatic ops
-(ADD x (MOVDconst [c])) -> (ADDconst [c] x)
-(SUB x (MOVDconst [c])) -> (SUBconst [c] x)
-(AND x (MOVDconst [c])) -> (ANDconst [c] x)
-(OR  x (MOVDconst [c])) -> (ORconst  [c] x)
-(XOR x (MOVDconst [c])) -> (XORconst [c] x)
-(TST x (MOVDconst [c])) -> (TSTconst [c] x)
-(TSTW x (MOVDconst [c])) -> (TSTWconst [c] x)
-(CMN x (MOVDconst [c])) -> (CMNconst [c] x)
-(CMNW x (MOVDconst [c])) -> (CMNWconst [c] x)
-(BIC x (MOVDconst [c])) -> (ANDconst [^c] x)
-(EON x (MOVDconst [c])) -> (XORconst [^c] x)
-(ORN x (MOVDconst [c])) -> (ORconst  [^c] x)
-
-(SLL x (MOVDconst [c])) -> (SLLconst x [c&63]) // Note: I don't think we ever generate bad constant shifts (i.e. c>=64)
-(SRL x (MOVDconst [c])) -> (SRLconst x [c&63])
-(SRA x (MOVDconst [c])) -> (SRAconst x [c&63])
-
-(CMP x (MOVDconst [c])) -> (CMPconst [c] x)
-(CMP (MOVDconst [c]) x) -> (InvertFlags (CMPconst [c] x))
+(ADD x (MOVDconst [c])) => (ADDconst [c] x)
+(SUB x (MOVDconst [c])) => (SUBconst [c] x)
+(AND x (MOVDconst [c])) => (ANDconst [c] x)
+(OR  x (MOVDconst [c])) => (ORconst  [c] x)
+(XOR x (MOVDconst [c])) => (XORconst [c] x)
+(TST x (MOVDconst [c])) => (TSTconst [c] x)
+(TSTW x (MOVDconst [c])) => (TSTWconst [int32(c)] x)
+(CMN x (MOVDconst [c])) => (CMNconst [c] x)
+(CMNW x (MOVDconst [c])) => (CMNWconst [int32(c)] x)
+(BIC x (MOVDconst [c])) => (ANDconst [^c] x)
+(EON x (MOVDconst [c])) => (XORconst [^c] x)
+(ORN x (MOVDconst [c])) => (ORconst  [^c] x)
+
+(SLL x (MOVDconst [c])) => (SLLconst x [c&63]) // Note: I don't think we ever generate bad constant shifts (i.e. c>=64)
+(SRL x (MOVDconst [c])) => (SRLconst x [c&63])
+(SRA x (MOVDconst [c])) => (SRAconst x [c&63])
+
+(CMP x (MOVDconst [c])) => (CMPconst [c] x)
+(CMP (MOVDconst [c]) x) => (InvertFlags (CMPconst [c] x))
 (CMPW x (MOVDconst [c])) => (CMPWconst [int32(c)] x)
 (CMPW (MOVDconst [c]) x) => (InvertFlags (CMPWconst [int32(c)] x))
 
 // Canonicalize the order of arguments to comparisons - helps with CSE.
-((CMP|CMPW) x y) && x.ID > y.ID -> (InvertFlags ((CMP|CMPW) y x))
+((CMP|CMPW) x y) && x.ID > y.ID => (InvertFlags ((CMP|CMPW) y x))
 
-// mul-neg -> mneg
-(NEG (MUL x y)) -> (MNEG x y)
-(NEG (MULW x y)) -> (MNEGW x y)
-(MUL (NEG x) y) -> (MNEG x y)
-(MULW (NEG x) y) -> (MNEGW x y)
+// mul-neg => mneg
+(NEG (MUL x y)) => (MNEG x y)
+(NEG (MULW x y)) => (MNEGW x y)
+(MUL (NEG x) y) => (MNEG x y)
+(MULW (NEG x) y) => (MNEGW x y)
 
 // madd/msub
-(ADD a l:(MUL  x y)) && l.Uses==1 && clobber(l) -> (MADD a x y)
-(SUB a l:(MUL  x y)) && l.Uses==1 && clobber(l) -> (MSUB a x y)
-(ADD a l:(MNEG x y)) && l.Uses==1 && clobber(l) -> (MSUB a x y)
-(SUB a l:(MNEG x y)) && l.Uses==1 && clobber(l) -> (MADD a x y)
+(ADD a l:(MUL  x y)) && l.Uses==1 && clobber(l) => (MADD a x y)
+(SUB a l:(MUL  x y)) && l.Uses==1 && clobber(l) => (MSUB a x y)
+(ADD a l:(MNEG x y)) && l.Uses==1 && clobber(l) => (MSUB a x y)
+(SUB a l:(MNEG x y)) && l.Uses==1 && clobber(l) => (MADD a x y)
 
-(ADD a l:(MULW  x y)) && a.Type.Size() != 8 && l.Uses==1 && clobber(l) -> (MADDW a x y)
-(SUB a l:(MULW  x y)) && a.Type.Size() != 8 && l.Uses==1 && clobber(l) -> (MSUBW a x y)
-(ADD a l:(MNEGW x y)) && a.Type.Size() != 8 && l.Uses==1 && clobber(l) -> (MSUBW a x y)
-(SUB a l:(MNEGW x y)) && a.Type.Size() != 8 && l.Uses==1 && clobber(l) -> (MADDW a x y)
+(ADD a l:(MULW  x y)) && a.Type.Size() != 8 && l.Uses==1 && clobber(l) => (MADDW a x y)
+(SUB a l:(MULW  x y)) && a.Type.Size() != 8 && l.Uses==1 && clobber(l) => (MSUBW a x y)
+(ADD a l:(MNEGW x y)) && a.Type.Size() != 8 && l.Uses==1 && clobber(l) => (MSUBW a x y)
+(SUB a l:(MNEGW x y)) && a.Type.Size() != 8 && l.Uses==1 && clobber(l) => (MADDW a x y)
 
 // optimize ADCSflags, SBCSflags and friends
-(ADCSflags x y (Select1 <types.TypeFlags> (ADDSconstflags [-1] (ADCzerocarry <typ.UInt64> c)))) -> (ADCSflags x y c)
-(ADCSflags x y (Select1 <types.TypeFlags> (ADDSconstflags [-1] (MOVDconst [0])))) -> (ADDSflags x y)
-(SBCSflags x y (Select1 <types.TypeFlags> (NEGSflags (NEG <typ.UInt64> (NGCzerocarry <typ.UInt64> bo))))) -> (SBCSflags x y bo)
-(SBCSflags x y (Select1 <types.TypeFlags> (NEGSflags (MOVDconst [0])))) -> (SUBSflags x y)
+(ADCSflags x y (Select1 <types.TypeFlags> (ADDSconstflags [-1] (ADCzerocarry <typ.UInt64> c)))) => (ADCSflags x y c)
+(ADCSflags x y (Select1 <types.TypeFlags> (ADDSconstflags [-1] (MOVDconst [0])))) => (ADDSflags x y)
+(SBCSflags x y (Select1 <types.TypeFlags> (NEGSflags (NEG <typ.UInt64> (NGCzerocarry <typ.UInt64> bo))))) => (SBCSflags x y bo)
+(SBCSflags x y (Select1 <types.TypeFlags> (NEGSflags (MOVDconst [0])))) => (SUBSflags x y)
 
 // mul by constant
-(MUL x (MOVDconst [-1])) -> (NEG x)
-(MUL _ (MOVDconst [0])) -> (MOVDconst [0])
-(MUL x (MOVDconst [1])) -> x
-(MUL x (MOVDconst [c])) && isPowerOfTwo(c) -> (SLLconst [log2(c)] x)
-(MUL x (MOVDconst [c])) && isPowerOfTwo(c-1) && c >= 3 -> (ADDshiftLL x x [log2(c-1)])
-(MUL x (MOVDconst [c])) && isPowerOfTwo(c+1) && c >= 7 -> (ADDshiftLL (NEG <x.Type> x) x [log2(c+1)])
-(MUL x (MOVDconst [c])) && c%3 == 0 && isPowerOfTwo(c/3) -> (SLLconst [log2(c/3)] (ADDshiftLL <x.Type> x x [1]))
-(MUL x (MOVDconst [c])) && c%5 == 0 && isPowerOfTwo(c/5) -> (SLLconst [log2(c/5)] (ADDshiftLL <x.Type> x x [2]))
-(MUL x (MOVDconst [c])) && c%7 == 0 && isPowerOfTwo(c/7) -> (SLLconst [log2(c/7)] (ADDshiftLL <x.Type> (NEG <x.Type> x) x [3]))
-(MUL x (MOVDconst [c])) && c%9 == 0 && isPowerOfTwo(c/9) -> (SLLconst [log2(c/9)] (ADDshiftLL <x.Type> x x [3]))
-
-(MULW x (MOVDconst [c])) && int32(c)==-1 -> (NEG x)
-(MULW _ (MOVDconst [c])) && int32(c)==0 -> (MOVDconst [0])
-(MULW x (MOVDconst [c])) && int32(c)==1 -> x
-(MULW x (MOVDconst [c])) && isPowerOfTwo(c) -> (SLLconst [log2(c)] x)
-(MULW x (MOVDconst [c])) && isPowerOfTwo(c-1) && int32(c) >= 3 -> (ADDshiftLL x x [log2(c-1)])
-(MULW x (MOVDconst [c])) && isPowerOfTwo(c+1) && int32(c) >= 7 -> (ADDshiftLL (NEG <x.Type> x) x [log2(c+1)])
-(MULW x (MOVDconst [c])) && c%3 == 0 && isPowerOfTwo(c/3) && is32Bit(c) -> (SLLconst [log2(c/3)] (ADDshiftLL <x.Type> x x [1]))
-(MULW x (MOVDconst [c])) && c%5 == 0 && isPowerOfTwo(c/5) && is32Bit(c) -> (SLLconst [log2(c/5)] (ADDshiftLL <x.Type> x x [2]))
-(MULW x (MOVDconst [c])) && c%7 == 0 && isPowerOfTwo(c/7) && is32Bit(c) -> (SLLconst [log2(c/7)] (ADDshiftLL <x.Type> (NEG <x.Type> x) x [3]))
-(MULW x (MOVDconst [c])) && c%9 == 0 && isPowerOfTwo(c/9) && is32Bit(c) -> (SLLconst [log2(c/9)] (ADDshiftLL <x.Type> x x [3]))
+(MUL x (MOVDconst [-1])) => (NEG x)
+(MUL _ (MOVDconst [0])) => (MOVDconst [0])
+(MUL x (MOVDconst [1])) => x
+(MUL x (MOVDconst [c])) && isPowerOfTwo(c) => (SLLconst [log2(c)] x)
+(MUL x (MOVDconst [c])) && isPowerOfTwo(c-1) && c >= 3 => (ADDshiftLL x x [log2(c-1)])
+(MUL x (MOVDconst [c])) && isPowerOfTwo(c+1) && c >= 7 => (ADDshiftLL (NEG <x.Type> x) x [log2(c+1)])
+(MUL x (MOVDconst [c])) && c%3 == 0 && isPowerOfTwo(c/3) => (SLLconst [log2(c/3)] (ADDshiftLL <x.Type> x x [1]))
+(MUL x (MOVDconst [c])) && c%5 == 0 && isPowerOfTwo(c/5) => (SLLconst [log2(c/5)] (ADDshiftLL <x.Type> x x [2]))
+(MUL x (MOVDconst [c])) && c%7 == 0 && isPowerOfTwo(c/7) => (SLLconst [log2(c/7)] (ADDshiftLL <x.Type> (NEG <x.Type> x) x [3]))
+(MUL x (MOVDconst [c])) && c%9 == 0 && isPowerOfTwo(c/9) => (SLLconst [log2(c/9)] (ADDshiftLL <x.Type> x x [3]))
+
+(MULW x (MOVDconst [c])) && int32(c)==-1 => (NEG x)
+(MULW _ (MOVDconst [c])) && int32(c)==0 => (MOVDconst [0])
+(MULW x (MOVDconst [c])) && int32(c)==1 => x
+(MULW x (MOVDconst [c])) && isPowerOfTwo(c) => (SLLconst [log2(c)] x)
+(MULW x (MOVDconst [c])) && isPowerOfTwo(c-1) && int32(c) >= 3 => (ADDshiftLL x x [log2(c-1)])
+(MULW x (MOVDconst [c])) && isPowerOfTwo(c+1) && int32(c) >= 7 => (ADDshiftLL (NEG <x.Type> x) x [log2(c+1)])
+(MULW x (MOVDconst [c])) && c%3 == 0 && isPowerOfTwo(c/3) && is32Bit(c) => (SLLconst [log2(c/3)] (ADDshiftLL <x.Type> x x [1]))
+(MULW x (MOVDconst [c])) && c%5 == 0 && isPowerOfTwo(c/5) && is32Bit(c) => (SLLconst [log2(c/5)] (ADDshiftLL <x.Type> x x [2]))
+(MULW x (MOVDconst [c])) && c%7 == 0 && isPowerOfTwo(c/7) && is32Bit(c) => (SLLconst [log2(c/7)] (ADDshiftLL <x.Type> (NEG <x.Type> x) x [3]))
+(MULW x (MOVDconst [c])) && c%9 == 0 && isPowerOfTwo(c/9) && is32Bit(c) => (SLLconst [log2(c/9)] (ADDshiftLL <x.Type> x x [3]))
 
 // mneg by constant
-(MNEG x (MOVDconst [-1])) -> x
-(MNEG _ (MOVDconst [0])) -> (MOVDconst [0])
-(MNEG x (MOVDconst [1])) -> (NEG x)
-(MNEG x (MOVDconst [c])) && isPowerOfTwo(c) -> (NEG (SLLconst <x.Type> [log2(c)] x))
-(MNEG x (MOVDconst [c])) && isPowerOfTwo(c-1) && c >= 3 -> (NEG (ADDshiftLL <x.Type> x x [log2(c-1)]))
-(MNEG x (MOVDconst [c])) && isPowerOfTwo(c+1) && c >= 7 -> (NEG (ADDshiftLL <x.Type> (NEG <x.Type> x) x [log2(c+1)]))
-(MNEG x (MOVDconst [c])) && c%3 == 0 && isPowerOfTwo(c/3) -> (SLLconst <x.Type> [log2(c/3)] (SUBshiftLL <x.Type> x x [2]))
-(MNEG x (MOVDconst [c])) && c%5 == 0 && isPowerOfTwo(c/5) -> (NEG (SLLconst <x.Type> [log2(c/5)] (ADDshiftLL <x.Type> x x [2])))
-(MNEG x (MOVDconst [c])) && c%7 == 0 && isPowerOfTwo(c/7) -> (SLLconst <x.Type> [log2(c/7)] (SUBshiftLL <x.Type> x x [3]))
-(MNEG x (MOVDconst [c])) && c%9 == 0 && isPowerOfTwo(c/9) -> (NEG (SLLconst <x.Type> [log2(c/9)] (ADDshiftLL <x.Type> x x [3])))
-
-(MNEGW x (MOVDconst [c])) && int32(c)==-1 -> x
-(MNEGW _ (MOVDconst [c])) && int32(c)==0 -> (MOVDconst [0])
-(MNEGW x (MOVDconst [c])) && int32(c)==1 -> (NEG x)
-(MNEGW x (MOVDconst [c])) && isPowerOfTwo(c) -> (NEG (SLLconst <x.Type> [log2(c)] x))
-(MNEGW x (MOVDconst [c])) && isPowerOfTwo(c-1) && int32(c) >= 3 -> (NEG (ADDshiftLL <x.Type> x x [log2(c-1)]))
-(MNEGW x (MOVDconst [c])) && isPowerOfTwo(c+1) && int32(c) >= 7 -> (NEG (ADDshiftLL <x.Type> (NEG <x.Type> x) x [log2(c+1)]))
-(MNEGW x (MOVDconst [c])) && c%3 == 0 && isPowerOfTwo(c/3) && is32Bit(c) -> (SLLconst <x.Type> [log2(c/3)] (SUBshiftLL <x.Type> x x [2]))
-(MNEGW x (MOVDconst [c])) && c%5 == 0 && isPowerOfTwo(c/5) && is32Bit(c) -> (NEG (SLLconst <x.Type> [log2(c/5)] (ADDshiftLL <x.Type> x x [2])))
-(MNEGW x (MOVDconst [c])) && c%7 == 0 && isPowerOfTwo(c/7) && is32Bit(c) -> (SLLconst <x.Type> [log2(c/7)] (SUBshiftLL <x.Type> x x [3]))
-(MNEGW x (MOVDconst [c])) && c%9 == 0 && isPowerOfTwo(c/9) && is32Bit(c) -> (NEG (SLLconst <x.Type> [log2(c/9)] (ADDshiftLL <x.Type> x x [3])))
-
-(MADD a x (MOVDconst [-1])) -> (SUB a x)
-(MADD a _ (MOVDconst [0])) -> a
-(MADD a x (MOVDconst [1])) -> (ADD a x)
-(MADD a x (MOVDconst [c])) && isPowerOfTwo(c) -> (ADDshiftLL a x [log2(c)])
-(MADD a x (MOVDconst [c])) && isPowerOfTwo(c-1) && c>=3 -> (ADD a (ADDshiftLL <x.Type> x x [log2(c-1)]))
-(MADD a x (MOVDconst [c])) && isPowerOfTwo(c+1) && c>=7 -> (SUB a (SUBshiftLL <x.Type> x x [log2(c+1)]))
-(MADD a x (MOVDconst [c])) && c%3 == 0 && isPowerOfTwo(c/3) -> (SUBshiftLL a (SUBshiftLL <x.Type> x x [2]) [log2(c/3)])
-(MADD a x (MOVDconst [c])) && c%5 == 0 && isPowerOfTwo(c/5) -> (ADDshiftLL a (ADDshiftLL <x.Type> x x [2]) [log2(c/5)])
-(MADD a x (MOVDconst [c])) && c%7 == 0 && isPowerOfTwo(c/7) -> (SUBshiftLL a (SUBshiftLL <x.Type> x x [3]) [log2(c/7)])
-(MADD a x (MOVDconst [c])) && c%9 == 0 && isPowerOfTwo(c/9) -> (ADDshiftLL a (ADDshiftLL <x.Type> x x [3]) [log2(c/9)])
-
-(MADD a (MOVDconst [-1]) x) -> (SUB a x)
-(MADD a (MOVDconst [0]) _) -> a
-(MADD a (MOVDconst [1]) x) -> (ADD a x)
-(MADD a (MOVDconst [c]) x) && isPowerOfTwo(c) -> (ADDshiftLL a x [log2(c)])
-(MADD a (MOVDconst [c]) x) && isPowerOfTwo(c-1) && c>=3 -> (ADD a (ADDshiftLL <x.Type> x x [log2(c-1)]))
-(MADD a (MOVDconst [c]) x) && isPowerOfTwo(c+1) && c>=7 -> (SUB a (SUBshiftLL <x.Type> x x [log2(c+1)]))
-(MADD a (MOVDconst [c]) x) && c%3 == 0 && isPowerOfTwo(c/3) -> (SUBshiftLL a (SUBshiftLL <x.Type> x x [2]) [log2(c/3)])
-(MADD a (MOVDconst [c]) x) && c%5 == 0 && isPowerOfTwo(c/5) -> (ADDshiftLL a (ADDshiftLL <x.Type> x x [2]) [log2(c/5)])
-(MADD a (MOVDconst [c]) x) && c%7 == 0 && isPowerOfTwo(c/7) -> (SUBshiftLL a (SUBshiftLL <x.Type> x x [3]) [log2(c/7)])
-(MADD a (MOVDconst [c]) x) && c%9 == 0 && isPowerOfTwo(c/9) -> (ADDshiftLL a (ADDshiftLL <x.Type> x x [3]) [log2(c/9)])
-
-(MADDW a x (MOVDconst [c])) && int32(c)==-1 -> (SUB a x)
-(MADDW a _ (MOVDconst [c])) && int32(c)==0 -> a
-(MADDW a x (MOVDconst [c])) && int32(c)==1 -> (ADD a x)
-(MADDW a x (MOVDconst [c])) && isPowerOfTwo(c) -> (ADDshiftLL a x [log2(c)])
-(MADDW a x (MOVDconst [c])) && isPowerOfTwo(c-1) && int32(c)>=3 -> (ADD a (ADDshiftLL <x.Type> x x [log2(c-1)]))
-(MADDW a x (MOVDconst [c])) && isPowerOfTwo(c+1) && int32(c)>=7 -> (SUB a (SUBshiftLL <x.Type> x x [log2(c+1)]))
-(MADDW a x (MOVDconst [c])) && c%3 == 0 && isPowerOfTwo(c/3) && is32Bit(c) -> (SUBshiftLL a (SUBshiftLL <x.Type> x x [2]) [log2(c/3)])
-(MADDW a x (MOVDconst [c])) && c%5 == 0 && isPowerOfTwo(c/5) && is32Bit(c) -> (ADDshiftLL a (ADDshiftLL <x.Type> x x [2]) [log2(c/5)])
-(MADDW a x (MOVDconst [c])) && c%7 == 0 && isPowerOfTwo(c/7) && is32Bit(c) -> (SUBshiftLL a (SUBshiftLL <x.Type> x x [3]) [log2(c/7)])
-(MADDW a x (MOVDconst [c])) && c%9 == 0 && isPowerOfTwo(c/9) && is32Bit(c) -> (ADDshiftLL a (ADDshiftLL <x.Type> x x [3]) [log2(c/9)])
-
-(MADDW a (MOVDconst [c]) x) && int32(c)==-1 -> (SUB a x)
-(MADDW a (MOVDconst [c]) _) && int32(c)==0 -> a
-(MADDW a (MOVDconst [c]) x) && int32(c)==1 -> (ADD a x)
-(MADDW a (MOVDconst [c]) x) && isPowerOfTwo(c) -> (ADDshiftLL a x [log2(c)])
-(MADDW a (MOVDconst [c]) x) && isPowerOfTwo(c-1) && int32(c)>=3 -> (ADD a (ADDshiftLL <x.Type> x x [log2(c-1)]))
-(MADDW a (MOVDconst [c]) x) && isPowerOfTwo(c+1) && int32(c)>=7 -> (SUB a (SUBshiftLL <x.Type> x x [log2(c+1)]))
-(MADDW a (MOVDconst [c]) x) && c%3 == 0 && isPowerOfTwo(c/3) && is32Bit(c) -> (SUBshiftLL a (SUBshiftLL <x.Type> x x [2]) [log2(c/3)])
-(MADDW a (MOVDconst [c]) x) && c%5 == 0 && isPowerOfTwo(c/5) && is32Bit(c) -> (ADDshiftLL a (ADDshiftLL <x.Type> x x [2]) [log2(c/5)])
-(MADDW a (MOVDconst [c]) x) && c%7 == 0 && isPowerOfTwo(c/7) && is32Bit(c) -> (SUBshiftLL a (SUBshiftLL <x.Type> x x [3]) [log2(c/7)])
-(MADDW a (MOVDconst [c]) x) && c%9 == 0 && isPowerOfTwo(c/9) && is32Bit(c) -> (ADDshiftLL a (ADDshiftLL <x.Type> x x [3]) [log2(c/9)])
-
-(MSUB a x (MOVDconst [-1])) -> (ADD a x)
-(MSUB a _ (MOVDconst [0])) -> a
-(MSUB a x (MOVDconst [1])) -> (SUB a x)
-(MSUB a x (MOVDconst [c])) && isPowerOfTwo(c) -> (SUBshiftLL a x [log2(c)])
-(MSUB a x (MOVDconst [c])) && isPowerOfTwo(c-1) && c>=3 -> (SUB a (ADDshiftLL <x.Type> x x [log2(c-1)]))
-(MSUB a x (MOVDconst [c])) && isPowerOfTwo(c+1) && c>=7 -> (ADD a (SUBshiftLL <x.Type> x x [log2(c+1)]))
-(MSUB a x (MOVDconst [c])) && c%3 == 0 && isPowerOfTwo(c/3) -> (ADDshiftLL a (SUBshiftLL <x.Type> x x [2]) [log2(c/3)])
-(MSUB a x (MOVDconst [c])) && c%5 == 0 && isPowerOfTwo(c/5) -> (SUBshiftLL a (ADDshiftLL <x.Type> x x [2]) [log2(c/5)])
-(MSUB a x (MOVDconst [c])) && c%7 == 0 && isPowerOfTwo(c/7) -> (ADDshiftLL a (SUBshiftLL <x.Type> x x [3]) [log2(c/7)])
-(MSUB a x (MOVDconst [c])) && c%9 == 0 && isPowerOfTwo(c/9) -> (SUBshiftLL a (ADDshiftLL <x.Type> x x [3]) [log2(c/9)])
-
-(MSUB a (MOVDconst [-1]) x) -> (ADD a x)
-(MSUB a (MOVDconst [0]) _) -> a
-(MSUB a (MOVDconst [1]) x) -> (SUB a x)
-(MSUB a (MOVDconst [c]) x) && isPowerOfTwo(c) -> (SUBshiftLL a x [log2(c)])
-(MSUB a (MOVDconst [c]) x) && isPowerOfTwo(c-1) && c>=3 -> (SUB a (ADDshiftLL <x.Type> x x [log2(c-1)]))
-(MSUB a (MOVDconst [c]) x) && isPowerOfTwo(c+1) && c>=7 -> (ADD a (SUBshiftLL <x.Type> x x [log2(c+1)]))
-(MSUB a (MOVDconst [c]) x) && c%3 == 0 && isPowerOfTwo(c/3) -> (ADDshiftLL a (SUBshiftLL <x.Type> x x [2]) [log2(c/3)])
-(MSUB a (MOVDconst [c]) x) && c%5 == 0 && isPowerOfTwo(c/5) -> (SUBshiftLL a (ADDshiftLL <x.Type> x x [2]) [log2(c/5)])
-(MSUB a (MOVDconst [c]) x) && c%7 == 0 && isPowerOfTwo(c/7) -> (ADDshiftLL a (SUBshiftLL <x.Type> x x [3]) [log2(c/7)])
-(MSUB a (MOVDconst [c]) x) && c%9 == 0 && isPowerOfTwo(c/9) -> (SUBshiftLL a (ADDshiftLL <x.Type> x x [3]) [log2(c/9)])
-
-(MSUBW a x (MOVDconst [c])) && int32(c)==-1 -> (ADD a x)
-(MSUBW a _ (MOVDconst [c])) && int32(c)==0 -> a
-(MSUBW a x (MOVDconst [c])) && int32(c)==1 -> (SUB a x)
-(MSUBW a x (MOVDconst [c])) && isPowerOfTwo(c) -> (SUBshiftLL a x [log2(c)])
-(MSUBW a x (MOVDconst [c])) && isPowerOfTwo(c-1) && int32(c)>=3 -> (SUB a (ADDshiftLL <x.Type> x x [log2(c-1)]))
-(MSUBW a x (MOVDconst [c])) && isPowerOfTwo(c+1) && int32(c)>=7 -> (ADD a (SUBshiftLL <x.Type> x x [log2(c+1)]))
-(MSUBW a x (MOVDconst [c])) && c%3 == 0 && isPowerOfTwo(c/3) && is32Bit(c) -> (ADDshiftLL a (SUBshiftLL <x.Type> x x [2]) [log2(c/3)])
-(MSUBW a x (MOVDconst [c])) && c%5 == 0 && isPowerOfTwo(c/5) && is32Bit(c) -> (SUBshiftLL a (ADDshiftLL <x.Type> x x [2]) [log2(c/5)])
-(MSUBW a x (MOVDconst [c])) && c%7 == 0 && isPowerOfTwo(c/7) && is32Bit(c) -> (ADDshiftLL a (SUBshiftLL <x.Type> x x [3]) [log2(c/7)])
-(MSUBW a x (MOVDconst [c])) && c%9 == 0 && isPowerOfTwo(c/9) && is32Bit(c) -> (SUBshiftLL a (ADDshiftLL <x.Type> x x [3]) [log2(c/9)])
-
-(MSUBW a (MOVDconst [c]) x) && int32(c)==-1 -> (ADD a x)
-(MSUBW a (MOVDconst [c]) _) && int32(c)==0 -> a
-(MSUBW a (MOVDconst [c]) x) && int32(c)==1 -> (SUB a x)
-(MSUBW a (MOVDconst [c]) x) && isPowerOfTwo(c) -> (SUBshiftLL a x [log2(c)])
-(MSUBW a (MOVDconst [c]) x) && isPowerOfTwo(c-1) && int32(c)>=3 -> (SUB a (ADDshiftLL <x.Type> x x [log2(c-1)]))
-(MSUBW a (MOVDconst [c]) x) && isPowerOfTwo(c+1) && int32(c)>=7 -> (ADD a (SUBshiftLL <x.Type> x x [log2(c+1)]))
-(MSUBW a (MOVDconst [c]) x) && c%3 == 0 && isPowerOfTwo(c/3) && is32Bit(c) -> (ADDshiftLL a (SUBshiftLL <x.Type> x x [2]) [log2(c/3)])
-(MSUBW a (MOVDconst [c]) x) && c%5 == 0 && isPowerOfTwo(c/5) && is32Bit(c) -> (SUBshiftLL a (ADDshiftLL <x.Type> x x [2]) [log2(c/5)])
-(MSUBW a (MOVDconst [c]) x) && c%7 == 0 && isPowerOfTwo(c/7) && is32Bit(c) -> (ADDshiftLL a (SUBshiftLL <x.Type> x x [3]) [log2(c/7)])
-(MSUBW a (MOVDconst [c]) x) && c%9 == 0 && isPowerOfTwo(c/9) && is32Bit(c) -> (SUBshiftLL a (ADDshiftLL <x.Type> x x [3]) [log2(c/9)])
+(MNEG x (MOVDconst [-1])) => x
+(MNEG _ (MOVDconst [0])) => (MOVDconst [0])
+(MNEG x (MOVDconst [1])) => (NEG x)
+(MNEG x (MOVDconst [c])) && isPowerOfTwo(c) => (NEG (SLLconst <x.Type> [log2(c)] x))
+(MNEG x (MOVDconst [c])) && isPowerOfTwo(c-1) && c >= 3 => (NEG (ADDshiftLL <x.Type> x x [log2(c-1)]))
+(MNEG x (MOVDconst [c])) && isPowerOfTwo(c+1) && c >= 7 => (NEG (ADDshiftLL <x.Type> (NEG <x.Type> x) x [log2(c+1)]))
+(MNEG x (MOVDconst [c])) && c%3 == 0 && isPowerOfTwo(c/3) => (SLLconst <x.Type> [log2(c/3)] (SUBshiftLL <x.Type> x x [2]))
+(MNEG x (MOVDconst [c])) && c%5 == 0 && isPowerOfTwo(c/5) => (NEG (SLLconst <x.Type> [log2(c/5)] (ADDshiftLL <x.Type> x x [2])))
+(MNEG x (MOVDconst [c])) && c%7 == 0 && isPowerOfTwo(c/7) => (SLLconst <x.Type> [log2(c/7)] (SUBshiftLL <x.Type> x x [3]))
+(MNEG x (MOVDconst [c])) && c%9 == 0 && isPowerOfTwo(c/9) => (NEG (SLLconst <x.Type> [log2(c/9)] (ADDshiftLL <x.Type> x x [3])))
+
+(MNEGW x (MOVDconst [c])) && int32(c)==-1 => x
+(MNEGW _ (MOVDconst [c])) && int32(c)==0 => (MOVDconst [0])
+(MNEGW x (MOVDconst [c])) && int32(c)==1 => (NEG x)
+(MNEGW x (MOVDconst [c])) && isPowerOfTwo(c) => (NEG (SLLconst <x.Type> [log2(c)] x))
+(MNEGW x (MOVDconst [c])) && isPowerOfTwo(c-1) && int32(c) >= 3 => (NEG (ADDshiftLL <x.Type> x x [log2(c-1)]))
+(MNEGW x (MOVDconst [c])) && isPowerOfTwo(c+1) && int32(c) >= 7 => (NEG (ADDshiftLL <x.Type> (NEG <x.Type> x) x [log2(c+1)]))
+(MNEGW x (MOVDconst [c])) && c%3 == 0 && isPowerOfTwo(c/3) && is32Bit(c) => (SLLconst <x.Type> [log2(c/3)] (SUBshiftLL <x.Type> x x [2]))
+(MNEGW x (MOVDconst [c])) && c%5 == 0 && isPowerOfTwo(c/5) && is32Bit(c) => (NEG (SLLconst <x.Type> [log2(c/5)] (ADDshiftLL <x.Type> x x [2])))
+(MNEGW x (MOVDconst [c])) && c%7 == 0 && isPowerOfTwo(c/7) && is32Bit(c) => (SLLconst <x.Type> [log2(c/7)] (SUBshiftLL <x.Type> x x [3]))
+(MNEGW x (MOVDconst [c])) && c%9 == 0 && isPowerOfTwo(c/9) && is32Bit(c) => (NEG (SLLconst <x.Type> [log2(c/9)] (ADDshiftLL <x.Type> x x [3])))
+
+(MADD a x (MOVDconst [-1])) => (SUB a x)
+(MADD a _ (MOVDconst [0])) => a
+(MADD a x (MOVDconst [1])) => (ADD a x)
+(MADD a x (MOVDconst [c])) && isPowerOfTwo(c) => (ADDshiftLL a x [log2(c)])
+(MADD a x (MOVDconst [c])) && isPowerOfTwo(c-1) && c>=3 => (ADD a (ADDshiftLL <x.Type> x x [log2(c-1)]))
+(MADD a x (MOVDconst [c])) && isPowerOfTwo(c+1) && c>=7 => (SUB a (SUBshiftLL <x.Type> x x [log2(c+1)]))
+(MADD a x (MOVDconst [c])) && c%3 == 0 && isPowerOfTwo(c/3) => (SUBshiftLL a (SUBshiftLL <x.Type> x x [2]) [log2(c/3)])
+(MADD a x (MOVDconst [c])) && c%5 == 0 && isPowerOfTwo(c/5) => (ADDshiftLL a (ADDshiftLL <x.Type> x x [2]) [log2(c/5)])
+(MADD a x (MOVDconst [c])) && c%7 == 0 && isPowerOfTwo(c/7) => (SUBshiftLL a (SUBshiftLL <x.Type> x x [3]) [log2(c/7)])
+(MADD a x (MOVDconst [c])) && c%9 == 0 && isPowerOfTwo(c/9) => (ADDshiftLL a (ADDshiftLL <x.Type> x x [3]) [log2(c/9)])
+
+(MADD a (MOVDconst [-1]) x) => (SUB a x)
+(MADD a (MOVDconst [0]) _) => a
+(MADD a (MOVDconst [1]) x) => (ADD a x)
+(MADD a (MOVDconst [c]) x) && isPowerOfTwo(c) => (ADDshiftLL a x [log2(c)])
+(MADD a (MOVDconst [c]) x) && isPowerOfTwo(c-1) && c>=3 => (ADD a (ADDshiftLL <x.Type> x x [log2(c-1)]))
+(MADD a (MOVDconst [c]) x) && isPowerOfTwo(c+1) && c>=7 => (SUB a (SUBshiftLL <x.Type> x x [log2(c+1)]))
+(MADD a (MOVDconst [c]) x) && c%3 == 0 && isPowerOfTwo(c/3) => (SUBshiftLL a (SUBshiftLL <x.Type> x x [2]) [log2(c/3)])
+(MADD a (MOVDconst [c]) x) && c%5 == 0 && isPowerOfTwo(c/5) => (ADDshiftLL a (ADDshiftLL <x.Type> x x [2]) [log2(c/5)])
+(MADD a (MOVDconst [c]) x) && c%7 == 0 && isPowerOfTwo(c/7) => (SUBshiftLL a (SUBshiftLL <x.Type> x x [3]) [log2(c/7)])
+(MADD a (MOVDconst [c]) x) && c%9 == 0 && isPowerOfTwo(c/9) => (ADDshiftLL a (ADDshiftLL <x.Type> x x [3]) [log2(c/9)])
+
+(MADDW a x (MOVDconst [c])) && int32(c)==-1 => (SUB a x)
+(MADDW a _ (MOVDconst [c])) && int32(c)==0 => a
+(MADDW a x (MOVDconst [c])) && int32(c)==1 => (ADD a x)
+(MADDW a x (MOVDconst [c])) && isPowerOfTwo(c) => (ADDshiftLL a x [log2(c)])
+(MADDW a x (MOVDconst [c])) && isPowerOfTwo(c-1) && int32(c)>=3 => (ADD a (ADDshiftLL <x.Type> x x [log2(c-1)]))
+(MADDW a x (MOVDconst [c])) && isPowerOfTwo(c+1) && int32(c)>=7 => (SUB a (SUBshiftLL <x.Type> x x [log2(c+1)]))
+(MADDW a x (MOVDconst [c])) && c%3 == 0 && isPowerOfTwo(c/3) && is32Bit(c) => (SUBshiftLL a (SUBshiftLL <x.Type> x x [2]) [log2(c/3)])
+(MADDW a x (MOVDconst [c])) && c%5 == 0 && isPowerOfTwo(c/5) && is32Bit(c) => (ADDshiftLL a (ADDshiftLL <x.Type> x x [2]) [log2(c/5)])
+(MADDW a x (MOVDconst [c])) && c%7 == 0 && isPowerOfTwo(c/7) && is32Bit(c) => (SUBshiftLL a (SUBshiftLL <x.Type> x x [3]) [log2(c/7)])
+(MADDW a x (MOVDconst [c])) && c%9 == 0 && isPowerOfTwo(c/9) && is32Bit(c) => (ADDshiftLL a (ADDshiftLL <x.Type> x x [3]) [log2(c/9)])
+
+(MADDW a (MOVDconst [c]) x) && int32(c)==-1 => (SUB a x)
+(MADDW a (MOVDconst [c]) _) && int32(c)==0 => a
+(MADDW a (MOVDconst [c]) x) && int32(c)==1 => (ADD a x)
+(MADDW a (MOVDconst [c]) x) && isPowerOfTwo(c) => (ADDshiftLL a x [log2(c)])
+(MADDW a (MOVDconst [c]) x) && isPowerOfTwo(c-1) && int32(c)>=3 => (ADD a (ADDshiftLL <x.Type> x x [log2(c-1)]))
+(MADDW a (MOVDconst [c]) x) && isPowerOfTwo(c+1) && int32(c)>=7 => (SUB a (SUBshiftLL <x.Type> x x [log2(c+1)]))
+(MADDW a (MOVDconst [c]) x) && c%3 == 0 && isPowerOfTwo(c/3) && is32Bit(c) => (SUBshiftLL a (SUBshiftLL <x.Type> x x [2]) [log2(c/3)])
+(MADDW a (MOVDconst [c]) x) && c%5 == 0 && isPowerOfTwo(c/5) && is32Bit(c) => (ADDshiftLL a (ADDshiftLL <x.Type> x x [2]) [log2(c/5)])
+(MADDW a (MOVDconst [c]) x) && c%7 == 0 && isPowerOfTwo(c/7) && is32Bit(c) => (SUBshiftLL a (SUBshiftLL <x.Type> x x [3]) [log2(c/7)])
+(MADDW a (MOVDconst [c]) x) && c%9 == 0 && isPowerOfTwo(c/9) && is32Bit(c) => (ADDshiftLL a (ADDshiftLL <x.Type> x x [3]) [log2(c/9)])
+
+(MSUB a x (MOVDconst [-1])) => (ADD a x)
+(MSUB a _ (MOVDconst [0])) => a
+(MSUB a x (MOVDconst [1])) => (SUB a x)
+(MSUB a x (MOVDconst [c])) && isPowerOfTwo(c) => (SUBshiftLL a x [log2(c)])
+(MSUB a x (MOVDconst [c])) && isPowerOfTwo(c-1) && c>=3 => (SUB a (ADDshiftLL <x.Type> x x [log2(c-1)]))
+(MSUB a x (MOVDconst [c])) && isPowerOfTwo(c+1) && c>=7 => (ADD a (SUBshiftLL <x.Type> x x [log2(c+1)]))
+(MSUB a x (MOVDconst [c])) && c%3 == 0 && isPowerOfTwo(c/3) => (ADDshiftLL a (SUBshiftLL <x.Type> x x [2]) [log2(c/3)])
+(MSUB a x (MOVDconst [c])) && c%5 == 0 && isPowerOfTwo(c/5) => (SUBshiftLL a (ADDshiftLL <x.Type> x x [2]) [log2(c/5)])
+(MSUB a x (MOVDconst [c])) && c%7 == 0 && isPowerOfTwo(c/7) => (ADDshiftLL a (SUBshiftLL <x.Type> x x [3]) [log2(c/7)])
+(MSUB a x (MOVDconst [c])) && c%9 == 0 && isPowerOfTwo(c/9) => (SUBshiftLL a (ADDshiftLL <x.Type> x x [3]) [log2(c/9)])
+
+(MSUB a (MOVDconst [-1]) x) => (ADD a x)
+(MSUB a (MOVDconst [0]) _) => a
+(MSUB a (MOVDconst [1]) x) => (SUB a x)
+(MSUB a (MOVDconst [c]) x) && isPowerOfTwo(c) => (SUBshiftLL a x [log2(c)])
+(MSUB a (MOVDconst [c]) x) && isPowerOfTwo(c-1) && c>=3 => (SUB a (ADDshiftLL <x.Type> x x [log2(c-1)]))
+(MSUB a (MOVDconst [c]) x) && isPowerOfTwo(c+1) && c>=7 => (ADD a (SUBshiftLL <x.Type> x x [log2(c+1)]))
+(MSUB a (MOVDconst [c]) x) && c%3 == 0 && isPowerOfTwo(c/3) => (ADDshiftLL a (SUBshiftLL <x.Type> x x [2]) [log2(c/3)])
+(MSUB a (MOVDconst [c]) x) && c%5 == 0 && isPowerOfTwo(c/5) => (SUBshiftLL a (ADDshiftLL <x.Type> x x [2]) [log2(c/5)])
+(MSUB a (MOVDconst [c]) x) && c%7 == 0 && isPowerOfTwo(c/7) => (ADDshiftLL a (SUBshiftLL <x.Type> x x [3]) [log2(c/7)])
+(MSUB a (MOVDconst [c]) x) && c%9 == 0 && isPowerOfTwo(c/9) => (SUBshiftLL a (ADDshiftLL <x.Type> x x [3]) [log2(c/9)])
+
+(MSUBW a x (MOVDconst [c])) && int32(c)==-1 => (ADD a x)
+(MSUBW a _ (MOVDconst [c])) && int32(c)==0 => a
+(MSUBW a x (MOVDconst [c])) && int32(c)==1 => (SUB a x)
+(MSUBW a x (MOVDconst [c])) && isPowerOfTwo(c) => (SUBshiftLL a x [log2(c)])
+(MSUBW a x (MOVDconst [c])) && isPowerOfTwo(c-1) && int32(c)>=3 => (SUB a (ADDshiftLL <x.Type> x x [log2(c-1)]))
+(MSUBW a x (MOVDconst [c])) && isPowerOfTwo(c+1) && int32(c)>=7 => (ADD a (SUBshiftLL <x.Type> x x [log2(c+1)]))
+(MSUBW a x (MOVDconst [c])) && c%3 == 0 && isPowerOfTwo(c/3) && is32Bit(c) => (ADDshiftLL a (SUBshiftLL <x.Type> x x [2]) [log2(c/3)])
+(MSUBW a x (MOVDconst [c])) && c%5 == 0 && isPowerOfTwo(c/5) && is32Bit(c) => (SUBshiftLL a (ADDshiftLL <x.Type> x x [2]) [log2(c/5)])
+(MSUBW a x (MOVDconst [c])) && c%7 == 0 && isPowerOfTwo(c/7) && is32Bit(c) => (ADDshiftLL a (SUBshiftLL <x.Type> x x [3]) [log2(c/7)])
+(MSUBW a x (MOVDconst [c])) && c%9 == 0 && isPowerOfTwo(c/9) && is32Bit(c) => (SUBshiftLL a (ADDshiftLL <x.Type> x x [3]) [log2(c/9)])
+
+(MSUBW a (MOVDconst [c]) x) && int32(c)==-1 => (ADD a x)
+(MSUBW a (MOVDconst [c]) _) && int32(c)==0 => a
+(MSUBW a (MOVDconst [c]) x) && int32(c)==1 => (SUB a x)
+(MSUBW a (MOVDconst [c]) x) && isPowerOfTwo(c) => (SUBshiftLL a x [log2(c)])
+(MSUBW a (MOVDconst [c]) x) && isPowerOfTwo(c-1) && int32(c)>=3 => (SUB a (ADDshiftLL <x.Type> x x [log2(c-1)]))
+(MSUBW a (MOVDconst [c]) x) && isPowerOfTwo(c+1) && int32(c)>=7 => (ADD a (SUBshiftLL <x.Type> x x [log2(c+1)]))
+(MSUBW a (MOVDconst [c]) x) && c%3 == 0 && isPowerOfTwo(c/3) && is32Bit(c) => (ADDshiftLL a (SUBshiftLL <x.Type> x x [2]) [log2(c/3)])
+(MSUBW a (MOVDconst [c]) x) && c%5 == 0 && isPowerOfTwo(c/5) && is32Bit(c) => (SUBshiftLL a (ADDshiftLL <x.Type> x x [2]) [log2(c/5)])
+(MSUBW a (MOVDconst [c]) x) && c%7 == 0 && isPowerOfTwo(c/7) && is32Bit(c) => (ADDshiftLL a (SUBshiftLL <x.Type> x x [3]) [log2(c/7)])
+(MSUBW a (MOVDconst [c]) x) && c%9 == 0 && isPowerOfTwo(c/9) && is32Bit(c) => (SUBshiftLL a (ADDshiftLL <x.Type> x x [3]) [log2(c/9)])
 
 // div by constant
-(UDIV x (MOVDconst [1])) -> x
-(UDIV x (MOVDconst [c])) && isPowerOfTwo(c) -> (SRLconst [log2(c)] x)
-(UDIVW x (MOVDconst [c])) && uint32(c)==1 -> x
-(UDIVW x (MOVDconst [c])) && isPowerOfTwo(c) && is32Bit(c) -> (SRLconst [log2(c)] x)
-(UMOD _ (MOVDconst [1])) -> (MOVDconst [0])
-(UMOD x (MOVDconst [c])) && isPowerOfTwo(c) -> (ANDconst [c-1] x)
-(UMODW _ (MOVDconst [c])) && uint32(c)==1 -> (MOVDconst [0])
-(UMODW x (MOVDconst [c])) && isPowerOfTwo(c) && is32Bit(c) -> (ANDconst [c-1] x)
+(UDIV x (MOVDconst [1])) => x
+(UDIV x (MOVDconst [c])) && isPowerOfTwo(c) => (SRLconst [log2(c)] x)
+(UDIVW x (MOVDconst [c])) && uint32(c)==1 => x
+(UDIVW x (MOVDconst [c])) && isPowerOfTwo(c) && is32Bit(c) => (SRLconst [log2(c)] x)
+(UMOD _ (MOVDconst [1])) => (MOVDconst [0])
+(UMOD x (MOVDconst [c])) && isPowerOfTwo(c) => (ANDconst [c-1] x)
+(UMODW _ (MOVDconst [c])) && uint32(c)==1 => (MOVDconst [0])
+(UMODW x (MOVDconst [c])) && isPowerOfTwo(c) && is32Bit(c) => (ANDconst [c-1] x)
 
 // generic simplifications
-(ADD x (NEG y)) -> (SUB x y)
-(SUB x x) -> (MOVDconst [0])
-(AND x x) -> x
-(OR  x x) -> x
-(XOR x x) -> (MOVDconst [0])
-(BIC x x) -> (MOVDconst [0])
-(EON x x) -> (MOVDconst [-1])
-(ORN x x) -> (MOVDconst [-1])
-(AND x (MVN y)) -> (BIC x y)
-(XOR x (MVN y)) -> (EON x y)
-(OR  x (MVN y)) -> (ORN x y)
-(MVN (XOR x y)) -> (EON x y)
+(ADD x (NEG y)) => (SUB x y)
+(SUB x x) => (MOVDconst [0])
+(AND x x) => x
+(OR  x x) => x
+(XOR x x) => (MOVDconst [0])
+(BIC x x) => (MOVDconst [0])
+(EON x x) => (MOVDconst [-1])
+(ORN x x) => (MOVDconst [-1])
+(AND x (MVN y)) => (BIC x y)
+(XOR x (MVN y)) => (EON x y)
+(OR  x (MVN y)) => (ORN x y)
+(MVN (XOR x y)) => (EON x y)
 (CSEL [cc] x (MOVDconst [0]) flag) => (CSEL0 [cc] x flag)
 (CSEL [cc] (MOVDconst [0]) y flag) => (CSEL0 [arm64Negate(cc)] y flag)
-(SUB x (SUB y z)) -> (SUB (ADD <v.Type> x z) y)
-(SUB (SUB x y) z) -> (SUB x (ADD <y.Type> y z))
+(SUB x (SUB y z)) => (SUB (ADD <v.Type> x z) y)
+(SUB (SUB x y) z) => (SUB x (ADD <y.Type> y z))
 
 // remove redundant *const ops
-(ADDconst [0]  x) -> x
-(SUBconst [0]  x) -> x
-(ANDconst [0]  _) -> (MOVDconst [0])
-(ANDconst [-1] x) -> x
-(ORconst  [0]  x) -> x
-(ORconst  [-1] _) -> (MOVDconst [-1])
-(XORconst [0]  x) -> x
-(XORconst [-1] x) -> (MVN x)
+(ADDconst [0]  x) => x
+(SUBconst [0]  x) => x
+(ANDconst [0]  _) => (MOVDconst [0])
+(ANDconst [-1] x) => x
+(ORconst  [0]  x) => x
+(ORconst  [-1] _) => (MOVDconst [-1])
+(XORconst [0]  x) => x
+(XORconst [-1] x) => (MVN x)
 
 // generic constant folding
-(ADDconst [c] (MOVDconst [d]))  -> (MOVDconst [c+d])
-(ADDconst [c] (ADDconst [d] x)) -> (ADDconst [c+d] x)
-(ADDconst [c] (SUBconst [d] x)) -> (ADDconst [c-d] x)
-(SUBconst [c] (MOVDconst [d]))  -> (MOVDconst [d-c])
-(SUBconst [c] (SUBconst [d] x)) -> (ADDconst [-c-d] x)
-(SUBconst [c] (ADDconst [d] x)) -> (ADDconst [-c+d] x)
-(SLLconst [c] (MOVDconst [d]))  -> (MOVDconst [d<<uint64(c)])
-(SRLconst [c] (MOVDconst [d]))  -> (MOVDconst [int64(uint64(d)>>uint64(c))])
-(SRAconst [c] (MOVDconst [d]))  -> (MOVDconst [d>>uint64(c)])
-(MUL   (MOVDconst [c]) (MOVDconst [d])) -> (MOVDconst [c*d])
-(MULW  (MOVDconst [c]) (MOVDconst [d])) -> (MOVDconst [int64(int32(c)*int32(d))])
-(MNEG  (MOVDconst [c]) (MOVDconst [d])) -> (MOVDconst [-c*d])
-(MNEGW (MOVDconst [c]) (MOVDconst [d])) -> (MOVDconst [-int64(int32(c)*int32(d))])
-(MADD  (MOVDconst [c]) x y) -> (ADDconst [c] (MUL   <x.Type> x y))
-(MADDW (MOVDconst [c]) x y) -> (ADDconst [c] (MULW  <x.Type> x y))
-(MSUB  (MOVDconst [c]) x y) -> (ADDconst [c] (MNEG  <x.Type> x y))
-(MSUBW (MOVDconst [c]) x y) -> (ADDconst [c] (MNEGW <x.Type> x y))
-(MADD  a (MOVDconst [c]) (MOVDconst [d])) -> (ADDconst [c*d] a)
-(MADDW a (MOVDconst [c]) (MOVDconst [d])) -> (ADDconst [int64(int32(c)*int32(d))] a)
-(MSUB  a (MOVDconst [c]) (MOVDconst [d])) -> (SUBconst [c*d] a)
-(MSUBW a (MOVDconst [c]) (MOVDconst [d])) -> (SUBconst [int64(int32(c)*int32(d))] a)
-(DIV   (MOVDconst [c]) (MOVDconst [d])) -> (MOVDconst [c/d])
-(UDIV  (MOVDconst [c]) (MOVDconst [d])) -> (MOVDconst [int64(uint64(c)/uint64(d))])
-(DIVW  (MOVDconst [c]) (MOVDconst [d])) -> (MOVDconst [int64(int32(c)/int32(d))])
-(UDIVW (MOVDconst [c]) (MOVDconst [d])) -> (MOVDconst [int64(uint32(c)/uint32(d))])
-(MOD   (MOVDconst [c]) (MOVDconst [d])) -> (MOVDconst [c%d])
-(UMOD  (MOVDconst [c]) (MOVDconst [d])) -> (MOVDconst [int64(uint64(c)%uint64(d))])
-(MODW  (MOVDconst [c]) (MOVDconst [d])) -> (MOVDconst [int64(int32(c)%int32(d))])
-(UMODW (MOVDconst [c]) (MOVDconst [d])) -> (MOVDconst [int64(uint32(c)%uint32(d))])
-(ANDconst [c] (MOVDconst [d]))  -> (MOVDconst [c&d])
-(ANDconst [c] (ANDconst [d] x)) -> (ANDconst [c&d] x)
-(ANDconst [c] (MOVWUreg x)) -> (ANDconst [c&(1<<32-1)] x)
-(ANDconst [c] (MOVHUreg x)) -> (ANDconst [c&(1<<16-1)] x)
-(ANDconst [c] (MOVBUreg x)) -> (ANDconst [c&(1<<8-1)] x)
-(MOVWUreg (ANDconst [c] x)) -> (ANDconst [c&(1<<32-1)] x)
-(MOVHUreg (ANDconst [c] x)) -> (ANDconst [c&(1<<16-1)] x)
-(MOVBUreg (ANDconst [c] x)) -> (ANDconst [c&(1<<8-1)] x)
-(ORconst  [c] (MOVDconst [d]))  -> (MOVDconst [c|d])
-(ORconst  [c] (ORconst [d] x))  -> (ORconst [c|d] x)
-(XORconst [c] (MOVDconst [d]))  -> (MOVDconst [c^d])
-(XORconst [c] (XORconst [d] x)) -> (XORconst [c^d] x)
-(MVN (MOVDconst [c])) -> (MOVDconst [^c])
-(NEG (MOVDconst [c])) -> (MOVDconst [-c])
-(MOVBreg  (MOVDconst [c])) -> (MOVDconst [int64(int8(c))])
-(MOVBUreg (MOVDconst [c])) -> (MOVDconst [int64(uint8(c))])
-(MOVHreg  (MOVDconst [c])) -> (MOVDconst [int64(int16(c))])
-(MOVHUreg (MOVDconst [c])) -> (MOVDconst [int64(uint16(c))])
-(MOVWreg  (MOVDconst [c])) -> (MOVDconst [int64(int32(c))])
-(MOVWUreg (MOVDconst [c])) -> (MOVDconst [int64(uint32(c))])
-(MOVDreg  (MOVDconst [c])) -> (MOVDconst [c])
+(ADDconst [c] (MOVDconst [d]))  => (MOVDconst [c+d])
+(ADDconst [c] (ADDconst [d] x)) => (ADDconst [c+d] x)
+(ADDconst [c] (SUBconst [d] x)) => (ADDconst [c-d] x)
+(SUBconst [c] (MOVDconst [d]))  => (MOVDconst [d-c])
+(SUBconst [c] (SUBconst [d] x)) => (ADDconst [-c-d] x)
+(SUBconst [c] (ADDconst [d] x)) => (ADDconst [-c+d] x)
+(SLLconst [c] (MOVDconst [d]))  => (MOVDconst [d<<uint64(c)])
+(SRLconst [c] (MOVDconst [d]))  => (MOVDconst [int64(uint64(d)>>uint64(c))])
+(SRAconst [c] (MOVDconst [d]))  => (MOVDconst [d>>uint64(c)])
+(MUL   (MOVDconst [c]) (MOVDconst [d])) => (MOVDconst [c*d])
+(MULW  (MOVDconst [c]) (MOVDconst [d])) => (MOVDconst [int64(int32(c)*int32(d))])
+(MNEG  (MOVDconst [c]) (MOVDconst [d])) => (MOVDconst [-c*d])
+(MNEGW (MOVDconst [c]) (MOVDconst [d])) => (MOVDconst [-int64(int32(c)*int32(d))])
+(MADD  (MOVDconst [c]) x y) => (ADDconst [c] (MUL   <x.Type> x y))
+(MADDW (MOVDconst [c]) x y) => (ADDconst [c] (MULW  <x.Type> x y))
+(MSUB  (MOVDconst [c]) x y) => (ADDconst [c] (MNEG  <x.Type> x y))
+(MSUBW (MOVDconst [c]) x y) => (ADDconst [c] (MNEGW <x.Type> x y))
+(MADD  a (MOVDconst [c]) (MOVDconst [d])) => (ADDconst [c*d] a)
+(MADDW a (MOVDconst [c]) (MOVDconst [d])) => (ADDconst [int64(int32(c)*int32(d))] a)
+(MSUB  a (MOVDconst [c]) (MOVDconst [d])) => (SUBconst [c*d] a)
+(MSUBW a (MOVDconst [c]) (MOVDconst [d])) => (SUBconst [int64(int32(c)*int32(d))] a)
+(DIV   (MOVDconst [c]) (MOVDconst [d])) => (MOVDconst [c/d])
+(UDIV  (MOVDconst [c]) (MOVDconst [d])) => (MOVDconst [int64(uint64(c)/uint64(d))])
+(DIVW  (MOVDconst [c]) (MOVDconst [d])) => (MOVDconst [int64(int32(c)/int32(d))])
+(UDIVW (MOVDconst [c]) (MOVDconst [d])) => (MOVDconst [int64(uint32(c)/uint32(d))])
+(MOD   (MOVDconst [c]) (MOVDconst [d])) => (MOVDconst [c%d])
+(UMOD  (MOVDconst [c]) (MOVDconst [d])) => (MOVDconst [int64(uint64(c)%uint64(d))])
+(MODW  (MOVDconst [c]) (MOVDconst [d])) => (MOVDconst [int64(int32(c)%int32(d))])
+(UMODW (MOVDconst [c]) (MOVDconst [d])) => (MOVDconst [int64(uint32(c)%uint32(d))])
+(ANDconst [c] (MOVDconst [d]))  => (MOVDconst [c&d])
+(ANDconst [c] (ANDconst [d] x)) => (ANDconst [c&d] x)
+(ANDconst [c] (MOVWUreg x)) => (ANDconst [c&(1<<32-1)] x)
+(ANDconst [c] (MOVHUreg x)) => (ANDconst [c&(1<<16-1)] x)
+(ANDconst [c] (MOVBUreg x)) => (ANDconst [c&(1<<8-1)] x)
+(MOVWUreg (ANDconst [c] x)) => (ANDconst [c&(1<<32-1)] x)
+(MOVHUreg (ANDconst [c] x)) => (ANDconst [c&(1<<16-1)] x)
+(MOVBUreg (ANDconst [c] x)) => (ANDconst [c&(1<<8-1)] x)
+(ORconst  [c] (MOVDconst [d]))  => (MOVDconst [c|d])
+(ORconst  [c] (ORconst [d] x))  => (ORconst [c|d] x)
+(XORconst [c] (MOVDconst [d]))  => (MOVDconst [c^d])
+(XORconst [c] (XORconst [d] x)) => (XORconst [c^d] x)
+(MVN (MOVDconst [c])) => (MOVDconst [^c])
+(NEG (MOVDconst [c])) => (MOVDconst [-c])
+(MOVBreg  (MOVDconst [c])) => (MOVDconst [int64(int8(c))])
+(MOVBUreg (MOVDconst [c])) => (MOVDconst [int64(uint8(c))])
+(MOVHreg  (MOVDconst [c])) => (MOVDconst [int64(int16(c))])
+(MOVHUreg (MOVDconst [c])) => (MOVDconst [int64(uint16(c))])
+(MOVWreg  (MOVDconst [c])) => (MOVDconst [int64(int32(c))])
+(MOVWUreg (MOVDconst [c])) => (MOVDconst [int64(uint32(c))])
+(MOVDreg  (MOVDconst [c])) => (MOVDconst [c])
 
 // constant comparisons
 (CMPconst  (MOVDconst [x]) [y]) => (FlagConstant [subFlags64(x,y)])
diff --git a/src/cmd/compile/internal/ssa/rewriteARM64.go b/src/cmd/compile/internal/ssa/rewriteARM64.go
index 0fb86b6bdd..6c48812121 100644
--- a/src/cmd/compile/internal/ssa/rewriteARM64.go
+++ b/src/cmd/compile/internal/ssa/rewriteARM64.go
@@ -1065,7 +1065,7 @@ func rewriteValueARM64_OpARM64ADCSflags(v *Value) bool {
 			break
 		}
 		v_2_0 := v_2.Args[0]
-		if v_2_0.Op != OpARM64ADDSconstflags || v_2_0.AuxInt != -1 {
+		if v_2_0.Op != OpARM64ADDSconstflags || auxIntToInt64(v_2_0.AuxInt) != -1 {
 			break
 		}
 		v_2_0_0 := v_2_0.Args[0]
@@ -1086,11 +1086,11 @@ func rewriteValueARM64_OpARM64ADCSflags(v *Value) bool {
 			break
 		}
 		v_2_0 := v_2.Args[0]
-		if v_2_0.Op != OpARM64ADDSconstflags || v_2_0.AuxInt != -1 {
+		if v_2_0.Op != OpARM64ADDSconstflags || auxIntToInt64(v_2_0.AuxInt) != -1 {
 			break
 		}
 		v_2_0_0 := v_2_0.Args[0]
-		if v_2_0_0.Op != OpARM64MOVDconst || v_2_0_0.AuxInt != 0 {
+		if v_2_0_0.Op != OpARM64MOVDconst || auxIntToInt64(v_2_0_0.AuxInt) != 0 {
 			break
 		}
 		v.reset(OpARM64ADDSflags)
@@ -1112,9 +1112,9 @@ func rewriteValueARM64_OpARM64ADD(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			v.reset(OpARM64ADDconst)
-			v.AuxInt = c
+			v.AuxInt = int64ToAuxInt(c)
 			v.AddArg(x)
 			return true
 		}
@@ -1593,7 +1593,7 @@ func rewriteValueARM64_OpARM64ADDconst(v *Value) bool {
 	// match: (ADDconst [0] x)
 	// result: x
 	for {
-		if v.AuxInt != 0 {
+		if auxIntToInt64(v.AuxInt) != 0 {
 			break
 		}
 		x := v_0
@@ -1603,40 +1603,40 @@ func rewriteValueARM64_OpARM64ADDconst(v *Value) bool {
 	// match: (ADDconst [c] (MOVDconst [d]))
 	// result: (MOVDconst [c+d])
 	for {
-		c := v.AuxInt
+		c := auxIntToInt64(v.AuxInt)
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_0.AuxInt
+		d := auxIntToInt64(v_0.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = c + d
+		v.AuxInt = int64ToAuxInt(c + d)
 		return true
 	}
 	// match: (ADDconst [c] (ADDconst [d] x))
 	// result: (ADDconst [c+d] x)
 	for {
-		c := v.AuxInt
+		c := auxIntToInt64(v.AuxInt)
 		if v_0.Op != OpARM64ADDconst {
 			break
 		}
-		d := v_0.AuxInt
+		d := auxIntToInt64(v_0.AuxInt)
 		x := v_0.Args[0]
 		v.reset(OpARM64ADDconst)
-		v.AuxInt = c + d
+		v.AuxInt = int64ToAuxInt(c + d)
 		v.AddArg(x)
 		return true
 	}
 	// match: (ADDconst [c] (SUBconst [d] x))
 	// result: (ADDconst [c-d] x)
 	for {
-		c := v.AuxInt
+		c := auxIntToInt64(v.AuxInt)
 		if v_0.Op != OpARM64SUBconst {
 			break
 		}
-		d := v_0.AuxInt
+		d := auxIntToInt64(v_0.AuxInt)
 		x := v_0.Args[0]
 		v.reset(OpARM64ADDconst)
-		v.AuxInt = c - d
+		v.AuxInt = int64ToAuxInt(c - d)
 		v.AddArg(x)
 		return true
 	}
@@ -1882,9 +1882,9 @@ func rewriteValueARM64_OpARM64AND(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			v.reset(OpARM64ANDconst)
-			v.AuxInt = c
+			v.AuxInt = int64ToAuxInt(c)
 			v.AddArg(x)
 			return true
 		}
@@ -1988,17 +1988,17 @@ func rewriteValueARM64_OpARM64ANDconst(v *Value) bool {
 	// match: (ANDconst [0] _)
 	// result: (MOVDconst [0])
 	for {
-		if v.AuxInt != 0 {
+		if auxIntToInt64(v.AuxInt) != 0 {
 			break
 		}
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = 0
+		v.AuxInt = int64ToAuxInt(0)
 		return true
 	}
 	// match: (ANDconst [-1] x)
 	// result: x
 	for {
-		if v.AuxInt != -1 {
+		if auxIntToInt64(v.AuxInt) != -1 {
 			break
 		}
 		x := v_0
@@ -2008,65 +2008,65 @@ func rewriteValueARM64_OpARM64ANDconst(v *Value) bool {
 	// match: (ANDconst [c] (MOVDconst [d]))
 	// result: (MOVDconst [c&d])
 	for {
-		c := v.AuxInt
+		c := auxIntToInt64(v.AuxInt)
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_0.AuxInt
+		d := auxIntToInt64(v_0.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = c & d
+		v.AuxInt = int64ToAuxInt(c & d)
 		return true
 	}
 	// match: (ANDconst [c] (ANDconst [d] x))
 	// result: (ANDconst [c&d] x)
 	for {
-		c := v.AuxInt
+		c := auxIntToInt64(v.AuxInt)
 		if v_0.Op != OpARM64ANDconst {
 			break
 		}
-		d := v_0.AuxInt
+		d := auxIntToInt64(v_0.AuxInt)
 		x := v_0.Args[0]
 		v.reset(OpARM64ANDconst)
-		v.AuxInt = c & d
+		v.AuxInt = int64ToAuxInt(c & d)
 		v.AddArg(x)
 		return true
 	}
 	// match: (ANDconst [c] (MOVWUreg x))
 	// result: (ANDconst [c&(1<<32-1)] x)
 	for {
-		c := v.AuxInt
+		c := auxIntToInt64(v.AuxInt)
 		if v_0.Op != OpARM64MOVWUreg {
 			break
 		}
 		x := v_0.Args[0]
 		v.reset(OpARM64ANDconst)
-		v.AuxInt = c & (1<<32 - 1)
+		v.AuxInt = int64ToAuxInt(c & (1<<32 - 1))
 		v.AddArg(x)
 		return true
 	}
 	// match: (ANDconst [c] (MOVHUreg x))
 	// result: (ANDconst [c&(1<<16-1)] x)
 	for {
-		c := v.AuxInt
+		c := auxIntToInt64(v.AuxInt)
 		if v_0.Op != OpARM64MOVHUreg {
 			break
 		}
 		x := v_0.Args[0]
 		v.reset(OpARM64ANDconst)
-		v.AuxInt = c & (1<<16 - 1)
+		v.AuxInt = int64ToAuxInt(c & (1<<16 - 1))
 		v.AddArg(x)
 		return true
 	}
 	// match: (ANDconst [c] (MOVBUreg x))
 	// result: (ANDconst [c&(1<<8-1)] x)
 	for {
-		c := v.AuxInt
+		c := auxIntToInt64(v.AuxInt)
 		if v_0.Op != OpARM64MOVBUreg {
 			break
 		}
 		x := v_0.Args[0]
 		v.reset(OpARM64ANDconst)
-		v.AuxInt = c & (1<<8 - 1)
+		v.AuxInt = int64ToAuxInt(c & (1<<8 - 1))
 		v.AddArg(x)
 		return true
 	}
@@ -2280,9 +2280,9 @@ func rewriteValueARM64_OpARM64BIC(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		v.reset(OpARM64ANDconst)
-		v.AuxInt = ^c
+		v.AuxInt = int64ToAuxInt(^c)
 		v.AddArg(x)
 		return true
 	}
@@ -2294,7 +2294,7 @@ func rewriteValueARM64_OpARM64BIC(v *Value) bool {
 			break
 		}
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = 0
+		v.AuxInt = int64ToAuxInt(0)
 		return true
 	}
 	// match: (BIC x0 x1:(SLLconst [c] y))
@@ -2475,9 +2475,9 @@ func rewriteValueARM64_OpARM64CMN(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			v.reset(OpARM64CMNconst)
-			v.AuxInt = c
+			v.AuxInt = int64ToAuxInt(c)
 			v.AddArg(x)
 			return true
 		}
@@ -2555,16 +2555,16 @@ func rewriteValueARM64_OpARM64CMNW(v *Value) bool {
 	v_1 := v.Args[1]
 	v_0 := v.Args[0]
 	// match: (CMNW x (MOVDconst [c]))
-	// result: (CMNWconst [c] x)
+	// result: (CMNWconst [int32(c)] x)
 	for {
 		for _i0 := 0; _i0 <= 1; _i0, v_0, v_1 = _i0+1, v_1, v_0 {
 			x := v_0
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			v.reset(OpARM64CMNWconst)
-			v.AuxInt = c
+			v.AuxInt = int32ToAuxInt(int32(c))
 			v.AddArg(x)
 			return true
 		}
@@ -2726,9 +2726,9 @@ func rewriteValueARM64_OpARM64CMP(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		v.reset(OpARM64CMPconst)
-		v.AuxInt = c
+		v.AuxInt = int64ToAuxInt(c)
 		v.AddArg(x)
 		return true
 	}
@@ -2738,11 +2738,11 @@ func rewriteValueARM64_OpARM64CMP(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		x := v_1
 		v.reset(OpARM64InvertFlags)
 		v0 := b.NewValue0(v.Pos, OpARM64CMPconst, types.TypeFlags)
-		v0.AuxInt = c
+		v0.AuxInt = int64ToAuxInt(c)
 		v0.AddArg(x)
 		v.AddArg(v0)
 		return true
@@ -3377,13 +3377,13 @@ func rewriteValueARM64_OpARM64DIV(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_1.AuxInt
+		d := auxIntToInt64(v_1.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = c / d
+		v.AuxInt = int64ToAuxInt(c / d)
 		return true
 	}
 	return false
@@ -3397,13 +3397,13 @@ func rewriteValueARM64_OpARM64DIVW(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_1.AuxInt
+		d := auxIntToInt64(v_1.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = int64(int32(c) / int32(d))
+		v.AuxInt = int64ToAuxInt(int64(int32(c) / int32(d)))
 		return true
 	}
 	return false
@@ -3418,9 +3418,9 @@ func rewriteValueARM64_OpARM64EON(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		v.reset(OpARM64XORconst)
-		v.AuxInt = ^c
+		v.AuxInt = int64ToAuxInt(^c)
 		v.AddArg(x)
 		return true
 	}
@@ -3432,7 +3432,7 @@ func rewriteValueARM64_OpARM64EON(v *Value) bool {
 			break
 		}
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = -1
+		v.AuxInt = int64ToAuxInt(-1)
 		return true
 	}
 	// match: (EON x0 x1:(SLLconst [c] y))
@@ -4858,7 +4858,7 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 	for {
 		a := v_0
 		x := v_1
-		if v_2.Op != OpARM64MOVDconst || v_2.AuxInt != -1 {
+		if v_2.Op != OpARM64MOVDconst || auxIntToInt64(v_2.AuxInt) != -1 {
 			break
 		}
 		v.reset(OpARM64SUB)
@@ -4869,7 +4869,7 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 	// result: a
 	for {
 		a := v_0
-		if v_2.Op != OpARM64MOVDconst || v_2.AuxInt != 0 {
+		if v_2.Op != OpARM64MOVDconst || auxIntToInt64(v_2.AuxInt) != 0 {
 			break
 		}
 		v.copyOf(a)
@@ -4880,7 +4880,7 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 	for {
 		a := v_0
 		x := v_1
-		if v_2.Op != OpARM64MOVDconst || v_2.AuxInt != 1 {
+		if v_2.Op != OpARM64MOVDconst || auxIntToInt64(v_2.AuxInt) != 1 {
 			break
 		}
 		v.reset(OpARM64ADD)
@@ -4896,12 +4896,12 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(isPowerOfTwo(c)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c)
+		v.AuxInt = int64ToAuxInt(log2(c))
 		v.AddArg2(a, x)
 		return true
 	}
@@ -4914,13 +4914,13 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(isPowerOfTwo(c-1) && c >= 3) {
 			break
 		}
 		v.reset(OpARM64ADD)
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = log2(c - 1)
+		v0.AuxInt = int64ToAuxInt(log2(c - 1))
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -4934,13 +4934,13 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(isPowerOfTwo(c+1) && c >= 7) {
 			break
 		}
 		v.reset(OpARM64SUB)
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = log2(c + 1)
+		v0.AuxInt = int64ToAuxInt(log2(c + 1))
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -4954,14 +4954,14 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(c%3 == 0 && isPowerOfTwo(c/3)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c / 3)
+		v.AuxInt = int64ToAuxInt(log2(c / 3))
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = 2
+		v0.AuxInt = int64ToAuxInt(2)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -4975,14 +4975,14 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(c%5 == 0 && isPowerOfTwo(c/5)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c / 5)
+		v.AuxInt = int64ToAuxInt(log2(c / 5))
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = 2
+		v0.AuxInt = int64ToAuxInt(2)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -4996,14 +4996,14 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(c%7 == 0 && isPowerOfTwo(c/7)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c / 7)
+		v.AuxInt = int64ToAuxInt(log2(c / 7))
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = 3
+		v0.AuxInt = int64ToAuxInt(3)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5017,14 +5017,14 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(c%9 == 0 && isPowerOfTwo(c/9)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c / 9)
+		v.AuxInt = int64ToAuxInt(log2(c / 9))
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = 3
+		v0.AuxInt = int64ToAuxInt(3)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5033,7 +5033,7 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 	// result: (SUB a x)
 	for {
 		a := v_0
-		if v_1.Op != OpARM64MOVDconst || v_1.AuxInt != -1 {
+		if v_1.Op != OpARM64MOVDconst || auxIntToInt64(v_1.AuxInt) != -1 {
 			break
 		}
 		x := v_2
@@ -5045,7 +5045,7 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 	// result: a
 	for {
 		a := v_0
-		if v_1.Op != OpARM64MOVDconst || v_1.AuxInt != 0 {
+		if v_1.Op != OpARM64MOVDconst || auxIntToInt64(v_1.AuxInt) != 0 {
 			break
 		}
 		v.copyOf(a)
@@ -5055,7 +5055,7 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 	// result: (ADD a x)
 	for {
 		a := v_0
-		if v_1.Op != OpARM64MOVDconst || v_1.AuxInt != 1 {
+		if v_1.Op != OpARM64MOVDconst || auxIntToInt64(v_1.AuxInt) != 1 {
 			break
 		}
 		x := v_2
@@ -5071,13 +5071,13 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(isPowerOfTwo(c)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c)
+		v.AuxInt = int64ToAuxInt(log2(c))
 		v.AddArg2(a, x)
 		return true
 	}
@@ -5089,14 +5089,14 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(isPowerOfTwo(c-1) && c >= 3) {
 			break
 		}
 		v.reset(OpARM64ADD)
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = log2(c - 1)
+		v0.AuxInt = int64ToAuxInt(log2(c - 1))
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5109,14 +5109,14 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(isPowerOfTwo(c+1) && c >= 7) {
 			break
 		}
 		v.reset(OpARM64SUB)
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = log2(c + 1)
+		v0.AuxInt = int64ToAuxInt(log2(c + 1))
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5129,15 +5129,15 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(c%3 == 0 && isPowerOfTwo(c/3)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c / 3)
+		v.AuxInt = int64ToAuxInt(log2(c / 3))
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = 2
+		v0.AuxInt = int64ToAuxInt(2)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5150,15 +5150,15 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(c%5 == 0 && isPowerOfTwo(c/5)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c / 5)
+		v.AuxInt = int64ToAuxInt(log2(c / 5))
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = 2
+		v0.AuxInt = int64ToAuxInt(2)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5171,15 +5171,15 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(c%7 == 0 && isPowerOfTwo(c/7)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c / 7)
+		v.AuxInt = int64ToAuxInt(log2(c / 7))
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = 3
+		v0.AuxInt = int64ToAuxInt(3)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5192,15 +5192,15 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(c%9 == 0 && isPowerOfTwo(c/9)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c / 9)
+		v.AuxInt = int64ToAuxInt(log2(c / 9))
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = 3
+		v0.AuxInt = int64ToAuxInt(3)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5211,11 +5211,11 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		x := v_1
 		y := v_2
 		v.reset(OpARM64ADDconst)
-		v.AuxInt = c
+		v.AuxInt = int64ToAuxInt(c)
 		v0 := b.NewValue0(v.Pos, OpARM64MUL, x.Type)
 		v0.AddArg2(x, y)
 		v.AddArg(v0)
@@ -5228,13 +5228,13 @@ func rewriteValueARM64_OpARM64MADD(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_2.AuxInt
+		d := auxIntToInt64(v_2.AuxInt)
 		v.reset(OpARM64ADDconst)
-		v.AuxInt = c * d
+		v.AuxInt = int64ToAuxInt(c * d)
 		v.AddArg(a)
 		return true
 	}
@@ -5254,7 +5254,7 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(int32(c) == -1) {
 			break
 		}
@@ -5270,7 +5270,7 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(int32(c) == 0) {
 			break
 		}
@@ -5286,7 +5286,7 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(int32(c) == 1) {
 			break
 		}
@@ -5303,12 +5303,12 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(isPowerOfTwo(c)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c)
+		v.AuxInt = int64ToAuxInt(log2(c))
 		v.AddArg2(a, x)
 		return true
 	}
@@ -5321,13 +5321,13 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(isPowerOfTwo(c-1) && int32(c) >= 3) {
 			break
 		}
 		v.reset(OpARM64ADD)
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = log2(c - 1)
+		v0.AuxInt = int64ToAuxInt(log2(c - 1))
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5341,13 +5341,13 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(isPowerOfTwo(c+1) && int32(c) >= 7) {
 			break
 		}
 		v.reset(OpARM64SUB)
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = log2(c + 1)
+		v0.AuxInt = int64ToAuxInt(log2(c + 1))
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5361,14 +5361,14 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(c%3 == 0 && isPowerOfTwo(c/3) && is32Bit(c)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c / 3)
+		v.AuxInt = int64ToAuxInt(log2(c / 3))
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = 2
+		v0.AuxInt = int64ToAuxInt(2)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5382,14 +5382,14 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(c%5 == 0 && isPowerOfTwo(c/5) && is32Bit(c)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c / 5)
+		v.AuxInt = int64ToAuxInt(log2(c / 5))
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = 2
+		v0.AuxInt = int64ToAuxInt(2)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5403,14 +5403,14 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(c%7 == 0 && isPowerOfTwo(c/7) && is32Bit(c)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c / 7)
+		v.AuxInt = int64ToAuxInt(log2(c / 7))
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = 3
+		v0.AuxInt = int64ToAuxInt(3)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5424,14 +5424,14 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(c%9 == 0 && isPowerOfTwo(c/9) && is32Bit(c)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c / 9)
+		v.AuxInt = int64ToAuxInt(log2(c / 9))
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = 3
+		v0.AuxInt = int64ToAuxInt(3)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5444,7 +5444,7 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(int32(c) == -1) {
 			break
@@ -5461,7 +5461,7 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		if !(int32(c) == 0) {
 			break
 		}
@@ -5476,7 +5476,7 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(int32(c) == 1) {
 			break
@@ -5493,13 +5493,13 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(isPowerOfTwo(c)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c)
+		v.AuxInt = int64ToAuxInt(log2(c))
 		v.AddArg2(a, x)
 		return true
 	}
@@ -5511,14 +5511,14 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(isPowerOfTwo(c-1) && int32(c) >= 3) {
 			break
 		}
 		v.reset(OpARM64ADD)
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = log2(c - 1)
+		v0.AuxInt = int64ToAuxInt(log2(c - 1))
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5531,14 +5531,14 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(isPowerOfTwo(c+1) && int32(c) >= 7) {
 			break
 		}
 		v.reset(OpARM64SUB)
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = log2(c + 1)
+		v0.AuxInt = int64ToAuxInt(log2(c + 1))
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5551,15 +5551,15 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(c%3 == 0 && isPowerOfTwo(c/3) && is32Bit(c)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c / 3)
+		v.AuxInt = int64ToAuxInt(log2(c / 3))
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = 2
+		v0.AuxInt = int64ToAuxInt(2)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5572,15 +5572,15 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(c%5 == 0 && isPowerOfTwo(c/5) && is32Bit(c)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c / 5)
+		v.AuxInt = int64ToAuxInt(log2(c / 5))
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = 2
+		v0.AuxInt = int64ToAuxInt(2)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5593,15 +5593,15 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(c%7 == 0 && isPowerOfTwo(c/7) && is32Bit(c)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c / 7)
+		v.AuxInt = int64ToAuxInt(log2(c / 7))
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = 3
+		v0.AuxInt = int64ToAuxInt(3)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5614,15 +5614,15 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(c%9 == 0 && isPowerOfTwo(c/9) && is32Bit(c)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c / 9)
+		v.AuxInt = int64ToAuxInt(log2(c / 9))
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = 3
+		v0.AuxInt = int64ToAuxInt(3)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -5633,11 +5633,11 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		x := v_1
 		y := v_2
 		v.reset(OpARM64ADDconst)
-		v.AuxInt = c
+		v.AuxInt = int64ToAuxInt(c)
 		v0 := b.NewValue0(v.Pos, OpARM64MULW, x.Type)
 		v0.AddArg2(x, y)
 		v.AddArg(v0)
@@ -5650,13 +5650,13 @@ func rewriteValueARM64_OpARM64MADDW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_2.AuxInt
+		d := auxIntToInt64(v_2.AuxInt)
 		v.reset(OpARM64ADDconst)
-		v.AuxInt = int64(int32(c) * int32(d))
+		v.AuxInt = int64ToAuxInt(int64(int32(c) * int32(d)))
 		v.AddArg(a)
 		return true
 	}
@@ -5671,7 +5671,7 @@ func rewriteValueARM64_OpARM64MNEG(v *Value) bool {
 	for {
 		for _i0 := 0; _i0 <= 1; _i0, v_0, v_1 = _i0+1, v_1, v_0 {
 			x := v_0
-			if v_1.Op != OpARM64MOVDconst || v_1.AuxInt != -1 {
+			if v_1.Op != OpARM64MOVDconst || auxIntToInt64(v_1.AuxInt) != -1 {
 				continue
 			}
 			v.copyOf(x)
@@ -5683,11 +5683,11 @@ func rewriteValueARM64_OpARM64MNEG(v *Value) bool {
 	// result: (MOVDconst [0])
 	for {
 		for _i0 := 0; _i0 <= 1; _i0, v_0, v_1 = _i0+1, v_1, v_0 {
-			if v_1.Op != OpARM64MOVDconst || v_1.AuxInt != 0 {
+			if v_1.Op != OpARM64MOVDconst || auxIntToInt64(v_1.AuxInt) != 0 {
 				continue
 			}
 			v.reset(OpARM64MOVDconst)
-			v.AuxInt = 0
+			v.AuxInt = int64ToAuxInt(0)
 			return true
 		}
 		break
@@ -5697,7 +5697,7 @@ func rewriteValueARM64_OpARM64MNEG(v *Value) bool {
 	for {
 		for _i0 := 0; _i0 <= 1; _i0, v_0, v_1 = _i0+1, v_1, v_0 {
 			x := v_0
-			if v_1.Op != OpARM64MOVDconst || v_1.AuxInt != 1 {
+			if v_1.Op != OpARM64MOVDconst || auxIntToInt64(v_1.AuxInt) != 1 {
 				continue
 			}
 			v.reset(OpARM64NEG)
@@ -5715,13 +5715,13 @@ func rewriteValueARM64_OpARM64MNEG(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(isPowerOfTwo(c)) {
 				continue
 			}
 			v.reset(OpARM64NEG)
 			v0 := b.NewValue0(v.Pos, OpARM64SLLconst, x.Type)
-			v0.AuxInt = log2(c)
+			v0.AuxInt = int64ToAuxInt(log2(c))
 			v0.AddArg(x)
 			v.AddArg(v0)
 			return true
@@ -5737,13 +5737,13 @@ func rewriteValueARM64_OpARM64MNEG(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(isPowerOfTwo(c-1) && c >= 3) {
 				continue
 			}
 			v.reset(OpARM64NEG)
 			v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-			v0.AuxInt = log2(c - 1)
+			v0.AuxInt = int64ToAuxInt(log2(c - 1))
 			v0.AddArg2(x, x)
 			v.AddArg(v0)
 			return true
@@ -5759,13 +5759,13 @@ func rewriteValueARM64_OpARM64MNEG(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(isPowerOfTwo(c+1) && c >= 7) {
 				continue
 			}
 			v.reset(OpARM64NEG)
 			v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-			v0.AuxInt = log2(c + 1)
+			v0.AuxInt = int64ToAuxInt(log2(c + 1))
 			v1 := b.NewValue0(v.Pos, OpARM64NEG, x.Type)
 			v1.AddArg(x)
 			v0.AddArg2(v1, x)
@@ -5783,15 +5783,15 @@ func rewriteValueARM64_OpARM64MNEG(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(c%3 == 0 && isPowerOfTwo(c/3)) {
 				continue
 			}
 			v.reset(OpARM64SLLconst)
 			v.Type = x.Type
-			v.AuxInt = log2(c / 3)
+			v.AuxInt = int64ToAuxInt(log2(c / 3))
 			v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-			v0.AuxInt = 2
+			v0.AuxInt = int64ToAuxInt(2)
 			v0.AddArg2(x, x)
 			v.AddArg(v0)
 			return true
@@ -5807,15 +5807,15 @@ func rewriteValueARM64_OpARM64MNEG(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(c%5 == 0 && isPowerOfTwo(c/5)) {
 				continue
 			}
 			v.reset(OpARM64NEG)
 			v0 := b.NewValue0(v.Pos, OpARM64SLLconst, x.Type)
-			v0.AuxInt = log2(c / 5)
+			v0.AuxInt = int64ToAuxInt(log2(c / 5))
 			v1 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-			v1.AuxInt = 2
+			v1.AuxInt = int64ToAuxInt(2)
 			v1.AddArg2(x, x)
 			v0.AddArg(v1)
 			v.AddArg(v0)
@@ -5832,15 +5832,15 @@ func rewriteValueARM64_OpARM64MNEG(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(c%7 == 0 && isPowerOfTwo(c/7)) {
 				continue
 			}
 			v.reset(OpARM64SLLconst)
 			v.Type = x.Type
-			v.AuxInt = log2(c / 7)
+			v.AuxInt = int64ToAuxInt(log2(c / 7))
 			v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-			v0.AuxInt = 3
+			v0.AuxInt = int64ToAuxInt(3)
 			v0.AddArg2(x, x)
 			v.AddArg(v0)
 			return true
@@ -5856,15 +5856,15 @@ func rewriteValueARM64_OpARM64MNEG(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(c%9 == 0 && isPowerOfTwo(c/9)) {
 				continue
 			}
 			v.reset(OpARM64NEG)
 			v0 := b.NewValue0(v.Pos, OpARM64SLLconst, x.Type)
-			v0.AuxInt = log2(c / 9)
+			v0.AuxInt = int64ToAuxInt(log2(c / 9))
 			v1 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-			v1.AuxInt = 3
+			v1.AuxInt = int64ToAuxInt(3)
 			v1.AddArg2(x, x)
 			v0.AddArg(v1)
 			v.AddArg(v0)
@@ -5879,13 +5879,13 @@ func rewriteValueARM64_OpARM64MNEG(v *Value) bool {
 			if v_0.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_0.AuxInt
+			c := auxIntToInt64(v_0.AuxInt)
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			d := v_1.AuxInt
+			d := auxIntToInt64(v_1.AuxInt)
 			v.reset(OpARM64MOVDconst)
-			v.AuxInt = -c * d
+			v.AuxInt = int64ToAuxInt(-c * d)
 			return true
 		}
 		break
@@ -5905,7 +5905,7 @@ func rewriteValueARM64_OpARM64MNEGW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(int32(c) == -1) {
 				continue
 			}
@@ -5922,12 +5922,12 @@ func rewriteValueARM64_OpARM64MNEGW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(int32(c) == 0) {
 				continue
 			}
 			v.reset(OpARM64MOVDconst)
-			v.AuxInt = 0
+			v.AuxInt = int64ToAuxInt(0)
 			return true
 		}
 		break
@@ -5941,7 +5941,7 @@ func rewriteValueARM64_OpARM64MNEGW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(int32(c) == 1) {
 				continue
 			}
@@ -5960,13 +5960,13 @@ func rewriteValueARM64_OpARM64MNEGW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(isPowerOfTwo(c)) {
 				continue
 			}
 			v.reset(OpARM64NEG)
 			v0 := b.NewValue0(v.Pos, OpARM64SLLconst, x.Type)
-			v0.AuxInt = log2(c)
+			v0.AuxInt = int64ToAuxInt(log2(c))
 			v0.AddArg(x)
 			v.AddArg(v0)
 			return true
@@ -5982,13 +5982,13 @@ func rewriteValueARM64_OpARM64MNEGW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(isPowerOfTwo(c-1) && int32(c) >= 3) {
 				continue
 			}
 			v.reset(OpARM64NEG)
 			v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-			v0.AuxInt = log2(c - 1)
+			v0.AuxInt = int64ToAuxInt(log2(c - 1))
 			v0.AddArg2(x, x)
 			v.AddArg(v0)
 			return true
@@ -6004,13 +6004,13 @@ func rewriteValueARM64_OpARM64MNEGW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(isPowerOfTwo(c+1) && int32(c) >= 7) {
 				continue
 			}
 			v.reset(OpARM64NEG)
 			v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-			v0.AuxInt = log2(c + 1)
+			v0.AuxInt = int64ToAuxInt(log2(c + 1))
 			v1 := b.NewValue0(v.Pos, OpARM64NEG, x.Type)
 			v1.AddArg(x)
 			v0.AddArg2(v1, x)
@@ -6028,15 +6028,15 @@ func rewriteValueARM64_OpARM64MNEGW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(c%3 == 0 && isPowerOfTwo(c/3) && is32Bit(c)) {
 				continue
 			}
 			v.reset(OpARM64SLLconst)
 			v.Type = x.Type
-			v.AuxInt = log2(c / 3)
+			v.AuxInt = int64ToAuxInt(log2(c / 3))
 			v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-			v0.AuxInt = 2
+			v0.AuxInt = int64ToAuxInt(2)
 			v0.AddArg2(x, x)
 			v.AddArg(v0)
 			return true
@@ -6052,15 +6052,15 @@ func rewriteValueARM64_OpARM64MNEGW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(c%5 == 0 && isPowerOfTwo(c/5) && is32Bit(c)) {
 				continue
 			}
 			v.reset(OpARM64NEG)
 			v0 := b.NewValue0(v.Pos, OpARM64SLLconst, x.Type)
-			v0.AuxInt = log2(c / 5)
+			v0.AuxInt = int64ToAuxInt(log2(c / 5))
 			v1 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-			v1.AuxInt = 2
+			v1.AuxInt = int64ToAuxInt(2)
 			v1.AddArg2(x, x)
 			v0.AddArg(v1)
 			v.AddArg(v0)
@@ -6077,15 +6077,15 @@ func rewriteValueARM64_OpARM64MNEGW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(c%7 == 0 && isPowerOfTwo(c/7) && is32Bit(c)) {
 				continue
 			}
 			v.reset(OpARM64SLLconst)
 			v.Type = x.Type
-			v.AuxInt = log2(c / 7)
+			v.AuxInt = int64ToAuxInt(log2(c / 7))
 			v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-			v0.AuxInt = 3
+			v0.AuxInt = int64ToAuxInt(3)
 			v0.AddArg2(x, x)
 			v.AddArg(v0)
 			return true
@@ -6101,15 +6101,15 @@ func rewriteValueARM64_OpARM64MNEGW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(c%9 == 0 && isPowerOfTwo(c/9) && is32Bit(c)) {
 				continue
 			}
 			v.reset(OpARM64NEG)
 			v0 := b.NewValue0(v.Pos, OpARM64SLLconst, x.Type)
-			v0.AuxInt = log2(c / 9)
+			v0.AuxInt = int64ToAuxInt(log2(c / 9))
 			v1 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-			v1.AuxInt = 3
+			v1.AuxInt = int64ToAuxInt(3)
 			v1.AddArg2(x, x)
 			v0.AddArg(v1)
 			v.AddArg(v0)
@@ -6124,13 +6124,13 @@ func rewriteValueARM64_OpARM64MNEGW(v *Value) bool {
 			if v_0.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_0.AuxInt
+			c := auxIntToInt64(v_0.AuxInt)
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			d := v_1.AuxInt
+			d := auxIntToInt64(v_1.AuxInt)
 			v.reset(OpARM64MOVDconst)
-			v.AuxInt = -int64(int32(c) * int32(d))
+			v.AuxInt = int64ToAuxInt(-int64(int32(c) * int32(d)))
 			return true
 		}
 		break
@@ -6146,13 +6146,13 @@ func rewriteValueARM64_OpARM64MOD(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_1.AuxInt
+		d := auxIntToInt64(v_1.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = c % d
+		v.AuxInt = int64ToAuxInt(c % d)
 		return true
 	}
 	return false
@@ -6166,13 +6166,13 @@ func rewriteValueARM64_OpARM64MODW(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_1.AuxInt
+		d := auxIntToInt64(v_1.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = int64(int32(c) % int32(d))
+		v.AuxInt = int64ToAuxInt(int64(int32(c) % int32(d)))
 		return true
 	}
 	return false
@@ -6380,10 +6380,10 @@ func rewriteValueARM64_OpARM64MOVBUreg(v *Value) bool {
 		if v_0.Op != OpARM64ANDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		x := v_0.Args[0]
 		v.reset(OpARM64ANDconst)
-		v.AuxInt = c & (1<<8 - 1)
+		v.AuxInt = int64ToAuxInt(c & (1<<8 - 1))
 		v.AddArg(x)
 		return true
 	}
@@ -6393,9 +6393,9 @@ func rewriteValueARM64_OpARM64MOVBUreg(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = int64(uint8(c))
+		v.AuxInt = int64ToAuxInt(int64(uint8(c)))
 		return true
 	}
 	// match: (MOVBUreg x)
@@ -6636,9 +6636,9 @@ func rewriteValueARM64_OpARM64MOVBreg(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = int64(int8(c))
+		v.AuxInt = int64ToAuxInt(int64(int8(c)))
 		return true
 	}
 	// match: (MOVBreg (SLLconst [lc] x))
@@ -8991,9 +8991,9 @@ func rewriteValueARM64_OpARM64MOVDreg(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = c
+		v.AuxInt = int64ToAuxInt(c)
 		return true
 	}
 	return false
@@ -9874,10 +9874,10 @@ func rewriteValueARM64_OpARM64MOVHUreg(v *Value) bool {
 		if v_0.Op != OpARM64ANDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		x := v_0.Args[0]
 		v.reset(OpARM64ANDconst)
-		v.AuxInt = c & (1<<16 - 1)
+		v.AuxInt = int64ToAuxInt(c & (1<<16 - 1))
 		v.AddArg(x)
 		return true
 	}
@@ -9887,9 +9887,9 @@ func rewriteValueARM64_OpARM64MOVHUreg(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = int64(uint16(c))
+		v.AuxInt = int64ToAuxInt(int64(uint16(c)))
 		return true
 	}
 	// match: (MOVHUreg (SLLconst [sc] x))
@@ -10301,9 +10301,9 @@ func rewriteValueARM64_OpARM64MOVHreg(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = int64(int16(c))
+		v.AuxInt = int64ToAuxInt(int64(int16(c)))
 		return true
 	}
 	// match: (MOVHreg (SLLconst [lc] x))
@@ -11971,10 +11971,10 @@ func rewriteValueARM64_OpARM64MOVWUreg(v *Value) bool {
 		if v_0.Op != OpARM64ANDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		x := v_0.Args[0]
 		v.reset(OpARM64ANDconst)
-		v.AuxInt = c & (1<<32 - 1)
+		v.AuxInt = int64ToAuxInt(c & (1<<32 - 1))
 		v.AddArg(x)
 		return true
 	}
@@ -11984,9 +11984,9 @@ func rewriteValueARM64_OpARM64MOVWUreg(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = int64(uint32(c))
+		v.AuxInt = int64ToAuxInt(int64(uint32(c)))
 		return true
 	}
 	// match: (MOVWUreg (SLLconst [sc] x))
@@ -12456,9 +12456,9 @@ func rewriteValueARM64_OpARM64MOVWreg(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = int64(int32(c))
+		v.AuxInt = int64ToAuxInt(int64(int32(c)))
 		return true
 	}
 	// match: (MOVWreg (SLLconst [lc] x))
@@ -13346,7 +13346,7 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 	for {
 		a := v_0
 		x := v_1
-		if v_2.Op != OpARM64MOVDconst || v_2.AuxInt != -1 {
+		if v_2.Op != OpARM64MOVDconst || auxIntToInt64(v_2.AuxInt) != -1 {
 			break
 		}
 		v.reset(OpARM64ADD)
@@ -13357,7 +13357,7 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 	// result: a
 	for {
 		a := v_0
-		if v_2.Op != OpARM64MOVDconst || v_2.AuxInt != 0 {
+		if v_2.Op != OpARM64MOVDconst || auxIntToInt64(v_2.AuxInt) != 0 {
 			break
 		}
 		v.copyOf(a)
@@ -13368,7 +13368,7 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 	for {
 		a := v_0
 		x := v_1
-		if v_2.Op != OpARM64MOVDconst || v_2.AuxInt != 1 {
+		if v_2.Op != OpARM64MOVDconst || auxIntToInt64(v_2.AuxInt) != 1 {
 			break
 		}
 		v.reset(OpARM64SUB)
@@ -13384,12 +13384,12 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(isPowerOfTwo(c)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c)
+		v.AuxInt = int64ToAuxInt(log2(c))
 		v.AddArg2(a, x)
 		return true
 	}
@@ -13402,13 +13402,13 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(isPowerOfTwo(c-1) && c >= 3) {
 			break
 		}
 		v.reset(OpARM64SUB)
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = log2(c - 1)
+		v0.AuxInt = int64ToAuxInt(log2(c - 1))
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -13422,13 +13422,13 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(isPowerOfTwo(c+1) && c >= 7) {
 			break
 		}
 		v.reset(OpARM64ADD)
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = log2(c + 1)
+		v0.AuxInt = int64ToAuxInt(log2(c + 1))
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -13442,14 +13442,14 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(c%3 == 0 && isPowerOfTwo(c/3)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c / 3)
+		v.AuxInt = int64ToAuxInt(log2(c / 3))
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = 2
+		v0.AuxInt = int64ToAuxInt(2)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -13463,14 +13463,14 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(c%5 == 0 && isPowerOfTwo(c/5)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c / 5)
+		v.AuxInt = int64ToAuxInt(log2(c / 5))
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = 2
+		v0.AuxInt = int64ToAuxInt(2)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -13484,14 +13484,14 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(c%7 == 0 && isPowerOfTwo(c/7)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c / 7)
+		v.AuxInt = int64ToAuxInt(log2(c / 7))
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = 3
+		v0.AuxInt = int64ToAuxInt(3)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -13505,14 +13505,14 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(c%9 == 0 && isPowerOfTwo(c/9)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c / 9)
+		v.AuxInt = int64ToAuxInt(log2(c / 9))
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = 3
+		v0.AuxInt = int64ToAuxInt(3)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -13521,7 +13521,7 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 	// result: (ADD a x)
 	for {
 		a := v_0
-		if v_1.Op != OpARM64MOVDconst || v_1.AuxInt != -1 {
+		if v_1.Op != OpARM64MOVDconst || auxIntToInt64(v_1.AuxInt) != -1 {
 			break
 		}
 		x := v_2
@@ -13533,7 +13533,7 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 	// result: a
 	for {
 		a := v_0
-		if v_1.Op != OpARM64MOVDconst || v_1.AuxInt != 0 {
+		if v_1.Op != OpARM64MOVDconst || auxIntToInt64(v_1.AuxInt) != 0 {
 			break
 		}
 		v.copyOf(a)
@@ -13543,7 +13543,7 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 	// result: (SUB a x)
 	for {
 		a := v_0
-		if v_1.Op != OpARM64MOVDconst || v_1.AuxInt != 1 {
+		if v_1.Op != OpARM64MOVDconst || auxIntToInt64(v_1.AuxInt) != 1 {
 			break
 		}
 		x := v_2
@@ -13559,13 +13559,13 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(isPowerOfTwo(c)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c)
+		v.AuxInt = int64ToAuxInt(log2(c))
 		v.AddArg2(a, x)
 		return true
 	}
@@ -13577,14 +13577,14 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(isPowerOfTwo(c-1) && c >= 3) {
 			break
 		}
 		v.reset(OpARM64SUB)
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = log2(c - 1)
+		v0.AuxInt = int64ToAuxInt(log2(c - 1))
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -13597,14 +13597,14 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(isPowerOfTwo(c+1) && c >= 7) {
 			break
 		}
 		v.reset(OpARM64ADD)
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = log2(c + 1)
+		v0.AuxInt = int64ToAuxInt(log2(c + 1))
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -13617,15 +13617,15 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(c%3 == 0 && isPowerOfTwo(c/3)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c / 3)
+		v.AuxInt = int64ToAuxInt(log2(c / 3))
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = 2
+		v0.AuxInt = int64ToAuxInt(2)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -13638,15 +13638,15 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(c%5 == 0 && isPowerOfTwo(c/5)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c / 5)
+		v.AuxInt = int64ToAuxInt(log2(c / 5))
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = 2
+		v0.AuxInt = int64ToAuxInt(2)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -13659,15 +13659,15 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(c%7 == 0 && isPowerOfTwo(c/7)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c / 7)
+		v.AuxInt = int64ToAuxInt(log2(c / 7))
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = 3
+		v0.AuxInt = int64ToAuxInt(3)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -13680,15 +13680,15 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(c%9 == 0 && isPowerOfTwo(c/9)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c / 9)
+		v.AuxInt = int64ToAuxInt(log2(c / 9))
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = 3
+		v0.AuxInt = int64ToAuxInt(3)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -13699,11 +13699,11 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		x := v_1
 		y := v_2
 		v.reset(OpARM64ADDconst)
-		v.AuxInt = c
+		v.AuxInt = int64ToAuxInt(c)
 		v0 := b.NewValue0(v.Pos, OpARM64MNEG, x.Type)
 		v0.AddArg2(x, y)
 		v.AddArg(v0)
@@ -13716,13 +13716,13 @@ func rewriteValueARM64_OpARM64MSUB(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_2.AuxInt
+		d := auxIntToInt64(v_2.AuxInt)
 		v.reset(OpARM64SUBconst)
-		v.AuxInt = c * d
+		v.AuxInt = int64ToAuxInt(c * d)
 		v.AddArg(a)
 		return true
 	}
@@ -13742,7 +13742,7 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(int32(c) == -1) {
 			break
 		}
@@ -13758,7 +13758,7 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(int32(c) == 0) {
 			break
 		}
@@ -13774,7 +13774,7 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(int32(c) == 1) {
 			break
 		}
@@ -13791,12 +13791,12 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(isPowerOfTwo(c)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c)
+		v.AuxInt = int64ToAuxInt(log2(c))
 		v.AddArg2(a, x)
 		return true
 	}
@@ -13809,13 +13809,13 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(isPowerOfTwo(c-1) && int32(c) >= 3) {
 			break
 		}
 		v.reset(OpARM64SUB)
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = log2(c - 1)
+		v0.AuxInt = int64ToAuxInt(log2(c - 1))
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -13829,13 +13829,13 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(isPowerOfTwo(c+1) && int32(c) >= 7) {
 			break
 		}
 		v.reset(OpARM64ADD)
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = log2(c + 1)
+		v0.AuxInt = int64ToAuxInt(log2(c + 1))
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -13849,14 +13849,14 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(c%3 == 0 && isPowerOfTwo(c/3) && is32Bit(c)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c / 3)
+		v.AuxInt = int64ToAuxInt(log2(c / 3))
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = 2
+		v0.AuxInt = int64ToAuxInt(2)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -13870,14 +13870,14 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(c%5 == 0 && isPowerOfTwo(c/5) && is32Bit(c)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c / 5)
+		v.AuxInt = int64ToAuxInt(log2(c / 5))
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = 2
+		v0.AuxInt = int64ToAuxInt(2)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -13891,14 +13891,14 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(c%7 == 0 && isPowerOfTwo(c/7) && is32Bit(c)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c / 7)
+		v.AuxInt = int64ToAuxInt(log2(c / 7))
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = 3
+		v0.AuxInt = int64ToAuxInt(3)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -13912,14 +13912,14 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_2.AuxInt
+		c := auxIntToInt64(v_2.AuxInt)
 		if !(c%9 == 0 && isPowerOfTwo(c/9) && is32Bit(c)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c / 9)
+		v.AuxInt = int64ToAuxInt(log2(c / 9))
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = 3
+		v0.AuxInt = int64ToAuxInt(3)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -13932,7 +13932,7 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(int32(c) == -1) {
 			break
@@ -13949,7 +13949,7 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		if !(int32(c) == 0) {
 			break
 		}
@@ -13964,7 +13964,7 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(int32(c) == 1) {
 			break
@@ -13981,13 +13981,13 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(isPowerOfTwo(c)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c)
+		v.AuxInt = int64ToAuxInt(log2(c))
 		v.AddArg2(a, x)
 		return true
 	}
@@ -13999,14 +13999,14 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(isPowerOfTwo(c-1) && int32(c) >= 3) {
 			break
 		}
 		v.reset(OpARM64SUB)
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = log2(c - 1)
+		v0.AuxInt = int64ToAuxInt(log2(c - 1))
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -14019,14 +14019,14 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(isPowerOfTwo(c+1) && int32(c) >= 7) {
 			break
 		}
 		v.reset(OpARM64ADD)
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = log2(c + 1)
+		v0.AuxInt = int64ToAuxInt(log2(c + 1))
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -14039,15 +14039,15 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(c%3 == 0 && isPowerOfTwo(c/3) && is32Bit(c)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c / 3)
+		v.AuxInt = int64ToAuxInt(log2(c / 3))
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = 2
+		v0.AuxInt = int64ToAuxInt(2)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -14060,15 +14060,15 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(c%5 == 0 && isPowerOfTwo(c/5) && is32Bit(c)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c / 5)
+		v.AuxInt = int64ToAuxInt(log2(c / 5))
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = 2
+		v0.AuxInt = int64ToAuxInt(2)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -14081,15 +14081,15 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(c%7 == 0 && isPowerOfTwo(c/7) && is32Bit(c)) {
 			break
 		}
 		v.reset(OpARM64ADDshiftLL)
-		v.AuxInt = log2(c / 7)
+		v.AuxInt = int64ToAuxInt(log2(c / 7))
 		v0 := b.NewValue0(v.Pos, OpARM64SUBshiftLL, x.Type)
-		v0.AuxInt = 3
+		v0.AuxInt = int64ToAuxInt(3)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -14102,15 +14102,15 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		x := v_2
 		if !(c%9 == 0 && isPowerOfTwo(c/9) && is32Bit(c)) {
 			break
 		}
 		v.reset(OpARM64SUBshiftLL)
-		v.AuxInt = log2(c / 9)
+		v.AuxInt = int64ToAuxInt(log2(c / 9))
 		v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-		v0.AuxInt = 3
+		v0.AuxInt = int64ToAuxInt(3)
 		v0.AddArg2(x, x)
 		v.AddArg2(a, v0)
 		return true
@@ -14121,11 +14121,11 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		x := v_1
 		y := v_2
 		v.reset(OpARM64ADDconst)
-		v.AuxInt = c
+		v.AuxInt = int64ToAuxInt(c)
 		v0 := b.NewValue0(v.Pos, OpARM64MNEGW, x.Type)
 		v0.AddArg2(x, y)
 		v.AddArg(v0)
@@ -14138,13 +14138,13 @@ func rewriteValueARM64_OpARM64MSUBW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		if v_2.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_2.AuxInt
+		d := auxIntToInt64(v_2.AuxInt)
 		v.reset(OpARM64SUBconst)
-		v.AuxInt = int64(int32(c) * int32(d))
+		v.AuxInt = int64ToAuxInt(int64(int32(c) * int32(d)))
 		v.AddArg(a)
 		return true
 	}
@@ -14174,7 +14174,7 @@ func rewriteValueARM64_OpARM64MUL(v *Value) bool {
 	for {
 		for _i0 := 0; _i0 <= 1; _i0, v_0, v_1 = _i0+1, v_1, v_0 {
 			x := v_0
-			if v_1.Op != OpARM64MOVDconst || v_1.AuxInt != -1 {
+			if v_1.Op != OpARM64MOVDconst || auxIntToInt64(v_1.AuxInt) != -1 {
 				continue
 			}
 			v.reset(OpARM64NEG)
@@ -14187,11 +14187,11 @@ func rewriteValueARM64_OpARM64MUL(v *Value) bool {
 	// result: (MOVDconst [0])
 	for {
 		for _i0 := 0; _i0 <= 1; _i0, v_0, v_1 = _i0+1, v_1, v_0 {
-			if v_1.Op != OpARM64MOVDconst || v_1.AuxInt != 0 {
+			if v_1.Op != OpARM64MOVDconst || auxIntToInt64(v_1.AuxInt) != 0 {
 				continue
 			}
 			v.reset(OpARM64MOVDconst)
-			v.AuxInt = 0
+			v.AuxInt = int64ToAuxInt(0)
 			return true
 		}
 		break
@@ -14201,7 +14201,7 @@ func rewriteValueARM64_OpARM64MUL(v *Value) bool {
 	for {
 		for _i0 := 0; _i0 <= 1; _i0, v_0, v_1 = _i0+1, v_1, v_0 {
 			x := v_0
-			if v_1.Op != OpARM64MOVDconst || v_1.AuxInt != 1 {
+			if v_1.Op != OpARM64MOVDconst || auxIntToInt64(v_1.AuxInt) != 1 {
 				continue
 			}
 			v.copyOf(x)
@@ -14218,12 +14218,12 @@ func rewriteValueARM64_OpARM64MUL(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(isPowerOfTwo(c)) {
 				continue
 			}
 			v.reset(OpARM64SLLconst)
-			v.AuxInt = log2(c)
+			v.AuxInt = int64ToAuxInt(log2(c))
 			v.AddArg(x)
 			return true
 		}
@@ -14238,12 +14238,12 @@ func rewriteValueARM64_OpARM64MUL(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(isPowerOfTwo(c-1) && c >= 3) {
 				continue
 			}
 			v.reset(OpARM64ADDshiftLL)
-			v.AuxInt = log2(c - 1)
+			v.AuxInt = int64ToAuxInt(log2(c - 1))
 			v.AddArg2(x, x)
 			return true
 		}
@@ -14258,12 +14258,12 @@ func rewriteValueARM64_OpARM64MUL(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(isPowerOfTwo(c+1) && c >= 7) {
 				continue
 			}
 			v.reset(OpARM64ADDshiftLL)
-			v.AuxInt = log2(c + 1)
+			v.AuxInt = int64ToAuxInt(log2(c + 1))
 			v0 := b.NewValue0(v.Pos, OpARM64NEG, x.Type)
 			v0.AddArg(x)
 			v.AddArg2(v0, x)
@@ -14280,14 +14280,14 @@ func rewriteValueARM64_OpARM64MUL(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(c%3 == 0 && isPowerOfTwo(c/3)) {
 				continue
 			}
 			v.reset(OpARM64SLLconst)
-			v.AuxInt = log2(c / 3)
+			v.AuxInt = int64ToAuxInt(log2(c / 3))
 			v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-			v0.AuxInt = 1
+			v0.AuxInt = int64ToAuxInt(1)
 			v0.AddArg2(x, x)
 			v.AddArg(v0)
 			return true
@@ -14303,14 +14303,14 @@ func rewriteValueARM64_OpARM64MUL(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(c%5 == 0 && isPowerOfTwo(c/5)) {
 				continue
 			}
 			v.reset(OpARM64SLLconst)
-			v.AuxInt = log2(c / 5)
+			v.AuxInt = int64ToAuxInt(log2(c / 5))
 			v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-			v0.AuxInt = 2
+			v0.AuxInt = int64ToAuxInt(2)
 			v0.AddArg2(x, x)
 			v.AddArg(v0)
 			return true
@@ -14326,14 +14326,14 @@ func rewriteValueARM64_OpARM64MUL(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(c%7 == 0 && isPowerOfTwo(c/7)) {
 				continue
 			}
 			v.reset(OpARM64SLLconst)
-			v.AuxInt = log2(c / 7)
+			v.AuxInt = int64ToAuxInt(log2(c / 7))
 			v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-			v0.AuxInt = 3
+			v0.AuxInt = int64ToAuxInt(3)
 			v1 := b.NewValue0(v.Pos, OpARM64NEG, x.Type)
 			v1.AddArg(x)
 			v0.AddArg2(v1, x)
@@ -14351,14 +14351,14 @@ func rewriteValueARM64_OpARM64MUL(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(c%9 == 0 && isPowerOfTwo(c/9)) {
 				continue
 			}
 			v.reset(OpARM64SLLconst)
-			v.AuxInt = log2(c / 9)
+			v.AuxInt = int64ToAuxInt(log2(c / 9))
 			v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-			v0.AuxInt = 3
+			v0.AuxInt = int64ToAuxInt(3)
 			v0.AddArg2(x, x)
 			v.AddArg(v0)
 			return true
@@ -14372,13 +14372,13 @@ func rewriteValueARM64_OpARM64MUL(v *Value) bool {
 			if v_0.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_0.AuxInt
+			c := auxIntToInt64(v_0.AuxInt)
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			d := v_1.AuxInt
+			d := auxIntToInt64(v_1.AuxInt)
 			v.reset(OpARM64MOVDconst)
-			v.AuxInt = c * d
+			v.AuxInt = int64ToAuxInt(c * d)
 			return true
 		}
 		break
@@ -14413,7 +14413,7 @@ func rewriteValueARM64_OpARM64MULW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(int32(c) == -1) {
 				continue
 			}
@@ -14431,12 +14431,12 @@ func rewriteValueARM64_OpARM64MULW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(int32(c) == 0) {
 				continue
 			}
 			v.reset(OpARM64MOVDconst)
-			v.AuxInt = 0
+			v.AuxInt = int64ToAuxInt(0)
 			return true
 		}
 		break
@@ -14450,7 +14450,7 @@ func rewriteValueARM64_OpARM64MULW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(int32(c) == 1) {
 				continue
 			}
@@ -14468,12 +14468,12 @@ func rewriteValueARM64_OpARM64MULW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(isPowerOfTwo(c)) {
 				continue
 			}
 			v.reset(OpARM64SLLconst)
-			v.AuxInt = log2(c)
+			v.AuxInt = int64ToAuxInt(log2(c))
 			v.AddArg(x)
 			return true
 		}
@@ -14488,12 +14488,12 @@ func rewriteValueARM64_OpARM64MULW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(isPowerOfTwo(c-1) && int32(c) >= 3) {
 				continue
 			}
 			v.reset(OpARM64ADDshiftLL)
-			v.AuxInt = log2(c - 1)
+			v.AuxInt = int64ToAuxInt(log2(c - 1))
 			v.AddArg2(x, x)
 			return true
 		}
@@ -14508,12 +14508,12 @@ func rewriteValueARM64_OpARM64MULW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(isPowerOfTwo(c+1) && int32(c) >= 7) {
 				continue
 			}
 			v.reset(OpARM64ADDshiftLL)
-			v.AuxInt = log2(c + 1)
+			v.AuxInt = int64ToAuxInt(log2(c + 1))
 			v0 := b.NewValue0(v.Pos, OpARM64NEG, x.Type)
 			v0.AddArg(x)
 			v.AddArg2(v0, x)
@@ -14530,14 +14530,14 @@ func rewriteValueARM64_OpARM64MULW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(c%3 == 0 && isPowerOfTwo(c/3) && is32Bit(c)) {
 				continue
 			}
 			v.reset(OpARM64SLLconst)
-			v.AuxInt = log2(c / 3)
+			v.AuxInt = int64ToAuxInt(log2(c / 3))
 			v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-			v0.AuxInt = 1
+			v0.AuxInt = int64ToAuxInt(1)
 			v0.AddArg2(x, x)
 			v.AddArg(v0)
 			return true
@@ -14553,14 +14553,14 @@ func rewriteValueARM64_OpARM64MULW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(c%5 == 0 && isPowerOfTwo(c/5) && is32Bit(c)) {
 				continue
 			}
 			v.reset(OpARM64SLLconst)
-			v.AuxInt = log2(c / 5)
+			v.AuxInt = int64ToAuxInt(log2(c / 5))
 			v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-			v0.AuxInt = 2
+			v0.AuxInt = int64ToAuxInt(2)
 			v0.AddArg2(x, x)
 			v.AddArg(v0)
 			return true
@@ -14576,14 +14576,14 @@ func rewriteValueARM64_OpARM64MULW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(c%7 == 0 && isPowerOfTwo(c/7) && is32Bit(c)) {
 				continue
 			}
 			v.reset(OpARM64SLLconst)
-			v.AuxInt = log2(c / 7)
+			v.AuxInt = int64ToAuxInt(log2(c / 7))
 			v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-			v0.AuxInt = 3
+			v0.AuxInt = int64ToAuxInt(3)
 			v1 := b.NewValue0(v.Pos, OpARM64NEG, x.Type)
 			v1.AddArg(x)
 			v0.AddArg2(v1, x)
@@ -14601,14 +14601,14 @@ func rewriteValueARM64_OpARM64MULW(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			if !(c%9 == 0 && isPowerOfTwo(c/9) && is32Bit(c)) {
 				continue
 			}
 			v.reset(OpARM64SLLconst)
-			v.AuxInt = log2(c / 9)
+			v.AuxInt = int64ToAuxInt(log2(c / 9))
 			v0 := b.NewValue0(v.Pos, OpARM64ADDshiftLL, x.Type)
-			v0.AuxInt = 3
+			v0.AuxInt = int64ToAuxInt(3)
 			v0.AddArg2(x, x)
 			v.AddArg(v0)
 			return true
@@ -14622,13 +14622,13 @@ func rewriteValueARM64_OpARM64MULW(v *Value) bool {
 			if v_0.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_0.AuxInt
+			c := auxIntToInt64(v_0.AuxInt)
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			d := v_1.AuxInt
+			d := auxIntToInt64(v_1.AuxInt)
 			v.reset(OpARM64MOVDconst)
-			v.AuxInt = int64(int32(c) * int32(d))
+			v.AuxInt = int64ToAuxInt(int64(int32(c) * int32(d)))
 			return true
 		}
 		break
@@ -14655,9 +14655,9 @@ func rewriteValueARM64_OpARM64MVN(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = ^c
+		v.AuxInt = int64ToAuxInt(^c)
 		return true
 	}
 	// match: (MVN x:(SLLconst [c] y))
@@ -14796,9 +14796,9 @@ func rewriteValueARM64_OpARM64NEG(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = -c
+		v.AuxInt = int64ToAuxInt(-c)
 		return true
 	}
 	// match: (NEG x:(SLLconst [c] y))
@@ -14944,9 +14944,9 @@ func rewriteValueARM64_OpARM64OR(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			v.reset(OpARM64ORconst)
-			v.AuxInt = c
+			v.AuxInt = int64ToAuxInt(c)
 			v.AddArg(x)
 			return true
 		}
@@ -16938,9 +16938,9 @@ func rewriteValueARM64_OpARM64ORN(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		v.reset(OpARM64ORconst)
-		v.AuxInt = ^c
+		v.AuxInt = int64ToAuxInt(^c)
 		v.AddArg(x)
 		return true
 	}
@@ -16952,7 +16952,7 @@ func rewriteValueARM64_OpARM64ORN(v *Value) bool {
 			break
 		}
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = -1
+		v.AuxInt = int64ToAuxInt(-1)
 		return true
 	}
 	// match: (ORN x0 x1:(SLLconst [c] y))
@@ -17127,7 +17127,7 @@ func rewriteValueARM64_OpARM64ORconst(v *Value) bool {
 	// match: (ORconst [0] x)
 	// result: x
 	for {
-		if v.AuxInt != 0 {
+		if auxIntToInt64(v.AuxInt) != 0 {
 			break
 		}
 		x := v_0
@@ -17137,36 +17137,36 @@ func rewriteValueARM64_OpARM64ORconst(v *Value) bool {
 	// match: (ORconst [-1] _)
 	// result: (MOVDconst [-1])
 	for {
-		if v.AuxInt != -1 {
+		if auxIntToInt64(v.AuxInt) != -1 {
 			break
 		}
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = -1
+		v.AuxInt = int64ToAuxInt(-1)
 		return true
 	}
 	// match: (ORconst [c] (MOVDconst [d]))
 	// result: (MOVDconst [c|d])
 	for {
-		c := v.AuxInt
+		c := auxIntToInt64(v.AuxInt)
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_0.AuxInt
+		d := auxIntToInt64(v_0.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = c | d
+		v.AuxInt = int64ToAuxInt(c | d)
 		return true
 	}
 	// match: (ORconst [c] (ORconst [d] x))
 	// result: (ORconst [c|d] x)
 	for {
-		c := v.AuxInt
+		c := auxIntToInt64(v.AuxInt)
 		if v_0.Op != OpARM64ORconst {
 			break
 		}
-		d := v_0.AuxInt
+		d := auxIntToInt64(v_0.AuxInt)
 		x := v_0.Args[0]
 		v.reset(OpARM64ORconst)
-		v.AuxInt = c | d
+		v.AuxInt = int64ToAuxInt(c | d)
 		v.AddArg(x)
 		return true
 	}
@@ -19064,7 +19064,7 @@ func rewriteValueARM64_OpARM64SBCSflags(v *Value) bool {
 			break
 		}
 		v_2_0_0 := v_2_0.Args[0]
-		if v_2_0_0.Op != OpARM64MOVDconst || v_2_0_0.AuxInt != 0 {
+		if v_2_0_0.Op != OpARM64MOVDconst || auxIntToInt64(v_2_0_0.AuxInt) != 0 {
 			break
 		}
 		v.reset(OpARM64SUBSflags)
@@ -19083,9 +19083,9 @@ func rewriteValueARM64_OpARM64SLL(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		v.reset(OpARM64SLLconst)
-		v.AuxInt = c & 63
+		v.AuxInt = int64ToAuxInt(c & 63)
 		v.AddArg(x)
 		return true
 	}
@@ -19096,13 +19096,13 @@ func rewriteValueARM64_OpARM64SLLconst(v *Value) bool {
 	// match: (SLLconst [c] (MOVDconst [d]))
 	// result: (MOVDconst [d<<uint64(c)])
 	for {
-		c := v.AuxInt
+		c := auxIntToInt64(v.AuxInt)
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_0.AuxInt
+		d := auxIntToInt64(v_0.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = d << uint64(c)
+		v.AuxInt = int64ToAuxInt(d << uint64(c))
 		return true
 	}
 	// match: (SLLconst [c] (SRLconst [c] x))
@@ -19221,9 +19221,9 @@ func rewriteValueARM64_OpARM64SRA(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		v.reset(OpARM64SRAconst)
-		v.AuxInt = c & 63
+		v.AuxInt = int64ToAuxInt(c & 63)
 		v.AddArg(x)
 		return true
 	}
@@ -19234,13 +19234,13 @@ func rewriteValueARM64_OpARM64SRAconst(v *Value) bool {
 	// match: (SRAconst [c] (MOVDconst [d]))
 	// result: (MOVDconst [d>>uint64(c)])
 	for {
-		c := v.AuxInt
+		c := auxIntToInt64(v.AuxInt)
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_0.AuxInt
+		d := auxIntToInt64(v_0.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = d >> uint64(c)
+		v.AuxInt = int64ToAuxInt(d >> uint64(c))
 		return true
 	}
 	// match: (SRAconst [rc] (SLLconst [lc] x))
@@ -19378,9 +19378,9 @@ func rewriteValueARM64_OpARM64SRL(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		v.reset(OpARM64SRLconst)
-		v.AuxInt = c & 63
+		v.AuxInt = int64ToAuxInt(c & 63)
 		v.AddArg(x)
 		return true
 	}
@@ -19391,13 +19391,13 @@ func rewriteValueARM64_OpARM64SRLconst(v *Value) bool {
 	// match: (SRLconst [c] (MOVDconst [d]))
 	// result: (MOVDconst [int64(uint64(d)>>uint64(c))])
 	for {
-		c := v.AuxInt
+		c := auxIntToInt64(v.AuxInt)
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_0.AuxInt
+		d := auxIntToInt64(v_0.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = int64(uint64(d) >> uint64(c))
+		v.AuxInt = int64ToAuxInt(int64(uint64(d) >> uint64(c)))
 		return true
 	}
 	// match: (SRLconst [c] (SLLconst [c] x))
@@ -19679,9 +19679,9 @@ func rewriteValueARM64_OpARM64SUB(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		v.reset(OpARM64SUBconst)
-		v.AuxInt = c
+		v.AuxInt = int64ToAuxInt(c)
 		v.AddArg(x)
 		return true
 	}
@@ -19765,7 +19765,7 @@ func rewriteValueARM64_OpARM64SUB(v *Value) bool {
 			break
 		}
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = 0
+		v.AuxInt = int64ToAuxInt(0)
 		return true
 	}
 	// match: (SUB x (SUB y z))
@@ -19862,7 +19862,7 @@ func rewriteValueARM64_OpARM64SUBconst(v *Value) bool {
 	// match: (SUBconst [0] x)
 	// result: x
 	for {
-		if v.AuxInt != 0 {
+		if auxIntToInt64(v.AuxInt) != 0 {
 			break
 		}
 		x := v_0
@@ -19872,40 +19872,40 @@ func rewriteValueARM64_OpARM64SUBconst(v *Value) bool {
 	// match: (SUBconst [c] (MOVDconst [d]))
 	// result: (MOVDconst [d-c])
 	for {
-		c := v.AuxInt
+		c := auxIntToInt64(v.AuxInt)
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_0.AuxInt
+		d := auxIntToInt64(v_0.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = d - c
+		v.AuxInt = int64ToAuxInt(d - c)
 		return true
 	}
 	// match: (SUBconst [c] (SUBconst [d] x))
 	// result: (ADDconst [-c-d] x)
 	for {
-		c := v.AuxInt
+		c := auxIntToInt64(v.AuxInt)
 		if v_0.Op != OpARM64SUBconst {
 			break
 		}
-		d := v_0.AuxInt
+		d := auxIntToInt64(v_0.AuxInt)
 		x := v_0.Args[0]
 		v.reset(OpARM64ADDconst)
-		v.AuxInt = -c - d
+		v.AuxInt = int64ToAuxInt(-c - d)
 		v.AddArg(x)
 		return true
 	}
 	// match: (SUBconst [c] (ADDconst [d] x))
 	// result: (ADDconst [-c+d] x)
 	for {
-		c := v.AuxInt
+		c := auxIntToInt64(v.AuxInt)
 		if v_0.Op != OpARM64ADDconst {
 			break
 		}
-		d := v_0.AuxInt
+		d := auxIntToInt64(v_0.AuxInt)
 		x := v_0.Args[0]
 		v.reset(OpARM64ADDconst)
-		v.AuxInt = -c + d
+		v.AuxInt = int64ToAuxInt(-c + d)
 		v.AddArg(x)
 		return true
 	}
@@ -20030,9 +20030,9 @@ func rewriteValueARM64_OpARM64TST(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			v.reset(OpARM64TSTconst)
-			v.AuxInt = c
+			v.AuxInt = int64ToAuxInt(c)
 			v.AddArg(x)
 			return true
 		}
@@ -20110,16 +20110,16 @@ func rewriteValueARM64_OpARM64TSTW(v *Value) bool {
 	v_1 := v.Args[1]
 	v_0 := v.Args[0]
 	// match: (TSTW x (MOVDconst [c]))
-	// result: (TSTWconst [c] x)
+	// result: (TSTWconst [int32(c)] x)
 	for {
 		for _i0 := 0; _i0 <= 1; _i0, v_0, v_1 = _i0+1, v_1, v_0 {
 			x := v_0
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			v.reset(OpARM64TSTWconst)
-			v.AuxInt = c
+			v.AuxInt = int32ToAuxInt(int32(c))
 			v.AddArg(x)
 			return true
 		}
@@ -20375,7 +20375,7 @@ func rewriteValueARM64_OpARM64UDIV(v *Value) bool {
 	// result: x
 	for {
 		x := v_0
-		if v_1.Op != OpARM64MOVDconst || v_1.AuxInt != 1 {
+		if v_1.Op != OpARM64MOVDconst || auxIntToInt64(v_1.AuxInt) != 1 {
 			break
 		}
 		v.copyOf(x)
@@ -20389,12 +20389,12 @@ func rewriteValueARM64_OpARM64UDIV(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		if !(isPowerOfTwo(c)) {
 			break
 		}
 		v.reset(OpARM64SRLconst)
-		v.AuxInt = log2(c)
+		v.AuxInt = int64ToAuxInt(log2(c))
 		v.AddArg(x)
 		return true
 	}
@@ -20404,13 +20404,13 @@ func rewriteValueARM64_OpARM64UDIV(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_1.AuxInt
+		d := auxIntToInt64(v_1.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = int64(uint64(c) / uint64(d))
+		v.AuxInt = int64ToAuxInt(int64(uint64(c) / uint64(d)))
 		return true
 	}
 	return false
@@ -20426,7 +20426,7 @@ func rewriteValueARM64_OpARM64UDIVW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		if !(uint32(c) == 1) {
 			break
 		}
@@ -20441,12 +20441,12 @@ func rewriteValueARM64_OpARM64UDIVW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		if !(isPowerOfTwo(c) && is32Bit(c)) {
 			break
 		}
 		v.reset(OpARM64SRLconst)
-		v.AuxInt = log2(c)
+		v.AuxInt = int64ToAuxInt(log2(c))
 		v.AddArg(x)
 		return true
 	}
@@ -20456,13 +20456,13 @@ func rewriteValueARM64_OpARM64UDIVW(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_1.AuxInt
+		d := auxIntToInt64(v_1.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = int64(uint32(c) / uint32(d))
+		v.AuxInt = int64ToAuxInt(int64(uint32(c) / uint32(d)))
 		return true
 	}
 	return false
@@ -20490,11 +20490,11 @@ func rewriteValueARM64_OpARM64UMOD(v *Value) bool {
 	// match: (UMOD _ (MOVDconst [1]))
 	// result: (MOVDconst [0])
 	for {
-		if v_1.Op != OpARM64MOVDconst || v_1.AuxInt != 1 {
+		if v_1.Op != OpARM64MOVDconst || auxIntToInt64(v_1.AuxInt) != 1 {
 			break
 		}
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = 0
+		v.AuxInt = int64ToAuxInt(0)
 		return true
 	}
 	// match: (UMOD x (MOVDconst [c]))
@@ -20505,12 +20505,12 @@ func rewriteValueARM64_OpARM64UMOD(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		if !(isPowerOfTwo(c)) {
 			break
 		}
 		v.reset(OpARM64ANDconst)
-		v.AuxInt = c - 1
+		v.AuxInt = int64ToAuxInt(c - 1)
 		v.AddArg(x)
 		return true
 	}
@@ -20520,13 +20520,13 @@ func rewriteValueARM64_OpARM64UMOD(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_1.AuxInt
+		d := auxIntToInt64(v_1.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = int64(uint64(c) % uint64(d))
+		v.AuxInt = int64ToAuxInt(int64(uint64(c) % uint64(d)))
 		return true
 	}
 	return false
@@ -20558,12 +20558,12 @@ func rewriteValueARM64_OpARM64UMODW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		if !(uint32(c) == 1) {
 			break
 		}
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = 0
+		v.AuxInt = int64ToAuxInt(0)
 		return true
 	}
 	// match: (UMODW x (MOVDconst [c]))
@@ -20574,12 +20574,12 @@ func rewriteValueARM64_OpARM64UMODW(v *Value) bool {
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_1.AuxInt
+		c := auxIntToInt64(v_1.AuxInt)
 		if !(isPowerOfTwo(c) && is32Bit(c)) {
 			break
 		}
 		v.reset(OpARM64ANDconst)
-		v.AuxInt = c - 1
+		v.AuxInt = int64ToAuxInt(c - 1)
 		v.AddArg(x)
 		return true
 	}
@@ -20589,13 +20589,13 @@ func rewriteValueARM64_OpARM64UMODW(v *Value) bool {
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		c := v_0.AuxInt
+		c := auxIntToInt64(v_0.AuxInt)
 		if v_1.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_1.AuxInt
+		d := auxIntToInt64(v_1.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = int64(uint32(c) % uint32(d))
+		v.AuxInt = int64ToAuxInt(int64(uint32(c) % uint32(d)))
 		return true
 	}
 	return false
@@ -20613,9 +20613,9 @@ func rewriteValueARM64_OpARM64XOR(v *Value) bool {
 			if v_1.Op != OpARM64MOVDconst {
 				continue
 			}
-			c := v_1.AuxInt
+			c := auxIntToInt64(v_1.AuxInt)
 			v.reset(OpARM64XORconst)
-			v.AuxInt = c
+			v.AuxInt = int64ToAuxInt(c)
 			v.AddArg(x)
 			return true
 		}
@@ -20629,7 +20629,7 @@ func rewriteValueARM64_OpARM64XOR(v *Value) bool {
 			break
 		}
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = 0
+		v.AuxInt = int64ToAuxInt(0)
 		return true
 	}
 	// match: (XOR x (MVN y))
@@ -21001,7 +21001,7 @@ func rewriteValueARM64_OpARM64XORconst(v *Value) bool {
 	// match: (XORconst [0] x)
 	// result: x
 	for {
-		if v.AuxInt != 0 {
+		if auxIntToInt64(v.AuxInt) != 0 {
 			break
 		}
 		x := v_0
@@ -21011,7 +21011,7 @@ func rewriteValueARM64_OpARM64XORconst(v *Value) bool {
 	// match: (XORconst [-1] x)
 	// result: (MVN x)
 	for {
-		if v.AuxInt != -1 {
+		if auxIntToInt64(v.AuxInt) != -1 {
 			break
 		}
 		x := v_0
@@ -21022,26 +21022,26 @@ func rewriteValueARM64_OpARM64XORconst(v *Value) bool {
 	// match: (XORconst [c] (MOVDconst [d]))
 	// result: (MOVDconst [c^d])
 	for {
-		c := v.AuxInt
+		c := auxIntToInt64(v.AuxInt)
 		if v_0.Op != OpARM64MOVDconst {
 			break
 		}
-		d := v_0.AuxInt
+		d := auxIntToInt64(v_0.AuxInt)
 		v.reset(OpARM64MOVDconst)
-		v.AuxInt = c ^ d
+		v.AuxInt = int64ToAuxInt(c ^ d)
 		return true
 	}
 	// match: (XORconst [c] (XORconst [d] x))
 	// result: (XORconst [c^d] x)
 	for {
-		c := v.AuxInt
+		c := auxIntToInt64(v.AuxInt)
 		if v_0.Op != OpARM64XORconst {
 			break
 		}
-		d := v_0.AuxInt
+		d := auxIntToInt64(v_0.AuxInt)
 		x := v_0.Args[0]
 		v.reset(OpARM64XORconst)
-		v.AuxInt = c ^ d
+		v.AuxInt = int64ToAuxInt(c ^ d)
 		v.AddArg(x)
 		return true
 	}
