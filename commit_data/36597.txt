commit f32348669c24ee601870e13f12119a149f206a1e
Author: Keith Randall <khr@golang.org>
Date:   Tue May 8 09:11:00 2018 -0700

    cmd/compile: rename memory-using operations
    
    Some *mem ops are loads, some are stores, some are modifications.
    Replace mem->load for the loads.
    Replace mem->store for the stores.
    Replace mem->modify for the load-modify-stores.
    
    The only semantic change in this CL is to mark
    ADD(Q|L)constmodify (which used to be ADD(Q|L)constmem) as
    both a read and a write, instead of just a write. This is arguably
    a bug fix, but the bug isn't triggerable at the moment, see CL 112157.
    
    Change-Id: Iccb45aea817b606adb2d712ff99b10ee28e4616a
    Reviewed-on: https://go-review.googlesource.com/112159
    Run-TryBot: Keith Randall <khr@golang.org>
    Reviewed-by: Brad Fitzpatrick <bradfitz@golang.org>
    TryBot-Result: Gobot Gobot <gobot@golang.org>
---
 src/cmd/compile/internal/amd64/ssa.go        |   26 +-
 src/cmd/compile/internal/ssa/flagalloc.go    |   16 +-
 src/cmd/compile/internal/ssa/gen/386.rules   |   32 +-
 src/cmd/compile/internal/ssa/gen/386Ops.go   |   22 +-
 src/cmd/compile/internal/ssa/gen/AMD64.rules |  322 +++----
 src/cmd/compile/internal/ssa/gen/AMD64Ops.go |   80 +-
 src/cmd/compile/internal/ssa/opGen.go        |  192 ++--
 src/cmd/compile/internal/ssa/rewrite.go      |    4 +-
 src/cmd/compile/internal/ssa/rewrite386.go   |  290 +++---
 src/cmd/compile/internal/ssa/rewriteAMD64.go | 1260 +++++++++++++-------------
 src/cmd/compile/internal/x86/ssa.go          |    4 +-
 11 files changed, 1124 insertions(+), 1124 deletions(-)

diff --git a/src/cmd/compile/internal/amd64/ssa.go b/src/cmd/compile/internal/amd64/ssa.go
index c0629ec514..307cdc5e83 100644
--- a/src/cmd/compile/internal/amd64/ssa.go
+++ b/src/cmd/compile/internal/amd64/ssa.go
@@ -587,14 +587,14 @@ func ssaGenValue(s *gc.SSAGenState, v *ssa.Value) {
 		p.From.Offset = v.AuxInt
 		p.To.Type = obj.TYPE_REG
 		p.To.Reg = v.Args[0].Reg()
-	case ssa.OpAMD64CMPQmem, ssa.OpAMD64CMPLmem, ssa.OpAMD64CMPWmem, ssa.OpAMD64CMPBmem:
+	case ssa.OpAMD64CMPQload, ssa.OpAMD64CMPLload, ssa.OpAMD64CMPWload, ssa.OpAMD64CMPBload:
 		p := s.Prog(v.Op.Asm())
 		p.From.Type = obj.TYPE_MEM
 		p.From.Reg = v.Args[0].Reg()
 		gc.AddAux(&p.From, v)
 		p.To.Type = obj.TYPE_REG
 		p.To.Reg = v.Args[1].Reg()
-	case ssa.OpAMD64CMPQconstmem, ssa.OpAMD64CMPLconstmem, ssa.OpAMD64CMPWconstmem, ssa.OpAMD64CMPBconstmem:
+	case ssa.OpAMD64CMPQconstload, ssa.OpAMD64CMPLconstload, ssa.OpAMD64CMPWconstload, ssa.OpAMD64CMPBconstload:
 		sc := v.AuxValAndOff()
 		p := s.Prog(v.Op.Asm())
 		p.From.Type = obj.TYPE_MEM
@@ -731,13 +731,13 @@ func ssaGenValue(s *gc.SSAGenState, v *ssa.Value) {
 		p.To.Scale = 1
 		p.To.Index = i
 		gc.AddAux(&p.To, v)
-	case ssa.OpAMD64ADDQconstmem, ssa.OpAMD64ADDLconstmem:
+	case ssa.OpAMD64ADDQconstmodify, ssa.OpAMD64ADDLconstmodify:
 		sc := v.AuxValAndOff()
 		off := sc.Off()
 		val := sc.Val()
 		if val == 1 {
 			var asm obj.As
-			if v.Op == ssa.OpAMD64ADDQconstmem {
+			if v.Op == ssa.OpAMD64ADDQconstmodify {
 				asm = x86.AINCQ
 			} else {
 				asm = x86.AINCL
@@ -807,10 +807,10 @@ func ssaGenValue(s *gc.SSAGenState, v *ssa.Value) {
 		p.From.Reg = v.Args[0].Reg()
 		p.To.Type = obj.TYPE_REG
 		p.To.Reg = v.Reg()
-	case ssa.OpAMD64ADDQmem, ssa.OpAMD64ADDLmem, ssa.OpAMD64SUBQmem, ssa.OpAMD64SUBLmem,
-		ssa.OpAMD64ANDQmem, ssa.OpAMD64ANDLmem, ssa.OpAMD64ORQmem, ssa.OpAMD64ORLmem,
-		ssa.OpAMD64XORQmem, ssa.OpAMD64XORLmem, ssa.OpAMD64ADDSDmem, ssa.OpAMD64ADDSSmem,
-		ssa.OpAMD64SUBSDmem, ssa.OpAMD64SUBSSmem, ssa.OpAMD64MULSDmem, ssa.OpAMD64MULSSmem:
+	case ssa.OpAMD64ADDQload, ssa.OpAMD64ADDLload, ssa.OpAMD64SUBQload, ssa.OpAMD64SUBLload,
+		ssa.OpAMD64ANDQload, ssa.OpAMD64ANDLload, ssa.OpAMD64ORQload, ssa.OpAMD64ORLload,
+		ssa.OpAMD64XORQload, ssa.OpAMD64XORLload, ssa.OpAMD64ADDSDload, ssa.OpAMD64ADDSSload,
+		ssa.OpAMD64SUBSDload, ssa.OpAMD64SUBSSload, ssa.OpAMD64MULSDload, ssa.OpAMD64MULSSload:
 		p := s.Prog(v.Op.Asm())
 		p.From.Type = obj.TYPE_MEM
 		p.From.Reg = v.Args[1].Reg()
@@ -1003,11 +1003,11 @@ func ssaGenValue(s *gc.SSAGenState, v *ssa.Value) {
 		p.To.Type = obj.TYPE_REG
 		p.To.Reg = v.Reg()
 
-	case ssa.OpAMD64SETEQmem, ssa.OpAMD64SETNEmem,
-		ssa.OpAMD64SETLmem, ssa.OpAMD64SETLEmem,
-		ssa.OpAMD64SETGmem, ssa.OpAMD64SETGEmem,
-		ssa.OpAMD64SETBmem, ssa.OpAMD64SETBEmem,
-		ssa.OpAMD64SETAmem, ssa.OpAMD64SETAEmem:
+	case ssa.OpAMD64SETEQstore, ssa.OpAMD64SETNEstore,
+		ssa.OpAMD64SETLstore, ssa.OpAMD64SETLEstore,
+		ssa.OpAMD64SETGstore, ssa.OpAMD64SETGEstore,
+		ssa.OpAMD64SETBstore, ssa.OpAMD64SETBEstore,
+		ssa.OpAMD64SETAstore, ssa.OpAMD64SETAEstore:
 		p := s.Prog(v.Op.Asm())
 		p.To.Type = obj.TYPE_MEM
 		p.To.Reg = v.Args[0].Reg()
diff --git a/src/cmd/compile/internal/ssa/flagalloc.go b/src/cmd/compile/internal/ssa/flagalloc.go
index 3c910a1afd..050595ff8d 100644
--- a/src/cmd/compile/internal/ssa/flagalloc.go
+++ b/src/cmd/compile/internal/ssa/flagalloc.go
@@ -121,53 +121,53 @@ func flagalloc(f *Func) {
 			// TODO: figure out how to do this without arch-dependent code.
 			if spill[v.ID] && v.MemoryArg() != nil {
 				switch v.Op {
-				case OpAMD64CMPQmem:
+				case OpAMD64CMPQload:
 					load := b.NewValue2IA(v.Pos, OpAMD64MOVQload, f.Config.Types.UInt64, v.AuxInt, v.Aux, v.Args[0], v.Args[2])
 					v.Op = OpAMD64CMPQ
 					v.AuxInt = 0
 					v.Aux = nil
 					v.SetArgs2(load, v.Args[1])
-				case OpAMD64CMPLmem:
+				case OpAMD64CMPLload:
 					load := b.NewValue2IA(v.Pos, OpAMD64MOVLload, f.Config.Types.UInt32, v.AuxInt, v.Aux, v.Args[0], v.Args[2])
 					v.Op = OpAMD64CMPL
 					v.AuxInt = 0
 					v.Aux = nil
 					v.SetArgs2(load, v.Args[1])
-				case OpAMD64CMPWmem:
+				case OpAMD64CMPWload:
 					load := b.NewValue2IA(v.Pos, OpAMD64MOVWload, f.Config.Types.UInt16, v.AuxInt, v.Aux, v.Args[0], v.Args[2])
 					v.Op = OpAMD64CMPW
 					v.AuxInt = 0
 					v.Aux = nil
 					v.SetArgs2(load, v.Args[1])
-				case OpAMD64CMPBmem:
+				case OpAMD64CMPBload:
 					load := b.NewValue2IA(v.Pos, OpAMD64MOVBload, f.Config.Types.UInt8, v.AuxInt, v.Aux, v.Args[0], v.Args[2])
 					v.Op = OpAMD64CMPB
 					v.AuxInt = 0
 					v.Aux = nil
 					v.SetArgs2(load, v.Args[1])
 
-				case OpAMD64CMPQconstmem:
+				case OpAMD64CMPQconstload:
 					vo := v.AuxValAndOff()
 					load := b.NewValue2IA(v.Pos, OpAMD64MOVQload, f.Config.Types.UInt64, vo.Off(), v.Aux, v.Args[0], v.Args[1])
 					v.Op = OpAMD64CMPQconst
 					v.AuxInt = vo.Val()
 					v.Aux = nil
 					v.SetArgs1(load)
-				case OpAMD64CMPLconstmem:
+				case OpAMD64CMPLconstload:
 					vo := v.AuxValAndOff()
 					load := b.NewValue2IA(v.Pos, OpAMD64MOVLload, f.Config.Types.UInt32, vo.Off(), v.Aux, v.Args[0], v.Args[1])
 					v.Op = OpAMD64CMPLconst
 					v.AuxInt = vo.Val()
 					v.Aux = nil
 					v.SetArgs1(load)
-				case OpAMD64CMPWconstmem:
+				case OpAMD64CMPWconstload:
 					vo := v.AuxValAndOff()
 					load := b.NewValue2IA(v.Pos, OpAMD64MOVWload, f.Config.Types.UInt16, vo.Off(), v.Aux, v.Args[0], v.Args[1])
 					v.Op = OpAMD64CMPWconst
 					v.AuxInt = vo.Val()
 					v.Aux = nil
 					v.SetArgs1(load)
-				case OpAMD64CMPBconstmem:
+				case OpAMD64CMPBconstload:
 					vo := v.AuxValAndOff()
 					load := b.NewValue2IA(v.Pos, OpAMD64MOVBload, f.Config.Types.UInt8, vo.Off(), v.Aux, v.Args[0], v.Args[1])
 					v.Op = OpAMD64CMPBconst
diff --git a/src/cmd/compile/internal/ssa/gen/386.rules b/src/cmd/compile/internal/ssa/gen/386.rules
index aa678add21..570685436a 100644
--- a/src/cmd/compile/internal/ssa/gen/386.rules
+++ b/src/cmd/compile/internal/ssa/gen/386.rules
@@ -635,12 +635,12 @@
 (MOVSSstore [off1] {sym} (ADDLconst [off2] ptr) val mem) && is32Bit(off1+off2) -> (MOVSSstore [off1+off2] {sym} ptr val mem)
 (MOVSDstore [off1] {sym} (ADDLconst [off2] ptr) val mem) && is32Bit(off1+off2) -> (MOVSDstore [off1+off2] {sym} ptr val mem)
 
-((ADD|SUB|AND|OR|XOR)Lmem [off1] {sym} val (ADDLconst [off2] base) mem) && is32Bit(off1+off2) ->
-	((ADD|SUB|AND|OR|XOR)Lmem [off1+off2] {sym} val base mem)
-((ADD|SUB|MUL)SSmem [off1] {sym} val (ADDLconst [off2] base) mem) && is32Bit(off1+off2) ->
-	((ADD|SUB|MUL)SSmem [off1+off2] {sym} val base mem)
-((ADD|SUB|MUL)SDmem [off1] {sym} val (ADDLconst [off2] base) mem) && is32Bit(off1+off2) ->
-	((ADD|SUB|MUL)SDmem [off1+off2] {sym} val base mem)
+((ADD|SUB|AND|OR|XOR)Lload [off1] {sym} val (ADDLconst [off2] base) mem) && is32Bit(off1+off2) ->
+	((ADD|SUB|AND|OR|XOR)Lload [off1+off2] {sym} val base mem)
+((ADD|SUB|MUL)SSload [off1] {sym} val (ADDLconst [off2] base) mem) && is32Bit(off1+off2) ->
+	((ADD|SUB|MUL)SSload [off1+off2] {sym} val base mem)
+((ADD|SUB|MUL)SDload [off1] {sym} val (ADDLconst [off2] base) mem) && is32Bit(off1+off2) ->
+	((ADD|SUB|MUL)SDload [off1+off2] {sym} val base mem)
 ((ADD|SUB|AND|OR|XOR)Lmodify [off1] {sym} (ADDLconst [off2] base) val mem) && is32Bit(off1+off2) ->
 	((ADD|SUB|AND|OR|XOR)Lmodify [off1+off2] {sym} base val mem)
 
@@ -756,15 +756,15 @@
 (MOVSDstore [off1] {sym1} (LEAL8 [off2] {sym2} ptr idx) val mem) && is32Bit(off1+off2) && canMergeSym(sym1, sym2) ->
 	(MOVSDstoreidx8 [off1+off2] {mergeSym(sym1,sym2)} ptr idx val mem)
 
-((ADD|SUB|AND|OR|XOR)Lmem [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
+((ADD|SUB|AND|OR|XOR)Lload [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
 	&& is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared) ->
-	((ADD|SUB|AND|OR|XOR)Lmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
-((ADD|SUB|MUL)SSmem [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
+	((ADD|SUB|AND|OR|XOR)Lload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+((ADD|SUB|MUL)SSload [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
 	&& is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared) ->
-	((ADD|SUB|MUL)SSmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
-((ADD|SUB|MUL)SDmem [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
+	((ADD|SUB|MUL)SSload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+((ADD|SUB|MUL)SDload [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
 	&& is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared) ->
-	((ADD|SUB|MUL)SDmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	((ADD|SUB|MUL)SDload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 ((ADD|SUB|AND|OR|XOR)Lmodify [off1] {sym1} (LEAL [off2] {sym2} base) val mem)
 	&& is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared) ->
 	((ADD|SUB|AND|OR|XOR)Lmodify [off1+off2] {mergeSym(sym1,sym2)} base val mem)
@@ -845,10 +845,10 @@
 (MOVSDstoreidx8 [c] {sym} ptr (ADDLconst [d] idx) val mem) -> (MOVSDstoreidx8 [int64(int32(c+8*d))] {sym} ptr idx val mem)
 
 // Merge load/store to op
-((ADD|AND|OR|XOR|SUB)L x l:(MOVLload [off] {sym} ptr mem)) && canMergeLoad(v, l, x) && clobber(l) -> ((ADD|AND|OR|XOR|SUB)Lmem x [off] {sym} ptr mem)
-((ADD|SUB|MUL)SD x l:(MOVSDload [off] {sym} ptr mem)) && canMergeLoad(v, l, x) && !config.use387 && clobber(l) -> ((ADD|SUB|MUL)SDmem x [off] {sym} ptr mem)
-((ADD|SUB|MUL)SS x l:(MOVSSload [off] {sym} ptr mem)) && canMergeLoad(v, l, x) && !config.use387 && clobber(l) -> ((ADD|SUB|MUL)SSmem x [off] {sym} ptr mem)
-(MOVLstore {sym} [off] ptr y:((ADD|AND|OR|XOR)Lmem x [off] {sym} ptr mem) mem) && y.Uses==1 && clobber(y) -> ((ADD|AND|OR|XOR)Lmodify [off] {sym} ptr x mem)
+((ADD|AND|OR|XOR|SUB)L x l:(MOVLload [off] {sym} ptr mem)) && canMergeLoad(v, l, x) && clobber(l) -> ((ADD|AND|OR|XOR|SUB)Lload x [off] {sym} ptr mem)
+((ADD|SUB|MUL)SD x l:(MOVSDload [off] {sym} ptr mem)) && canMergeLoad(v, l, x) && !config.use387 && clobber(l) -> ((ADD|SUB|MUL)SDload x [off] {sym} ptr mem)
+((ADD|SUB|MUL)SS x l:(MOVSSload [off] {sym} ptr mem)) && canMergeLoad(v, l, x) && !config.use387 && clobber(l) -> ((ADD|SUB|MUL)SSload x [off] {sym} ptr mem)
+(MOVLstore {sym} [off] ptr y:((ADD|AND|OR|XOR)Lload x [off] {sym} ptr mem) mem) && y.Uses==1 && clobber(y) -> ((ADD|AND|OR|XOR)Lmodify [off] {sym} ptr x mem)
 (MOVLstore {sym} [off] ptr y:((ADD|SUB|AND|OR|XOR)L l:(MOVLload [off] {sym} ptr mem) x) mem) && y.Uses==1 && l.Uses==1 && clobber(y) && clobber(l) ->
 	((ADD|SUB|AND|OR|XOR)Lmodify [off] {sym} ptr x mem)
 
diff --git a/src/cmd/compile/internal/ssa/gen/386Ops.go b/src/cmd/compile/internal/ssa/gen/386Ops.go
index 076782e2fa..6c1d506ae4 100644
--- a/src/cmd/compile/internal/ssa/gen/386Ops.go
+++ b/src/cmd/compile/internal/ssa/gen/386Ops.go
@@ -175,12 +175,12 @@ func init() {
 		{name: "MOVSDstoreidx1", argLength: 4, reg: fpstoreidx, asm: "MOVSD", aux: "SymOff", symEffect: "Write"},                // fp64 indexed by i store
 		{name: "MOVSDstoreidx8", argLength: 4, reg: fpstoreidx, asm: "MOVSD", aux: "SymOff", symEffect: "Write"},                // fp64 indexed by 8i store
 
-		{name: "ADDSSmem", argLength: 3, reg: fp21load, asm: "ADDSS", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp32 arg0 + tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
-		{name: "ADDSDmem", argLength: 3, reg: fp21load, asm: "ADDSD", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp64 arg0 + tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
-		{name: "SUBSSmem", argLength: 3, reg: fp21load, asm: "SUBSS", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp32 arg0 - tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
-		{name: "SUBSDmem", argLength: 3, reg: fp21load, asm: "SUBSD", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp64 arg0 - tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
-		{name: "MULSSmem", argLength: 3, reg: fp21load, asm: "MULSS", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp32 arg0 * tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
-		{name: "MULSDmem", argLength: 3, reg: fp21load, asm: "MULSD", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp64 arg0 * tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
+		{name: "ADDSSload", argLength: 3, reg: fp21load, asm: "ADDSS", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp32 arg0 + tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
+		{name: "ADDSDload", argLength: 3, reg: fp21load, asm: "ADDSD", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp64 arg0 + tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
+		{name: "SUBSSload", argLength: 3, reg: fp21load, asm: "SUBSS", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp32 arg0 - tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
+		{name: "SUBSDload", argLength: 3, reg: fp21load, asm: "SUBSD", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp64 arg0 - tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
+		{name: "MULSSload", argLength: 3, reg: fp21load, asm: "MULSS", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp32 arg0 * tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
+		{name: "MULSDload", argLength: 3, reg: fp21load, asm: "MULSD", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp64 arg0 * tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
 
 		// binary ops
 		{name: "ADDL", argLength: 2, reg: gp21sp, asm: "ADDL", commutative: true, clobberFlags: true},                // arg0 + arg1
@@ -267,11 +267,11 @@ func init() {
 		{name: "ROLWconst", argLength: 1, reg: gp11, asm: "ROLW", aux: "Int16", resultInArg0: true, clobberFlags: true}, // arg0 rotate left auxint, rotate amount 0-15
 		{name: "ROLBconst", argLength: 1, reg: gp11, asm: "ROLB", aux: "Int8", resultInArg0: true, clobberFlags: true},  // arg0 rotate left auxint, rotate amount 0-7
 
-		{name: "ADDLmem", argLength: 3, reg: gp21load, asm: "ADDL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 + tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
-		{name: "SUBLmem", argLength: 3, reg: gp21load, asm: "SUBL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 - tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
-		{name: "ANDLmem", argLength: 3, reg: gp21load, asm: "ANDL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 & tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
-		{name: "ORLmem", argLength: 3, reg: gp21load, asm: "ORL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"},   // arg0 | tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
-		{name: "XORLmem", argLength: 3, reg: gp21load, asm: "XORL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 ^ tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
+		{name: "ADDLload", argLength: 3, reg: gp21load, asm: "ADDL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 + tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
+		{name: "SUBLload", argLength: 3, reg: gp21load, asm: "SUBL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 - tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
+		{name: "ANDLload", argLength: 3, reg: gp21load, asm: "ANDL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 & tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
+		{name: "ORLload", argLength: 3, reg: gp21load, asm: "ORL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"},   // arg0 | tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
+		{name: "XORLload", argLength: 3, reg: gp21load, asm: "XORL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 ^ tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
 
 		// unary ops
 		{name: "NEGL", argLength: 1, reg: gp11, asm: "NEGL", resultInArg0: true, clobberFlags: true}, // -arg0
diff --git a/src/cmd/compile/internal/ssa/gen/AMD64.rules b/src/cmd/compile/internal/ssa/gen/AMD64.rules
index 45c82a0cd7..23b03d3080 100644
--- a/src/cmd/compile/internal/ssa/gen/AMD64.rules
+++ b/src/cmd/compile/internal/ssa/gen/AMD64.rules
@@ -456,16 +456,16 @@
 (Addr {sym} base) && config.PtrSize == 8 -> (LEAQ {sym} base)
 (Addr {sym} base) && config.PtrSize == 4 -> (LEAL {sym} base)
 
-(MOVBstore [off] {sym} ptr y:(SETL x) mem) && y.Uses == 1 -> (SETLmem [off] {sym} ptr x mem)
-(MOVBstore [off] {sym} ptr y:(SETLE x) mem) && y.Uses == 1 -> (SETLEmem [off] {sym} ptr x mem)
-(MOVBstore [off] {sym} ptr y:(SETG x) mem) && y.Uses == 1 -> (SETGmem [off] {sym} ptr x mem)
-(MOVBstore [off] {sym} ptr y:(SETGE x) mem) && y.Uses == 1 -> (SETGEmem [off] {sym} ptr x mem)
-(MOVBstore [off] {sym} ptr y:(SETEQ x) mem) && y.Uses == 1 -> (SETEQmem [off] {sym} ptr x mem)
-(MOVBstore [off] {sym} ptr y:(SETNE x) mem) && y.Uses == 1 -> (SETNEmem [off] {sym} ptr x mem)
-(MOVBstore [off] {sym} ptr y:(SETB x) mem) && y.Uses == 1 -> (SETBmem [off] {sym} ptr x mem)
-(MOVBstore [off] {sym} ptr y:(SETBE x) mem) && y.Uses == 1 -> (SETBEmem [off] {sym} ptr x mem)
-(MOVBstore [off] {sym} ptr y:(SETA x) mem) && y.Uses == 1 -> (SETAmem [off] {sym} ptr x mem)
-(MOVBstore [off] {sym} ptr y:(SETAE x) mem) && y.Uses == 1 -> (SETAEmem [off] {sym} ptr x mem)
+(MOVBstore [off] {sym} ptr y:(SETL x) mem) && y.Uses == 1 -> (SETLstore [off] {sym} ptr x mem)
+(MOVBstore [off] {sym} ptr y:(SETLE x) mem) && y.Uses == 1 -> (SETLEstore [off] {sym} ptr x mem)
+(MOVBstore [off] {sym} ptr y:(SETG x) mem) && y.Uses == 1 -> (SETGstore [off] {sym} ptr x mem)
+(MOVBstore [off] {sym} ptr y:(SETGE x) mem) && y.Uses == 1 -> (SETGEstore [off] {sym} ptr x mem)
+(MOVBstore [off] {sym} ptr y:(SETEQ x) mem) && y.Uses == 1 -> (SETEQstore [off] {sym} ptr x mem)
+(MOVBstore [off] {sym} ptr y:(SETNE x) mem) && y.Uses == 1 -> (SETNEstore [off] {sym} ptr x mem)
+(MOVBstore [off] {sym} ptr y:(SETB x) mem) && y.Uses == 1 -> (SETBstore [off] {sym} ptr x mem)
+(MOVBstore [off] {sym} ptr y:(SETBE x) mem) && y.Uses == 1 -> (SETBEstore [off] {sym} ptr x mem)
+(MOVBstore [off] {sym} ptr y:(SETA x) mem) && y.Uses == 1 -> (SETAstore [off] {sym} ptr x mem)
+(MOVBstore [off] {sym} ptr y:(SETAE x) mem) && y.Uses == 1 -> (SETAEstore [off] {sym} ptr x mem)
 
 // block rewrites
 (If (SETL  cmp) yes no) -> (LT  cmp yes no)
@@ -562,17 +562,17 @@
     -> (SET(B|AE)  (BTQconst [log2(c)] x))
 (SET(NE|EQ) (TESTQ (MOVQconst [c]) x)) && isUint64PowerOfTwo(c) && !config.nacl
     -> (SET(B|AE)  (BTQconst [log2(c)] x))
-// SET..mem variant
-(SET(NE|EQ)mem [off] {sym} ptr (TESTL (SHLL (MOVLconst [1]) x) y) mem) && !config.nacl
-    -> (SET(B|AE)mem  [off] {sym} ptr (BTL x y) mem)
-(SET(NE|EQ)mem [off] {sym} ptr (TESTQ (SHLQ (MOVQconst [1]) x) y) mem) && !config.nacl
-    -> (SET(B|AE)mem  [off] {sym} ptr (BTQ x y) mem)
-(SET(NE|EQ)mem [off] {sym} ptr (TESTLconst [c] x) mem) && isUint32PowerOfTwo(c) && !config.nacl
-    -> (SET(B|AE)mem  [off] {sym} ptr (BTLconst [log2uint32(c)] x) mem)
-(SET(NE|EQ)mem [off] {sym} ptr (TESTQconst [c] x) mem) && isUint64PowerOfTwo(c) && !config.nacl
-    -> (SET(B|AE)mem  [off] {sym} ptr (BTQconst [log2(c)] x) mem)
-(SET(NE|EQ)mem [off] {sym} ptr (TESTQ (MOVQconst [c]) x) mem) && isUint64PowerOfTwo(c) && !config.nacl
-    -> (SET(B|AE)mem  [off] {sym} ptr (BTQconst [log2(c)] x) mem)
+// SET..store variant
+(SET(NE|EQ)store [off] {sym} ptr (TESTL (SHLL (MOVLconst [1]) x) y) mem) && !config.nacl
+    -> (SET(B|AE)store  [off] {sym} ptr (BTL x y) mem)
+(SET(NE|EQ)store [off] {sym} ptr (TESTQ (SHLQ (MOVQconst [1]) x) y) mem) && !config.nacl
+    -> (SET(B|AE)store  [off] {sym} ptr (BTQ x y) mem)
+(SET(NE|EQ)store [off] {sym} ptr (TESTLconst [c] x) mem) && isUint32PowerOfTwo(c) && !config.nacl
+    -> (SET(B|AE)store  [off] {sym} ptr (BTLconst [log2uint32(c)] x) mem)
+(SET(NE|EQ)store [off] {sym} ptr (TESTQconst [c] x) mem) && isUint64PowerOfTwo(c) && !config.nacl
+    -> (SET(B|AE)store  [off] {sym} ptr (BTQconst [log2(c)] x) mem)
+(SET(NE|EQ)store [off] {sym} ptr (TESTQ (MOVQconst [c]) x) mem) && isUint64PowerOfTwo(c) && !config.nacl
+    -> (SET(B|AE)store  [off] {sym} ptr (BTQconst [log2(c)] x) mem)
 
 // Handle bit-testing in the form (a>>b)&1 != 0 by building the above rules
 // and further combining shifts.
@@ -586,9 +586,9 @@
 // Rewrite a & 1 != 1 into a & 1 == 0.
 // Among other things, this lets us turn (a>>b)&1 != 1 into a bit test.
 (SET(NE|EQ) (CMPLconst [1] s:(ANDLconst [1] _))) -> (SET(EQ|NE) (CMPLconst [0] s))
-(SET(NE|EQ)mem [off] {sym} ptr (CMPLconst [1] s:(ANDLconst [1] _)) mem) -> (SET(EQ|NE)mem [off] {sym} ptr (CMPLconst [0] s) mem)
+(SET(NE|EQ)store [off] {sym} ptr (CMPLconst [1] s:(ANDLconst [1] _)) mem) -> (SET(EQ|NE)store [off] {sym} ptr (CMPLconst [0] s) mem)
 (SET(NE|EQ) (CMPQconst [1] s:(ANDQconst [1] _))) -> (SET(EQ|NE) (CMPQconst [0] s))
-(SET(NE|EQ)mem [off] {sym} ptr (CMPQconst [1] s:(ANDQconst [1] _)) mem) -> (SET(EQ|NE)mem [off] {sym} ptr (CMPQconst [0] s) mem)
+(SET(NE|EQ)store [off] {sym} ptr (CMPQconst [1] s:(ANDQconst [1] _)) mem) -> (SET(EQ|NE)store [off] {sym} ptr (CMPQconst [0] s) mem)
 
 // Recognize bit setting (a |= 1<<b) and toggling (a ^= 1<<b)
 (OR(Q|L) (SHL(Q|L) (MOV(Q|L)const [1]) y) x) && !config.nacl -> (BTS(Q|L) x y)
@@ -639,29 +639,29 @@
     -> ((SETB|SETAE|ULT|UGE) (BTQconst [63] x))
 ((SETNE|SETEQ|NE|EQ) (TESTL z1:(SHLLconst [31] (SHRQconst [31] x)) z2)) && z1==z2 && !config.nacl
     -> ((SETB|SETAE|ULT|UGE) (BTQconst [31] x))
-(SET(NE|EQ)mem [off] {sym} ptr (TESTQ z1:(SHLQconst [63] (SHRQconst [63] x)) z2) mem) && z1==z2 && !config.nacl
-    -> (SET(B|AE)mem [off] {sym} ptr (BTQconst [63] x) mem)
-(SET(NE|EQ)mem [off] {sym} ptr (TESTL z1:(SHLLconst [31] (SHRLconst [31] x)) z2) mem) && z1==z2 && !config.nacl
-    -> (SET(B|AE)mem [off] {sym} ptr (BTLconst [31] x) mem)
+(SET(NE|EQ)store [off] {sym} ptr (TESTQ z1:(SHLQconst [63] (SHRQconst [63] x)) z2) mem) && z1==z2 && !config.nacl
+    -> (SET(B|AE)store [off] {sym} ptr (BTQconst [63] x) mem)
+(SET(NE|EQ)store [off] {sym} ptr (TESTL z1:(SHLLconst [31] (SHRLconst [31] x)) z2) mem) && z1==z2 && !config.nacl
+    -> (SET(B|AE)store [off] {sym} ptr (BTLconst [31] x) mem)
 
 ((SETNE|SETEQ|NE|EQ) (TESTQ z1:(SHRQconst [63] (SHLQconst [63] x)) z2)) && z1==z2 && !config.nacl
     -> ((SETB|SETAE|ULT|UGE)  (BTQconst [0] x))
 ((SETNE|SETEQ|NE|EQ) (TESTL z1:(SHRLconst [31] (SHLLconst [31] x)) z2)) && z1==z2 && !config.nacl
     -> ((SETB|SETAE|ULT|UGE)  (BTLconst [0] x))
-(SET(NE|EQ)mem [off] {sym} ptr (TESTQ z1:(SHRQconst [63] (SHLQconst [63] x)) z2) mem) && z1==z2 && !config.nacl
-    -> (SET(B|AE)mem [off] {sym} ptr (BTQconst [0] x) mem)
-(SET(NE|EQ)mem [off] {sym} ptr (TESTL z1:(SHRLconst [31] (SHLLconst [31] x)) z2) mem) && z1==z2 && !config.nacl
-    -> (SET(B|AE)mem [off] {sym} ptr (BTLconst [0] x) mem)
+(SET(NE|EQ)store [off] {sym} ptr (TESTQ z1:(SHRQconst [63] (SHLQconst [63] x)) z2) mem) && z1==z2 && !config.nacl
+    -> (SET(B|AE)store [off] {sym} ptr (BTQconst [0] x) mem)
+(SET(NE|EQ)store [off] {sym} ptr (TESTL z1:(SHRLconst [31] (SHLLconst [31] x)) z2) mem) && z1==z2 && !config.nacl
+    -> (SET(B|AE)store [off] {sym} ptr (BTLconst [0] x) mem)
 
 // Special-case manually testing last bit with "a>>63 != 0" (without "&1")
 ((SETNE|SETEQ|NE|EQ) (TESTQ z1:(SHRQconst [63] x) z2)) && z1==z2 && !config.nacl
     -> ((SETB|SETAE|ULT|UGE) (BTQconst [63] x))
 ((SETNE|SETEQ|NE|EQ) (TESTL z1:(SHRLconst [31] x) z2)) && z1==z2 && !config.nacl
     -> ((SETB|SETAE|ULT|UGE) (BTLconst [31] x))
-(SET(NE|EQ)mem [off] {sym} ptr (TESTQ z1:(SHRQconst [63] x) z2) mem) && z1==z2 && !config.nacl
-    -> (SET(B|AE)mem [off] {sym} ptr (BTQconst [63] x) mem)
-(SET(NE|EQ)mem [off] {sym} ptr (TESTL z1:(SHRLconst [31] x) z2) mem) && z1==z2 && !config.nacl
-    -> (SET(B|AE)mem [off] {sym} ptr (BTLconst [31] x) mem)
+(SET(NE|EQ)store [off] {sym} ptr (TESTQ z1:(SHRQconst [63] x) z2) mem) && z1==z2 && !config.nacl
+    -> (SET(B|AE)store [off] {sym} ptr (BTQconst [63] x) mem)
+(SET(NE|EQ)store [off] {sym} ptr (TESTL z1:(SHRLconst [31] x) z2) mem) && z1==z2 && !config.nacl
+    -> (SET(B|AE)store [off] {sym} ptr (BTLconst [31] x) mem)
 
 // Fold combinations of bit ops on same bit. An example is math.Copysign(c,-1)
 (BTS(Q|L)const [c] (BTR(Q|L)const [c] x)) -> (BTS(Q|L)const [c] x)
@@ -947,16 +947,16 @@
 (SETEQ (InvertFlags x)) -> (SETEQ x)
 (SETNE (InvertFlags x)) -> (SETNE x)
 
-(SETLmem [off] {sym} ptr (InvertFlags x) mem) -> (SETGmem [off] {sym} ptr x mem)
-(SETGmem [off] {sym} ptr (InvertFlags x) mem) -> (SETLmem [off] {sym} ptr x mem)
-(SETBmem [off] {sym} ptr (InvertFlags x) mem) -> (SETAmem [off] {sym} ptr x mem)
-(SETAmem [off] {sym} ptr (InvertFlags x) mem) -> (SETBmem [off] {sym} ptr x mem)
-(SETLEmem [off] {sym} ptr (InvertFlags x) mem) -> (SETGEmem [off] {sym} ptr x mem)
-(SETGEmem [off] {sym} ptr (InvertFlags x) mem) -> (SETLEmem [off] {sym} ptr x mem)
-(SETBEmem [off] {sym} ptr (InvertFlags x) mem) -> (SETAEmem [off] {sym} ptr x mem)
-(SETAEmem [off] {sym} ptr (InvertFlags x) mem) -> (SETBEmem [off] {sym} ptr x mem)
-(SETEQmem [off] {sym} ptr (InvertFlags x) mem) -> (SETEQmem [off] {sym} ptr x mem)
-(SETNEmem [off] {sym} ptr (InvertFlags x) mem) -> (SETNEmem [off] {sym} ptr x mem)
+(SETLstore [off] {sym} ptr (InvertFlags x) mem) -> (SETGstore [off] {sym} ptr x mem)
+(SETGstore [off] {sym} ptr (InvertFlags x) mem) -> (SETLstore [off] {sym} ptr x mem)
+(SETBstore [off] {sym} ptr (InvertFlags x) mem) -> (SETAstore [off] {sym} ptr x mem)
+(SETAstore [off] {sym} ptr (InvertFlags x) mem) -> (SETBstore [off] {sym} ptr x mem)
+(SETLEstore [off] {sym} ptr (InvertFlags x) mem) -> (SETGEstore [off] {sym} ptr x mem)
+(SETGEstore [off] {sym} ptr (InvertFlags x) mem) -> (SETLEstore [off] {sym} ptr x mem)
+(SETBEstore [off] {sym} ptr (InvertFlags x) mem) -> (SETAEstore [off] {sym} ptr x mem)
+(SETAEstore [off] {sym} ptr (InvertFlags x) mem) -> (SETBEstore [off] {sym} ptr x mem)
+(SETEQstore [off] {sym} ptr (InvertFlags x) mem) -> (SETEQstore [off] {sym} ptr x mem)
+(SETNEstore [off] {sym} ptr (InvertFlags x) mem) -> (SETNEstore [off] {sym} ptr x mem)
 
 // sign extended loads
 // Note: The combined instruction must end up in the same block
@@ -1027,18 +1027,18 @@
     (MOV(Q|L|W|B|SS|SD|O)load  [off1+off2] {sym} ptr mem)
 (MOV(Q|L|W|B|SS|SD|O)store  [off1] {sym} (ADDQconst [off2] ptr) val mem) && is32Bit(off1+off2) ->
 	(MOV(Q|L|W|B|SS|SD|O)store  [off1+off2] {sym} ptr val mem)
-(SET(L|G|B|A|LE|GE|BE|AE|EQ|NE)mem [off1] {sym} (ADDQconst [off2] base) val mem) && is32Bit(off1+off2) ->
-	(SET(L|G|B|A|LE|GE|BE|AE|EQ|NE)mem [off1+off2] {sym} base val mem)
-((ADD|SUB|AND|OR|XOR)Qmem [off1] {sym} val (ADDQconst [off2] base) mem) && is32Bit(off1+off2) ->
-	((ADD|SUB|AND|OR|XOR)Qmem [off1+off2] {sym} val base mem)
-((ADD|SUB|AND|OR|XOR)Lmem [off1] {sym} val (ADDQconst [off2] base) mem) && is32Bit(off1+off2) ->
-	((ADD|SUB|AND|OR|XOR)Lmem [off1+off2] {sym} val base mem)
-((ADD|SUB|MUL)SSmem [off1] {sym} val (ADDQconst [off2] base) mem) && is32Bit(off1+off2) ->
-	((ADD|SUB|MUL)SSmem [off1+off2] {sym} val base mem)
-((ADD|SUB|MUL)SDmem [off1] {sym} val (ADDQconst [off2] base) mem) && is32Bit(off1+off2) ->
-	((ADD|SUB|MUL)SDmem [off1+off2] {sym} val base mem)
-(ADD(L|Q)constmem [valoff1] {sym} (ADDQconst [off2] base) mem) && ValAndOff(valoff1).canAdd(off2) ->
-	(ADD(L|Q)constmem [ValAndOff(valoff1).add(off2)] {sym} base mem)
+(SET(L|G|B|A|LE|GE|BE|AE|EQ|NE)store [off1] {sym} (ADDQconst [off2] base) val mem) && is32Bit(off1+off2) ->
+	(SET(L|G|B|A|LE|GE|BE|AE|EQ|NE)store [off1+off2] {sym} base val mem)
+((ADD|SUB|AND|OR|XOR)Qload [off1] {sym} val (ADDQconst [off2] base) mem) && is32Bit(off1+off2) ->
+	((ADD|SUB|AND|OR|XOR)Qload [off1+off2] {sym} val base mem)
+((ADD|SUB|AND|OR|XOR)Lload [off1] {sym} val (ADDQconst [off2] base) mem) && is32Bit(off1+off2) ->
+	((ADD|SUB|AND|OR|XOR)Lload [off1+off2] {sym} val base mem)
+((ADD|SUB|MUL)SSload [off1] {sym} val (ADDQconst [off2] base) mem) && is32Bit(off1+off2) ->
+	((ADD|SUB|MUL)SSload [off1+off2] {sym} val base mem)
+((ADD|SUB|MUL)SDload [off1] {sym} val (ADDQconst [off2] base) mem) && is32Bit(off1+off2) ->
+	((ADD|SUB|MUL)SDload [off1+off2] {sym} val base mem)
+(ADD(L|Q)constmodify [valoff1] {sym} (ADDQconst [off2] base) mem) && ValAndOff(valoff1).canAdd(off2) ->
+	(ADD(L|Q)constmodify [ValAndOff(valoff1).add(off2)] {sym} base mem)
 
 // Fold constants into stores.
 (MOVQstore [off] {sym} ptr (MOVQconst [c]) mem) && validValAndOff(c,off) ->
@@ -1064,24 +1064,24 @@
 	(MOV(Q|L|W|B|SS|SD|O)store [off1+off2] {mergeSym(sym1,sym2)} base val mem)
 (MOV(Q|L|W|B)storeconst [sc] {sym1} (LEAQ [off] {sym2} ptr) mem) && canMergeSym(sym1, sym2) && ValAndOff(sc).canAdd(off) ->
 	(MOV(Q|L|W|B)storeconst [ValAndOff(sc).add(off)] {mergeSym(sym1, sym2)} ptr mem)
-(SET(L|G|B|A|LE|GE|BE|AE|EQ|NE)mem [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
+(SET(L|G|B|A|LE|GE|BE|AE|EQ|NE)store [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
 	&& is32Bit(off1+off2) && canMergeSym(sym1, sym2) ->
-	(SET(L|G|B|A|LE|GE|BE|AE|EQ|NE)mem [off1+off2] {mergeSym(sym1,sym2)} base val mem)
-((ADD|SUB|AND|OR|XOR)Qmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	(SET(L|G|B|A|LE|GE|BE|AE|EQ|NE)store [off1+off2] {mergeSym(sym1,sym2)} base val mem)
+((ADD|SUB|AND|OR|XOR)Qload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	&& is32Bit(off1+off2) && canMergeSym(sym1, sym2) ->
-	((ADD|SUB|AND|OR|XOR)Qmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
-((ADD|SUB|AND|OR|XOR)Lmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	((ADD|SUB|AND|OR|XOR)Qload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+((ADD|SUB|AND|OR|XOR)Lload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	&& is32Bit(off1+off2) && canMergeSym(sym1, sym2) ->
-	((ADD|SUB|AND|OR|XOR)Lmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
-((ADD|SUB|MUL)SSmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	((ADD|SUB|AND|OR|XOR)Lload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+((ADD|SUB|MUL)SSload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	&& is32Bit(off1+off2) && canMergeSym(sym1, sym2) ->
-	((ADD|SUB|MUL)SSmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
-((ADD|SUB|MUL)SDmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	((ADD|SUB|MUL)SSload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+((ADD|SUB|MUL)SDload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	&& is32Bit(off1+off2) && canMergeSym(sym1, sym2) ->
-	((ADD|SUB|MUL)SDmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
-(ADD(L|Q)constmem [valoff1] {sym1} (LEAQ [off2] {sym2} base) mem)
+	((ADD|SUB|MUL)SDload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+(ADD(L|Q)constmodify [valoff1] {sym1} (LEAQ [off2] {sym2} base) mem)
 	&& ValAndOff(valoff1).canAdd(off2) && canMergeSym(sym1, sym2) ->
-	(ADD(L|Q)constmem [ValAndOff(valoff1).add(off2)] {mergeSym(sym1,sym2)} base mem)
+	(ADD(L|Q)constmodify [ValAndOff(valoff1).add(off2)] {mergeSym(sym1,sym2)} base mem)
 
 // generating indexed loads and stores
 (MOV(B|W|L|Q|SS|SD)load [off1] {sym1} (LEAQ1 [off2] {sym2} ptr idx) mem) && is32Bit(off1+off2) && canMergeSym(sym1, sym2) ->
@@ -1275,65 +1275,65 @@
 ((SETNE|SETG|SETGE|SETA|SETAE)   (FlagGT_UGT)) -> (MOVLconst [1])
 ((SETEQ|SETL|SETLE|SETB|SETBE)   (FlagGT_UGT)) -> (MOVLconst [0])
 
-(SETEQmem [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETEQmem [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETEQmem [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETEQmem [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETEQmem [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-
-(SETNEmem [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETNEmem [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETNEmem [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETNEmem [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETNEmem [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-
-(SETLmem  [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETLmem  [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETLmem  [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETLmem  [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETLmem  [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-
-(SETLEmem [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETLEmem [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETLEmem [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETLEmem [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETLEmem [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-
-(SETGmem  [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETGmem  [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETGmem  [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETGmem  [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETGmem  [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-
-(SETGEmem [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETGEmem [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETGEmem [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETGEmem [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETGEmem [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-
-(SETBmem  [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETBmem  [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETBmem  [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETBmem  [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETBmem  [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-
-(SETBEmem [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETBEmem [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETBEmem [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETBEmem [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETBEmem [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-
-(SETAmem  [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETAmem  [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETAmem  [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETAmem  [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETAmem  [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-
-(SETAEmem [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETAEmem [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETAEmem [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
-(SETAEmem [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
-(SETAEmem [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETEQstore [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETEQstore [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETEQstore [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETEQstore [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETEQstore [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+
+(SETNEstore [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETNEstore [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETNEstore [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETNEstore [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETNEstore [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+
+(SETLstore  [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETLstore  [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETLstore  [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETLstore  [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETLstore  [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+
+(SETLEstore [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETLEstore [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETLEstore [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETLEstore [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETLEstore [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+
+(SETGstore  [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETGstore  [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETGstore  [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETGstore  [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETGstore  [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+
+(SETGEstore [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETGEstore [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETGEstore [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETGEstore [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETGEstore [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+
+(SETBstore  [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETBstore  [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETBstore  [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETBstore  [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETBstore  [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+
+(SETBEstore [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETBEstore [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETBEstore [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETBEstore [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETBEstore [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+
+(SETAstore  [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETAstore  [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETAstore  [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETAstore  [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETAstore  [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+
+(SETAEstore [off] {sym} ptr x:(FlagEQ)     mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETAEstore [off] {sym} ptr x:(FlagLT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETAEstore [off] {sym} ptr x:(FlagLT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
+(SETAEstore [off] {sym} ptr x:(FlagGT_ULT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
+(SETAEstore [off] {sym} ptr x:(FlagGT_UGT) mem) -> (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 
 // Remove redundant *const ops
 (ADDQconst [0] x) -> x
@@ -2263,10 +2263,10 @@
 
 // Merge load and op
 // TODO: add indexed variants?
-((ADD|SUB|AND|OR|XOR)Q x l:(MOVQload [off] {sym} ptr mem)) && canMergeLoad(v, l, x) && clobber(l) -> ((ADD|SUB|AND|OR|XOR)Qmem x [off] {sym} ptr mem)
-((ADD|SUB|AND|OR|XOR)L x l:(MOVLload [off] {sym} ptr mem)) && canMergeLoad(v, l, x) && clobber(l) -> ((ADD|SUB|AND|OR|XOR)Lmem x [off] {sym} ptr mem)
-((ADD|SUB|MUL)SD x l:(MOVSDload [off] {sym} ptr mem)) && canMergeLoad(v, l, x) && clobber(l) -> ((ADD|SUB|MUL)SDmem x [off] {sym} ptr mem)
-((ADD|SUB|MUL)SS x l:(MOVSSload [off] {sym} ptr mem)) && canMergeLoad(v, l, x) && clobber(l) -> ((ADD|SUB|MUL)SSmem x [off] {sym} ptr mem)
+((ADD|SUB|AND|OR|XOR)Q x l:(MOVQload [off] {sym} ptr mem)) && canMergeLoad(v, l, x) && clobber(l) -> ((ADD|SUB|AND|OR|XOR)Qload x [off] {sym} ptr mem)
+((ADD|SUB|AND|OR|XOR)L x l:(MOVLload [off] {sym} ptr mem)) && canMergeLoad(v, l, x) && clobber(l) -> ((ADD|SUB|AND|OR|XOR)Lload x [off] {sym} ptr mem)
+((ADD|SUB|MUL)SD x l:(MOVSDload [off] {sym} ptr mem)) && canMergeLoad(v, l, x) && clobber(l) -> ((ADD|SUB|MUL)SDload x [off] {sym} ptr mem)
+((ADD|SUB|MUL)SS x l:(MOVSSload [off] {sym} ptr mem)) && canMergeLoad(v, l, x) && clobber(l) -> ((ADD|SUB|MUL)SSload x [off] {sym} ptr mem)
 
 // Merge ADDQconst and LEAQ into atomic loads.
 (MOVQatomicload [off1] {sym} (ADDQconst [off2] ptr) mem) && is32Bit(off1+off2) ->
@@ -2352,10 +2352,10 @@
 
 (MOVQstore [off] {sym} ptr a:(ADDQconst [c] l:(MOVQload [off] {sym} ptr2 mem)) mem)
 	&& isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c,off) ->
-	(ADDQconstmem {sym} [makeValAndOff(c,off)] ptr mem)
+	(ADDQconstmodify {sym} [makeValAndOff(c,off)] ptr mem)
 (MOVLstore [off] {sym} ptr a:(ADDLconst [c] l:(MOVLload [off] {sym} ptr2 mem)) mem)
 	&& isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c,off) ->
-	(ADDLconstmem {sym} [makeValAndOff(c,off)] ptr mem)
+	(ADDLconstmodify {sym} [makeValAndOff(c,off)] ptr mem)
 
 // float <-> int register moves, with no conversion.
 // These come up when compiling math.{Float{32,64}bits,Float{32,64}frombits}.
@@ -2365,28 +2365,28 @@
 (MOVSSload [off] {sym} ptr (MOVLstore  [off] {sym} ptr val _)) -> (MOVLi2f val)
 
 // Other load-like ops.
-(ADDQmem x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _)) -> (ADDQ x (MOVQf2i y))
-(ADDLmem x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _)) -> (ADDL x (MOVLf2i y))
-(SUBQmem x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _)) -> (SUBQ x (MOVQf2i y))
-(SUBLmem x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _)) -> (SUBL x (MOVLf2i y))
-(ANDQmem x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _)) -> (ANDQ x (MOVQf2i y))
-(ANDLmem x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _)) -> (ANDL x (MOVLf2i y))
-( ORQmem x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _)) -> ( ORQ x (MOVQf2i y))
-( ORLmem x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _)) -> ( ORL x (MOVLf2i y))
-(XORQmem x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _)) -> (XORQ x (MOVQf2i y))
-(XORLmem x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _)) -> (XORL x (MOVLf2i y))
-
-(ADDQconstmem [valOff] {sym} ptr (MOVSDstore [ValAndOff(valOff).Off()] {sym} ptr x _)) ->
+(ADDQload x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _)) -> (ADDQ x (MOVQf2i y))
+(ADDLload x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _)) -> (ADDL x (MOVLf2i y))
+(SUBQload x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _)) -> (SUBQ x (MOVQf2i y))
+(SUBLload x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _)) -> (SUBL x (MOVLf2i y))
+(ANDQload x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _)) -> (ANDQ x (MOVQf2i y))
+(ANDLload x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _)) -> (ANDL x (MOVLf2i y))
+( ORQload x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _)) -> ( ORQ x (MOVQf2i y))
+( ORLload x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _)) -> ( ORL x (MOVLf2i y))
+(XORQload x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _)) -> (XORQ x (MOVQf2i y))
+(XORLload x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _)) -> (XORL x (MOVLf2i y))
+
+(ADDQconstmodify [valOff] {sym} ptr (MOVSDstore [ValAndOff(valOff).Off()] {sym} ptr x _)) ->
   (ADDQconst [ValAndOff(valOff).Val()] (MOVQf2i x))
-(ADDLconstmem [valOff] {sym} ptr (MOVSSstore [ValAndOff(valOff).Off()] {sym} ptr x _)) ->
+(ADDLconstmodify [valOff] {sym} ptr (MOVSSstore [ValAndOff(valOff).Off()] {sym} ptr x _)) ->
   (ADDLconst [ValAndOff(valOff).Val()] (MOVLf2i x))
 
-(ADDSDmem x [off] {sym} ptr (MOVQstore [off] {sym} ptr y _)) -> (ADDSD x (MOVQi2f y))
-(ADDSSmem x [off] {sym} ptr (MOVLstore [off] {sym} ptr y _)) -> (ADDSS x (MOVLi2f y))
-(SUBSDmem x [off] {sym} ptr (MOVQstore [off] {sym} ptr y _)) -> (SUBSD x (MOVQi2f y))
-(SUBSSmem x [off] {sym} ptr (MOVLstore [off] {sym} ptr y _)) -> (SUBSS x (MOVLi2f y))
-(MULSDmem x [off] {sym} ptr (MOVQstore [off] {sym} ptr y _)) -> (MULSD x (MOVQi2f y))
-(MULSSmem x [off] {sym} ptr (MOVLstore [off] {sym} ptr y _)) -> (MULSS x (MOVLi2f y))
+(ADDSDload x [off] {sym} ptr (MOVQstore [off] {sym} ptr y _)) -> (ADDSD x (MOVQi2f y))
+(ADDSSload x [off] {sym} ptr (MOVLstore [off] {sym} ptr y _)) -> (ADDSS x (MOVLi2f y))
+(SUBSDload x [off] {sym} ptr (MOVQstore [off] {sym} ptr y _)) -> (SUBSD x (MOVQi2f y))
+(SUBSSload x [off] {sym} ptr (MOVLstore [off] {sym} ptr y _)) -> (SUBSS x (MOVLi2f y))
+(MULSDload x [off] {sym} ptr (MOVQstore [off] {sym} ptr y _)) -> (MULSD x (MOVQi2f y))
+(MULSSload x [off] {sym} ptr (MOVLstore [off] {sym} ptr y _)) -> (MULSS x (MOVLi2f y))
 
 // Redirect stores to use the other register set.
 (MOVQstore  [off] {sym} ptr (MOVQf2i val) mem) -> (MOVSDstore [off] {sym} ptr val mem)
@@ -2407,23 +2407,23 @@
 
 // Fold loads into compares
 // Note: these may be undone by the flagalloc pass.
-(CMP(Q|L|W|B) l:(MOV(Q|L|W|B)load {sym} [off] ptr mem) x) && canMergeLoad(v, l, x) && clobber(l) -> (CMP(Q|L|W|B)mem {sym} [off] ptr x mem)
-(CMP(Q|L|W|B) x l:(MOV(Q|L|W|B)load {sym} [off] ptr mem)) && canMergeLoad(v, l, x) && clobber(l) -> (InvertFlags (CMP(Q|L|W|B)mem {sym} [off] ptr x mem))
+(CMP(Q|L|W|B) l:(MOV(Q|L|W|B)load {sym} [off] ptr mem) x) && canMergeLoad(v, l, x) && clobber(l) -> (CMP(Q|L|W|B)load {sym} [off] ptr x mem)
+(CMP(Q|L|W|B) x l:(MOV(Q|L|W|B)load {sym} [off] ptr mem)) && canMergeLoad(v, l, x) && clobber(l) -> (InvertFlags (CMP(Q|L|W|B)load {sym} [off] ptr x mem))
 
 (CMP(Q|L|W|B)const l:(MOV(Q|L|W|B)load {sym} [off] ptr mem) [c])
 	&& l.Uses == 1
 	&& validValAndOff(c, off)
 	&& clobber(l) ->
-  @l.Block (CMP(Q|L|W|B)constmem {sym} [makeValAndOff(c,off)] ptr mem)
+  @l.Block (CMP(Q|L|W|B)constload {sym} [makeValAndOff(c,off)] ptr mem)
 
-(CMPQmem {sym} [off] ptr (MOVQconst [c]) mem) && validValAndOff(c,off) -> (CMPQconstmem {sym} [makeValAndOff(c,off)] ptr mem)
-(CMPLmem {sym} [off] ptr (MOVLconst [c]) mem) && validValAndOff(c,off) -> (CMPLconstmem {sym} [makeValAndOff(c,off)] ptr mem)
-(CMPWmem {sym} [off] ptr (MOVLconst [c]) mem) && validValAndOff(int64(int16(c)),off) -> (CMPWconstmem {sym} [makeValAndOff(int64(int16(c)),off)] ptr mem)
-(CMPBmem {sym} [off] ptr (MOVLconst [c]) mem) && validValAndOff(int64(int8(c)),off) -> (CMPBconstmem {sym} [makeValAndOff(int64(int8(c)),off)] ptr mem)
+(CMPQload {sym} [off] ptr (MOVQconst [c]) mem) && validValAndOff(c,off) -> (CMPQconstload {sym} [makeValAndOff(c,off)] ptr mem)
+(CMPLload {sym} [off] ptr (MOVLconst [c]) mem) && validValAndOff(c,off) -> (CMPLconstload {sym} [makeValAndOff(c,off)] ptr mem)
+(CMPWload {sym} [off] ptr (MOVLconst [c]) mem) && validValAndOff(int64(int16(c)),off) -> (CMPWconstload {sym} [makeValAndOff(int64(int16(c)),off)] ptr mem)
+(CMPBload {sym} [off] ptr (MOVLconst [c]) mem) && validValAndOff(int64(int8(c)),off) -> (CMPBconstload {sym} [makeValAndOff(int64(int8(c)),off)] ptr mem)
 
 (TEST(Q|L|W|B)  l:(MOV(Q|L|W|B)load {sym} [off] ptr mem) l2)
         && l == l2
 	&& l.Uses == 2
 	&& validValAndOff(0,off)
 	&& clobber(l) ->
-  @l.Block (CMP(Q|L|W|B)constmem {sym} [makeValAndOff(0,off)] ptr mem)
+  @l.Block (CMP(Q|L|W|B)constload {sym} [makeValAndOff(0,off)] ptr mem)
diff --git a/src/cmd/compile/internal/ssa/gen/AMD64Ops.go b/src/cmd/compile/internal/ssa/gen/AMD64Ops.go
index b3bd6d06dd..e54ba11da8 100644
--- a/src/cmd/compile/internal/ssa/gen/AMD64Ops.go
+++ b/src/cmd/compile/internal/ssa/gen/AMD64Ops.go
@@ -183,20 +183,20 @@ func init() {
 		{name: "MOVSDstoreidx1", argLength: 4, reg: fpstoreidx, asm: "MOVSD", aux: "SymOff", symEffect: "Write"},                // fp64 indexed by i store
 		{name: "MOVSDstoreidx8", argLength: 4, reg: fpstoreidx, asm: "MOVSD", aux: "SymOff", symEffect: "Write"},                // fp64 indexed by 8i store
 
-		{name: "ADDSSmem", argLength: 3, reg: fp21load, asm: "ADDSS", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp32 arg0 + tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
-		{name: "ADDSDmem", argLength: 3, reg: fp21load, asm: "ADDSD", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp64 arg0 + tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
-		{name: "SUBSSmem", argLength: 3, reg: fp21load, asm: "SUBSS", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp32 arg0 - tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
-		{name: "SUBSDmem", argLength: 3, reg: fp21load, asm: "SUBSD", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp64 arg0 - tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
-		{name: "MULSSmem", argLength: 3, reg: fp21load, asm: "MULSS", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp32 arg0 * tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
-		{name: "MULSDmem", argLength: 3, reg: fp21load, asm: "MULSD", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp64 arg0 * tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
+		{name: "ADDSSload", argLength: 3, reg: fp21load, asm: "ADDSS", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp32 arg0 + tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
+		{name: "ADDSDload", argLength: 3, reg: fp21load, asm: "ADDSD", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp64 arg0 + tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
+		{name: "SUBSSload", argLength: 3, reg: fp21load, asm: "SUBSS", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp32 arg0 - tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
+		{name: "SUBSDload", argLength: 3, reg: fp21load, asm: "SUBSD", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp64 arg0 - tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
+		{name: "MULSSload", argLength: 3, reg: fp21load, asm: "MULSS", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp32 arg0 * tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
+		{name: "MULSDload", argLength: 3, reg: fp21load, asm: "MULSD", aux: "SymOff", resultInArg0: true, faultOnNilArg1: true, symEffect: "Read"}, // fp64 arg0 * tmp, tmp loaded from arg1+auxint+aux, arg2 = mem
 
 		// binary ops
-		{name: "ADDQ", argLength: 2, reg: gp21sp, asm: "ADDQ", commutative: true, clobberFlags: true},                                                           // arg0 + arg1
-		{name: "ADDL", argLength: 2, reg: gp21sp, asm: "ADDL", commutative: true, clobberFlags: true},                                                           // arg0 + arg1
-		{name: "ADDQconst", argLength: 1, reg: gp11sp, asm: "ADDQ", aux: "Int32", typ: "UInt64", clobberFlags: true},                                            // arg0 + auxint
-		{name: "ADDLconst", argLength: 1, reg: gp11sp, asm: "ADDL", aux: "Int32", clobberFlags: true},                                                           // arg0 + auxint
-		{name: "ADDQconstmem", argLength: 2, reg: gpstoreconst, asm: "ADDQ", aux: "SymValAndOff", clobberFlags: true, faultOnNilArg0: true, symEffect: "Write"}, // add ValAndOff(AuxInt).Val() to arg0+ValAndOff(AuxInt).Off()+aux, arg1=mem
-		{name: "ADDLconstmem", argLength: 2, reg: gpstoreconst, asm: "ADDL", aux: "SymValAndOff", clobberFlags: true, faultOnNilArg0: true, symEffect: "Write"}, // add ValAndOff(AuxInt).Val() to arg0+ValAndOff(AuxInt).Off()+aux, arg1=mem
+		{name: "ADDQ", argLength: 2, reg: gp21sp, asm: "ADDQ", commutative: true, clobberFlags: true},                                                                   // arg0 + arg1
+		{name: "ADDL", argLength: 2, reg: gp21sp, asm: "ADDL", commutative: true, clobberFlags: true},                                                                   // arg0 + arg1
+		{name: "ADDQconst", argLength: 1, reg: gp11sp, asm: "ADDQ", aux: "Int32", typ: "UInt64", clobberFlags: true},                                                    // arg0 + auxint
+		{name: "ADDLconst", argLength: 1, reg: gp11sp, asm: "ADDL", aux: "Int32", clobberFlags: true},                                                                   // arg0 + auxint
+		{name: "ADDQconstmodify", argLength: 2, reg: gpstoreconst, asm: "ADDQ", aux: "SymValAndOff", clobberFlags: true, faultOnNilArg0: true, symEffect: "Read,Write"}, // add ValAndOff(AuxInt).Val() to arg0+ValAndOff(AuxInt).Off()+aux, arg1=mem
+		{name: "ADDLconstmodify", argLength: 2, reg: gpstoreconst, asm: "ADDL", aux: "SymValAndOff", clobberFlags: true, faultOnNilArg0: true, symEffect: "Read,Write"}, // add ValAndOff(AuxInt).Val() to arg0+ValAndOff(AuxInt).Off()+aux, arg1=mem
 
 		{name: "SUBQ", argLength: 2, reg: gp21, asm: "SUBQ", resultInArg0: true, clobberFlags: true},                    // arg0 - arg1
 		{name: "SUBL", argLength: 2, reg: gp21, asm: "SUBL", resultInArg0: true, clobberFlags: true},                    // arg0 - arg1
@@ -250,16 +250,16 @@ func init() {
 		{name: "CMPBconst", argLength: 1, reg: gp1flags, asm: "CMPB", typ: "Flags", aux: "Int8"},  // arg0 compare to auxint
 
 		// compare *(arg0+auxint+aux) to arg1 (in that order). arg2=mem.
-		{name: "CMPQmem", argLength: 3, reg: gp1flagsLoad, asm: "CMPQ", aux: "SymOff", typ: "Flags", symEffect: "Read", faultOnNilArg0: true},
-		{name: "CMPLmem", argLength: 3, reg: gp1flagsLoad, asm: "CMPL", aux: "SymOff", typ: "Flags", symEffect: "Read", faultOnNilArg0: true},
-		{name: "CMPWmem", argLength: 3, reg: gp1flagsLoad, asm: "CMPW", aux: "SymOff", typ: "Flags", symEffect: "Read", faultOnNilArg0: true},
-		{name: "CMPBmem", argLength: 3, reg: gp1flagsLoad, asm: "CMPB", aux: "SymOff", typ: "Flags", symEffect: "Read", faultOnNilArg0: true},
+		{name: "CMPQload", argLength: 3, reg: gp1flagsLoad, asm: "CMPQ", aux: "SymOff", typ: "Flags", symEffect: "Read", faultOnNilArg0: true},
+		{name: "CMPLload", argLength: 3, reg: gp1flagsLoad, asm: "CMPL", aux: "SymOff", typ: "Flags", symEffect: "Read", faultOnNilArg0: true},
+		{name: "CMPWload", argLength: 3, reg: gp1flagsLoad, asm: "CMPW", aux: "SymOff", typ: "Flags", symEffect: "Read", faultOnNilArg0: true},
+		{name: "CMPBload", argLength: 3, reg: gp1flagsLoad, asm: "CMPB", aux: "SymOff", typ: "Flags", symEffect: "Read", faultOnNilArg0: true},
 
 		// compare *(arg0+ValAndOff(AuxInt).Off()+aux) to ValAndOff(AuxInt).Val() (in that order). arg1=mem.
-		{name: "CMPQconstmem", argLength: 2, reg: gp0flagsLoad, asm: "CMPQ", aux: "SymValAndOff", typ: "Flags", symEffect: "Read", faultOnNilArg0: true},
-		{name: "CMPLconstmem", argLength: 2, reg: gp0flagsLoad, asm: "CMPL", aux: "SymValAndOff", typ: "Flags", symEffect: "Read", faultOnNilArg0: true},
-		{name: "CMPWconstmem", argLength: 2, reg: gp0flagsLoad, asm: "CMPW", aux: "SymValAndOff", typ: "Flags", symEffect: "Read", faultOnNilArg0: true},
-		{name: "CMPBconstmem", argLength: 2, reg: gp0flagsLoad, asm: "CMPB", aux: "SymValAndOff", typ: "Flags", symEffect: "Read", faultOnNilArg0: true},
+		{name: "CMPQconstload", argLength: 2, reg: gp0flagsLoad, asm: "CMPQ", aux: "SymValAndOff", typ: "Flags", symEffect: "Read", faultOnNilArg0: true},
+		{name: "CMPLconstload", argLength: 2, reg: gp0flagsLoad, asm: "CMPL", aux: "SymValAndOff", typ: "Flags", symEffect: "Read", faultOnNilArg0: true},
+		{name: "CMPWconstload", argLength: 2, reg: gp0flagsLoad, asm: "CMPW", aux: "SymValAndOff", typ: "Flags", symEffect: "Read", faultOnNilArg0: true},
+		{name: "CMPBconstload", argLength: 2, reg: gp0flagsLoad, asm: "CMPB", aux: "SymValAndOff", typ: "Flags", symEffect: "Read", faultOnNilArg0: true},
 
 		{name: "UCOMISS", argLength: 2, reg: fp2flags, asm: "UCOMISS", typ: "Flags"}, // arg0 compare to arg1, f32
 		{name: "UCOMISD", argLength: 2, reg: fp2flags, asm: "UCOMISD", typ: "Flags"}, // arg0 compare to arg1, f64
@@ -327,16 +327,16 @@ func init() {
 		{name: "ROLWconst", argLength: 1, reg: gp11, asm: "ROLW", aux: "Int8", resultInArg0: true, clobberFlags: true}, // arg0 rotate left auxint, rotate amount 0-15
 		{name: "ROLBconst", argLength: 1, reg: gp11, asm: "ROLB", aux: "Int8", resultInArg0: true, clobberFlags: true}, // arg0 rotate left auxint, rotate amount 0-7
 
-		{name: "ADDLmem", argLength: 3, reg: gp21load, asm: "ADDL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 + tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
-		{name: "ADDQmem", argLength: 3, reg: gp21load, asm: "ADDQ", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 + tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
-		{name: "SUBQmem", argLength: 3, reg: gp21load, asm: "SUBQ", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 - tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
-		{name: "SUBLmem", argLength: 3, reg: gp21load, asm: "SUBL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 - tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
-		{name: "ANDLmem", argLength: 3, reg: gp21load, asm: "ANDL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 & tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
-		{name: "ANDQmem", argLength: 3, reg: gp21load, asm: "ANDQ", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 & tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
-		{name: "ORQmem", argLength: 3, reg: gp21load, asm: "ORQ", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"},   // arg0 | tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
-		{name: "ORLmem", argLength: 3, reg: gp21load, asm: "ORL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"},   // arg0 | tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
-		{name: "XORQmem", argLength: 3, reg: gp21load, asm: "XORQ", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 ^ tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
-		{name: "XORLmem", argLength: 3, reg: gp21load, asm: "XORL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 ^ tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
+		{name: "ADDLload", argLength: 3, reg: gp21load, asm: "ADDL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 + tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
+		{name: "ADDQload", argLength: 3, reg: gp21load, asm: "ADDQ", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 + tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
+		{name: "SUBQload", argLength: 3, reg: gp21load, asm: "SUBQ", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 - tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
+		{name: "SUBLload", argLength: 3, reg: gp21load, asm: "SUBL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 - tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
+		{name: "ANDLload", argLength: 3, reg: gp21load, asm: "ANDL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 & tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
+		{name: "ANDQload", argLength: 3, reg: gp21load, asm: "ANDQ", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 & tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
+		{name: "ORQload", argLength: 3, reg: gp21load, asm: "ORQ", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"},   // arg0 | tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
+		{name: "ORLload", argLength: 3, reg: gp21load, asm: "ORL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"},   // arg0 | tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
+		{name: "XORQload", argLength: 3, reg: gp21load, asm: "XORQ", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 ^ tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
+		{name: "XORLload", argLength: 3, reg: gp21load, asm: "XORL", aux: "SymOff", resultInArg0: true, clobberFlags: true, faultOnNilArg1: true, symEffect: "Read"}, // arg0 ^ tmp, tmp loaded from  arg1+auxint+aux, arg2 = mem
 
 		// unary ops
 		{name: "NEGQ", argLength: 1, reg: gp11, asm: "NEGQ", resultInArg0: true, clobberFlags: true}, // -arg0
@@ -435,16 +435,16 @@ func init() {
 		{name: "SETA", argLength: 1, reg: readflags, asm: "SETHI"},  // extract unsigned > condition from arg0
 		{name: "SETAE", argLength: 1, reg: readflags, asm: "SETCC"}, // extract unsigned >= condition from arg0
 		// Variants that store result to memory
-		{name: "SETEQmem", argLength: 3, reg: gpstoreconst, asm: "SETEQ", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"}, // extract == condition from arg1 to arg0+auxint+aux, arg2=mem
-		{name: "SETNEmem", argLength: 3, reg: gpstoreconst, asm: "SETNE", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"}, // extract != condition from arg1 to arg0+auxint+aux, arg2=mem
-		{name: "SETLmem", argLength: 3, reg: gpstoreconst, asm: "SETLT", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"},  // extract signed < condition from arg1 to arg0+auxint+aux, arg2=mem
-		{name: "SETLEmem", argLength: 3, reg: gpstoreconst, asm: "SETLE", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"}, // extract signed <= condition from arg1 to arg0+auxint+aux, arg2=mem
-		{name: "SETGmem", argLength: 3, reg: gpstoreconst, asm: "SETGT", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"},  // extract signed > condition from arg1 to arg0+auxint+aux, arg2=mem
-		{name: "SETGEmem", argLength: 3, reg: gpstoreconst, asm: "SETGE", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"}, // extract signed >= condition from arg1 to arg0+auxint+aux, arg2=mem
-		{name: "SETBmem", argLength: 3, reg: gpstoreconst, asm: "SETCS", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"},  // extract unsigned < condition from arg1 to arg0+auxint+aux, arg2=mem
-		{name: "SETBEmem", argLength: 3, reg: gpstoreconst, asm: "SETLS", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"}, // extract unsigned <= condition from arg1 to arg0+auxint+aux, arg2=mem
-		{name: "SETAmem", argLength: 3, reg: gpstoreconst, asm: "SETHI", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"},  // extract unsigned > condition from arg1 to arg0+auxint+aux, arg2=mem
-		{name: "SETAEmem", argLength: 3, reg: gpstoreconst, asm: "SETCC", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"}, // extract unsigned >= condition from arg1 to arg0+auxint+aux, arg2=mem
+		{name: "SETEQstore", argLength: 3, reg: gpstoreconst, asm: "SETEQ", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"}, // extract == condition from arg1 to arg0+auxint+aux, arg2=mem
+		{name: "SETNEstore", argLength: 3, reg: gpstoreconst, asm: "SETNE", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"}, // extract != condition from arg1 to arg0+auxint+aux, arg2=mem
+		{name: "SETLstore", argLength: 3, reg: gpstoreconst, asm: "SETLT", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"},  // extract signed < condition from arg1 to arg0+auxint+aux, arg2=mem
+		{name: "SETLEstore", argLength: 3, reg: gpstoreconst, asm: "SETLE", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"}, // extract signed <= condition from arg1 to arg0+auxint+aux, arg2=mem
+		{name: "SETGstore", argLength: 3, reg: gpstoreconst, asm: "SETGT", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"},  // extract signed > condition from arg1 to arg0+auxint+aux, arg2=mem
+		{name: "SETGEstore", argLength: 3, reg: gpstoreconst, asm: "SETGE", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"}, // extract signed >= condition from arg1 to arg0+auxint+aux, arg2=mem
+		{name: "SETBstore", argLength: 3, reg: gpstoreconst, asm: "SETCS", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"},  // extract unsigned < condition from arg1 to arg0+auxint+aux, arg2=mem
+		{name: "SETBEstore", argLength: 3, reg: gpstoreconst, asm: "SETLS", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"}, // extract unsigned <= condition from arg1 to arg0+auxint+aux, arg2=mem
+		{name: "SETAstore", argLength: 3, reg: gpstoreconst, asm: "SETHI", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"},  // extract unsigned > condition from arg1 to arg0+auxint+aux, arg2=mem
+		{name: "SETAEstore", argLength: 3, reg: gpstoreconst, asm: "SETCC", aux: "SymOff", typ: "Mem", faultOnNilArg0: true, symEffect: "Write"}, // extract unsigned >= condition from arg1 to arg0+auxint+aux, arg2=mem
 		// Need different opcodes for floating point conditions because
 		// any comparison involving a NaN is always FALSE and thus
 		// the patterns for inverting conditions cannot be used.
diff --git a/src/cmd/compile/internal/ssa/opGen.go b/src/cmd/compile/internal/ssa/opGen.go
index 2570bf771e..07c6995eaf 100644
--- a/src/cmd/compile/internal/ssa/opGen.go
+++ b/src/cmd/compile/internal/ssa/opGen.go
@@ -256,12 +256,12 @@ const (
 	Op386MOVSSstoreidx4
 	Op386MOVSDstoreidx1
 	Op386MOVSDstoreidx8
-	Op386ADDSSmem
-	Op386ADDSDmem
-	Op386SUBSSmem
-	Op386SUBSDmem
-	Op386MULSSmem
-	Op386MULSDmem
+	Op386ADDSSload
+	Op386ADDSDload
+	Op386SUBSSload
+	Op386SUBSDload
+	Op386MULSSload
+	Op386MULSDload
 	Op386ADDL
 	Op386ADDLconst
 	Op386ADDLcarry
@@ -325,11 +325,11 @@ const (
 	Op386ROLLconst
 	Op386ROLWconst
 	Op386ROLBconst
-	Op386ADDLmem
-	Op386SUBLmem
-	Op386ANDLmem
-	Op386ORLmem
-	Op386XORLmem
+	Op386ADDLload
+	Op386SUBLload
+	Op386ANDLload
+	Op386ORLload
+	Op386XORLload
 	Op386NEGL
 	Op386NOTL
 	Op386BSFL
@@ -450,18 +450,18 @@ const (
 	OpAMD64MOVSSstoreidx4
 	OpAMD64MOVSDstoreidx1
 	OpAMD64MOVSDstoreidx8
-	OpAMD64ADDSSmem
-	OpAMD64ADDSDmem
-	OpAMD64SUBSSmem
-	OpAMD64SUBSDmem
-	OpAMD64MULSSmem
-	OpAMD64MULSDmem
+	OpAMD64ADDSSload
+	OpAMD64ADDSDload
+	OpAMD64SUBSSload
+	OpAMD64SUBSDload
+	OpAMD64MULSSload
+	OpAMD64MULSDload
 	OpAMD64ADDQ
 	OpAMD64ADDL
 	OpAMD64ADDQconst
 	OpAMD64ADDLconst
-	OpAMD64ADDQconstmem
-	OpAMD64ADDLconstmem
+	OpAMD64ADDQconstmodify
+	OpAMD64ADDLconstmodify
 	OpAMD64SUBQ
 	OpAMD64SUBL
 	OpAMD64SUBQconst
@@ -503,14 +503,14 @@ const (
 	OpAMD64CMPLconst
 	OpAMD64CMPWconst
 	OpAMD64CMPBconst
-	OpAMD64CMPQmem
-	OpAMD64CMPLmem
-	OpAMD64CMPWmem
-	OpAMD64CMPBmem
-	OpAMD64CMPQconstmem
-	OpAMD64CMPLconstmem
-	OpAMD64CMPWconstmem
-	OpAMD64CMPBconstmem
+	OpAMD64CMPQload
+	OpAMD64CMPLload
+	OpAMD64CMPWload
+	OpAMD64CMPBload
+	OpAMD64CMPQconstload
+	OpAMD64CMPLconstload
+	OpAMD64CMPWconstload
+	OpAMD64CMPBconstload
 	OpAMD64UCOMISS
 	OpAMD64UCOMISD
 	OpAMD64BTL
@@ -569,16 +569,16 @@ const (
 	OpAMD64ROLLconst
 	OpAMD64ROLWconst
 	OpAMD64ROLBconst
-	OpAMD64ADDLmem
-	OpAMD64ADDQmem
-	OpAMD64SUBQmem
-	OpAMD64SUBLmem
-	OpAMD64ANDLmem
-	OpAMD64ANDQmem
-	OpAMD64ORQmem
-	OpAMD64ORLmem
-	OpAMD64XORQmem
-	OpAMD64XORLmem
+	OpAMD64ADDLload
+	OpAMD64ADDQload
+	OpAMD64SUBQload
+	OpAMD64SUBLload
+	OpAMD64ANDLload
+	OpAMD64ANDQload
+	OpAMD64ORQload
+	OpAMD64ORLload
+	OpAMD64XORQload
+	OpAMD64XORLload
 	OpAMD64NEGQ
 	OpAMD64NEGL
 	OpAMD64NOTQ
@@ -647,16 +647,16 @@ const (
 	OpAMD64SETBE
 	OpAMD64SETA
 	OpAMD64SETAE
-	OpAMD64SETEQmem
-	OpAMD64SETNEmem
-	OpAMD64SETLmem
-	OpAMD64SETLEmem
-	OpAMD64SETGmem
-	OpAMD64SETGEmem
-	OpAMD64SETBmem
-	OpAMD64SETBEmem
-	OpAMD64SETAmem
-	OpAMD64SETAEmem
+	OpAMD64SETEQstore
+	OpAMD64SETNEstore
+	OpAMD64SETLstore
+	OpAMD64SETLEstore
+	OpAMD64SETGstore
+	OpAMD64SETGEstore
+	OpAMD64SETBstore
+	OpAMD64SETBEstore
+	OpAMD64SETAstore
+	OpAMD64SETAEstore
 	OpAMD64SETEQF
 	OpAMD64SETNEF
 	OpAMD64SETORD
@@ -2626,7 +2626,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "ADDSSmem",
+		name:           "ADDSSload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -2644,7 +2644,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "ADDSDmem",
+		name:           "ADDSDload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -2662,7 +2662,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "SUBSSmem",
+		name:           "SUBSSload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -2680,7 +2680,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "SUBSDmem",
+		name:           "SUBSDload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -2698,7 +2698,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "MULSSmem",
+		name:           "MULSSload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -2716,7 +2716,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "MULSDmem",
+		name:           "MULSDload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -3684,7 +3684,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "ADDLmem",
+		name:           "ADDLload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -3703,7 +3703,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "SUBLmem",
+		name:           "SUBLload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -3722,7 +3722,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "ANDLmem",
+		name:           "ANDLload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -3741,7 +3741,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "ORLmem",
+		name:           "ORLload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -3760,7 +3760,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "XORLmem",
+		name:           "XORLload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -5333,7 +5333,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "ADDSSmem",
+		name:           "ADDSSload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -5351,7 +5351,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "ADDSDmem",
+		name:           "ADDSDload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -5369,7 +5369,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "SUBSSmem",
+		name:           "SUBSSload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -5387,7 +5387,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "SUBSDmem",
+		name:           "SUBSDload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -5405,7 +5405,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "MULSSmem",
+		name:           "MULSSload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -5423,7 +5423,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "MULSDmem",
+		name:           "MULSDload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -5503,12 +5503,12 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "ADDQconstmem",
+		name:           "ADDQconstmodify",
 		auxType:        auxSymValAndOff,
 		argLen:         2,
 		clobberFlags:   true,
 		faultOnNilArg0: true,
-		symEffect:      SymWrite,
+		symEffect:      SymRead | SymWrite,
 		asm:            x86.AADDQ,
 		reg: regInfo{
 			inputs: []inputInfo{
@@ -5517,12 +5517,12 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "ADDLconstmem",
+		name:           "ADDLconstmodify",
 		auxType:        auxSymValAndOff,
 		argLen:         2,
 		clobberFlags:   true,
 		faultOnNilArg0: true,
-		symEffect:      SymWrite,
+		symEffect:      SymRead | SymWrite,
 		asm:            x86.AADDL,
 		reg: regInfo{
 			inputs: []inputInfo{
@@ -6159,7 +6159,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "CMPQmem",
+		name:           "CMPQload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		faultOnNilArg0: true,
@@ -6173,7 +6173,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "CMPLmem",
+		name:           "CMPLload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		faultOnNilArg0: true,
@@ -6187,7 +6187,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "CMPWmem",
+		name:           "CMPWload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		faultOnNilArg0: true,
@@ -6201,7 +6201,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "CMPBmem",
+		name:           "CMPBload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		faultOnNilArg0: true,
@@ -6215,7 +6215,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "CMPQconstmem",
+		name:           "CMPQconstload",
 		auxType:        auxSymValAndOff,
 		argLen:         2,
 		faultOnNilArg0: true,
@@ -6228,7 +6228,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "CMPLconstmem",
+		name:           "CMPLconstload",
 		auxType:        auxSymValAndOff,
 		argLen:         2,
 		faultOnNilArg0: true,
@@ -6241,7 +6241,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "CMPWconstmem",
+		name:           "CMPWconstload",
 		auxType:        auxSymValAndOff,
 		argLen:         2,
 		faultOnNilArg0: true,
@@ -6254,7 +6254,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "CMPBconstmem",
+		name:           "CMPBconstload",
 		auxType:        auxSymValAndOff,
 		argLen:         2,
 		faultOnNilArg0: true,
@@ -7129,7 +7129,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "ADDLmem",
+		name:           "ADDLload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -7148,7 +7148,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "ADDQmem",
+		name:           "ADDQload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -7167,7 +7167,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "SUBQmem",
+		name:           "SUBQload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -7186,7 +7186,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "SUBLmem",
+		name:           "SUBLload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -7205,7 +7205,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "ANDLmem",
+		name:           "ANDLload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -7224,7 +7224,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "ANDQmem",
+		name:           "ANDQload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -7243,7 +7243,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "ORQmem",
+		name:           "ORQload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -7262,7 +7262,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "ORLmem",
+		name:           "ORLload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -7281,7 +7281,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "XORQmem",
+		name:           "XORQload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -7300,7 +7300,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "XORLmem",
+		name:           "XORLload",
 		auxType:        auxSymOff,
 		argLen:         3,
 		resultInArg0:   true,
@@ -8269,7 +8269,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "SETEQmem",
+		name:           "SETEQstore",
 		auxType:        auxSymOff,
 		argLen:         3,
 		faultOnNilArg0: true,
@@ -8282,7 +8282,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "SETNEmem",
+		name:           "SETNEstore",
 		auxType:        auxSymOff,
 		argLen:         3,
 		faultOnNilArg0: true,
@@ -8295,7 +8295,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "SETLmem",
+		name:           "SETLstore",
 		auxType:        auxSymOff,
 		argLen:         3,
 		faultOnNilArg0: true,
@@ -8308,7 +8308,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "SETLEmem",
+		name:           "SETLEstore",
 		auxType:        auxSymOff,
 		argLen:         3,
 		faultOnNilArg0: true,
@@ -8321,7 +8321,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "SETGmem",
+		name:           "SETGstore",
 		auxType:        auxSymOff,
 		argLen:         3,
 		faultOnNilArg0: true,
@@ -8334,7 +8334,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "SETGEmem",
+		name:           "SETGEstore",
 		auxType:        auxSymOff,
 		argLen:         3,
 		faultOnNilArg0: true,
@@ -8347,7 +8347,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "SETBmem",
+		name:           "SETBstore",
 		auxType:        auxSymOff,
 		argLen:         3,
 		faultOnNilArg0: true,
@@ -8360,7 +8360,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "SETBEmem",
+		name:           "SETBEstore",
 		auxType:        auxSymOff,
 		argLen:         3,
 		faultOnNilArg0: true,
@@ -8373,7 +8373,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "SETAmem",
+		name:           "SETAstore",
 		auxType:        auxSymOff,
 		argLen:         3,
 		faultOnNilArg0: true,
@@ -8386,7 +8386,7 @@ var opcodeTable = [...]opInfo{
 		},
 	},
 	{
-		name:           "SETAEmem",
+		name:           "SETAEstore",
 		auxType:        auxSymOff,
 		argLen:         3,
 		faultOnNilArg0: true,
diff --git a/src/cmd/compile/internal/ssa/rewrite.go b/src/cmd/compile/internal/ssa/rewrite.go
index 4ccebca27c..a7bfe4ccb8 100644
--- a/src/cmd/compile/internal/ssa/rewrite.go
+++ b/src/cmd/compile/internal/ssa/rewrite.go
@@ -848,8 +848,8 @@ func zeroUpper32Bits(x *Value, depth int) bool {
 	switch x.Op {
 	case OpAMD64MOVLconst, OpAMD64MOVLload, OpAMD64MOVLQZX, OpAMD64MOVLloadidx1,
 		OpAMD64MOVWload, OpAMD64MOVWloadidx1, OpAMD64MOVBload, OpAMD64MOVBloadidx1,
-		OpAMD64MOVLloadidx4, OpAMD64ADDLmem, OpAMD64SUBLmem, OpAMD64ANDLmem,
-		OpAMD64ORLmem, OpAMD64XORLmem, OpAMD64CVTTSD2SL,
+		OpAMD64MOVLloadidx4, OpAMD64ADDLload, OpAMD64SUBLload, OpAMD64ANDLload,
+		OpAMD64ORLload, OpAMD64XORLload, OpAMD64CVTTSD2SL,
 		OpAMD64ADDL, OpAMD64ADDLconst, OpAMD64SUBL, OpAMD64SUBLconst,
 		OpAMD64ANDL, OpAMD64ANDLconst, OpAMD64ORL, OpAMD64ORLconst,
 		OpAMD64XORL, OpAMD64XORLconst, OpAMD64NEGL, OpAMD64NOTL:
diff --git a/src/cmd/compile/internal/ssa/rewrite386.go b/src/cmd/compile/internal/ssa/rewrite386.go
index 6cafcdc5e7..7d9810b4a6 100644
--- a/src/cmd/compile/internal/ssa/rewrite386.go
+++ b/src/cmd/compile/internal/ssa/rewrite386.go
@@ -23,24 +23,24 @@ func rewriteValue386(v *Value) bool {
 		return rewriteValue386_Op386ADDLcarry_0(v)
 	case Op386ADDLconst:
 		return rewriteValue386_Op386ADDLconst_0(v)
-	case Op386ADDLmem:
-		return rewriteValue386_Op386ADDLmem_0(v)
+	case Op386ADDLload:
+		return rewriteValue386_Op386ADDLload_0(v)
 	case Op386ADDLmodify:
 		return rewriteValue386_Op386ADDLmodify_0(v)
 	case Op386ADDSD:
 		return rewriteValue386_Op386ADDSD_0(v)
-	case Op386ADDSDmem:
-		return rewriteValue386_Op386ADDSDmem_0(v)
+	case Op386ADDSDload:
+		return rewriteValue386_Op386ADDSDload_0(v)
 	case Op386ADDSS:
 		return rewriteValue386_Op386ADDSS_0(v)
-	case Op386ADDSSmem:
-		return rewriteValue386_Op386ADDSSmem_0(v)
+	case Op386ADDSSload:
+		return rewriteValue386_Op386ADDSSload_0(v)
 	case Op386ANDL:
 		return rewriteValue386_Op386ANDL_0(v)
 	case Op386ANDLconst:
 		return rewriteValue386_Op386ANDLconst_0(v)
-	case Op386ANDLmem:
-		return rewriteValue386_Op386ANDLmem_0(v)
+	case Op386ANDLload:
+		return rewriteValue386_Op386ANDLload_0(v)
 	case Op386ANDLmodify:
 		return rewriteValue386_Op386ANDLmodify_0(v)
 	case Op386CMPB:
@@ -159,12 +159,12 @@ func rewriteValue386(v *Value) bool {
 		return rewriteValue386_Op386MULLconst_0(v) || rewriteValue386_Op386MULLconst_10(v) || rewriteValue386_Op386MULLconst_20(v) || rewriteValue386_Op386MULLconst_30(v)
 	case Op386MULSD:
 		return rewriteValue386_Op386MULSD_0(v)
-	case Op386MULSDmem:
-		return rewriteValue386_Op386MULSDmem_0(v)
+	case Op386MULSDload:
+		return rewriteValue386_Op386MULSDload_0(v)
 	case Op386MULSS:
 		return rewriteValue386_Op386MULSS_0(v)
-	case Op386MULSSmem:
-		return rewriteValue386_Op386MULSSmem_0(v)
+	case Op386MULSSload:
+		return rewriteValue386_Op386MULSSload_0(v)
 	case Op386NEGL:
 		return rewriteValue386_Op386NEGL_0(v)
 	case Op386NOTL:
@@ -173,8 +173,8 @@ func rewriteValue386(v *Value) bool {
 		return rewriteValue386_Op386ORL_0(v) || rewriteValue386_Op386ORL_10(v) || rewriteValue386_Op386ORL_20(v) || rewriteValue386_Op386ORL_30(v) || rewriteValue386_Op386ORL_40(v) || rewriteValue386_Op386ORL_50(v)
 	case Op386ORLconst:
 		return rewriteValue386_Op386ORLconst_0(v)
-	case Op386ORLmem:
-		return rewriteValue386_Op386ORLmem_0(v)
+	case Op386ORLload:
+		return rewriteValue386_Op386ORLload_0(v)
 	case Op386ORLmodify:
 		return rewriteValue386_Op386ORLmodify_0(v)
 	case Op386ROLBconst:
@@ -241,24 +241,24 @@ func rewriteValue386(v *Value) bool {
 		return rewriteValue386_Op386SUBLcarry_0(v)
 	case Op386SUBLconst:
 		return rewriteValue386_Op386SUBLconst_0(v)
-	case Op386SUBLmem:
-		return rewriteValue386_Op386SUBLmem_0(v)
+	case Op386SUBLload:
+		return rewriteValue386_Op386SUBLload_0(v)
 	case Op386SUBLmodify:
 		return rewriteValue386_Op386SUBLmodify_0(v)
 	case Op386SUBSD:
 		return rewriteValue386_Op386SUBSD_0(v)
-	case Op386SUBSDmem:
-		return rewriteValue386_Op386SUBSDmem_0(v)
+	case Op386SUBSDload:
+		return rewriteValue386_Op386SUBSDload_0(v)
 	case Op386SUBSS:
 		return rewriteValue386_Op386SUBSS_0(v)
-	case Op386SUBSSmem:
-		return rewriteValue386_Op386SUBSSmem_0(v)
+	case Op386SUBSSload:
+		return rewriteValue386_Op386SUBSSload_0(v)
 	case Op386XORL:
 		return rewriteValue386_Op386XORL_0(v) || rewriteValue386_Op386XORL_10(v)
 	case Op386XORLconst:
 		return rewriteValue386_Op386XORLconst_0(v)
-	case Op386XORLmem:
-		return rewriteValue386_Op386XORLmem_0(v)
+	case Op386XORLload:
+		return rewriteValue386_Op386XORLload_0(v)
 	case Op386XORLmodify:
 		return rewriteValue386_Op386XORLmodify_0(v)
 	case OpAdd16:
@@ -1238,7 +1238,7 @@ func rewriteValue386_Op386ADDL_20(v *Value) bool {
 	}
 	// match: (ADDL x l:(MOVLload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ADDLmem x [off] {sym} ptr mem)
+	// result: (ADDLload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -1254,7 +1254,7 @@ func rewriteValue386_Op386ADDL_20(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(Op386ADDLmem)
+		v.reset(Op386ADDLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -1264,7 +1264,7 @@ func rewriteValue386_Op386ADDL_20(v *Value) bool {
 	}
 	// match: (ADDL l:(MOVLload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ADDLmem x [off] {sym} ptr mem)
+	// result: (ADDLload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -1280,7 +1280,7 @@ func rewriteValue386_Op386ADDL_20(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(Op386ADDLmem)
+		v.reset(Op386ADDLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -1539,14 +1539,14 @@ func rewriteValue386_Op386ADDLconst_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValue386_Op386ADDLmem_0(v *Value) bool {
+func rewriteValue386_Op386ADDLload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	config := b.Func.Config
 	_ = config
-	// match: (ADDLmem [off1] {sym} val (ADDLconst [off2] base) mem)
+	// match: (ADDLload [off1] {sym} val (ADDLconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (ADDLmem [off1+off2] {sym} val base mem)
+	// result: (ADDLload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -1562,7 +1562,7 @@ func rewriteValue386_Op386ADDLmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(Op386ADDLmem)
+		v.reset(Op386ADDLload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -1570,9 +1570,9 @@ func rewriteValue386_Op386ADDLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ADDLmem [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
+	// match: (ADDLload [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)
-	// result: (ADDLmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (ADDLload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -1589,7 +1589,7 @@ func rewriteValue386_Op386ADDLmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)) {
 			break
 		}
-		v.reset(Op386ADDLmem)
+		v.reset(Op386ADDLload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -1666,7 +1666,7 @@ func rewriteValue386_Op386ADDSD_0(v *Value) bool {
 	_ = config
 	// match: (ADDSD x l:(MOVSDload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && !config.use387 && clobber(l)
-	// result: (ADDSDmem x [off] {sym} ptr mem)
+	// result: (ADDSDload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -1682,7 +1682,7 @@ func rewriteValue386_Op386ADDSD_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && !config.use387 && clobber(l)) {
 			break
 		}
-		v.reset(Op386ADDSDmem)
+		v.reset(Op386ADDSDload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -1692,7 +1692,7 @@ func rewriteValue386_Op386ADDSD_0(v *Value) bool {
 	}
 	// match: (ADDSD l:(MOVSDload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && !config.use387 && clobber(l)
-	// result: (ADDSDmem x [off] {sym} ptr mem)
+	// result: (ADDSDload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -1708,7 +1708,7 @@ func rewriteValue386_Op386ADDSD_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && !config.use387 && clobber(l)) {
 			break
 		}
-		v.reset(Op386ADDSDmem)
+		v.reset(Op386ADDSDload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -1718,14 +1718,14 @@ func rewriteValue386_Op386ADDSD_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValue386_Op386ADDSDmem_0(v *Value) bool {
+func rewriteValue386_Op386ADDSDload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	config := b.Func.Config
 	_ = config
-	// match: (ADDSDmem [off1] {sym} val (ADDLconst [off2] base) mem)
+	// match: (ADDSDload [off1] {sym} val (ADDLconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (ADDSDmem [off1+off2] {sym} val base mem)
+	// result: (ADDSDload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -1741,7 +1741,7 @@ func rewriteValue386_Op386ADDSDmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(Op386ADDSDmem)
+		v.reset(Op386ADDSDload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -1749,9 +1749,9 @@ func rewriteValue386_Op386ADDSDmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ADDSDmem [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
+	// match: (ADDSDload [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)
-	// result: (ADDSDmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (ADDSDload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -1768,7 +1768,7 @@ func rewriteValue386_Op386ADDSDmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)) {
 			break
 		}
-		v.reset(Op386ADDSDmem)
+		v.reset(Op386ADDSDload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -1785,7 +1785,7 @@ func rewriteValue386_Op386ADDSS_0(v *Value) bool {
 	_ = config
 	// match: (ADDSS x l:(MOVSSload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && !config.use387 && clobber(l)
-	// result: (ADDSSmem x [off] {sym} ptr mem)
+	// result: (ADDSSload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -1801,7 +1801,7 @@ func rewriteValue386_Op386ADDSS_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && !config.use387 && clobber(l)) {
 			break
 		}
-		v.reset(Op386ADDSSmem)
+		v.reset(Op386ADDSSload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -1811,7 +1811,7 @@ func rewriteValue386_Op386ADDSS_0(v *Value) bool {
 	}
 	// match: (ADDSS l:(MOVSSload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && !config.use387 && clobber(l)
-	// result: (ADDSSmem x [off] {sym} ptr mem)
+	// result: (ADDSSload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -1827,7 +1827,7 @@ func rewriteValue386_Op386ADDSS_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && !config.use387 && clobber(l)) {
 			break
 		}
-		v.reset(Op386ADDSSmem)
+		v.reset(Op386ADDSSload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -1837,14 +1837,14 @@ func rewriteValue386_Op386ADDSS_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValue386_Op386ADDSSmem_0(v *Value) bool {
+func rewriteValue386_Op386ADDSSload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	config := b.Func.Config
 	_ = config
-	// match: (ADDSSmem [off1] {sym} val (ADDLconst [off2] base) mem)
+	// match: (ADDSSload [off1] {sym} val (ADDLconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (ADDSSmem [off1+off2] {sym} val base mem)
+	// result: (ADDSSload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -1860,7 +1860,7 @@ func rewriteValue386_Op386ADDSSmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(Op386ADDSSmem)
+		v.reset(Op386ADDSSload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -1868,9 +1868,9 @@ func rewriteValue386_Op386ADDSSmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ADDSSmem [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
+	// match: (ADDSSload [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)
-	// result: (ADDSSmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (ADDSSload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -1887,7 +1887,7 @@ func rewriteValue386_Op386ADDSSmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)) {
 			break
 		}
-		v.reset(Op386ADDSSmem)
+		v.reset(Op386ADDSSload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -1932,7 +1932,7 @@ func rewriteValue386_Op386ANDL_0(v *Value) bool {
 	}
 	// match: (ANDL x l:(MOVLload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ANDLmem x [off] {sym} ptr mem)
+	// result: (ANDLload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -1948,7 +1948,7 @@ func rewriteValue386_Op386ANDL_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(Op386ANDLmem)
+		v.reset(Op386ANDLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -1958,7 +1958,7 @@ func rewriteValue386_Op386ANDL_0(v *Value) bool {
 	}
 	// match: (ANDL l:(MOVLload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ANDLmem x [off] {sym} ptr mem)
+	// result: (ANDLload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -1974,7 +1974,7 @@ func rewriteValue386_Op386ANDL_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(Op386ANDLmem)
+		v.reset(Op386ANDLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -2057,14 +2057,14 @@ func rewriteValue386_Op386ANDLconst_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValue386_Op386ANDLmem_0(v *Value) bool {
+func rewriteValue386_Op386ANDLload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	config := b.Func.Config
 	_ = config
-	// match: (ANDLmem [off1] {sym} val (ADDLconst [off2] base) mem)
+	// match: (ANDLload [off1] {sym} val (ADDLconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (ANDLmem [off1+off2] {sym} val base mem)
+	// result: (ANDLload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -2080,7 +2080,7 @@ func rewriteValue386_Op386ANDLmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(Op386ANDLmem)
+		v.reset(Op386ANDLload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -2088,9 +2088,9 @@ func rewriteValue386_Op386ANDLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ANDLmem [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
+	// match: (ANDLload [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)
-	// result: (ANDLmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (ANDLload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -2107,7 +2107,7 @@ func rewriteValue386_Op386ANDLmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)) {
 			break
 		}
-		v.reset(Op386ANDLmem)
+		v.reset(Op386ANDLload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -5427,7 +5427,7 @@ func rewriteValue386_Op386MOVLstore_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (MOVLstore {sym} [off] ptr y:(ADDLmem x [off] {sym} ptr mem) mem)
+	// match: (MOVLstore {sym} [off] ptr y:(ADDLload x [off] {sym} ptr mem) mem)
 	// cond: y.Uses==1 && clobber(y)
 	// result: (ADDLmodify [off] {sym} ptr x mem)
 	for {
@@ -5436,7 +5436,7 @@ func rewriteValue386_Op386MOVLstore_0(v *Value) bool {
 		_ = v.Args[2]
 		ptr := v.Args[0]
 		y := v.Args[1]
-		if y.Op != Op386ADDLmem {
+		if y.Op != Op386ADDLload {
 			break
 		}
 		if y.AuxInt != off {
@@ -5465,7 +5465,7 @@ func rewriteValue386_Op386MOVLstore_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (MOVLstore {sym} [off] ptr y:(ANDLmem x [off] {sym} ptr mem) mem)
+	// match: (MOVLstore {sym} [off] ptr y:(ANDLload x [off] {sym} ptr mem) mem)
 	// cond: y.Uses==1 && clobber(y)
 	// result: (ANDLmodify [off] {sym} ptr x mem)
 	for {
@@ -5474,7 +5474,7 @@ func rewriteValue386_Op386MOVLstore_0(v *Value) bool {
 		_ = v.Args[2]
 		ptr := v.Args[0]
 		y := v.Args[1]
-		if y.Op != Op386ANDLmem {
+		if y.Op != Op386ANDLload {
 			break
 		}
 		if y.AuxInt != off {
@@ -5503,7 +5503,7 @@ func rewriteValue386_Op386MOVLstore_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (MOVLstore {sym} [off] ptr y:(ORLmem x [off] {sym} ptr mem) mem)
+	// match: (MOVLstore {sym} [off] ptr y:(ORLload x [off] {sym} ptr mem) mem)
 	// cond: y.Uses==1 && clobber(y)
 	// result: (ORLmodify [off] {sym} ptr x mem)
 	for {
@@ -5512,7 +5512,7 @@ func rewriteValue386_Op386MOVLstore_0(v *Value) bool {
 		_ = v.Args[2]
 		ptr := v.Args[0]
 		y := v.Args[1]
-		if y.Op != Op386ORLmem {
+		if y.Op != Op386ORLload {
 			break
 		}
 		if y.AuxInt != off {
@@ -5541,7 +5541,7 @@ func rewriteValue386_Op386MOVLstore_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (MOVLstore {sym} [off] ptr y:(XORLmem x [off] {sym} ptr mem) mem)
+	// match: (MOVLstore {sym} [off] ptr y:(XORLload x [off] {sym} ptr mem) mem)
 	// cond: y.Uses==1 && clobber(y)
 	// result: (XORLmodify [off] {sym} ptr x mem)
 	for {
@@ -5550,7 +5550,7 @@ func rewriteValue386_Op386MOVLstore_0(v *Value) bool {
 		_ = v.Args[2]
 		ptr := v.Args[0]
 		y := v.Args[1]
-		if y.Op != Op386XORLmem {
+		if y.Op != Op386XORLload {
 			break
 		}
 		if y.AuxInt != off {
@@ -9998,7 +9998,7 @@ func rewriteValue386_Op386MULSD_0(v *Value) bool {
 	_ = config
 	// match: (MULSD x l:(MOVSDload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && !config.use387 && clobber(l)
-	// result: (MULSDmem x [off] {sym} ptr mem)
+	// result: (MULSDload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -10014,7 +10014,7 @@ func rewriteValue386_Op386MULSD_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && !config.use387 && clobber(l)) {
 			break
 		}
-		v.reset(Op386MULSDmem)
+		v.reset(Op386MULSDload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -10024,7 +10024,7 @@ func rewriteValue386_Op386MULSD_0(v *Value) bool {
 	}
 	// match: (MULSD l:(MOVSDload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && !config.use387 && clobber(l)
-	// result: (MULSDmem x [off] {sym} ptr mem)
+	// result: (MULSDload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -10040,7 +10040,7 @@ func rewriteValue386_Op386MULSD_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && !config.use387 && clobber(l)) {
 			break
 		}
-		v.reset(Op386MULSDmem)
+		v.reset(Op386MULSDload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -10050,14 +10050,14 @@ func rewriteValue386_Op386MULSD_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValue386_Op386MULSDmem_0(v *Value) bool {
+func rewriteValue386_Op386MULSDload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	config := b.Func.Config
 	_ = config
-	// match: (MULSDmem [off1] {sym} val (ADDLconst [off2] base) mem)
+	// match: (MULSDload [off1] {sym} val (ADDLconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (MULSDmem [off1+off2] {sym} val base mem)
+	// result: (MULSDload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -10073,7 +10073,7 @@ func rewriteValue386_Op386MULSDmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(Op386MULSDmem)
+		v.reset(Op386MULSDload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -10081,9 +10081,9 @@ func rewriteValue386_Op386MULSDmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (MULSDmem [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
+	// match: (MULSDload [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)
-	// result: (MULSDmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (MULSDload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -10100,7 +10100,7 @@ func rewriteValue386_Op386MULSDmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)) {
 			break
 		}
-		v.reset(Op386MULSDmem)
+		v.reset(Op386MULSDload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -10117,7 +10117,7 @@ func rewriteValue386_Op386MULSS_0(v *Value) bool {
 	_ = config
 	// match: (MULSS x l:(MOVSSload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && !config.use387 && clobber(l)
-	// result: (MULSSmem x [off] {sym} ptr mem)
+	// result: (MULSSload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -10133,7 +10133,7 @@ func rewriteValue386_Op386MULSS_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && !config.use387 && clobber(l)) {
 			break
 		}
-		v.reset(Op386MULSSmem)
+		v.reset(Op386MULSSload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -10143,7 +10143,7 @@ func rewriteValue386_Op386MULSS_0(v *Value) bool {
 	}
 	// match: (MULSS l:(MOVSSload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && !config.use387 && clobber(l)
-	// result: (MULSSmem x [off] {sym} ptr mem)
+	// result: (MULSSload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -10159,7 +10159,7 @@ func rewriteValue386_Op386MULSS_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && !config.use387 && clobber(l)) {
 			break
 		}
-		v.reset(Op386MULSSmem)
+		v.reset(Op386MULSSload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -10169,14 +10169,14 @@ func rewriteValue386_Op386MULSS_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValue386_Op386MULSSmem_0(v *Value) bool {
+func rewriteValue386_Op386MULSSload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	config := b.Func.Config
 	_ = config
-	// match: (MULSSmem [off1] {sym} val (ADDLconst [off2] base) mem)
+	// match: (MULSSload [off1] {sym} val (ADDLconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (MULSSmem [off1+off2] {sym} val base mem)
+	// result: (MULSSload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -10192,7 +10192,7 @@ func rewriteValue386_Op386MULSSmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(Op386MULSSmem)
+		v.reset(Op386MULSSload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -10200,9 +10200,9 @@ func rewriteValue386_Op386MULSSmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (MULSSmem [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
+	// match: (MULSSload [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)
-	// result: (MULSSmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (MULSSload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -10219,7 +10219,7 @@ func rewriteValue386_Op386MULSSmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)) {
 			break
 		}
-		v.reset(Op386MULSSmem)
+		v.reset(Op386MULSSload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -10462,7 +10462,7 @@ func rewriteValue386_Op386ORL_0(v *Value) bool {
 	}
 	// match: (ORL x l:(MOVLload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ORLmem x [off] {sym} ptr mem)
+	// result: (ORLload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -10478,7 +10478,7 @@ func rewriteValue386_Op386ORL_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(Op386ORLmem)
+		v.reset(Op386ORLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -10488,7 +10488,7 @@ func rewriteValue386_Op386ORL_0(v *Value) bool {
 	}
 	// match: (ORL l:(MOVLload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ORLmem x [off] {sym} ptr mem)
+	// result: (ORLload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -10504,7 +10504,7 @@ func rewriteValue386_Op386ORL_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(Op386ORLmem)
+		v.reset(Op386ORLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -14120,14 +14120,14 @@ func rewriteValue386_Op386ORLconst_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValue386_Op386ORLmem_0(v *Value) bool {
+func rewriteValue386_Op386ORLload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	config := b.Func.Config
 	_ = config
-	// match: (ORLmem [off1] {sym} val (ADDLconst [off2] base) mem)
+	// match: (ORLload [off1] {sym} val (ADDLconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (ORLmem [off1+off2] {sym} val base mem)
+	// result: (ORLload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -14143,7 +14143,7 @@ func rewriteValue386_Op386ORLmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(Op386ORLmem)
+		v.reset(Op386ORLload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -14151,9 +14151,9 @@ func rewriteValue386_Op386ORLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ORLmem [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
+	// match: (ORLload [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)
-	// result: (ORLmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (ORLload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -14170,7 +14170,7 @@ func rewriteValue386_Op386ORLmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)) {
 			break
 		}
-		v.reset(Op386ORLmem)
+		v.reset(Op386ORLload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -15603,7 +15603,7 @@ func rewriteValue386_Op386SUBL_0(v *Value) bool {
 	}
 	// match: (SUBL x l:(MOVLload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (SUBLmem x [off] {sym} ptr mem)
+	// result: (SUBLload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -15619,7 +15619,7 @@ func rewriteValue386_Op386SUBL_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(Op386SUBLmem)
+		v.reset(Op386SUBLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -15688,14 +15688,14 @@ func rewriteValue386_Op386SUBLconst_0(v *Value) bool {
 		return true
 	}
 }
-func rewriteValue386_Op386SUBLmem_0(v *Value) bool {
+func rewriteValue386_Op386SUBLload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	config := b.Func.Config
 	_ = config
-	// match: (SUBLmem [off1] {sym} val (ADDLconst [off2] base) mem)
+	// match: (SUBLload [off1] {sym} val (ADDLconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (SUBLmem [off1+off2] {sym} val base mem)
+	// result: (SUBLload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -15711,7 +15711,7 @@ func rewriteValue386_Op386SUBLmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(Op386SUBLmem)
+		v.reset(Op386SUBLload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -15719,9 +15719,9 @@ func rewriteValue386_Op386SUBLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SUBLmem [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
+	// match: (SUBLload [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)
-	// result: (SUBLmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (SUBLload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -15738,7 +15738,7 @@ func rewriteValue386_Op386SUBLmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)) {
 			break
 		}
-		v.reset(Op386SUBLmem)
+		v.reset(Op386SUBLload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -15815,7 +15815,7 @@ func rewriteValue386_Op386SUBSD_0(v *Value) bool {
 	_ = config
 	// match: (SUBSD x l:(MOVSDload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && !config.use387 && clobber(l)
-	// result: (SUBSDmem x [off] {sym} ptr mem)
+	// result: (SUBSDload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -15831,7 +15831,7 @@ func rewriteValue386_Op386SUBSD_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && !config.use387 && clobber(l)) {
 			break
 		}
-		v.reset(Op386SUBSDmem)
+		v.reset(Op386SUBSDload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -15841,14 +15841,14 @@ func rewriteValue386_Op386SUBSD_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValue386_Op386SUBSDmem_0(v *Value) bool {
+func rewriteValue386_Op386SUBSDload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	config := b.Func.Config
 	_ = config
-	// match: (SUBSDmem [off1] {sym} val (ADDLconst [off2] base) mem)
+	// match: (SUBSDload [off1] {sym} val (ADDLconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (SUBSDmem [off1+off2] {sym} val base mem)
+	// result: (SUBSDload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -15864,7 +15864,7 @@ func rewriteValue386_Op386SUBSDmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(Op386SUBSDmem)
+		v.reset(Op386SUBSDload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -15872,9 +15872,9 @@ func rewriteValue386_Op386SUBSDmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SUBSDmem [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
+	// match: (SUBSDload [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)
-	// result: (SUBSDmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (SUBSDload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -15891,7 +15891,7 @@ func rewriteValue386_Op386SUBSDmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)) {
 			break
 		}
-		v.reset(Op386SUBSDmem)
+		v.reset(Op386SUBSDload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -15908,7 +15908,7 @@ func rewriteValue386_Op386SUBSS_0(v *Value) bool {
 	_ = config
 	// match: (SUBSS x l:(MOVSSload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && !config.use387 && clobber(l)
-	// result: (SUBSSmem x [off] {sym} ptr mem)
+	// result: (SUBSSload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -15924,7 +15924,7 @@ func rewriteValue386_Op386SUBSS_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && !config.use387 && clobber(l)) {
 			break
 		}
-		v.reset(Op386SUBSSmem)
+		v.reset(Op386SUBSSload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -15934,14 +15934,14 @@ func rewriteValue386_Op386SUBSS_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValue386_Op386SUBSSmem_0(v *Value) bool {
+func rewriteValue386_Op386SUBSSload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	config := b.Func.Config
 	_ = config
-	// match: (SUBSSmem [off1] {sym} val (ADDLconst [off2] base) mem)
+	// match: (SUBSSload [off1] {sym} val (ADDLconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (SUBSSmem [off1+off2] {sym} val base mem)
+	// result: (SUBSSload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -15957,7 +15957,7 @@ func rewriteValue386_Op386SUBSSmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(Op386SUBSSmem)
+		v.reset(Op386SUBSSload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -15965,9 +15965,9 @@ func rewriteValue386_Op386SUBSSmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SUBSSmem [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
+	// match: (SUBSSload [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)
-	// result: (SUBSSmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (SUBSSload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -15984,7 +15984,7 @@ func rewriteValue386_Op386SUBSSmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)) {
 			break
 		}
-		v.reset(Op386SUBSSmem)
+		v.reset(Op386SUBSSload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -16195,7 +16195,7 @@ func rewriteValue386_Op386XORL_0(v *Value) bool {
 	}
 	// match: (XORL x l:(MOVLload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (XORLmem x [off] {sym} ptr mem)
+	// result: (XORLload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -16211,7 +16211,7 @@ func rewriteValue386_Op386XORL_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(Op386XORLmem)
+		v.reset(Op386XORLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -16221,7 +16221,7 @@ func rewriteValue386_Op386XORL_0(v *Value) bool {
 	}
 	// match: (XORL l:(MOVLload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (XORLmem x [off] {sym} ptr mem)
+	// result: (XORLload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -16237,7 +16237,7 @@ func rewriteValue386_Op386XORL_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(Op386XORLmem)
+		v.reset(Op386XORLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -16310,14 +16310,14 @@ func rewriteValue386_Op386XORLconst_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValue386_Op386XORLmem_0(v *Value) bool {
+func rewriteValue386_Op386XORLload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	config := b.Func.Config
 	_ = config
-	// match: (XORLmem [off1] {sym} val (ADDLconst [off2] base) mem)
+	// match: (XORLload [off1] {sym} val (ADDLconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (XORLmem [off1+off2] {sym} val base mem)
+	// result: (XORLload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -16333,7 +16333,7 @@ func rewriteValue386_Op386XORLmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(Op386XORLmem)
+		v.reset(Op386XORLload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -16341,9 +16341,9 @@ func rewriteValue386_Op386XORLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (XORLmem [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
+	// match: (XORLload [off1] {sym1} val (LEAL [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)
-	// result: (XORLmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (XORLload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -16360,7 +16360,7 @@ func rewriteValue386_Op386XORLmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2) && (base.Op != OpSB || !config.ctxt.Flag_shared)) {
 			break
 		}
-		v.reset(Op386XORLmem)
+		v.reset(Op386XORLload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
diff --git a/src/cmd/compile/internal/ssa/rewriteAMD64.go b/src/cmd/compile/internal/ssa/rewriteAMD64.go
index 3ff7e48765..5ccd176e34 100644
--- a/src/cmd/compile/internal/ssa/rewriteAMD64.go
+++ b/src/cmd/compile/internal/ssa/rewriteAMD64.go
@@ -19,38 +19,38 @@ func rewriteValueAMD64(v *Value) bool {
 		return rewriteValueAMD64_OpAMD64ADDL_0(v) || rewriteValueAMD64_OpAMD64ADDL_10(v) || rewriteValueAMD64_OpAMD64ADDL_20(v)
 	case OpAMD64ADDLconst:
 		return rewriteValueAMD64_OpAMD64ADDLconst_0(v) || rewriteValueAMD64_OpAMD64ADDLconst_10(v)
-	case OpAMD64ADDLconstmem:
-		return rewriteValueAMD64_OpAMD64ADDLconstmem_0(v)
-	case OpAMD64ADDLmem:
-		return rewriteValueAMD64_OpAMD64ADDLmem_0(v)
+	case OpAMD64ADDLconstmodify:
+		return rewriteValueAMD64_OpAMD64ADDLconstmodify_0(v)
+	case OpAMD64ADDLload:
+		return rewriteValueAMD64_OpAMD64ADDLload_0(v)
 	case OpAMD64ADDQ:
 		return rewriteValueAMD64_OpAMD64ADDQ_0(v) || rewriteValueAMD64_OpAMD64ADDQ_10(v) || rewriteValueAMD64_OpAMD64ADDQ_20(v)
 	case OpAMD64ADDQconst:
 		return rewriteValueAMD64_OpAMD64ADDQconst_0(v) || rewriteValueAMD64_OpAMD64ADDQconst_10(v)
-	case OpAMD64ADDQconstmem:
-		return rewriteValueAMD64_OpAMD64ADDQconstmem_0(v)
-	case OpAMD64ADDQmem:
-		return rewriteValueAMD64_OpAMD64ADDQmem_0(v)
+	case OpAMD64ADDQconstmodify:
+		return rewriteValueAMD64_OpAMD64ADDQconstmodify_0(v)
+	case OpAMD64ADDQload:
+		return rewriteValueAMD64_OpAMD64ADDQload_0(v)
 	case OpAMD64ADDSD:
 		return rewriteValueAMD64_OpAMD64ADDSD_0(v)
-	case OpAMD64ADDSDmem:
-		return rewriteValueAMD64_OpAMD64ADDSDmem_0(v)
+	case OpAMD64ADDSDload:
+		return rewriteValueAMD64_OpAMD64ADDSDload_0(v)
 	case OpAMD64ADDSS:
 		return rewriteValueAMD64_OpAMD64ADDSS_0(v)
-	case OpAMD64ADDSSmem:
-		return rewriteValueAMD64_OpAMD64ADDSSmem_0(v)
+	case OpAMD64ADDSSload:
+		return rewriteValueAMD64_OpAMD64ADDSSload_0(v)
 	case OpAMD64ANDL:
 		return rewriteValueAMD64_OpAMD64ANDL_0(v)
 	case OpAMD64ANDLconst:
 		return rewriteValueAMD64_OpAMD64ANDLconst_0(v)
-	case OpAMD64ANDLmem:
-		return rewriteValueAMD64_OpAMD64ANDLmem_0(v)
+	case OpAMD64ANDLload:
+		return rewriteValueAMD64_OpAMD64ANDLload_0(v)
 	case OpAMD64ANDQ:
 		return rewriteValueAMD64_OpAMD64ANDQ_0(v)
 	case OpAMD64ANDQconst:
 		return rewriteValueAMD64_OpAMD64ANDQconst_0(v)
-	case OpAMD64ANDQmem:
-		return rewriteValueAMD64_OpAMD64ANDQmem_0(v)
+	case OpAMD64ANDQload:
+		return rewriteValueAMD64_OpAMD64ANDQload_0(v)
 	case OpAMD64BSFQ:
 		return rewriteValueAMD64_OpAMD64BSFQ_0(v)
 	case OpAMD64BTLconst:
@@ -129,26 +129,26 @@ func rewriteValueAMD64(v *Value) bool {
 		return rewriteValueAMD64_OpAMD64CMPB_0(v)
 	case OpAMD64CMPBconst:
 		return rewriteValueAMD64_OpAMD64CMPBconst_0(v)
-	case OpAMD64CMPBmem:
-		return rewriteValueAMD64_OpAMD64CMPBmem_0(v)
+	case OpAMD64CMPBload:
+		return rewriteValueAMD64_OpAMD64CMPBload_0(v)
 	case OpAMD64CMPL:
 		return rewriteValueAMD64_OpAMD64CMPL_0(v)
 	case OpAMD64CMPLconst:
 		return rewriteValueAMD64_OpAMD64CMPLconst_0(v) || rewriteValueAMD64_OpAMD64CMPLconst_10(v)
-	case OpAMD64CMPLmem:
-		return rewriteValueAMD64_OpAMD64CMPLmem_0(v)
+	case OpAMD64CMPLload:
+		return rewriteValueAMD64_OpAMD64CMPLload_0(v)
 	case OpAMD64CMPQ:
 		return rewriteValueAMD64_OpAMD64CMPQ_0(v)
 	case OpAMD64CMPQconst:
 		return rewriteValueAMD64_OpAMD64CMPQconst_0(v) || rewriteValueAMD64_OpAMD64CMPQconst_10(v)
-	case OpAMD64CMPQmem:
-		return rewriteValueAMD64_OpAMD64CMPQmem_0(v)
+	case OpAMD64CMPQload:
+		return rewriteValueAMD64_OpAMD64CMPQload_0(v)
 	case OpAMD64CMPW:
 		return rewriteValueAMD64_OpAMD64CMPW_0(v)
 	case OpAMD64CMPWconst:
 		return rewriteValueAMD64_OpAMD64CMPWconst_0(v)
-	case OpAMD64CMPWmem:
-		return rewriteValueAMD64_OpAMD64CMPWmem_0(v)
+	case OpAMD64CMPWload:
+		return rewriteValueAMD64_OpAMD64CMPWload_0(v)
 	case OpAMD64CMPXCHGLlock:
 		return rewriteValueAMD64_OpAMD64CMPXCHGLlock_0(v)
 	case OpAMD64CMPXCHGQlock:
@@ -311,12 +311,12 @@ func rewriteValueAMD64(v *Value) bool {
 		return rewriteValueAMD64_OpAMD64MULQconst_0(v) || rewriteValueAMD64_OpAMD64MULQconst_10(v) || rewriteValueAMD64_OpAMD64MULQconst_20(v) || rewriteValueAMD64_OpAMD64MULQconst_30(v)
 	case OpAMD64MULSD:
 		return rewriteValueAMD64_OpAMD64MULSD_0(v)
-	case OpAMD64MULSDmem:
-		return rewriteValueAMD64_OpAMD64MULSDmem_0(v)
+	case OpAMD64MULSDload:
+		return rewriteValueAMD64_OpAMD64MULSDload_0(v)
 	case OpAMD64MULSS:
 		return rewriteValueAMD64_OpAMD64MULSS_0(v)
-	case OpAMD64MULSSmem:
-		return rewriteValueAMD64_OpAMD64MULSSmem_0(v)
+	case OpAMD64MULSSload:
+		return rewriteValueAMD64_OpAMD64MULSSload_0(v)
 	case OpAMD64NEGL:
 		return rewriteValueAMD64_OpAMD64NEGL_0(v)
 	case OpAMD64NEGQ:
@@ -329,14 +329,14 @@ func rewriteValueAMD64(v *Value) bool {
 		return rewriteValueAMD64_OpAMD64ORL_0(v) || rewriteValueAMD64_OpAMD64ORL_10(v) || rewriteValueAMD64_OpAMD64ORL_20(v) || rewriteValueAMD64_OpAMD64ORL_30(v) || rewriteValueAMD64_OpAMD64ORL_40(v) || rewriteValueAMD64_OpAMD64ORL_50(v) || rewriteValueAMD64_OpAMD64ORL_60(v) || rewriteValueAMD64_OpAMD64ORL_70(v) || rewriteValueAMD64_OpAMD64ORL_80(v) || rewriteValueAMD64_OpAMD64ORL_90(v) || rewriteValueAMD64_OpAMD64ORL_100(v) || rewriteValueAMD64_OpAMD64ORL_110(v) || rewriteValueAMD64_OpAMD64ORL_120(v) || rewriteValueAMD64_OpAMD64ORL_130(v)
 	case OpAMD64ORLconst:
 		return rewriteValueAMD64_OpAMD64ORLconst_0(v)
-	case OpAMD64ORLmem:
-		return rewriteValueAMD64_OpAMD64ORLmem_0(v)
+	case OpAMD64ORLload:
+		return rewriteValueAMD64_OpAMD64ORLload_0(v)
 	case OpAMD64ORQ:
 		return rewriteValueAMD64_OpAMD64ORQ_0(v) || rewriteValueAMD64_OpAMD64ORQ_10(v) || rewriteValueAMD64_OpAMD64ORQ_20(v) || rewriteValueAMD64_OpAMD64ORQ_30(v) || rewriteValueAMD64_OpAMD64ORQ_40(v) || rewriteValueAMD64_OpAMD64ORQ_50(v) || rewriteValueAMD64_OpAMD64ORQ_60(v) || rewriteValueAMD64_OpAMD64ORQ_70(v) || rewriteValueAMD64_OpAMD64ORQ_80(v) || rewriteValueAMD64_OpAMD64ORQ_90(v) || rewriteValueAMD64_OpAMD64ORQ_100(v) || rewriteValueAMD64_OpAMD64ORQ_110(v) || rewriteValueAMD64_OpAMD64ORQ_120(v) || rewriteValueAMD64_OpAMD64ORQ_130(v) || rewriteValueAMD64_OpAMD64ORQ_140(v) || rewriteValueAMD64_OpAMD64ORQ_150(v) || rewriteValueAMD64_OpAMD64ORQ_160(v)
 	case OpAMD64ORQconst:
 		return rewriteValueAMD64_OpAMD64ORQconst_0(v)
-	case OpAMD64ORQmem:
-		return rewriteValueAMD64_OpAMD64ORQmem_0(v)
+	case OpAMD64ORQload:
+		return rewriteValueAMD64_OpAMD64ORQload_0(v)
 	case OpAMD64ROLB:
 		return rewriteValueAMD64_OpAMD64ROLB_0(v)
 	case OpAMD64ROLBconst:
@@ -385,42 +385,42 @@ func rewriteValueAMD64(v *Value) bool {
 		return rewriteValueAMD64_OpAMD64SETA_0(v)
 	case OpAMD64SETAE:
 		return rewriteValueAMD64_OpAMD64SETAE_0(v)
-	case OpAMD64SETAEmem:
-		return rewriteValueAMD64_OpAMD64SETAEmem_0(v)
-	case OpAMD64SETAmem:
-		return rewriteValueAMD64_OpAMD64SETAmem_0(v)
+	case OpAMD64SETAEstore:
+		return rewriteValueAMD64_OpAMD64SETAEstore_0(v)
+	case OpAMD64SETAstore:
+		return rewriteValueAMD64_OpAMD64SETAstore_0(v)
 	case OpAMD64SETB:
 		return rewriteValueAMD64_OpAMD64SETB_0(v)
 	case OpAMD64SETBE:
 		return rewriteValueAMD64_OpAMD64SETBE_0(v)
-	case OpAMD64SETBEmem:
-		return rewriteValueAMD64_OpAMD64SETBEmem_0(v)
-	case OpAMD64SETBmem:
-		return rewriteValueAMD64_OpAMD64SETBmem_0(v)
+	case OpAMD64SETBEstore:
+		return rewriteValueAMD64_OpAMD64SETBEstore_0(v)
+	case OpAMD64SETBstore:
+		return rewriteValueAMD64_OpAMD64SETBstore_0(v)
 	case OpAMD64SETEQ:
 		return rewriteValueAMD64_OpAMD64SETEQ_0(v) || rewriteValueAMD64_OpAMD64SETEQ_10(v) || rewriteValueAMD64_OpAMD64SETEQ_20(v)
-	case OpAMD64SETEQmem:
-		return rewriteValueAMD64_OpAMD64SETEQmem_0(v) || rewriteValueAMD64_OpAMD64SETEQmem_10(v) || rewriteValueAMD64_OpAMD64SETEQmem_20(v)
+	case OpAMD64SETEQstore:
+		return rewriteValueAMD64_OpAMD64SETEQstore_0(v) || rewriteValueAMD64_OpAMD64SETEQstore_10(v) || rewriteValueAMD64_OpAMD64SETEQstore_20(v)
 	case OpAMD64SETG:
 		return rewriteValueAMD64_OpAMD64SETG_0(v)
 	case OpAMD64SETGE:
 		return rewriteValueAMD64_OpAMD64SETGE_0(v)
-	case OpAMD64SETGEmem:
-		return rewriteValueAMD64_OpAMD64SETGEmem_0(v)
-	case OpAMD64SETGmem:
-		return rewriteValueAMD64_OpAMD64SETGmem_0(v)
+	case OpAMD64SETGEstore:
+		return rewriteValueAMD64_OpAMD64SETGEstore_0(v)
+	case OpAMD64SETGstore:
+		return rewriteValueAMD64_OpAMD64SETGstore_0(v)
 	case OpAMD64SETL:
 		return rewriteValueAMD64_OpAMD64SETL_0(v)
 	case OpAMD64SETLE:
 		return rewriteValueAMD64_OpAMD64SETLE_0(v)
-	case OpAMD64SETLEmem:
-		return rewriteValueAMD64_OpAMD64SETLEmem_0(v)
-	case OpAMD64SETLmem:
-		return rewriteValueAMD64_OpAMD64SETLmem_0(v)
+	case OpAMD64SETLEstore:
+		return rewriteValueAMD64_OpAMD64SETLEstore_0(v)
+	case OpAMD64SETLstore:
+		return rewriteValueAMD64_OpAMD64SETLstore_0(v)
 	case OpAMD64SETNE:
 		return rewriteValueAMD64_OpAMD64SETNE_0(v) || rewriteValueAMD64_OpAMD64SETNE_10(v) || rewriteValueAMD64_OpAMD64SETNE_20(v)
-	case OpAMD64SETNEmem:
-		return rewriteValueAMD64_OpAMD64SETNEmem_0(v) || rewriteValueAMD64_OpAMD64SETNEmem_10(v) || rewriteValueAMD64_OpAMD64SETNEmem_20(v)
+	case OpAMD64SETNEstore:
+		return rewriteValueAMD64_OpAMD64SETNEstore_0(v) || rewriteValueAMD64_OpAMD64SETNEstore_10(v) || rewriteValueAMD64_OpAMD64SETNEstore_20(v)
 	case OpAMD64SHLL:
 		return rewriteValueAMD64_OpAMD64SHLL_0(v)
 	case OpAMD64SHLLconst:
@@ -449,22 +449,22 @@ func rewriteValueAMD64(v *Value) bool {
 		return rewriteValueAMD64_OpAMD64SUBL_0(v)
 	case OpAMD64SUBLconst:
 		return rewriteValueAMD64_OpAMD64SUBLconst_0(v)
-	case OpAMD64SUBLmem:
-		return rewriteValueAMD64_OpAMD64SUBLmem_0(v)
+	case OpAMD64SUBLload:
+		return rewriteValueAMD64_OpAMD64SUBLload_0(v)
 	case OpAMD64SUBQ:
 		return rewriteValueAMD64_OpAMD64SUBQ_0(v)
 	case OpAMD64SUBQconst:
 		return rewriteValueAMD64_OpAMD64SUBQconst_0(v)
-	case OpAMD64SUBQmem:
-		return rewriteValueAMD64_OpAMD64SUBQmem_0(v)
+	case OpAMD64SUBQload:
+		return rewriteValueAMD64_OpAMD64SUBQload_0(v)
 	case OpAMD64SUBSD:
 		return rewriteValueAMD64_OpAMD64SUBSD_0(v)
-	case OpAMD64SUBSDmem:
-		return rewriteValueAMD64_OpAMD64SUBSDmem_0(v)
+	case OpAMD64SUBSDload:
+		return rewriteValueAMD64_OpAMD64SUBSDload_0(v)
 	case OpAMD64SUBSS:
 		return rewriteValueAMD64_OpAMD64SUBSS_0(v)
-	case OpAMD64SUBSSmem:
-		return rewriteValueAMD64_OpAMD64SUBSSmem_0(v)
+	case OpAMD64SUBSSload:
+		return rewriteValueAMD64_OpAMD64SUBSSload_0(v)
 	case OpAMD64TESTB:
 		return rewriteValueAMD64_OpAMD64TESTB_0(v)
 	case OpAMD64TESTBconst:
@@ -493,14 +493,14 @@ func rewriteValueAMD64(v *Value) bool {
 		return rewriteValueAMD64_OpAMD64XORL_0(v) || rewriteValueAMD64_OpAMD64XORL_10(v)
 	case OpAMD64XORLconst:
 		return rewriteValueAMD64_OpAMD64XORLconst_0(v) || rewriteValueAMD64_OpAMD64XORLconst_10(v)
-	case OpAMD64XORLmem:
-		return rewriteValueAMD64_OpAMD64XORLmem_0(v)
+	case OpAMD64XORLload:
+		return rewriteValueAMD64_OpAMD64XORLload_0(v)
 	case OpAMD64XORQ:
 		return rewriteValueAMD64_OpAMD64XORQ_0(v) || rewriteValueAMD64_OpAMD64XORQ_10(v)
 	case OpAMD64XORQconst:
 		return rewriteValueAMD64_OpAMD64XORQconst_0(v)
-	case OpAMD64XORQmem:
-		return rewriteValueAMD64_OpAMD64XORQmem_0(v)
+	case OpAMD64XORQload:
+		return rewriteValueAMD64_OpAMD64XORQload_0(v)
 	case OpAdd16:
 		return rewriteValueAMD64_OpAdd16_0(v)
 	case OpAdd32:
@@ -1603,7 +1603,7 @@ func rewriteValueAMD64_OpAMD64ADDL_20(v *Value) bool {
 	}
 	// match: (ADDL x l:(MOVLload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ADDLmem x [off] {sym} ptr mem)
+	// result: (ADDLload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -1619,7 +1619,7 @@ func rewriteValueAMD64_OpAMD64ADDL_20(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64ADDLmem)
+		v.reset(OpAMD64ADDLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -1629,7 +1629,7 @@ func rewriteValueAMD64_OpAMD64ADDL_20(v *Value) bool {
 	}
 	// match: (ADDL l:(MOVLload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ADDLmem x [off] {sym} ptr mem)
+	// result: (ADDLload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -1645,7 +1645,7 @@ func rewriteValueAMD64_OpAMD64ADDL_20(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64ADDLmem)
+		v.reset(OpAMD64ADDLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -1873,14 +1873,14 @@ func rewriteValueAMD64_OpAMD64ADDLconst_10(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64ADDLconstmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64ADDLconstmodify_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	typ := &b.Func.Config.Types
 	_ = typ
-	// match: (ADDLconstmem [valoff1] {sym} (ADDQconst [off2] base) mem)
+	// match: (ADDLconstmodify [valoff1] {sym} (ADDQconst [off2] base) mem)
 	// cond: ValAndOff(valoff1).canAdd(off2)
-	// result: (ADDLconstmem [ValAndOff(valoff1).add(off2)] {sym} base mem)
+	// result: (ADDLconstmodify [ValAndOff(valoff1).add(off2)] {sym} base mem)
 	for {
 		valoff1 := v.AuxInt
 		sym := v.Aux
@@ -1895,16 +1895,16 @@ func rewriteValueAMD64_OpAMD64ADDLconstmem_0(v *Value) bool {
 		if !(ValAndOff(valoff1).canAdd(off2)) {
 			break
 		}
-		v.reset(OpAMD64ADDLconstmem)
+		v.reset(OpAMD64ADDLconstmodify)
 		v.AuxInt = ValAndOff(valoff1).add(off2)
 		v.Aux = sym
 		v.AddArg(base)
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ADDLconstmem [valoff1] {sym1} (LEAQ [off2] {sym2} base) mem)
+	// match: (ADDLconstmodify [valoff1] {sym1} (LEAQ [off2] {sym2} base) mem)
 	// cond: ValAndOff(valoff1).canAdd(off2) && canMergeSym(sym1, sym2)
-	// result: (ADDLconstmem [ValAndOff(valoff1).add(off2)] {mergeSym(sym1,sym2)} base mem)
+	// result: (ADDLconstmodify [ValAndOff(valoff1).add(off2)] {mergeSym(sym1,sym2)} base mem)
 	for {
 		valoff1 := v.AuxInt
 		sym1 := v.Aux
@@ -1920,14 +1920,14 @@ func rewriteValueAMD64_OpAMD64ADDLconstmem_0(v *Value) bool {
 		if !(ValAndOff(valoff1).canAdd(off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64ADDLconstmem)
+		v.reset(OpAMD64ADDLconstmodify)
 		v.AuxInt = ValAndOff(valoff1).add(off2)
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(base)
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ADDLconstmem [valOff] {sym} ptr (MOVSSstore [ValAndOff(valOff).Off()] {sym} ptr x _))
+	// match: (ADDLconstmodify [valOff] {sym} ptr (MOVSSstore [ValAndOff(valOff).Off()] {sym} ptr x _))
 	// cond:
 	// result: (ADDLconst [ValAndOff(valOff).Val()] (MOVLf2i x))
 	for {
@@ -1959,14 +1959,14 @@ func rewriteValueAMD64_OpAMD64ADDLconstmem_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64ADDLmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64ADDLload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	typ := &b.Func.Config.Types
 	_ = typ
-	// match: (ADDLmem [off1] {sym} val (ADDQconst [off2] base) mem)
+	// match: (ADDLload [off1] {sym} val (ADDQconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (ADDLmem [off1+off2] {sym} val base mem)
+	// result: (ADDLload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -1982,7 +1982,7 @@ func rewriteValueAMD64_OpAMD64ADDLmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64ADDLmem)
+		v.reset(OpAMD64ADDLload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -1990,9 +1990,9 @@ func rewriteValueAMD64_OpAMD64ADDLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ADDLmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	// match: (ADDLload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (ADDLmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (ADDLload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -2009,7 +2009,7 @@ func rewriteValueAMD64_OpAMD64ADDLmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64ADDLmem)
+		v.reset(OpAMD64ADDLload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -2017,7 +2017,7 @@ func rewriteValueAMD64_OpAMD64ADDLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ADDLmem x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _))
+	// match: (ADDLload x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _))
 	// cond:
 	// result: (ADDL x (MOVLf2i y))
 	for {
@@ -2499,7 +2499,7 @@ func rewriteValueAMD64_OpAMD64ADDQ_20(v *Value) bool {
 	}
 	// match: (ADDQ x l:(MOVQload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ADDQmem x [off] {sym} ptr mem)
+	// result: (ADDQload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -2515,7 +2515,7 @@ func rewriteValueAMD64_OpAMD64ADDQ_20(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64ADDQmem)
+		v.reset(OpAMD64ADDQload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -2525,7 +2525,7 @@ func rewriteValueAMD64_OpAMD64ADDQ_20(v *Value) bool {
 	}
 	// match: (ADDQ l:(MOVQload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ADDQmem x [off] {sym} ptr mem)
+	// result: (ADDQload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -2541,7 +2541,7 @@ func rewriteValueAMD64_OpAMD64ADDQ_20(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64ADDQmem)
+		v.reset(OpAMD64ADDQload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -2771,14 +2771,14 @@ func rewriteValueAMD64_OpAMD64ADDQconst_10(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64ADDQconstmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64ADDQconstmodify_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	typ := &b.Func.Config.Types
 	_ = typ
-	// match: (ADDQconstmem [valoff1] {sym} (ADDQconst [off2] base) mem)
+	// match: (ADDQconstmodify [valoff1] {sym} (ADDQconst [off2] base) mem)
 	// cond: ValAndOff(valoff1).canAdd(off2)
-	// result: (ADDQconstmem [ValAndOff(valoff1).add(off2)] {sym} base mem)
+	// result: (ADDQconstmodify [ValAndOff(valoff1).add(off2)] {sym} base mem)
 	for {
 		valoff1 := v.AuxInt
 		sym := v.Aux
@@ -2793,16 +2793,16 @@ func rewriteValueAMD64_OpAMD64ADDQconstmem_0(v *Value) bool {
 		if !(ValAndOff(valoff1).canAdd(off2)) {
 			break
 		}
-		v.reset(OpAMD64ADDQconstmem)
+		v.reset(OpAMD64ADDQconstmodify)
 		v.AuxInt = ValAndOff(valoff1).add(off2)
 		v.Aux = sym
 		v.AddArg(base)
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ADDQconstmem [valoff1] {sym1} (LEAQ [off2] {sym2} base) mem)
+	// match: (ADDQconstmodify [valoff1] {sym1} (LEAQ [off2] {sym2} base) mem)
 	// cond: ValAndOff(valoff1).canAdd(off2) && canMergeSym(sym1, sym2)
-	// result: (ADDQconstmem [ValAndOff(valoff1).add(off2)] {mergeSym(sym1,sym2)} base mem)
+	// result: (ADDQconstmodify [ValAndOff(valoff1).add(off2)] {mergeSym(sym1,sym2)} base mem)
 	for {
 		valoff1 := v.AuxInt
 		sym1 := v.Aux
@@ -2818,14 +2818,14 @@ func rewriteValueAMD64_OpAMD64ADDQconstmem_0(v *Value) bool {
 		if !(ValAndOff(valoff1).canAdd(off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64ADDQconstmem)
+		v.reset(OpAMD64ADDQconstmodify)
 		v.AuxInt = ValAndOff(valoff1).add(off2)
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(base)
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ADDQconstmem [valOff] {sym} ptr (MOVSDstore [ValAndOff(valOff).Off()] {sym} ptr x _))
+	// match: (ADDQconstmodify [valOff] {sym} ptr (MOVSDstore [ValAndOff(valOff).Off()] {sym} ptr x _))
 	// cond:
 	// result: (ADDQconst [ValAndOff(valOff).Val()] (MOVQf2i x))
 	for {
@@ -2857,14 +2857,14 @@ func rewriteValueAMD64_OpAMD64ADDQconstmem_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64ADDQmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64ADDQload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	typ := &b.Func.Config.Types
 	_ = typ
-	// match: (ADDQmem [off1] {sym} val (ADDQconst [off2] base) mem)
+	// match: (ADDQload [off1] {sym} val (ADDQconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (ADDQmem [off1+off2] {sym} val base mem)
+	// result: (ADDQload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -2880,7 +2880,7 @@ func rewriteValueAMD64_OpAMD64ADDQmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64ADDQmem)
+		v.reset(OpAMD64ADDQload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -2888,9 +2888,9 @@ func rewriteValueAMD64_OpAMD64ADDQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ADDQmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	// match: (ADDQload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (ADDQmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (ADDQload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -2907,7 +2907,7 @@ func rewriteValueAMD64_OpAMD64ADDQmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64ADDQmem)
+		v.reset(OpAMD64ADDQload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -2915,7 +2915,7 @@ func rewriteValueAMD64_OpAMD64ADDQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ADDQmem x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _))
+	// match: (ADDQload x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _))
 	// cond:
 	// result: (ADDQ x (MOVQf2i y))
 	for {
@@ -2951,7 +2951,7 @@ func rewriteValueAMD64_OpAMD64ADDQmem_0(v *Value) bool {
 func rewriteValueAMD64_OpAMD64ADDSD_0(v *Value) bool {
 	// match: (ADDSD x l:(MOVSDload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ADDSDmem x [off] {sym} ptr mem)
+	// result: (ADDSDload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -2967,7 +2967,7 @@ func rewriteValueAMD64_OpAMD64ADDSD_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64ADDSDmem)
+		v.reset(OpAMD64ADDSDload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -2977,7 +2977,7 @@ func rewriteValueAMD64_OpAMD64ADDSD_0(v *Value) bool {
 	}
 	// match: (ADDSD l:(MOVSDload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ADDSDmem x [off] {sym} ptr mem)
+	// result: (ADDSDload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -2993,7 +2993,7 @@ func rewriteValueAMD64_OpAMD64ADDSD_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64ADDSDmem)
+		v.reset(OpAMD64ADDSDload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -3003,14 +3003,14 @@ func rewriteValueAMD64_OpAMD64ADDSD_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64ADDSDmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64ADDSDload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	typ := &b.Func.Config.Types
 	_ = typ
-	// match: (ADDSDmem [off1] {sym} val (ADDQconst [off2] base) mem)
+	// match: (ADDSDload [off1] {sym} val (ADDQconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (ADDSDmem [off1+off2] {sym} val base mem)
+	// result: (ADDSDload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -3026,7 +3026,7 @@ func rewriteValueAMD64_OpAMD64ADDSDmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64ADDSDmem)
+		v.reset(OpAMD64ADDSDload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -3034,9 +3034,9 @@ func rewriteValueAMD64_OpAMD64ADDSDmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ADDSDmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	// match: (ADDSDload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (ADDSDmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (ADDSDload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -3053,7 +3053,7 @@ func rewriteValueAMD64_OpAMD64ADDSDmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64ADDSDmem)
+		v.reset(OpAMD64ADDSDload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -3061,7 +3061,7 @@ func rewriteValueAMD64_OpAMD64ADDSDmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ADDSDmem x [off] {sym} ptr (MOVQstore [off] {sym} ptr y _))
+	// match: (ADDSDload x [off] {sym} ptr (MOVQstore [off] {sym} ptr y _))
 	// cond:
 	// result: (ADDSD x (MOVQi2f y))
 	for {
@@ -3097,7 +3097,7 @@ func rewriteValueAMD64_OpAMD64ADDSDmem_0(v *Value) bool {
 func rewriteValueAMD64_OpAMD64ADDSS_0(v *Value) bool {
 	// match: (ADDSS x l:(MOVSSload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ADDSSmem x [off] {sym} ptr mem)
+	// result: (ADDSSload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -3113,7 +3113,7 @@ func rewriteValueAMD64_OpAMD64ADDSS_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64ADDSSmem)
+		v.reset(OpAMD64ADDSSload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -3123,7 +3123,7 @@ func rewriteValueAMD64_OpAMD64ADDSS_0(v *Value) bool {
 	}
 	// match: (ADDSS l:(MOVSSload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ADDSSmem x [off] {sym} ptr mem)
+	// result: (ADDSSload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -3139,7 +3139,7 @@ func rewriteValueAMD64_OpAMD64ADDSS_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64ADDSSmem)
+		v.reset(OpAMD64ADDSSload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -3149,14 +3149,14 @@ func rewriteValueAMD64_OpAMD64ADDSS_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64ADDSSmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64ADDSSload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	typ := &b.Func.Config.Types
 	_ = typ
-	// match: (ADDSSmem [off1] {sym} val (ADDQconst [off2] base) mem)
+	// match: (ADDSSload [off1] {sym} val (ADDQconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (ADDSSmem [off1+off2] {sym} val base mem)
+	// result: (ADDSSload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -3172,7 +3172,7 @@ func rewriteValueAMD64_OpAMD64ADDSSmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64ADDSSmem)
+		v.reset(OpAMD64ADDSSload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -3180,9 +3180,9 @@ func rewriteValueAMD64_OpAMD64ADDSSmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ADDSSmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	// match: (ADDSSload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (ADDSSmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (ADDSSload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -3199,7 +3199,7 @@ func rewriteValueAMD64_OpAMD64ADDSSmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64ADDSSmem)
+		v.reset(OpAMD64ADDSSload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -3207,7 +3207,7 @@ func rewriteValueAMD64_OpAMD64ADDSSmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ADDSSmem x [off] {sym} ptr (MOVLstore [off] {sym} ptr y _))
+	// match: (ADDSSload x [off] {sym} ptr (MOVLstore [off] {sym} ptr y _))
 	// cond:
 	// result: (ADDSS x (MOVLi2f y))
 	for {
@@ -3393,7 +3393,7 @@ func rewriteValueAMD64_OpAMD64ANDL_0(v *Value) bool {
 	}
 	// match: (ANDL x l:(MOVLload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ANDLmem x [off] {sym} ptr mem)
+	// result: (ANDLload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -3409,7 +3409,7 @@ func rewriteValueAMD64_OpAMD64ANDL_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64ANDLmem)
+		v.reset(OpAMD64ANDLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -3419,7 +3419,7 @@ func rewriteValueAMD64_OpAMD64ANDL_0(v *Value) bool {
 	}
 	// match: (ANDL l:(MOVLload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ANDLmem x [off] {sym} ptr mem)
+	// result: (ANDLload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -3435,7 +3435,7 @@ func rewriteValueAMD64_OpAMD64ANDL_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64ANDLmem)
+		v.reset(OpAMD64ANDLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -3546,14 +3546,14 @@ func rewriteValueAMD64_OpAMD64ANDLconst_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64ANDLmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64ANDLload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	typ := &b.Func.Config.Types
 	_ = typ
-	// match: (ANDLmem [off1] {sym} val (ADDQconst [off2] base) mem)
+	// match: (ANDLload [off1] {sym} val (ADDQconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (ANDLmem [off1+off2] {sym} val base mem)
+	// result: (ANDLload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -3569,7 +3569,7 @@ func rewriteValueAMD64_OpAMD64ANDLmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64ANDLmem)
+		v.reset(OpAMD64ANDLload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -3577,9 +3577,9 @@ func rewriteValueAMD64_OpAMD64ANDLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ANDLmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	// match: (ANDLload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (ANDLmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (ANDLload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -3596,7 +3596,7 @@ func rewriteValueAMD64_OpAMD64ANDLmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64ANDLmem)
+		v.reset(OpAMD64ANDLload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -3604,7 +3604,7 @@ func rewriteValueAMD64_OpAMD64ANDLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ANDLmem x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _))
+	// match: (ANDLload x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _))
 	// cond:
 	// result: (ANDL x (MOVLf2i y))
 	for {
@@ -3796,7 +3796,7 @@ func rewriteValueAMD64_OpAMD64ANDQ_0(v *Value) bool {
 	}
 	// match: (ANDQ x l:(MOVQload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ANDQmem x [off] {sym} ptr mem)
+	// result: (ANDQload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -3812,7 +3812,7 @@ func rewriteValueAMD64_OpAMD64ANDQ_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64ANDQmem)
+		v.reset(OpAMD64ANDQload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -3822,7 +3822,7 @@ func rewriteValueAMD64_OpAMD64ANDQ_0(v *Value) bool {
 	}
 	// match: (ANDQ l:(MOVQload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ANDQmem x [off] {sym} ptr mem)
+	// result: (ANDQload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -3838,7 +3838,7 @@ func rewriteValueAMD64_OpAMD64ANDQ_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64ANDQmem)
+		v.reset(OpAMD64ANDQload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -3959,14 +3959,14 @@ func rewriteValueAMD64_OpAMD64ANDQconst_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64ANDQmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64ANDQload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	typ := &b.Func.Config.Types
 	_ = typ
-	// match: (ANDQmem [off1] {sym} val (ADDQconst [off2] base) mem)
+	// match: (ANDQload [off1] {sym} val (ADDQconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (ANDQmem [off1+off2] {sym} val base mem)
+	// result: (ANDQload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -3982,7 +3982,7 @@ func rewriteValueAMD64_OpAMD64ANDQmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64ANDQmem)
+		v.reset(OpAMD64ANDQload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -3990,9 +3990,9 @@ func rewriteValueAMD64_OpAMD64ANDQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ANDQmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	// match: (ANDQload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (ANDQmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (ANDQload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -4009,7 +4009,7 @@ func rewriteValueAMD64_OpAMD64ANDQmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64ANDQmem)
+		v.reset(OpAMD64ANDQload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -4017,7 +4017,7 @@ func rewriteValueAMD64_OpAMD64ANDQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ANDQmem x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _))
+	// match: (ANDQload x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _))
 	// cond:
 	// result: (ANDQ x (MOVQf2i y))
 	for {
@@ -7382,7 +7382,7 @@ func rewriteValueAMD64_OpAMD64CMPB_0(v *Value) bool {
 	}
 	// match: (CMPB l:(MOVBload {sym} [off] ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (CMPBmem {sym} [off] ptr x mem)
+	// result: (CMPBload {sym} [off] ptr x mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -7398,7 +7398,7 @@ func rewriteValueAMD64_OpAMD64CMPB_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64CMPBmem)
+		v.reset(OpAMD64CMPBload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -7408,7 +7408,7 @@ func rewriteValueAMD64_OpAMD64CMPB_0(v *Value) bool {
 	}
 	// match: (CMPB x l:(MOVBload {sym} [off] ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (InvertFlags (CMPBmem {sym} [off] ptr x mem))
+	// result: (InvertFlags (CMPBload {sym} [off] ptr x mem))
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -7425,7 +7425,7 @@ func rewriteValueAMD64_OpAMD64CMPB_0(v *Value) bool {
 			break
 		}
 		v.reset(OpAMD64InvertFlags)
-		v0 := b.NewValue0(v.Pos, OpAMD64CMPBmem, types.TypeFlags)
+		v0 := b.NewValue0(v.Pos, OpAMD64CMPBload, types.TypeFlags)
 		v0.AuxInt = off
 		v0.Aux = sym
 		v0.AddArg(ptr)
@@ -7587,7 +7587,7 @@ func rewriteValueAMD64_OpAMD64CMPBconst_0(v *Value) bool {
 	}
 	// match: (CMPBconst l:(MOVBload {sym} [off] ptr mem) [c])
 	// cond: l.Uses == 1 && validValAndOff(c, off) && clobber(l)
-	// result: @l.Block (CMPBconstmem {sym} [makeValAndOff(c,off)] ptr mem)
+	// result: @l.Block (CMPBconstload {sym} [makeValAndOff(c,off)] ptr mem)
 	for {
 		c := v.AuxInt
 		l := v.Args[0]
@@ -7603,7 +7603,7 @@ func rewriteValueAMD64_OpAMD64CMPBconst_0(v *Value) bool {
 			break
 		}
 		b = l.Block
-		v0 := b.NewValue0(v.Pos, OpAMD64CMPBconstmem, types.TypeFlags)
+		v0 := b.NewValue0(v.Pos, OpAMD64CMPBconstload, types.TypeFlags)
 		v.reset(OpCopy)
 		v.AddArg(v0)
 		v0.AuxInt = makeValAndOff(c, off)
@@ -7614,10 +7614,10 @@ func rewriteValueAMD64_OpAMD64CMPBconst_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64CMPBmem_0(v *Value) bool {
-	// match: (CMPBmem {sym} [off] ptr (MOVLconst [c]) mem)
+func rewriteValueAMD64_OpAMD64CMPBload_0(v *Value) bool {
+	// match: (CMPBload {sym} [off] ptr (MOVLconst [c]) mem)
 	// cond: validValAndOff(int64(int8(c)),off)
-	// result: (CMPBconstmem {sym} [makeValAndOff(int64(int8(c)),off)] ptr mem)
+	// result: (CMPBconstload {sym} [makeValAndOff(int64(int8(c)),off)] ptr mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -7632,7 +7632,7 @@ func rewriteValueAMD64_OpAMD64CMPBmem_0(v *Value) bool {
 		if !(validValAndOff(int64(int8(c)), off)) {
 			break
 		}
-		v.reset(OpAMD64CMPBconstmem)
+		v.reset(OpAMD64CMPBconstload)
 		v.AuxInt = makeValAndOff(int64(int8(c)), off)
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -7680,7 +7680,7 @@ func rewriteValueAMD64_OpAMD64CMPL_0(v *Value) bool {
 	}
 	// match: (CMPL l:(MOVLload {sym} [off] ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (CMPLmem {sym} [off] ptr x mem)
+	// result: (CMPLload {sym} [off] ptr x mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -7696,7 +7696,7 @@ func rewriteValueAMD64_OpAMD64CMPL_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64CMPLmem)
+		v.reset(OpAMD64CMPLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -7706,7 +7706,7 @@ func rewriteValueAMD64_OpAMD64CMPL_0(v *Value) bool {
 	}
 	// match: (CMPL x l:(MOVLload {sym} [off] ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (InvertFlags (CMPLmem {sym} [off] ptr x mem))
+	// result: (InvertFlags (CMPLload {sym} [off] ptr x mem))
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -7723,7 +7723,7 @@ func rewriteValueAMD64_OpAMD64CMPL_0(v *Value) bool {
 			break
 		}
 		v.reset(OpAMD64InvertFlags)
-		v0 := b.NewValue0(v.Pos, OpAMD64CMPLmem, types.TypeFlags)
+		v0 := b.NewValue0(v.Pos, OpAMD64CMPLload, types.TypeFlags)
 		v0.AuxInt = off
 		v0.Aux = sym
 		v0.AddArg(ptr)
@@ -7904,7 +7904,7 @@ func rewriteValueAMD64_OpAMD64CMPLconst_10(v *Value) bool {
 	_ = b
 	// match: (CMPLconst l:(MOVLload {sym} [off] ptr mem) [c])
 	// cond: l.Uses == 1 && validValAndOff(c, off) && clobber(l)
-	// result: @l.Block (CMPLconstmem {sym} [makeValAndOff(c,off)] ptr mem)
+	// result: @l.Block (CMPLconstload {sym} [makeValAndOff(c,off)] ptr mem)
 	for {
 		c := v.AuxInt
 		l := v.Args[0]
@@ -7920,7 +7920,7 @@ func rewriteValueAMD64_OpAMD64CMPLconst_10(v *Value) bool {
 			break
 		}
 		b = l.Block
-		v0 := b.NewValue0(v.Pos, OpAMD64CMPLconstmem, types.TypeFlags)
+		v0 := b.NewValue0(v.Pos, OpAMD64CMPLconstload, types.TypeFlags)
 		v.reset(OpCopy)
 		v.AddArg(v0)
 		v0.AuxInt = makeValAndOff(c, off)
@@ -7931,10 +7931,10 @@ func rewriteValueAMD64_OpAMD64CMPLconst_10(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64CMPLmem_0(v *Value) bool {
-	// match: (CMPLmem {sym} [off] ptr (MOVLconst [c]) mem)
+func rewriteValueAMD64_OpAMD64CMPLload_0(v *Value) bool {
+	// match: (CMPLload {sym} [off] ptr (MOVLconst [c]) mem)
 	// cond: validValAndOff(c,off)
-	// result: (CMPLconstmem {sym} [makeValAndOff(c,off)] ptr mem)
+	// result: (CMPLconstload {sym} [makeValAndOff(c,off)] ptr mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -7949,7 +7949,7 @@ func rewriteValueAMD64_OpAMD64CMPLmem_0(v *Value) bool {
 		if !(validValAndOff(c, off)) {
 			break
 		}
-		v.reset(OpAMD64CMPLconstmem)
+		v.reset(OpAMD64CMPLconstload)
 		v.AuxInt = makeValAndOff(c, off)
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -8003,7 +8003,7 @@ func rewriteValueAMD64_OpAMD64CMPQ_0(v *Value) bool {
 	}
 	// match: (CMPQ l:(MOVQload {sym} [off] ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (CMPQmem {sym} [off] ptr x mem)
+	// result: (CMPQload {sym} [off] ptr x mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -8019,7 +8019,7 @@ func rewriteValueAMD64_OpAMD64CMPQ_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64CMPQmem)
+		v.reset(OpAMD64CMPQload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -8029,7 +8029,7 @@ func rewriteValueAMD64_OpAMD64CMPQ_0(v *Value) bool {
 	}
 	// match: (CMPQ x l:(MOVQload {sym} [off] ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (InvertFlags (CMPQmem {sym} [off] ptr x mem))
+	// result: (InvertFlags (CMPQload {sym} [off] ptr x mem))
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -8046,7 +8046,7 @@ func rewriteValueAMD64_OpAMD64CMPQ_0(v *Value) bool {
 			break
 		}
 		v.reset(OpAMD64InvertFlags)
-		v0 := b.NewValue0(v.Pos, OpAMD64CMPQmem, types.TypeFlags)
+		v0 := b.NewValue0(v.Pos, OpAMD64CMPQload, types.TypeFlags)
 		v0.AuxInt = off
 		v0.Aux = sym
 		v0.AddArg(ptr)
@@ -8344,7 +8344,7 @@ func rewriteValueAMD64_OpAMD64CMPQconst_10(v *Value) bool {
 	}
 	// match: (CMPQconst l:(MOVQload {sym} [off] ptr mem) [c])
 	// cond: l.Uses == 1 && validValAndOff(c, off) && clobber(l)
-	// result: @l.Block (CMPQconstmem {sym} [makeValAndOff(c,off)] ptr mem)
+	// result: @l.Block (CMPQconstload {sym} [makeValAndOff(c,off)] ptr mem)
 	for {
 		c := v.AuxInt
 		l := v.Args[0]
@@ -8360,7 +8360,7 @@ func rewriteValueAMD64_OpAMD64CMPQconst_10(v *Value) bool {
 			break
 		}
 		b = l.Block
-		v0 := b.NewValue0(v.Pos, OpAMD64CMPQconstmem, types.TypeFlags)
+		v0 := b.NewValue0(v.Pos, OpAMD64CMPQconstload, types.TypeFlags)
 		v.reset(OpCopy)
 		v.AddArg(v0)
 		v0.AuxInt = makeValAndOff(c, off)
@@ -8371,10 +8371,10 @@ func rewriteValueAMD64_OpAMD64CMPQconst_10(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64CMPQmem_0(v *Value) bool {
-	// match: (CMPQmem {sym} [off] ptr (MOVQconst [c]) mem)
+func rewriteValueAMD64_OpAMD64CMPQload_0(v *Value) bool {
+	// match: (CMPQload {sym} [off] ptr (MOVQconst [c]) mem)
 	// cond: validValAndOff(c,off)
-	// result: (CMPQconstmem {sym} [makeValAndOff(c,off)] ptr mem)
+	// result: (CMPQconstload {sym} [makeValAndOff(c,off)] ptr mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -8389,7 +8389,7 @@ func rewriteValueAMD64_OpAMD64CMPQmem_0(v *Value) bool {
 		if !(validValAndOff(c, off)) {
 			break
 		}
-		v.reset(OpAMD64CMPQconstmem)
+		v.reset(OpAMD64CMPQconstload)
 		v.AuxInt = makeValAndOff(c, off)
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -8437,7 +8437,7 @@ func rewriteValueAMD64_OpAMD64CMPW_0(v *Value) bool {
 	}
 	// match: (CMPW l:(MOVWload {sym} [off] ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (CMPWmem {sym} [off] ptr x mem)
+	// result: (CMPWload {sym} [off] ptr x mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -8453,7 +8453,7 @@ func rewriteValueAMD64_OpAMD64CMPW_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64CMPWmem)
+		v.reset(OpAMD64CMPWload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -8463,7 +8463,7 @@ func rewriteValueAMD64_OpAMD64CMPW_0(v *Value) bool {
 	}
 	// match: (CMPW x l:(MOVWload {sym} [off] ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (InvertFlags (CMPWmem {sym} [off] ptr x mem))
+	// result: (InvertFlags (CMPWload {sym} [off] ptr x mem))
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -8480,7 +8480,7 @@ func rewriteValueAMD64_OpAMD64CMPW_0(v *Value) bool {
 			break
 		}
 		v.reset(OpAMD64InvertFlags)
-		v0 := b.NewValue0(v.Pos, OpAMD64CMPWmem, types.TypeFlags)
+		v0 := b.NewValue0(v.Pos, OpAMD64CMPWload, types.TypeFlags)
 		v0.AuxInt = off
 		v0.Aux = sym
 		v0.AddArg(ptr)
@@ -8642,7 +8642,7 @@ func rewriteValueAMD64_OpAMD64CMPWconst_0(v *Value) bool {
 	}
 	// match: (CMPWconst l:(MOVWload {sym} [off] ptr mem) [c])
 	// cond: l.Uses == 1 && validValAndOff(c, off) && clobber(l)
-	// result: @l.Block (CMPWconstmem {sym} [makeValAndOff(c,off)] ptr mem)
+	// result: @l.Block (CMPWconstload {sym} [makeValAndOff(c,off)] ptr mem)
 	for {
 		c := v.AuxInt
 		l := v.Args[0]
@@ -8658,7 +8658,7 @@ func rewriteValueAMD64_OpAMD64CMPWconst_0(v *Value) bool {
 			break
 		}
 		b = l.Block
-		v0 := b.NewValue0(v.Pos, OpAMD64CMPWconstmem, types.TypeFlags)
+		v0 := b.NewValue0(v.Pos, OpAMD64CMPWconstload, types.TypeFlags)
 		v.reset(OpCopy)
 		v.AddArg(v0)
 		v0.AuxInt = makeValAndOff(c, off)
@@ -8669,10 +8669,10 @@ func rewriteValueAMD64_OpAMD64CMPWconst_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64CMPWmem_0(v *Value) bool {
-	// match: (CMPWmem {sym} [off] ptr (MOVLconst [c]) mem)
+func rewriteValueAMD64_OpAMD64CMPWload_0(v *Value) bool {
+	// match: (CMPWload {sym} [off] ptr (MOVLconst [c]) mem)
 	// cond: validValAndOff(int64(int16(c)),off)
-	// result: (CMPWconstmem {sym} [makeValAndOff(int64(int16(c)),off)] ptr mem)
+	// result: (CMPWconstload {sym} [makeValAndOff(int64(int16(c)),off)] ptr mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -8687,7 +8687,7 @@ func rewriteValueAMD64_OpAMD64CMPWmem_0(v *Value) bool {
 		if !(validValAndOff(int64(int16(c)), off)) {
 			break
 		}
-		v.reset(OpAMD64CMPWconstmem)
+		v.reset(OpAMD64CMPWconstload)
 		v.AuxInt = makeValAndOff(int64(int16(c)), off)
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -10615,7 +10615,7 @@ func rewriteValueAMD64_OpAMD64MOVBloadidx1_0(v *Value) bool {
 func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 	// match: (MOVBstore [off] {sym} ptr y:(SETL x) mem)
 	// cond: y.Uses == 1
-	// result: (SETLmem [off] {sym} ptr x mem)
+	// result: (SETLstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -10630,7 +10630,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 		if !(y.Uses == 1) {
 			break
 		}
-		v.reset(OpAMD64SETLmem)
+		v.reset(OpAMD64SETLstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -10640,7 +10640,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 	}
 	// match: (MOVBstore [off] {sym} ptr y:(SETLE x) mem)
 	// cond: y.Uses == 1
-	// result: (SETLEmem [off] {sym} ptr x mem)
+	// result: (SETLEstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -10655,7 +10655,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 		if !(y.Uses == 1) {
 			break
 		}
-		v.reset(OpAMD64SETLEmem)
+		v.reset(OpAMD64SETLEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -10665,7 +10665,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 	}
 	// match: (MOVBstore [off] {sym} ptr y:(SETG x) mem)
 	// cond: y.Uses == 1
-	// result: (SETGmem [off] {sym} ptr x mem)
+	// result: (SETGstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -10680,7 +10680,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 		if !(y.Uses == 1) {
 			break
 		}
-		v.reset(OpAMD64SETGmem)
+		v.reset(OpAMD64SETGstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -10690,7 +10690,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 	}
 	// match: (MOVBstore [off] {sym} ptr y:(SETGE x) mem)
 	// cond: y.Uses == 1
-	// result: (SETGEmem [off] {sym} ptr x mem)
+	// result: (SETGEstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -10705,7 +10705,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 		if !(y.Uses == 1) {
 			break
 		}
-		v.reset(OpAMD64SETGEmem)
+		v.reset(OpAMD64SETGEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -10715,7 +10715,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 	}
 	// match: (MOVBstore [off] {sym} ptr y:(SETEQ x) mem)
 	// cond: y.Uses == 1
-	// result: (SETEQmem [off] {sym} ptr x mem)
+	// result: (SETEQstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -10730,7 +10730,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 		if !(y.Uses == 1) {
 			break
 		}
-		v.reset(OpAMD64SETEQmem)
+		v.reset(OpAMD64SETEQstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -10740,7 +10740,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 	}
 	// match: (MOVBstore [off] {sym} ptr y:(SETNE x) mem)
 	// cond: y.Uses == 1
-	// result: (SETNEmem [off] {sym} ptr x mem)
+	// result: (SETNEstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -10755,7 +10755,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 		if !(y.Uses == 1) {
 			break
 		}
-		v.reset(OpAMD64SETNEmem)
+		v.reset(OpAMD64SETNEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -10765,7 +10765,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 	}
 	// match: (MOVBstore [off] {sym} ptr y:(SETB x) mem)
 	// cond: y.Uses == 1
-	// result: (SETBmem [off] {sym} ptr x mem)
+	// result: (SETBstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -10780,7 +10780,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 		if !(y.Uses == 1) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -10790,7 +10790,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 	}
 	// match: (MOVBstore [off] {sym} ptr y:(SETBE x) mem)
 	// cond: y.Uses == 1
-	// result: (SETBEmem [off] {sym} ptr x mem)
+	// result: (SETBEstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -10805,7 +10805,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 		if !(y.Uses == 1) {
 			break
 		}
-		v.reset(OpAMD64SETBEmem)
+		v.reset(OpAMD64SETBEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -10815,7 +10815,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 	}
 	// match: (MOVBstore [off] {sym} ptr y:(SETA x) mem)
 	// cond: y.Uses == 1
-	// result: (SETAmem [off] {sym} ptr x mem)
+	// result: (SETAstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -10830,7 +10830,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 		if !(y.Uses == 1) {
 			break
 		}
-		v.reset(OpAMD64SETAmem)
+		v.reset(OpAMD64SETAstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -10840,7 +10840,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 	}
 	// match: (MOVBstore [off] {sym} ptr y:(SETAE x) mem)
 	// cond: y.Uses == 1
-	// result: (SETAEmem [off] {sym} ptr x mem)
+	// result: (SETAEstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -10855,7 +10855,7 @@ func rewriteValueAMD64_OpAMD64MOVBstore_0(v *Value) bool {
 		if !(y.Uses == 1) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -14327,7 +14327,7 @@ func rewriteValueAMD64_OpAMD64MOVLstore_10(v *Value) bool {
 	}
 	// match: (MOVLstore [off] {sym} ptr a:(ADDLconst [c] l:(MOVLload [off] {sym} ptr2 mem)) mem)
 	// cond: isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c,off)
-	// result: (ADDLconstmem {sym} [makeValAndOff(c,off)] ptr mem)
+	// result: (ADDLconstmodify {sym} [makeValAndOff(c,off)] ptr mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -14357,7 +14357,7 @@ func rewriteValueAMD64_OpAMD64MOVLstore_10(v *Value) bool {
 		if !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off)) {
 			break
 		}
-		v.reset(OpAMD64ADDLconstmem)
+		v.reset(OpAMD64ADDLconstmodify)
 		v.AuxInt = makeValAndOff(c, off)
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -16305,7 +16305,7 @@ func rewriteValueAMD64_OpAMD64MOVQstore_0(v *Value) bool {
 	}
 	// match: (MOVQstore [off] {sym} ptr a:(ADDQconst [c] l:(MOVQload [off] {sym} ptr2 mem)) mem)
 	// cond: isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c,off)
-	// result: (ADDQconstmem {sym} [makeValAndOff(c,off)] ptr mem)
+	// result: (ADDQconstmodify {sym} [makeValAndOff(c,off)] ptr mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -16335,7 +16335,7 @@ func rewriteValueAMD64_OpAMD64MOVQstore_0(v *Value) bool {
 		if !(isSamePtr(ptr, ptr2) && a.Uses == 1 && l.Uses == 1 && validValAndOff(c, off)) {
 			break
 		}
-		v.reset(OpAMD64ADDQconstmem)
+		v.reset(OpAMD64ADDQconstmodify)
 		v.AuxInt = makeValAndOff(c, off)
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -21797,7 +21797,7 @@ func rewriteValueAMD64_OpAMD64MULQconst_30(v *Value) bool {
 func rewriteValueAMD64_OpAMD64MULSD_0(v *Value) bool {
 	// match: (MULSD x l:(MOVSDload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (MULSDmem x [off] {sym} ptr mem)
+	// result: (MULSDload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -21813,7 +21813,7 @@ func rewriteValueAMD64_OpAMD64MULSD_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64MULSDmem)
+		v.reset(OpAMD64MULSDload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -21823,7 +21823,7 @@ func rewriteValueAMD64_OpAMD64MULSD_0(v *Value) bool {
 	}
 	// match: (MULSD l:(MOVSDload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (MULSDmem x [off] {sym} ptr mem)
+	// result: (MULSDload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -21839,7 +21839,7 @@ func rewriteValueAMD64_OpAMD64MULSD_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64MULSDmem)
+		v.reset(OpAMD64MULSDload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -21849,14 +21849,14 @@ func rewriteValueAMD64_OpAMD64MULSD_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64MULSDmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64MULSDload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	typ := &b.Func.Config.Types
 	_ = typ
-	// match: (MULSDmem [off1] {sym} val (ADDQconst [off2] base) mem)
+	// match: (MULSDload [off1] {sym} val (ADDQconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (MULSDmem [off1+off2] {sym} val base mem)
+	// result: (MULSDload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -21872,7 +21872,7 @@ func rewriteValueAMD64_OpAMD64MULSDmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64MULSDmem)
+		v.reset(OpAMD64MULSDload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -21880,9 +21880,9 @@ func rewriteValueAMD64_OpAMD64MULSDmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (MULSDmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	// match: (MULSDload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (MULSDmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (MULSDload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -21899,7 +21899,7 @@ func rewriteValueAMD64_OpAMD64MULSDmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64MULSDmem)
+		v.reset(OpAMD64MULSDload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -21907,7 +21907,7 @@ func rewriteValueAMD64_OpAMD64MULSDmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (MULSDmem x [off] {sym} ptr (MOVQstore [off] {sym} ptr y _))
+	// match: (MULSDload x [off] {sym} ptr (MOVQstore [off] {sym} ptr y _))
 	// cond:
 	// result: (MULSD x (MOVQi2f y))
 	for {
@@ -21943,7 +21943,7 @@ func rewriteValueAMD64_OpAMD64MULSDmem_0(v *Value) bool {
 func rewriteValueAMD64_OpAMD64MULSS_0(v *Value) bool {
 	// match: (MULSS x l:(MOVSSload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (MULSSmem x [off] {sym} ptr mem)
+	// result: (MULSSload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -21959,7 +21959,7 @@ func rewriteValueAMD64_OpAMD64MULSS_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64MULSSmem)
+		v.reset(OpAMD64MULSSload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -21969,7 +21969,7 @@ func rewriteValueAMD64_OpAMD64MULSS_0(v *Value) bool {
 	}
 	// match: (MULSS l:(MOVSSload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (MULSSmem x [off] {sym} ptr mem)
+	// result: (MULSSload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -21985,7 +21985,7 @@ func rewriteValueAMD64_OpAMD64MULSS_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64MULSSmem)
+		v.reset(OpAMD64MULSSload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -21995,14 +21995,14 @@ func rewriteValueAMD64_OpAMD64MULSS_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64MULSSmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64MULSSload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	typ := &b.Func.Config.Types
 	_ = typ
-	// match: (MULSSmem [off1] {sym} val (ADDQconst [off2] base) mem)
+	// match: (MULSSload [off1] {sym} val (ADDQconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (MULSSmem [off1+off2] {sym} val base mem)
+	// result: (MULSSload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -22018,7 +22018,7 @@ func rewriteValueAMD64_OpAMD64MULSSmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64MULSSmem)
+		v.reset(OpAMD64MULSSload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -22026,9 +22026,9 @@ func rewriteValueAMD64_OpAMD64MULSSmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (MULSSmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	// match: (MULSSload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (MULSSmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (MULSSload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -22045,7 +22045,7 @@ func rewriteValueAMD64_OpAMD64MULSSmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64MULSSmem)
+		v.reset(OpAMD64MULSSload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -22053,7 +22053,7 @@ func rewriteValueAMD64_OpAMD64MULSSmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (MULSSmem x [off] {sym} ptr (MOVLstore [off] {sym} ptr y _))
+	// match: (MULSSload x [off] {sym} ptr (MOVLstore [off] {sym} ptr y _))
 	// cond:
 	// result: (MULSS x (MOVLi2f y))
 	for {
@@ -30716,7 +30716,7 @@ func rewriteValueAMD64_OpAMD64ORL_130(v *Value) bool {
 	}
 	// match: (ORL x l:(MOVLload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ORLmem x [off] {sym} ptr mem)
+	// result: (ORLload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -30732,7 +30732,7 @@ func rewriteValueAMD64_OpAMD64ORL_130(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64ORLmem)
+		v.reset(OpAMD64ORLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -30742,7 +30742,7 @@ func rewriteValueAMD64_OpAMD64ORL_130(v *Value) bool {
 	}
 	// match: (ORL l:(MOVLload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ORLmem x [off] {sym} ptr mem)
+	// result: (ORLload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -30758,7 +30758,7 @@ func rewriteValueAMD64_OpAMD64ORL_130(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64ORLmem)
+		v.reset(OpAMD64ORLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -30829,14 +30829,14 @@ func rewriteValueAMD64_OpAMD64ORLconst_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64ORLmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64ORLload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	typ := &b.Func.Config.Types
 	_ = typ
-	// match: (ORLmem [off1] {sym} val (ADDQconst [off2] base) mem)
+	// match: (ORLload [off1] {sym} val (ADDQconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (ORLmem [off1+off2] {sym} val base mem)
+	// result: (ORLload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -30852,7 +30852,7 @@ func rewriteValueAMD64_OpAMD64ORLmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64ORLmem)
+		v.reset(OpAMD64ORLload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -30860,9 +30860,9 @@ func rewriteValueAMD64_OpAMD64ORLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ORLmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	// match: (ORLload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (ORLmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (ORLload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -30879,7 +30879,7 @@ func rewriteValueAMD64_OpAMD64ORLmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64ORLmem)
+		v.reset(OpAMD64ORLload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -30887,7 +30887,7 @@ func rewriteValueAMD64_OpAMD64ORLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ORLmem x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _))
+	// match: (ORLload x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _))
 	// cond:
 	// result: ( ORL x (MOVLf2i y))
 	for {
@@ -41627,7 +41627,7 @@ func rewriteValueAMD64_OpAMD64ORQ_160(v *Value) bool {
 	}
 	// match: (ORQ x l:(MOVQload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ORQmem x [off] {sym} ptr mem)
+	// result: (ORQload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -41643,7 +41643,7 @@ func rewriteValueAMD64_OpAMD64ORQ_160(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64ORQmem)
+		v.reset(OpAMD64ORQload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -41653,7 +41653,7 @@ func rewriteValueAMD64_OpAMD64ORQ_160(v *Value) bool {
 	}
 	// match: (ORQ l:(MOVQload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (ORQmem x [off] {sym} ptr mem)
+	// result: (ORQload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -41669,7 +41669,7 @@ func rewriteValueAMD64_OpAMD64ORQ_160(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64ORQmem)
+		v.reset(OpAMD64ORQload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -41738,14 +41738,14 @@ func rewriteValueAMD64_OpAMD64ORQconst_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64ORQmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64ORQload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	typ := &b.Func.Config.Types
 	_ = typ
-	// match: (ORQmem [off1] {sym} val (ADDQconst [off2] base) mem)
+	// match: (ORQload [off1] {sym} val (ADDQconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (ORQmem [off1+off2] {sym} val base mem)
+	// result: (ORQload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -41761,7 +41761,7 @@ func rewriteValueAMD64_OpAMD64ORQmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64ORQmem)
+		v.reset(OpAMD64ORQload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -41769,9 +41769,9 @@ func rewriteValueAMD64_OpAMD64ORQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ORQmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	// match: (ORQload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (ORQmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (ORQload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -41788,7 +41788,7 @@ func rewriteValueAMD64_OpAMD64ORQmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64ORQmem)
+		v.reset(OpAMD64ORQload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -41796,7 +41796,7 @@ func rewriteValueAMD64_OpAMD64ORQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (ORQmem x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _))
+	// match: (ORQload x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _))
 	// cond:
 	// result: ( ORQ x (MOVQf2i y))
 	for {
@@ -43411,12 +43411,12 @@ func rewriteValueAMD64_OpAMD64SETAE_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64SETAEmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64SETAEstore_0(v *Value) bool {
 	b := v.Block
 	_ = b
-	// match: (SETAEmem [off] {sym} ptr (InvertFlags x) mem)
+	// match: (SETAEstore [off] {sym} ptr (InvertFlags x) mem)
 	// cond:
-	// result: (SETBEmem [off] {sym} ptr x mem)
+	// result: (SETBEstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -43428,7 +43428,7 @@ func rewriteValueAMD64_OpAMD64SETAEmem_0(v *Value) bool {
 		}
 		x := v_1.Args[0]
 		mem := v.Args[2]
-		v.reset(OpAMD64SETBEmem)
+		v.reset(OpAMD64SETBEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -43436,9 +43436,9 @@ func rewriteValueAMD64_OpAMD64SETAEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETAEmem [off1] {sym} (ADDQconst [off2] base) val mem)
+	// match: (SETAEstore [off1] {sym} (ADDQconst [off2] base) val mem)
 	// cond: is32Bit(off1+off2)
-	// result: (SETAEmem [off1+off2] {sym} base val mem)
+	// result: (SETAEstore [off1+off2] {sym} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -43454,7 +43454,7 @@ func rewriteValueAMD64_OpAMD64SETAEmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(base)
@@ -43462,9 +43462,9 @@ func rewriteValueAMD64_OpAMD64SETAEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETAEmem [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
+	// match: (SETAEstore [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (SETAEmem [off1+off2] {mergeSym(sym1,sym2)} base val mem)
+	// result: (SETAEstore [off1+off2] {mergeSym(sym1,sym2)} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -43481,7 +43481,7 @@ func rewriteValueAMD64_OpAMD64SETAEmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(base)
@@ -43489,7 +43489,7 @@ func rewriteValueAMD64_OpAMD64SETAEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETAEmem [off] {sym} ptr x:(FlagEQ) mem)
+	// match: (SETAEstore [off] {sym} ptr x:(FlagEQ) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -43512,7 +43512,7 @@ func rewriteValueAMD64_OpAMD64SETAEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETAEmem [off] {sym} ptr x:(FlagLT_ULT) mem)
+	// match: (SETAEstore [off] {sym} ptr x:(FlagLT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -43535,7 +43535,7 @@ func rewriteValueAMD64_OpAMD64SETAEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETAEmem [off] {sym} ptr x:(FlagLT_UGT) mem)
+	// match: (SETAEstore [off] {sym} ptr x:(FlagLT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -43558,7 +43558,7 @@ func rewriteValueAMD64_OpAMD64SETAEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETAEmem [off] {sym} ptr x:(FlagGT_ULT) mem)
+	// match: (SETAEstore [off] {sym} ptr x:(FlagGT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -43581,7 +43581,7 @@ func rewriteValueAMD64_OpAMD64SETAEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETAEmem [off] {sym} ptr x:(FlagGT_UGT) mem)
+	// match: (SETAEstore [off] {sym} ptr x:(FlagGT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -43606,12 +43606,12 @@ func rewriteValueAMD64_OpAMD64SETAEmem_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64SETAmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64SETAstore_0(v *Value) bool {
 	b := v.Block
 	_ = b
-	// match: (SETAmem [off] {sym} ptr (InvertFlags x) mem)
+	// match: (SETAstore [off] {sym} ptr (InvertFlags x) mem)
 	// cond:
-	// result: (SETBmem [off] {sym} ptr x mem)
+	// result: (SETBstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -43623,7 +43623,7 @@ func rewriteValueAMD64_OpAMD64SETAmem_0(v *Value) bool {
 		}
 		x := v_1.Args[0]
 		mem := v.Args[2]
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -43631,9 +43631,9 @@ func rewriteValueAMD64_OpAMD64SETAmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETAmem [off1] {sym} (ADDQconst [off2] base) val mem)
+	// match: (SETAstore [off1] {sym} (ADDQconst [off2] base) val mem)
 	// cond: is32Bit(off1+off2)
-	// result: (SETAmem [off1+off2] {sym} base val mem)
+	// result: (SETAstore [off1+off2] {sym} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -43649,7 +43649,7 @@ func rewriteValueAMD64_OpAMD64SETAmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64SETAmem)
+		v.reset(OpAMD64SETAstore)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(base)
@@ -43657,9 +43657,9 @@ func rewriteValueAMD64_OpAMD64SETAmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETAmem [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
+	// match: (SETAstore [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (SETAmem [off1+off2] {mergeSym(sym1,sym2)} base val mem)
+	// result: (SETAstore [off1+off2] {mergeSym(sym1,sym2)} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -43676,7 +43676,7 @@ func rewriteValueAMD64_OpAMD64SETAmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64SETAmem)
+		v.reset(OpAMD64SETAstore)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(base)
@@ -43684,7 +43684,7 @@ func rewriteValueAMD64_OpAMD64SETAmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETAmem [off] {sym} ptr x:(FlagEQ) mem)
+	// match: (SETAstore [off] {sym} ptr x:(FlagEQ) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -43707,7 +43707,7 @@ func rewriteValueAMD64_OpAMD64SETAmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETAmem [off] {sym} ptr x:(FlagLT_ULT) mem)
+	// match: (SETAstore [off] {sym} ptr x:(FlagLT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -43730,7 +43730,7 @@ func rewriteValueAMD64_OpAMD64SETAmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETAmem [off] {sym} ptr x:(FlagLT_UGT) mem)
+	// match: (SETAstore [off] {sym} ptr x:(FlagLT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -43753,7 +43753,7 @@ func rewriteValueAMD64_OpAMD64SETAmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETAmem [off] {sym} ptr x:(FlagGT_ULT) mem)
+	// match: (SETAstore [off] {sym} ptr x:(FlagGT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -43776,7 +43776,7 @@ func rewriteValueAMD64_OpAMD64SETAmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETAmem [off] {sym} ptr x:(FlagGT_UGT) mem)
+	// match: (SETAstore [off] {sym} ptr x:(FlagGT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -43953,12 +43953,12 @@ func rewriteValueAMD64_OpAMD64SETBE_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64SETBEmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64SETBEstore_0(v *Value) bool {
 	b := v.Block
 	_ = b
-	// match: (SETBEmem [off] {sym} ptr (InvertFlags x) mem)
+	// match: (SETBEstore [off] {sym} ptr (InvertFlags x) mem)
 	// cond:
-	// result: (SETAEmem [off] {sym} ptr x mem)
+	// result: (SETAEstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -43970,7 +43970,7 @@ func rewriteValueAMD64_OpAMD64SETBEmem_0(v *Value) bool {
 		}
 		x := v_1.Args[0]
 		mem := v.Args[2]
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -43978,9 +43978,9 @@ func rewriteValueAMD64_OpAMD64SETBEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETBEmem [off1] {sym} (ADDQconst [off2] base) val mem)
+	// match: (SETBEstore [off1] {sym} (ADDQconst [off2] base) val mem)
 	// cond: is32Bit(off1+off2)
-	// result: (SETBEmem [off1+off2] {sym} base val mem)
+	// result: (SETBEstore [off1+off2] {sym} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -43996,7 +43996,7 @@ func rewriteValueAMD64_OpAMD64SETBEmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64SETBEmem)
+		v.reset(OpAMD64SETBEstore)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(base)
@@ -44004,9 +44004,9 @@ func rewriteValueAMD64_OpAMD64SETBEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETBEmem [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
+	// match: (SETBEstore [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (SETBEmem [off1+off2] {mergeSym(sym1,sym2)} base val mem)
+	// result: (SETBEstore [off1+off2] {mergeSym(sym1,sym2)} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -44023,7 +44023,7 @@ func rewriteValueAMD64_OpAMD64SETBEmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64SETBEmem)
+		v.reset(OpAMD64SETBEstore)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(base)
@@ -44031,7 +44031,7 @@ func rewriteValueAMD64_OpAMD64SETBEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETBEmem [off] {sym} ptr x:(FlagEQ) mem)
+	// match: (SETBEstore [off] {sym} ptr x:(FlagEQ) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -44054,7 +44054,7 @@ func rewriteValueAMD64_OpAMD64SETBEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETBEmem [off] {sym} ptr x:(FlagLT_ULT) mem)
+	// match: (SETBEstore [off] {sym} ptr x:(FlagLT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -44077,7 +44077,7 @@ func rewriteValueAMD64_OpAMD64SETBEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETBEmem [off] {sym} ptr x:(FlagLT_UGT) mem)
+	// match: (SETBEstore [off] {sym} ptr x:(FlagLT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -44100,7 +44100,7 @@ func rewriteValueAMD64_OpAMD64SETBEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETBEmem [off] {sym} ptr x:(FlagGT_ULT) mem)
+	// match: (SETBEstore [off] {sym} ptr x:(FlagGT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -44123,7 +44123,7 @@ func rewriteValueAMD64_OpAMD64SETBEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETBEmem [off] {sym} ptr x:(FlagGT_UGT) mem)
+	// match: (SETBEstore [off] {sym} ptr x:(FlagGT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -44148,12 +44148,12 @@ func rewriteValueAMD64_OpAMD64SETBEmem_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64SETBmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64SETBstore_0(v *Value) bool {
 	b := v.Block
 	_ = b
-	// match: (SETBmem [off] {sym} ptr (InvertFlags x) mem)
+	// match: (SETBstore [off] {sym} ptr (InvertFlags x) mem)
 	// cond:
-	// result: (SETAmem [off] {sym} ptr x mem)
+	// result: (SETAstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -44165,7 +44165,7 @@ func rewriteValueAMD64_OpAMD64SETBmem_0(v *Value) bool {
 		}
 		x := v_1.Args[0]
 		mem := v.Args[2]
-		v.reset(OpAMD64SETAmem)
+		v.reset(OpAMD64SETAstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -44173,9 +44173,9 @@ func rewriteValueAMD64_OpAMD64SETBmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETBmem [off1] {sym} (ADDQconst [off2] base) val mem)
+	// match: (SETBstore [off1] {sym} (ADDQconst [off2] base) val mem)
 	// cond: is32Bit(off1+off2)
-	// result: (SETBmem [off1+off2] {sym} base val mem)
+	// result: (SETBstore [off1+off2] {sym} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -44191,7 +44191,7 @@ func rewriteValueAMD64_OpAMD64SETBmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(base)
@@ -44199,9 +44199,9 @@ func rewriteValueAMD64_OpAMD64SETBmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETBmem [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
+	// match: (SETBstore [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (SETBmem [off1+off2] {mergeSym(sym1,sym2)} base val mem)
+	// result: (SETBstore [off1+off2] {mergeSym(sym1,sym2)} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -44218,7 +44218,7 @@ func rewriteValueAMD64_OpAMD64SETBmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(base)
@@ -44226,7 +44226,7 @@ func rewriteValueAMD64_OpAMD64SETBmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETBmem [off] {sym} ptr x:(FlagEQ) mem)
+	// match: (SETBstore [off] {sym} ptr x:(FlagEQ) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -44249,7 +44249,7 @@ func rewriteValueAMD64_OpAMD64SETBmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETBmem [off] {sym} ptr x:(FlagLT_ULT) mem)
+	// match: (SETBstore [off] {sym} ptr x:(FlagLT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -44272,7 +44272,7 @@ func rewriteValueAMD64_OpAMD64SETBmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETBmem [off] {sym} ptr x:(FlagLT_UGT) mem)
+	// match: (SETBstore [off] {sym} ptr x:(FlagLT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -44295,7 +44295,7 @@ func rewriteValueAMD64_OpAMD64SETBmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETBmem [off] {sym} ptr x:(FlagGT_ULT) mem)
+	// match: (SETBstore [off] {sym} ptr x:(FlagGT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -44318,7 +44318,7 @@ func rewriteValueAMD64_OpAMD64SETBmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETBmem [off] {sym} ptr x:(FlagGT_UGT) mem)
+	// match: (SETBstore [off] {sym} ptr x:(FlagGT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -45101,14 +45101,14 @@ func rewriteValueAMD64_OpAMD64SETEQ_20(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64SETEQstore_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	config := b.Func.Config
 	_ = config
-	// match: (SETEQmem [off] {sym} ptr (TESTL (SHLL (MOVLconst [1]) x) y) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTL (SHLL (MOVLconst [1]) x) y) mem)
 	// cond: !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTL x y) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTL x y) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45137,7 +45137,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 		if !(!config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45148,9 +45148,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (TESTL y (SHLL (MOVLconst [1]) x)) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTL y (SHLL (MOVLconst [1]) x)) mem)
 	// cond: !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTL x y) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTL x y) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45179,7 +45179,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 		if !(!config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45190,9 +45190,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (TESTQ (SHLQ (MOVQconst [1]) x) y) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTQ (SHLQ (MOVQconst [1]) x) y) mem)
 	// cond: !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTQ x y) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTQ x y) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45221,7 +45221,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 		if !(!config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45232,9 +45232,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (TESTQ y (SHLQ (MOVQconst [1]) x)) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTQ y (SHLQ (MOVQconst [1]) x)) mem)
 	// cond: !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTQ x y) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTQ x y) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45263,7 +45263,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 		if !(!config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45274,9 +45274,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (TESTLconst [c] x) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTLconst [c] x) mem)
 	// cond: isUint32PowerOfTwo(c) && !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTLconst [log2uint32(c)] x) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTLconst [log2uint32(c)] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45292,7 +45292,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 		if !(isUint32PowerOfTwo(c) && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45303,9 +45303,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (TESTQconst [c] x) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTQconst [c] x) mem)
 	// cond: isUint64PowerOfTwo(c) && !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTQconst [log2(c)] x) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTQconst [log2(c)] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45321,7 +45321,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 		if !(isUint64PowerOfTwo(c) && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45332,9 +45332,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (TESTQ (MOVQconst [c]) x) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTQ (MOVQconst [c]) x) mem)
 	// cond: isUint64PowerOfTwo(c) && !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTQconst [log2(c)] x) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTQconst [log2(c)] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45355,7 +45355,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 		if !(isUint64PowerOfTwo(c) && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45366,9 +45366,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (TESTQ x (MOVQconst [c])) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTQ x (MOVQconst [c])) mem)
 	// cond: isUint64PowerOfTwo(c) && !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTQconst [log2(c)] x) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTQconst [log2(c)] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45389,7 +45389,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 		if !(isUint64PowerOfTwo(c) && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45400,9 +45400,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (CMPLconst [1] s:(ANDLconst [1] _)) mem)
+	// match: (SETEQstore [off] {sym} ptr (CMPLconst [1] s:(ANDLconst [1] _)) mem)
 	// cond:
-	// result: (SETNEmem [off] {sym} ptr (CMPLconst [0] s) mem)
+	// result: (SETNEstore [off] {sym} ptr (CMPLconst [0] s) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45423,7 +45423,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 			break
 		}
 		mem := v.Args[2]
-		v.reset(OpAMD64SETNEmem)
+		v.reset(OpAMD64SETNEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45434,9 +45434,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (CMPQconst [1] s:(ANDQconst [1] _)) mem)
+	// match: (SETEQstore [off] {sym} ptr (CMPQconst [1] s:(ANDQconst [1] _)) mem)
 	// cond:
-	// result: (SETNEmem [off] {sym} ptr (CMPQconst [0] s) mem)
+	// result: (SETNEstore [off] {sym} ptr (CMPQconst [0] s) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45457,7 +45457,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 			break
 		}
 		mem := v.Args[2]
-		v.reset(OpAMD64SETNEmem)
+		v.reset(OpAMD64SETNEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45470,14 +45470,14 @@ func rewriteValueAMD64_OpAMD64SETEQmem_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
+func rewriteValueAMD64_OpAMD64SETEQstore_10(v *Value) bool {
 	b := v.Block
 	_ = b
 	config := b.Func.Config
 	_ = config
-	// match: (SETEQmem [off] {sym} ptr (TESTQ z1:(SHLQconst [63] (SHRQconst [63] x)) z2) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTQ z1:(SHLQconst [63] (SHRQconst [63] x)) z2) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTQconst [63] x) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTQconst [63] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45508,7 +45508,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45519,9 +45519,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (TESTQ z2 z1:(SHLQconst [63] (SHRQconst [63] x))) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTQ z2 z1:(SHLQconst [63] (SHRQconst [63] x))) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTQconst [63] x) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTQconst [63] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45552,7 +45552,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45563,9 +45563,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (TESTL z1:(SHLLconst [31] (SHRLconst [31] x)) z2) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTL z1:(SHLLconst [31] (SHRLconst [31] x)) z2) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTLconst [31] x) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTLconst [31] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45596,7 +45596,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45607,9 +45607,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (TESTL z2 z1:(SHLLconst [31] (SHRLconst [31] x))) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTL z2 z1:(SHLLconst [31] (SHRLconst [31] x))) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTLconst [31] x) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTLconst [31] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45640,7 +45640,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45651,9 +45651,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (TESTQ z1:(SHRQconst [63] (SHLQconst [63] x)) z2) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTQ z1:(SHRQconst [63] (SHLQconst [63] x)) z2) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTQconst [0] x) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTQconst [0] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45684,7 +45684,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45695,9 +45695,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (TESTQ z2 z1:(SHRQconst [63] (SHLQconst [63] x))) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTQ z2 z1:(SHRQconst [63] (SHLQconst [63] x))) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTQconst [0] x) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTQconst [0] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45728,7 +45728,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45739,9 +45739,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (TESTL z1:(SHRLconst [31] (SHLLconst [31] x)) z2) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTL z1:(SHRLconst [31] (SHLLconst [31] x)) z2) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTLconst [0] x) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTLconst [0] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45772,7 +45772,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45783,9 +45783,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (TESTL z2 z1:(SHRLconst [31] (SHLLconst [31] x))) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTL z2 z1:(SHRLconst [31] (SHLLconst [31] x))) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTLconst [0] x) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTLconst [0] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45816,7 +45816,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45827,9 +45827,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (TESTQ z1:(SHRQconst [63] x) z2) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTQ z1:(SHRQconst [63] x) z2) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTQconst [63] x) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTQconst [63] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45853,7 +45853,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45864,9 +45864,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (TESTQ z2 z1:(SHRQconst [63] x)) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTQ z2 z1:(SHRQconst [63] x)) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTQconst [63] x) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTQconst [63] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45890,7 +45890,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45903,14 +45903,14 @@ func rewriteValueAMD64_OpAMD64SETEQmem_10(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64SETEQmem_20(v *Value) bool {
+func rewriteValueAMD64_OpAMD64SETEQstore_20(v *Value) bool {
 	b := v.Block
 	_ = b
 	config := b.Func.Config
 	_ = config
-	// match: (SETEQmem [off] {sym} ptr (TESTL z1:(SHRLconst [31] x) z2) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTL z1:(SHRLconst [31] x) z2) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTLconst [31] x) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTLconst [31] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45934,7 +45934,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_20(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45945,9 +45945,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_20(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (TESTL z2 z1:(SHRLconst [31] x)) mem)
+	// match: (SETEQstore [off] {sym} ptr (TESTL z2 z1:(SHRLconst [31] x)) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETAEmem [off] {sym} ptr (BTLconst [31] x) mem)
+	// result: (SETAEstore [off] {sym} ptr (BTLconst [31] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45971,7 +45971,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_20(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETAEmem)
+		v.reset(OpAMD64SETAEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -45982,9 +45982,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_20(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr (InvertFlags x) mem)
+	// match: (SETEQstore [off] {sym} ptr (InvertFlags x) mem)
 	// cond:
-	// result: (SETEQmem [off] {sym} ptr x mem)
+	// result: (SETEQstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -45996,7 +45996,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_20(v *Value) bool {
 		}
 		x := v_1.Args[0]
 		mem := v.Args[2]
-		v.reset(OpAMD64SETEQmem)
+		v.reset(OpAMD64SETEQstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -46004,9 +46004,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_20(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off1] {sym} (ADDQconst [off2] base) val mem)
+	// match: (SETEQstore [off1] {sym} (ADDQconst [off2] base) val mem)
 	// cond: is32Bit(off1+off2)
-	// result: (SETEQmem [off1+off2] {sym} base val mem)
+	// result: (SETEQstore [off1+off2] {sym} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -46022,7 +46022,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_20(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64SETEQmem)
+		v.reset(OpAMD64SETEQstore)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(base)
@@ -46030,9 +46030,9 @@ func rewriteValueAMD64_OpAMD64SETEQmem_20(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
+	// match: (SETEQstore [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (SETEQmem [off1+off2] {mergeSym(sym1,sym2)} base val mem)
+	// result: (SETEQstore [off1+off2] {mergeSym(sym1,sym2)} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -46049,7 +46049,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_20(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64SETEQmem)
+		v.reset(OpAMD64SETEQstore)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(base)
@@ -46057,7 +46057,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_20(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr x:(FlagEQ) mem)
+	// match: (SETEQstore [off] {sym} ptr x:(FlagEQ) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -46080,7 +46080,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_20(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr x:(FlagLT_ULT) mem)
+	// match: (SETEQstore [off] {sym} ptr x:(FlagLT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -46103,7 +46103,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_20(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr x:(FlagLT_UGT) mem)
+	// match: (SETEQstore [off] {sym} ptr x:(FlagLT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -46126,7 +46126,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_20(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr x:(FlagGT_ULT) mem)
+	// match: (SETEQstore [off] {sym} ptr x:(FlagGT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -46149,7 +46149,7 @@ func rewriteValueAMD64_OpAMD64SETEQmem_20(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETEQmem [off] {sym} ptr x:(FlagGT_UGT) mem)
+	// match: (SETEQstore [off] {sym} ptr x:(FlagGT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -46326,12 +46326,12 @@ func rewriteValueAMD64_OpAMD64SETGE_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64SETGEmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64SETGEstore_0(v *Value) bool {
 	b := v.Block
 	_ = b
-	// match: (SETGEmem [off] {sym} ptr (InvertFlags x) mem)
+	// match: (SETGEstore [off] {sym} ptr (InvertFlags x) mem)
 	// cond:
-	// result: (SETLEmem [off] {sym} ptr x mem)
+	// result: (SETLEstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -46343,7 +46343,7 @@ func rewriteValueAMD64_OpAMD64SETGEmem_0(v *Value) bool {
 		}
 		x := v_1.Args[0]
 		mem := v.Args[2]
-		v.reset(OpAMD64SETLEmem)
+		v.reset(OpAMD64SETLEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -46351,9 +46351,9 @@ func rewriteValueAMD64_OpAMD64SETGEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETGEmem [off1] {sym} (ADDQconst [off2] base) val mem)
+	// match: (SETGEstore [off1] {sym} (ADDQconst [off2] base) val mem)
 	// cond: is32Bit(off1+off2)
-	// result: (SETGEmem [off1+off2] {sym} base val mem)
+	// result: (SETGEstore [off1+off2] {sym} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -46369,7 +46369,7 @@ func rewriteValueAMD64_OpAMD64SETGEmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64SETGEmem)
+		v.reset(OpAMD64SETGEstore)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(base)
@@ -46377,9 +46377,9 @@ func rewriteValueAMD64_OpAMD64SETGEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETGEmem [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
+	// match: (SETGEstore [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (SETGEmem [off1+off2] {mergeSym(sym1,sym2)} base val mem)
+	// result: (SETGEstore [off1+off2] {mergeSym(sym1,sym2)} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -46396,7 +46396,7 @@ func rewriteValueAMD64_OpAMD64SETGEmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64SETGEmem)
+		v.reset(OpAMD64SETGEstore)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(base)
@@ -46404,7 +46404,7 @@ func rewriteValueAMD64_OpAMD64SETGEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETGEmem [off] {sym} ptr x:(FlagEQ) mem)
+	// match: (SETGEstore [off] {sym} ptr x:(FlagEQ) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -46427,7 +46427,7 @@ func rewriteValueAMD64_OpAMD64SETGEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETGEmem [off] {sym} ptr x:(FlagLT_ULT) mem)
+	// match: (SETGEstore [off] {sym} ptr x:(FlagLT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -46450,7 +46450,7 @@ func rewriteValueAMD64_OpAMD64SETGEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETGEmem [off] {sym} ptr x:(FlagLT_UGT) mem)
+	// match: (SETGEstore [off] {sym} ptr x:(FlagLT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -46473,7 +46473,7 @@ func rewriteValueAMD64_OpAMD64SETGEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETGEmem [off] {sym} ptr x:(FlagGT_ULT) mem)
+	// match: (SETGEstore [off] {sym} ptr x:(FlagGT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -46496,7 +46496,7 @@ func rewriteValueAMD64_OpAMD64SETGEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETGEmem [off] {sym} ptr x:(FlagGT_UGT) mem)
+	// match: (SETGEstore [off] {sym} ptr x:(FlagGT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -46521,12 +46521,12 @@ func rewriteValueAMD64_OpAMD64SETGEmem_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64SETGmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64SETGstore_0(v *Value) bool {
 	b := v.Block
 	_ = b
-	// match: (SETGmem [off] {sym} ptr (InvertFlags x) mem)
+	// match: (SETGstore [off] {sym} ptr (InvertFlags x) mem)
 	// cond:
-	// result: (SETLmem [off] {sym} ptr x mem)
+	// result: (SETLstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -46538,7 +46538,7 @@ func rewriteValueAMD64_OpAMD64SETGmem_0(v *Value) bool {
 		}
 		x := v_1.Args[0]
 		mem := v.Args[2]
-		v.reset(OpAMD64SETLmem)
+		v.reset(OpAMD64SETLstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -46546,9 +46546,9 @@ func rewriteValueAMD64_OpAMD64SETGmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETGmem [off1] {sym} (ADDQconst [off2] base) val mem)
+	// match: (SETGstore [off1] {sym} (ADDQconst [off2] base) val mem)
 	// cond: is32Bit(off1+off2)
-	// result: (SETGmem [off1+off2] {sym} base val mem)
+	// result: (SETGstore [off1+off2] {sym} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -46564,7 +46564,7 @@ func rewriteValueAMD64_OpAMD64SETGmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64SETGmem)
+		v.reset(OpAMD64SETGstore)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(base)
@@ -46572,9 +46572,9 @@ func rewriteValueAMD64_OpAMD64SETGmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETGmem [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
+	// match: (SETGstore [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (SETGmem [off1+off2] {mergeSym(sym1,sym2)} base val mem)
+	// result: (SETGstore [off1+off2] {mergeSym(sym1,sym2)} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -46591,7 +46591,7 @@ func rewriteValueAMD64_OpAMD64SETGmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64SETGmem)
+		v.reset(OpAMD64SETGstore)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(base)
@@ -46599,7 +46599,7 @@ func rewriteValueAMD64_OpAMD64SETGmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETGmem [off] {sym} ptr x:(FlagEQ) mem)
+	// match: (SETGstore [off] {sym} ptr x:(FlagEQ) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -46622,7 +46622,7 @@ func rewriteValueAMD64_OpAMD64SETGmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETGmem [off] {sym} ptr x:(FlagLT_ULT) mem)
+	// match: (SETGstore [off] {sym} ptr x:(FlagLT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -46645,7 +46645,7 @@ func rewriteValueAMD64_OpAMD64SETGmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETGmem [off] {sym} ptr x:(FlagLT_UGT) mem)
+	// match: (SETGstore [off] {sym} ptr x:(FlagLT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -46668,7 +46668,7 @@ func rewriteValueAMD64_OpAMD64SETGmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETGmem [off] {sym} ptr x:(FlagGT_ULT) mem)
+	// match: (SETGstore [off] {sym} ptr x:(FlagGT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -46691,7 +46691,7 @@ func rewriteValueAMD64_OpAMD64SETGmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETGmem [off] {sym} ptr x:(FlagGT_UGT) mem)
+	// match: (SETGstore [off] {sym} ptr x:(FlagGT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -46868,12 +46868,12 @@ func rewriteValueAMD64_OpAMD64SETLE_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64SETLEmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64SETLEstore_0(v *Value) bool {
 	b := v.Block
 	_ = b
-	// match: (SETLEmem [off] {sym} ptr (InvertFlags x) mem)
+	// match: (SETLEstore [off] {sym} ptr (InvertFlags x) mem)
 	// cond:
-	// result: (SETGEmem [off] {sym} ptr x mem)
+	// result: (SETGEstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -46885,7 +46885,7 @@ func rewriteValueAMD64_OpAMD64SETLEmem_0(v *Value) bool {
 		}
 		x := v_1.Args[0]
 		mem := v.Args[2]
-		v.reset(OpAMD64SETGEmem)
+		v.reset(OpAMD64SETGEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -46893,9 +46893,9 @@ func rewriteValueAMD64_OpAMD64SETLEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETLEmem [off1] {sym} (ADDQconst [off2] base) val mem)
+	// match: (SETLEstore [off1] {sym} (ADDQconst [off2] base) val mem)
 	// cond: is32Bit(off1+off2)
-	// result: (SETLEmem [off1+off2] {sym} base val mem)
+	// result: (SETLEstore [off1+off2] {sym} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -46911,7 +46911,7 @@ func rewriteValueAMD64_OpAMD64SETLEmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64SETLEmem)
+		v.reset(OpAMD64SETLEstore)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(base)
@@ -46919,9 +46919,9 @@ func rewriteValueAMD64_OpAMD64SETLEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETLEmem [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
+	// match: (SETLEstore [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (SETLEmem [off1+off2] {mergeSym(sym1,sym2)} base val mem)
+	// result: (SETLEstore [off1+off2] {mergeSym(sym1,sym2)} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -46938,7 +46938,7 @@ func rewriteValueAMD64_OpAMD64SETLEmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64SETLEmem)
+		v.reset(OpAMD64SETLEstore)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(base)
@@ -46946,7 +46946,7 @@ func rewriteValueAMD64_OpAMD64SETLEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETLEmem [off] {sym} ptr x:(FlagEQ) mem)
+	// match: (SETLEstore [off] {sym} ptr x:(FlagEQ) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -46969,7 +46969,7 @@ func rewriteValueAMD64_OpAMD64SETLEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETLEmem [off] {sym} ptr x:(FlagLT_ULT) mem)
+	// match: (SETLEstore [off] {sym} ptr x:(FlagLT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -46992,7 +46992,7 @@ func rewriteValueAMD64_OpAMD64SETLEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETLEmem [off] {sym} ptr x:(FlagLT_UGT) mem)
+	// match: (SETLEstore [off] {sym} ptr x:(FlagLT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -47015,7 +47015,7 @@ func rewriteValueAMD64_OpAMD64SETLEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETLEmem [off] {sym} ptr x:(FlagGT_ULT) mem)
+	// match: (SETLEstore [off] {sym} ptr x:(FlagGT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -47038,7 +47038,7 @@ func rewriteValueAMD64_OpAMD64SETLEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETLEmem [off] {sym} ptr x:(FlagGT_UGT) mem)
+	// match: (SETLEstore [off] {sym} ptr x:(FlagGT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -47063,12 +47063,12 @@ func rewriteValueAMD64_OpAMD64SETLEmem_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64SETLmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64SETLstore_0(v *Value) bool {
 	b := v.Block
 	_ = b
-	// match: (SETLmem [off] {sym} ptr (InvertFlags x) mem)
+	// match: (SETLstore [off] {sym} ptr (InvertFlags x) mem)
 	// cond:
-	// result: (SETGmem [off] {sym} ptr x mem)
+	// result: (SETGstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -47080,7 +47080,7 @@ func rewriteValueAMD64_OpAMD64SETLmem_0(v *Value) bool {
 		}
 		x := v_1.Args[0]
 		mem := v.Args[2]
-		v.reset(OpAMD64SETGmem)
+		v.reset(OpAMD64SETGstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -47088,9 +47088,9 @@ func rewriteValueAMD64_OpAMD64SETLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETLmem [off1] {sym} (ADDQconst [off2] base) val mem)
+	// match: (SETLstore [off1] {sym} (ADDQconst [off2] base) val mem)
 	// cond: is32Bit(off1+off2)
-	// result: (SETLmem [off1+off2] {sym} base val mem)
+	// result: (SETLstore [off1+off2] {sym} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -47106,7 +47106,7 @@ func rewriteValueAMD64_OpAMD64SETLmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64SETLmem)
+		v.reset(OpAMD64SETLstore)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(base)
@@ -47114,9 +47114,9 @@ func rewriteValueAMD64_OpAMD64SETLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETLmem [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
+	// match: (SETLstore [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (SETLmem [off1+off2] {mergeSym(sym1,sym2)} base val mem)
+	// result: (SETLstore [off1+off2] {mergeSym(sym1,sym2)} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -47133,7 +47133,7 @@ func rewriteValueAMD64_OpAMD64SETLmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64SETLmem)
+		v.reset(OpAMD64SETLstore)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(base)
@@ -47141,7 +47141,7 @@ func rewriteValueAMD64_OpAMD64SETLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETLmem [off] {sym} ptr x:(FlagEQ) mem)
+	// match: (SETLstore [off] {sym} ptr x:(FlagEQ) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -47164,7 +47164,7 @@ func rewriteValueAMD64_OpAMD64SETLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETLmem [off] {sym} ptr x:(FlagLT_ULT) mem)
+	// match: (SETLstore [off] {sym} ptr x:(FlagLT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -47187,7 +47187,7 @@ func rewriteValueAMD64_OpAMD64SETLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETLmem [off] {sym} ptr x:(FlagLT_UGT) mem)
+	// match: (SETLstore [off] {sym} ptr x:(FlagLT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -47210,7 +47210,7 @@ func rewriteValueAMD64_OpAMD64SETLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETLmem [off] {sym} ptr x:(FlagGT_ULT) mem)
+	// match: (SETLstore [off] {sym} ptr x:(FlagGT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -47233,7 +47233,7 @@ func rewriteValueAMD64_OpAMD64SETLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETLmem [off] {sym} ptr x:(FlagGT_UGT) mem)
+	// match: (SETLstore [off] {sym} ptr x:(FlagGT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -48016,14 +48016,14 @@ func rewriteValueAMD64_OpAMD64SETNE_20(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64SETNEstore_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	config := b.Func.Config
 	_ = config
-	// match: (SETNEmem [off] {sym} ptr (TESTL (SHLL (MOVLconst [1]) x) y) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTL (SHLL (MOVLconst [1]) x) y) mem)
 	// cond: !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTL x y) mem)
+	// result: (SETBstore [off] {sym} ptr (BTL x y) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48052,7 +48052,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 		if !(!config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48063,9 +48063,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (TESTL y (SHLL (MOVLconst [1]) x)) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTL y (SHLL (MOVLconst [1]) x)) mem)
 	// cond: !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTL x y) mem)
+	// result: (SETBstore [off] {sym} ptr (BTL x y) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48094,7 +48094,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 		if !(!config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48105,9 +48105,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (TESTQ (SHLQ (MOVQconst [1]) x) y) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTQ (SHLQ (MOVQconst [1]) x) y) mem)
 	// cond: !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTQ x y) mem)
+	// result: (SETBstore [off] {sym} ptr (BTQ x y) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48136,7 +48136,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 		if !(!config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48147,9 +48147,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (TESTQ y (SHLQ (MOVQconst [1]) x)) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTQ y (SHLQ (MOVQconst [1]) x)) mem)
 	// cond: !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTQ x y) mem)
+	// result: (SETBstore [off] {sym} ptr (BTQ x y) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48178,7 +48178,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 		if !(!config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48189,9 +48189,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (TESTLconst [c] x) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTLconst [c] x) mem)
 	// cond: isUint32PowerOfTwo(c) && !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTLconst [log2uint32(c)] x) mem)
+	// result: (SETBstore [off] {sym} ptr (BTLconst [log2uint32(c)] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48207,7 +48207,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 		if !(isUint32PowerOfTwo(c) && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48218,9 +48218,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (TESTQconst [c] x) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTQconst [c] x) mem)
 	// cond: isUint64PowerOfTwo(c) && !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTQconst [log2(c)] x) mem)
+	// result: (SETBstore [off] {sym} ptr (BTQconst [log2(c)] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48236,7 +48236,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 		if !(isUint64PowerOfTwo(c) && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48247,9 +48247,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (TESTQ (MOVQconst [c]) x) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTQ (MOVQconst [c]) x) mem)
 	// cond: isUint64PowerOfTwo(c) && !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTQconst [log2(c)] x) mem)
+	// result: (SETBstore [off] {sym} ptr (BTQconst [log2(c)] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48270,7 +48270,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 		if !(isUint64PowerOfTwo(c) && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48281,9 +48281,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (TESTQ x (MOVQconst [c])) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTQ x (MOVQconst [c])) mem)
 	// cond: isUint64PowerOfTwo(c) && !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTQconst [log2(c)] x) mem)
+	// result: (SETBstore [off] {sym} ptr (BTQconst [log2(c)] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48304,7 +48304,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 		if !(isUint64PowerOfTwo(c) && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48315,9 +48315,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (CMPLconst [1] s:(ANDLconst [1] _)) mem)
+	// match: (SETNEstore [off] {sym} ptr (CMPLconst [1] s:(ANDLconst [1] _)) mem)
 	// cond:
-	// result: (SETEQmem [off] {sym} ptr (CMPLconst [0] s) mem)
+	// result: (SETEQstore [off] {sym} ptr (CMPLconst [0] s) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48338,7 +48338,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 			break
 		}
 		mem := v.Args[2]
-		v.reset(OpAMD64SETEQmem)
+		v.reset(OpAMD64SETEQstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48349,9 +48349,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (CMPQconst [1] s:(ANDQconst [1] _)) mem)
+	// match: (SETNEstore [off] {sym} ptr (CMPQconst [1] s:(ANDQconst [1] _)) mem)
 	// cond:
-	// result: (SETEQmem [off] {sym} ptr (CMPQconst [0] s) mem)
+	// result: (SETEQstore [off] {sym} ptr (CMPQconst [0] s) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48372,7 +48372,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 			break
 		}
 		mem := v.Args[2]
-		v.reset(OpAMD64SETEQmem)
+		v.reset(OpAMD64SETEQstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48385,14 +48385,14 @@ func rewriteValueAMD64_OpAMD64SETNEmem_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
+func rewriteValueAMD64_OpAMD64SETNEstore_10(v *Value) bool {
 	b := v.Block
 	_ = b
 	config := b.Func.Config
 	_ = config
-	// match: (SETNEmem [off] {sym} ptr (TESTQ z1:(SHLQconst [63] (SHRQconst [63] x)) z2) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTQ z1:(SHLQconst [63] (SHRQconst [63] x)) z2) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTQconst [63] x) mem)
+	// result: (SETBstore [off] {sym} ptr (BTQconst [63] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48423,7 +48423,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48434,9 +48434,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (TESTQ z2 z1:(SHLQconst [63] (SHRQconst [63] x))) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTQ z2 z1:(SHLQconst [63] (SHRQconst [63] x))) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTQconst [63] x) mem)
+	// result: (SETBstore [off] {sym} ptr (BTQconst [63] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48467,7 +48467,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48478,9 +48478,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (TESTL z1:(SHLLconst [31] (SHRLconst [31] x)) z2) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTL z1:(SHLLconst [31] (SHRLconst [31] x)) z2) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTLconst [31] x) mem)
+	// result: (SETBstore [off] {sym} ptr (BTLconst [31] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48511,7 +48511,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48522,9 +48522,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (TESTL z2 z1:(SHLLconst [31] (SHRLconst [31] x))) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTL z2 z1:(SHLLconst [31] (SHRLconst [31] x))) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTLconst [31] x) mem)
+	// result: (SETBstore [off] {sym} ptr (BTLconst [31] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48555,7 +48555,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48566,9 +48566,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (TESTQ z1:(SHRQconst [63] (SHLQconst [63] x)) z2) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTQ z1:(SHRQconst [63] (SHLQconst [63] x)) z2) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTQconst [0] x) mem)
+	// result: (SETBstore [off] {sym} ptr (BTQconst [0] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48599,7 +48599,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48610,9 +48610,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (TESTQ z2 z1:(SHRQconst [63] (SHLQconst [63] x))) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTQ z2 z1:(SHRQconst [63] (SHLQconst [63] x))) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTQconst [0] x) mem)
+	// result: (SETBstore [off] {sym} ptr (BTQconst [0] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48643,7 +48643,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48654,9 +48654,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (TESTL z1:(SHRLconst [31] (SHLLconst [31] x)) z2) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTL z1:(SHRLconst [31] (SHLLconst [31] x)) z2) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTLconst [0] x) mem)
+	// result: (SETBstore [off] {sym} ptr (BTLconst [0] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48687,7 +48687,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48698,9 +48698,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (TESTL z2 z1:(SHRLconst [31] (SHLLconst [31] x))) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTL z2 z1:(SHRLconst [31] (SHLLconst [31] x))) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTLconst [0] x) mem)
+	// result: (SETBstore [off] {sym} ptr (BTLconst [0] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48731,7 +48731,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48742,9 +48742,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (TESTQ z1:(SHRQconst [63] x) z2) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTQ z1:(SHRQconst [63] x) z2) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTQconst [63] x) mem)
+	// result: (SETBstore [off] {sym} ptr (BTQconst [63] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48768,7 +48768,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48779,9 +48779,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (TESTQ z2 z1:(SHRQconst [63] x)) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTQ z2 z1:(SHRQconst [63] x)) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTQconst [63] x) mem)
+	// result: (SETBstore [off] {sym} ptr (BTQconst [63] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48805,7 +48805,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48818,14 +48818,14 @@ func rewriteValueAMD64_OpAMD64SETNEmem_10(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64SETNEmem_20(v *Value) bool {
+func rewriteValueAMD64_OpAMD64SETNEstore_20(v *Value) bool {
 	b := v.Block
 	_ = b
 	config := b.Func.Config
 	_ = config
-	// match: (SETNEmem [off] {sym} ptr (TESTL z1:(SHRLconst [31] x) z2) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTL z1:(SHRLconst [31] x) z2) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTLconst [31] x) mem)
+	// result: (SETBstore [off] {sym} ptr (BTLconst [31] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48849,7 +48849,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_20(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48860,9 +48860,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_20(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (TESTL z2 z1:(SHRLconst [31] x)) mem)
+	// match: (SETNEstore [off] {sym} ptr (TESTL z2 z1:(SHRLconst [31] x)) mem)
 	// cond: z1==z2 && !config.nacl
-	// result: (SETBmem [off] {sym} ptr (BTLconst [31] x) mem)
+	// result: (SETBstore [off] {sym} ptr (BTLconst [31] x) mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48886,7 +48886,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_20(v *Value) bool {
 		if !(z1 == z2 && !config.nacl) {
 			break
 		}
-		v.reset(OpAMD64SETBmem)
+		v.reset(OpAMD64SETBstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48897,9 +48897,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_20(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr (InvertFlags x) mem)
+	// match: (SETNEstore [off] {sym} ptr (InvertFlags x) mem)
 	// cond:
-	// result: (SETNEmem [off] {sym} ptr x mem)
+	// result: (SETNEstore [off] {sym} ptr x mem)
 	for {
 		off := v.AuxInt
 		sym := v.Aux
@@ -48911,7 +48911,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_20(v *Value) bool {
 		}
 		x := v_1.Args[0]
 		mem := v.Args[2]
-		v.reset(OpAMD64SETNEmem)
+		v.reset(OpAMD64SETNEstore)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(ptr)
@@ -48919,9 +48919,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_20(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off1] {sym} (ADDQconst [off2] base) val mem)
+	// match: (SETNEstore [off1] {sym} (ADDQconst [off2] base) val mem)
 	// cond: is32Bit(off1+off2)
-	// result: (SETNEmem [off1+off2] {sym} base val mem)
+	// result: (SETNEstore [off1+off2] {sym} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -48937,7 +48937,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_20(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64SETNEmem)
+		v.reset(OpAMD64SETNEstore)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(base)
@@ -48945,9 +48945,9 @@ func rewriteValueAMD64_OpAMD64SETNEmem_20(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
+	// match: (SETNEstore [off1] {sym1} (LEAQ [off2] {sym2} base) val mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (SETNEmem [off1+off2] {mergeSym(sym1,sym2)} base val mem)
+	// result: (SETNEstore [off1+off2] {mergeSym(sym1,sym2)} base val mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -48964,7 +48964,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_20(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64SETNEmem)
+		v.reset(OpAMD64SETNEstore)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(base)
@@ -48972,7 +48972,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_20(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr x:(FlagEQ) mem)
+	// match: (SETNEstore [off] {sym} ptr x:(FlagEQ) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [0]) mem)
 	for {
@@ -48995,7 +48995,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_20(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr x:(FlagLT_ULT) mem)
+	// match: (SETNEstore [off] {sym} ptr x:(FlagLT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -49018,7 +49018,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_20(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr x:(FlagLT_UGT) mem)
+	// match: (SETNEstore [off] {sym} ptr x:(FlagLT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -49041,7 +49041,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_20(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr x:(FlagGT_ULT) mem)
+	// match: (SETNEstore [off] {sym} ptr x:(FlagGT_ULT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -49064,7 +49064,7 @@ func rewriteValueAMD64_OpAMD64SETNEmem_20(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SETNEmem [off] {sym} ptr x:(FlagGT_UGT) mem)
+	// match: (SETNEstore [off] {sym} ptr x:(FlagGT_UGT) mem)
 	// cond:
 	// result: (MOVBstore [off] {sym} ptr (MOVLconst <x.Type> [1]) mem)
 	for {
@@ -50395,7 +50395,7 @@ func rewriteValueAMD64_OpAMD64SUBL_0(v *Value) bool {
 	}
 	// match: (SUBL x l:(MOVLload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (SUBLmem x [off] {sym} ptr mem)
+	// result: (SUBLload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -50411,7 +50411,7 @@ func rewriteValueAMD64_OpAMD64SUBL_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64SUBLmem)
+		v.reset(OpAMD64SUBLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -50448,14 +50448,14 @@ func rewriteValueAMD64_OpAMD64SUBLconst_0(v *Value) bool {
 		return true
 	}
 }
-func rewriteValueAMD64_OpAMD64SUBLmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64SUBLload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	typ := &b.Func.Config.Types
 	_ = typ
-	// match: (SUBLmem [off1] {sym} val (ADDQconst [off2] base) mem)
+	// match: (SUBLload [off1] {sym} val (ADDQconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (SUBLmem [off1+off2] {sym} val base mem)
+	// result: (SUBLload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -50471,7 +50471,7 @@ func rewriteValueAMD64_OpAMD64SUBLmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64SUBLmem)
+		v.reset(OpAMD64SUBLload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -50479,9 +50479,9 @@ func rewriteValueAMD64_OpAMD64SUBLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SUBLmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	// match: (SUBLload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (SUBLmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (SUBLload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -50498,7 +50498,7 @@ func rewriteValueAMD64_OpAMD64SUBLmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64SUBLmem)
+		v.reset(OpAMD64SUBLload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -50506,7 +50506,7 @@ func rewriteValueAMD64_OpAMD64SUBLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SUBLmem x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _))
+	// match: (SUBLload x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _))
 	// cond:
 	// result: (SUBL x (MOVLf2i y))
 	for {
@@ -50597,7 +50597,7 @@ func rewriteValueAMD64_OpAMD64SUBQ_0(v *Value) bool {
 	}
 	// match: (SUBQ x l:(MOVQload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (SUBQmem x [off] {sym} ptr mem)
+	// result: (SUBQload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -50613,7 +50613,7 @@ func rewriteValueAMD64_OpAMD64SUBQ_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64SUBQmem)
+		v.reset(OpAMD64SUBQload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -50686,14 +50686,14 @@ func rewriteValueAMD64_OpAMD64SUBQconst_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64SUBQmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64SUBQload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	typ := &b.Func.Config.Types
 	_ = typ
-	// match: (SUBQmem [off1] {sym} val (ADDQconst [off2] base) mem)
+	// match: (SUBQload [off1] {sym} val (ADDQconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (SUBQmem [off1+off2] {sym} val base mem)
+	// result: (SUBQload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -50709,7 +50709,7 @@ func rewriteValueAMD64_OpAMD64SUBQmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64SUBQmem)
+		v.reset(OpAMD64SUBQload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -50717,9 +50717,9 @@ func rewriteValueAMD64_OpAMD64SUBQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SUBQmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	// match: (SUBQload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (SUBQmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (SUBQload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -50736,7 +50736,7 @@ func rewriteValueAMD64_OpAMD64SUBQmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64SUBQmem)
+		v.reset(OpAMD64SUBQload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -50744,7 +50744,7 @@ func rewriteValueAMD64_OpAMD64SUBQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SUBQmem x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _))
+	// match: (SUBQload x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _))
 	// cond:
 	// result: (SUBQ x (MOVQf2i y))
 	for {
@@ -50780,7 +50780,7 @@ func rewriteValueAMD64_OpAMD64SUBQmem_0(v *Value) bool {
 func rewriteValueAMD64_OpAMD64SUBSD_0(v *Value) bool {
 	// match: (SUBSD x l:(MOVSDload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (SUBSDmem x [off] {sym} ptr mem)
+	// result: (SUBSDload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -50796,7 +50796,7 @@ func rewriteValueAMD64_OpAMD64SUBSD_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64SUBSDmem)
+		v.reset(OpAMD64SUBSDload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -50806,14 +50806,14 @@ func rewriteValueAMD64_OpAMD64SUBSD_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64SUBSDmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64SUBSDload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	typ := &b.Func.Config.Types
 	_ = typ
-	// match: (SUBSDmem [off1] {sym} val (ADDQconst [off2] base) mem)
+	// match: (SUBSDload [off1] {sym} val (ADDQconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (SUBSDmem [off1+off2] {sym} val base mem)
+	// result: (SUBSDload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -50829,7 +50829,7 @@ func rewriteValueAMD64_OpAMD64SUBSDmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64SUBSDmem)
+		v.reset(OpAMD64SUBSDload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -50837,9 +50837,9 @@ func rewriteValueAMD64_OpAMD64SUBSDmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SUBSDmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	// match: (SUBSDload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (SUBSDmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (SUBSDload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -50856,7 +50856,7 @@ func rewriteValueAMD64_OpAMD64SUBSDmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64SUBSDmem)
+		v.reset(OpAMD64SUBSDload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -50864,7 +50864,7 @@ func rewriteValueAMD64_OpAMD64SUBSDmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SUBSDmem x [off] {sym} ptr (MOVQstore [off] {sym} ptr y _))
+	// match: (SUBSDload x [off] {sym} ptr (MOVQstore [off] {sym} ptr y _))
 	// cond:
 	// result: (SUBSD x (MOVQi2f y))
 	for {
@@ -50900,7 +50900,7 @@ func rewriteValueAMD64_OpAMD64SUBSDmem_0(v *Value) bool {
 func rewriteValueAMD64_OpAMD64SUBSS_0(v *Value) bool {
 	// match: (SUBSS x l:(MOVSSload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (SUBSSmem x [off] {sym} ptr mem)
+	// result: (SUBSSload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -50916,7 +50916,7 @@ func rewriteValueAMD64_OpAMD64SUBSS_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64SUBSSmem)
+		v.reset(OpAMD64SUBSSload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -50926,14 +50926,14 @@ func rewriteValueAMD64_OpAMD64SUBSS_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64SUBSSmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64SUBSSload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	typ := &b.Func.Config.Types
 	_ = typ
-	// match: (SUBSSmem [off1] {sym} val (ADDQconst [off2] base) mem)
+	// match: (SUBSSload [off1] {sym} val (ADDQconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (SUBSSmem [off1+off2] {sym} val base mem)
+	// result: (SUBSSload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -50949,7 +50949,7 @@ func rewriteValueAMD64_OpAMD64SUBSSmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64SUBSSmem)
+		v.reset(OpAMD64SUBSSload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -50957,9 +50957,9 @@ func rewriteValueAMD64_OpAMD64SUBSSmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SUBSSmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	// match: (SUBSSload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (SUBSSmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (SUBSSload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -50976,7 +50976,7 @@ func rewriteValueAMD64_OpAMD64SUBSSmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64SUBSSmem)
+		v.reset(OpAMD64SUBSSload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -50984,7 +50984,7 @@ func rewriteValueAMD64_OpAMD64SUBSSmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (SUBSSmem x [off] {sym} ptr (MOVLstore [off] {sym} ptr y _))
+	// match: (SUBSSload x [off] {sym} ptr (MOVLstore [off] {sym} ptr y _))
 	// cond:
 	// result: (SUBSS x (MOVLi2f y))
 	for {
@@ -51054,7 +51054,7 @@ func rewriteValueAMD64_OpAMD64TESTB_0(v *Value) bool {
 	}
 	// match: (TESTB l:(MOVBload {sym} [off] ptr mem) l2)
 	// cond: l == l2 && l.Uses == 2 && validValAndOff(0,off) && clobber(l)
-	// result: @l.Block (CMPBconstmem {sym} [makeValAndOff(0,off)] ptr mem)
+	// result: @l.Block (CMPBconstload {sym} [makeValAndOff(0,off)] ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -51071,7 +51071,7 @@ func rewriteValueAMD64_OpAMD64TESTB_0(v *Value) bool {
 			break
 		}
 		b = l.Block
-		v0 := b.NewValue0(v.Pos, OpAMD64CMPBconstmem, types.TypeFlags)
+		v0 := b.NewValue0(v.Pos, OpAMD64CMPBconstload, types.TypeFlags)
 		v.reset(OpCopy)
 		v.AddArg(v0)
 		v0.AuxInt = makeValAndOff(0, off)
@@ -51082,7 +51082,7 @@ func rewriteValueAMD64_OpAMD64TESTB_0(v *Value) bool {
 	}
 	// match: (TESTB l2 l:(MOVBload {sym} [off] ptr mem))
 	// cond: l == l2 && l.Uses == 2 && validValAndOff(0,off) && clobber(l)
-	// result: @l.Block (CMPBconstmem {sym} [makeValAndOff(0,off)] ptr mem)
+	// result: @l.Block (CMPBconstload {sym} [makeValAndOff(0,off)] ptr mem)
 	for {
 		_ = v.Args[1]
 		l2 := v.Args[0]
@@ -51099,7 +51099,7 @@ func rewriteValueAMD64_OpAMD64TESTB_0(v *Value) bool {
 			break
 		}
 		b = l.Block
-		v0 := b.NewValue0(v.Pos, OpAMD64CMPBconstmem, types.TypeFlags)
+		v0 := b.NewValue0(v.Pos, OpAMD64CMPBconstload, types.TypeFlags)
 		v.reset(OpCopy)
 		v.AddArg(v0)
 		v0.AuxInt = makeValAndOff(0, off)
@@ -51166,7 +51166,7 @@ func rewriteValueAMD64_OpAMD64TESTL_0(v *Value) bool {
 	}
 	// match: (TESTL l:(MOVLload {sym} [off] ptr mem) l2)
 	// cond: l == l2 && l.Uses == 2 && validValAndOff(0,off) && clobber(l)
-	// result: @l.Block (CMPLconstmem {sym} [makeValAndOff(0,off)] ptr mem)
+	// result: @l.Block (CMPLconstload {sym} [makeValAndOff(0,off)] ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -51183,7 +51183,7 @@ func rewriteValueAMD64_OpAMD64TESTL_0(v *Value) bool {
 			break
 		}
 		b = l.Block
-		v0 := b.NewValue0(v.Pos, OpAMD64CMPLconstmem, types.TypeFlags)
+		v0 := b.NewValue0(v.Pos, OpAMD64CMPLconstload, types.TypeFlags)
 		v.reset(OpCopy)
 		v.AddArg(v0)
 		v0.AuxInt = makeValAndOff(0, off)
@@ -51194,7 +51194,7 @@ func rewriteValueAMD64_OpAMD64TESTL_0(v *Value) bool {
 	}
 	// match: (TESTL l2 l:(MOVLload {sym} [off] ptr mem))
 	// cond: l == l2 && l.Uses == 2 && validValAndOff(0,off) && clobber(l)
-	// result: @l.Block (CMPLconstmem {sym} [makeValAndOff(0,off)] ptr mem)
+	// result: @l.Block (CMPLconstload {sym} [makeValAndOff(0,off)] ptr mem)
 	for {
 		_ = v.Args[1]
 		l2 := v.Args[0]
@@ -51211,7 +51211,7 @@ func rewriteValueAMD64_OpAMD64TESTL_0(v *Value) bool {
 			break
 		}
 		b = l.Block
-		v0 := b.NewValue0(v.Pos, OpAMD64CMPLconstmem, types.TypeFlags)
+		v0 := b.NewValue0(v.Pos, OpAMD64CMPLconstload, types.TypeFlags)
 		v.reset(OpCopy)
 		v.AddArg(v0)
 		v0.AuxInt = makeValAndOff(0, off)
@@ -51284,7 +51284,7 @@ func rewriteValueAMD64_OpAMD64TESTQ_0(v *Value) bool {
 	}
 	// match: (TESTQ l:(MOVQload {sym} [off] ptr mem) l2)
 	// cond: l == l2 && l.Uses == 2 && validValAndOff(0,off) && clobber(l)
-	// result: @l.Block (CMPQconstmem {sym} [makeValAndOff(0,off)] ptr mem)
+	// result: @l.Block (CMPQconstload {sym} [makeValAndOff(0,off)] ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -51301,7 +51301,7 @@ func rewriteValueAMD64_OpAMD64TESTQ_0(v *Value) bool {
 			break
 		}
 		b = l.Block
-		v0 := b.NewValue0(v.Pos, OpAMD64CMPQconstmem, types.TypeFlags)
+		v0 := b.NewValue0(v.Pos, OpAMD64CMPQconstload, types.TypeFlags)
 		v.reset(OpCopy)
 		v.AddArg(v0)
 		v0.AuxInt = makeValAndOff(0, off)
@@ -51312,7 +51312,7 @@ func rewriteValueAMD64_OpAMD64TESTQ_0(v *Value) bool {
 	}
 	// match: (TESTQ l2 l:(MOVQload {sym} [off] ptr mem))
 	// cond: l == l2 && l.Uses == 2 && validValAndOff(0,off) && clobber(l)
-	// result: @l.Block (CMPQconstmem {sym} [makeValAndOff(0,off)] ptr mem)
+	// result: @l.Block (CMPQconstload {sym} [makeValAndOff(0,off)] ptr mem)
 	for {
 		_ = v.Args[1]
 		l2 := v.Args[0]
@@ -51329,7 +51329,7 @@ func rewriteValueAMD64_OpAMD64TESTQ_0(v *Value) bool {
 			break
 		}
 		b = l.Block
-		v0 := b.NewValue0(v.Pos, OpAMD64CMPQconstmem, types.TypeFlags)
+		v0 := b.NewValue0(v.Pos, OpAMD64CMPQconstload, types.TypeFlags)
 		v.reset(OpCopy)
 		v.AddArg(v0)
 		v0.AuxInt = makeValAndOff(0, off)
@@ -51396,7 +51396,7 @@ func rewriteValueAMD64_OpAMD64TESTW_0(v *Value) bool {
 	}
 	// match: (TESTW l:(MOVWload {sym} [off] ptr mem) l2)
 	// cond: l == l2 && l.Uses == 2 && validValAndOff(0,off) && clobber(l)
-	// result: @l.Block (CMPWconstmem {sym} [makeValAndOff(0,off)] ptr mem)
+	// result: @l.Block (CMPWconstload {sym} [makeValAndOff(0,off)] ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -51413,7 +51413,7 @@ func rewriteValueAMD64_OpAMD64TESTW_0(v *Value) bool {
 			break
 		}
 		b = l.Block
-		v0 := b.NewValue0(v.Pos, OpAMD64CMPWconstmem, types.TypeFlags)
+		v0 := b.NewValue0(v.Pos, OpAMD64CMPWconstload, types.TypeFlags)
 		v.reset(OpCopy)
 		v.AddArg(v0)
 		v0.AuxInt = makeValAndOff(0, off)
@@ -51424,7 +51424,7 @@ func rewriteValueAMD64_OpAMD64TESTW_0(v *Value) bool {
 	}
 	// match: (TESTW l2 l:(MOVWload {sym} [off] ptr mem))
 	// cond: l == l2 && l.Uses == 2 && validValAndOff(0,off) && clobber(l)
-	// result: @l.Block (CMPWconstmem {sym} [makeValAndOff(0,off)] ptr mem)
+	// result: @l.Block (CMPWconstload {sym} [makeValAndOff(0,off)] ptr mem)
 	for {
 		_ = v.Args[1]
 		l2 := v.Args[0]
@@ -51441,7 +51441,7 @@ func rewriteValueAMD64_OpAMD64TESTW_0(v *Value) bool {
 			break
 		}
 		b = l.Block
-		v0 := b.NewValue0(v.Pos, OpAMD64CMPWconstmem, types.TypeFlags)
+		v0 := b.NewValue0(v.Pos, OpAMD64CMPWconstload, types.TypeFlags)
 		v.reset(OpCopy)
 		v.AddArg(v0)
 		v0.AuxInt = makeValAndOff(0, off)
@@ -51954,7 +51954,7 @@ func rewriteValueAMD64_OpAMD64XORL_10(v *Value) bool {
 	}
 	// match: (XORL x l:(MOVLload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (XORLmem x [off] {sym} ptr mem)
+	// result: (XORLload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -51970,7 +51970,7 @@ func rewriteValueAMD64_OpAMD64XORL_10(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64XORLmem)
+		v.reset(OpAMD64XORLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -51980,7 +51980,7 @@ func rewriteValueAMD64_OpAMD64XORL_10(v *Value) bool {
 	}
 	// match: (XORL l:(MOVLload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (XORLmem x [off] {sym} ptr mem)
+	// result: (XORLload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -51996,7 +51996,7 @@ func rewriteValueAMD64_OpAMD64XORL_10(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64XORLmem)
+		v.reset(OpAMD64XORLload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -52234,14 +52234,14 @@ func rewriteValueAMD64_OpAMD64XORLconst_10(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64XORLmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64XORLload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	typ := &b.Func.Config.Types
 	_ = typ
-	// match: (XORLmem [off1] {sym} val (ADDQconst [off2] base) mem)
+	// match: (XORLload [off1] {sym} val (ADDQconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (XORLmem [off1+off2] {sym} val base mem)
+	// result: (XORLload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -52257,7 +52257,7 @@ func rewriteValueAMD64_OpAMD64XORLmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64XORLmem)
+		v.reset(OpAMD64XORLload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -52265,9 +52265,9 @@ func rewriteValueAMD64_OpAMD64XORLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (XORLmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	// match: (XORLload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (XORLmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (XORLload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -52284,7 +52284,7 @@ func rewriteValueAMD64_OpAMD64XORLmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64XORLmem)
+		v.reset(OpAMD64XORLload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -52292,7 +52292,7 @@ func rewriteValueAMD64_OpAMD64XORLmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (XORLmem x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _))
+	// match: (XORLload x [off] {sym} ptr (MOVSSstore [off] {sym} ptr y _))
 	// cond:
 	// result: (XORL x (MOVLf2i y))
 	for {
@@ -52529,7 +52529,7 @@ func rewriteValueAMD64_OpAMD64XORQ_0(v *Value) bool {
 	}
 	// match: (XORQ x l:(MOVQload [off] {sym} ptr mem))
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (XORQmem x [off] {sym} ptr mem)
+	// result: (XORQload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		x := v.Args[0]
@@ -52545,7 +52545,7 @@ func rewriteValueAMD64_OpAMD64XORQ_0(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64XORQmem)
+		v.reset(OpAMD64XORQload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -52558,7 +52558,7 @@ func rewriteValueAMD64_OpAMD64XORQ_0(v *Value) bool {
 func rewriteValueAMD64_OpAMD64XORQ_10(v *Value) bool {
 	// match: (XORQ l:(MOVQload [off] {sym} ptr mem) x)
 	// cond: canMergeLoad(v, l, x) && clobber(l)
-	// result: (XORQmem x [off] {sym} ptr mem)
+	// result: (XORQload x [off] {sym} ptr mem)
 	for {
 		_ = v.Args[1]
 		l := v.Args[0]
@@ -52574,7 +52574,7 @@ func rewriteValueAMD64_OpAMD64XORQ_10(v *Value) bool {
 		if !(canMergeLoad(v, l, x) && clobber(l)) {
 			break
 		}
-		v.reset(OpAMD64XORQmem)
+		v.reset(OpAMD64XORQload)
 		v.AuxInt = off
 		v.Aux = sym
 		v.AddArg(x)
@@ -52648,14 +52648,14 @@ func rewriteValueAMD64_OpAMD64XORQconst_0(v *Value) bool {
 	}
 	return false
 }
-func rewriteValueAMD64_OpAMD64XORQmem_0(v *Value) bool {
+func rewriteValueAMD64_OpAMD64XORQload_0(v *Value) bool {
 	b := v.Block
 	_ = b
 	typ := &b.Func.Config.Types
 	_ = typ
-	// match: (XORQmem [off1] {sym} val (ADDQconst [off2] base) mem)
+	// match: (XORQload [off1] {sym} val (ADDQconst [off2] base) mem)
 	// cond: is32Bit(off1+off2)
-	// result: (XORQmem [off1+off2] {sym} val base mem)
+	// result: (XORQload [off1+off2] {sym} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym := v.Aux
@@ -52671,7 +52671,7 @@ func rewriteValueAMD64_OpAMD64XORQmem_0(v *Value) bool {
 		if !(is32Bit(off1 + off2)) {
 			break
 		}
-		v.reset(OpAMD64XORQmem)
+		v.reset(OpAMD64XORQload)
 		v.AuxInt = off1 + off2
 		v.Aux = sym
 		v.AddArg(val)
@@ -52679,9 +52679,9 @@ func rewriteValueAMD64_OpAMD64XORQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (XORQmem [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
+	// match: (XORQload [off1] {sym1} val (LEAQ [off2] {sym2} base) mem)
 	// cond: is32Bit(off1+off2) && canMergeSym(sym1, sym2)
-	// result: (XORQmem [off1+off2] {mergeSym(sym1,sym2)} val base mem)
+	// result: (XORQload [off1+off2] {mergeSym(sym1,sym2)} val base mem)
 	for {
 		off1 := v.AuxInt
 		sym1 := v.Aux
@@ -52698,7 +52698,7 @@ func rewriteValueAMD64_OpAMD64XORQmem_0(v *Value) bool {
 		if !(is32Bit(off1+off2) && canMergeSym(sym1, sym2)) {
 			break
 		}
-		v.reset(OpAMD64XORQmem)
+		v.reset(OpAMD64XORQload)
 		v.AuxInt = off1 + off2
 		v.Aux = mergeSym(sym1, sym2)
 		v.AddArg(val)
@@ -52706,7 +52706,7 @@ func rewriteValueAMD64_OpAMD64XORQmem_0(v *Value) bool {
 		v.AddArg(mem)
 		return true
 	}
-	// match: (XORQmem x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _))
+	// match: (XORQload x [off] {sym} ptr (MOVSDstore [off] {sym} ptr y _))
 	// cond:
 	// result: (XORQ x (MOVQf2i y))
 	for {
diff --git a/src/cmd/compile/internal/x86/ssa.go b/src/cmd/compile/internal/x86/ssa.go
index b8b8a8b33d..b781d95725 100644
--- a/src/cmd/compile/internal/x86/ssa.go
+++ b/src/cmd/compile/internal/x86/ssa.go
@@ -510,8 +510,8 @@ func ssaGenValue(s *gc.SSAGenState, v *ssa.Value) {
 		gc.AddAux(&p.From, v)
 		p.To.Type = obj.TYPE_REG
 		p.To.Reg = v.Reg()
-	case ssa.Op386ADDLmem, ssa.Op386SUBLmem, ssa.Op386ANDLmem, ssa.Op386ORLmem, ssa.Op386XORLmem,
-		ssa.Op386ADDSDmem, ssa.Op386ADDSSmem, ssa.Op386SUBSDmem, ssa.Op386SUBSSmem, ssa.Op386MULSDmem, ssa.Op386MULSSmem:
+	case ssa.Op386ADDLload, ssa.Op386SUBLload, ssa.Op386ANDLload, ssa.Op386ORLload, ssa.Op386XORLload,
+		ssa.Op386ADDSDload, ssa.Op386ADDSSload, ssa.Op386SUBSDload, ssa.Op386SUBSSload, ssa.Op386MULSDload, ssa.Op386MULSSload:
 		p := s.Prog(v.Op.Asm())
 		p.From.Type = obj.TYPE_MEM
 		p.From.Reg = v.Args[1].Reg()
