commit 5fea2ccc77eb50a9704fa04b7c61755fe34e1d95
Author: Brad Fitzpatrick <bradfitz@golang.org>
Date:   Tue Mar 1 23:21:55 2016 +0000

    all: single space after period.
    
    The tree's pretty inconsistent about single space vs double space
    after a period in documentation. Make it consistently a single space,
    per earlier decisions. This means contributors won't be confused by
    misleading precedence.
    
    This CL doesn't use go/doc to parse. It only addresses // comments.
    It was generated with:
    
    $ perl -i -npe 's,^(\s*// .+[a-z]\.)  +([A-Z]),$1 $2,' $(git grep -l -E '^\s*//(.+\.)  +([A-Z])')
    $ go test go/doc -update
    
    Change-Id: Iccdb99c37c797ef1f804a94b22ba5ee4b500c4f7
    Reviewed-on: https://go-review.googlesource.com/20022
    Reviewed-by: Rob Pike <r@golang.org>
    Reviewed-by: Dave Day <djd@golang.org>
    Run-TryBot: Brad Fitzpatrick <bradfitz@golang.org>
    TryBot-Result: Gobot Gobot <gobot@golang.org>
---
 src/archive/tar/writer.go                          |  4 +-
 src/bufio/bufio.go                                 |  4 +-
 src/bytes/buffer.go                                | 10 +--
 src/bytes/bytes.go                                 | 18 ++---
 src/bytes/bytes_test.go                            |  4 +-
 src/bytes/compare_test.go                          |  2 +-
 src/bytes/equal_test.go                            |  4 +-
 src/cmd/cgo/ast.go                                 |  2 +-
 src/cmd/cgo/gcc.go                                 | 70 ++++++++---------
 src/cmd/cgo/main.go                                |  4 +-
 src/cmd/cgo/out.go                                 | 10 +--
 src/cmd/cgo/util.go                                |  2 +-
 src/cmd/compile/internal/amd64/peep.go             |  4 +-
 src/cmd/compile/internal/arm/cgen64.go             |  2 +-
 src/cmd/compile/internal/arm64/cgen.go             |  2 +-
 src/cmd/compile/internal/big/arith_test.go         |  2 +-
 src/cmd/compile/internal/big/nat.go                |  4 +-
 src/cmd/compile/internal/big/rat.go                |  4 +-
 src/cmd/compile/internal/big/ratconv_test.go       |  2 +-
 src/cmd/compile/internal/gc/alg.go                 |  2 +-
 src/cmd/compile/internal/gc/align.go               |  4 +-
 src/cmd/compile/internal/gc/bimport.go             |  2 +-
 src/cmd/compile/internal/gc/builtin/runtime.go     |  2 +-
 src/cmd/compile/internal/gc/builtin/unsafe.go      |  2 +-
 src/cmd/compile/internal/gc/cgen.go                |  2 +-
 src/cmd/compile/internal/gc/dcl.go                 |  4 +-
 src/cmd/compile/internal/gc/esc.go                 | 22 +++---
 src/cmd/compile/internal/gc/fmt.go                 |  4 +-
 src/cmd/compile/internal/gc/global_test.go         |  6 +-
 src/cmd/compile/internal/gc/inl.go                 | 10 +--
 src/cmd/compile/internal/gc/order.go               |  2 +-
 src/cmd/compile/internal/gc/parser.go              |  2 +-
 src/cmd/compile/internal/gc/plive.go               | 82 ++++++++++----------
 src/cmd/compile/internal/gc/reflect.go             |  4 +-
 src/cmd/compile/internal/gc/ssa.go                 | 86 ++++++++++-----------
 src/cmd/compile/internal/gc/subr.go                |  8 +-
 .../compile/internal/gc/testdata/addressed_ssa.go  |  2 +-
 .../internal/gc/testdata/gen/arithBoundaryGen.go   |  2 +-
 .../internal/gc/testdata/gen/arithConstGen.go      |  2 +-
 .../compile/internal/gc/testdata/loadstore_ssa.go  |  2 +-
 src/cmd/compile/internal/gc/testdata/phi_ssa.go    |  2 +-
 src/cmd/compile/internal/gc/testdata/unsafe_ssa.go |  4 +-
 src/cmd/compile/internal/gc/type.go                |  2 +-
 src/cmd/compile/internal/gc/typecheck.go           | 10 +--
 src/cmd/compile/internal/gc/walk.go                |  6 +-
 src/cmd/compile/internal/mips64/cgen.go            |  2 +-
 src/cmd/compile/internal/mips64/peep.go            |  6 +-
 src/cmd/compile/internal/ppc64/cgen.go             |  2 +-
 src/cmd/compile/internal/ppc64/gsubr.go            |  4 +-
 src/cmd/compile/internal/ppc64/opt.go              |  2 +-
 src/cmd/compile/internal/ppc64/peep.go             |  6 +-
 src/cmd/compile/internal/ppc64/prog.go             |  4 +-
 src/cmd/compile/internal/ssa/block.go              | 14 ++--
 src/cmd/compile/internal/ssa/check.go              |  2 +-
 src/cmd/compile/internal/ssa/compile.go            |  6 +-
 src/cmd/compile/internal/ssa/config.go             |  4 +-
 src/cmd/compile/internal/ssa/cse.go                | 12 +--
 src/cmd/compile/internal/ssa/deadcode.go           | 18 ++---
 src/cmd/compile/internal/ssa/deadstore.go          |  8 +-
 src/cmd/compile/internal/ssa/deadstore_test.go     |  2 +-
 src/cmd/compile/internal/ssa/dom.go                | 14 ++--
 src/cmd/compile/internal/ssa/flagalloc.go          |  8 +-
 src/cmd/compile/internal/ssa/func.go               |  8 +-
 src/cmd/compile/internal/ssa/gen/AMD64.rules       | 10 +--
 src/cmd/compile/internal/ssa/gen/AMD64Ops.go       |  8 +-
 src/cmd/compile/internal/ssa/gen/generic.rules     |  2 +-
 src/cmd/compile/internal/ssa/gen/genericOps.go     | 18 ++---
 src/cmd/compile/internal/ssa/gen/main.go           |  4 +-
 src/cmd/compile/internal/ssa/gen/rulegen.go        | 20 ++---
 src/cmd/compile/internal/ssa/likelyadjust.go       |  6 +-
 src/cmd/compile/internal/ssa/magic.go              |  2 +-
 src/cmd/compile/internal/ssa/nilcheck.go           |  2 +-
 src/cmd/compile/internal/ssa/op.go                 |  2 +-
 src/cmd/compile/internal/ssa/phielim.go            |  8 +-
 src/cmd/compile/internal/ssa/regalloc.go           | 90 +++++++++++-----------
 src/cmd/compile/internal/ssa/rewrite.go            |  2 +-
 src/cmd/compile/internal/ssa/schedule.go           | 20 ++---
 src/cmd/compile/internal/ssa/sparsetree.go         |  4 +-
 src/cmd/compile/internal/ssa/stackalloc.go         | 10 +--
 src/cmd/compile/internal/ssa/value.go              | 12 +--
 src/cmd/compile/internal/x86/cgen64.go             |  2 +-
 src/cmd/compile/internal/x86/gsubr.go              |  2 +-
 src/cmd/compile/internal/x86/peep.go               |  2 +-
 src/cmd/cover/cover.go                             |  4 +-
 src/cmd/dist/build.go                              |  6 +-
 src/cmd/dist/buildruntime.go                       |  2 +-
 src/cmd/dist/test.go                               |  2 +-
 src/cmd/fix/main.go                                |  2 +-
 src/cmd/fix/typecheck.go                           | 14 ++--
 src/cmd/go/build.go                                | 52 ++++++-------
 src/cmd/go/get.go                                  | 14 ++--
 src/cmd/go/go_test.go                              | 20 ++---
 src/cmd/go/main.go                                 |  6 +-
 src/cmd/go/note.go                                 |  2 +-
 src/cmd/go/pkg.go                                  | 24 +++---
 src/cmd/go/run.go                                  |  2 +-
 src/cmd/go/test.go                                 |  4 +-
 src/cmd/go/vcs.go                                  |  2 +-
 src/cmd/gofmt/internal.go                          |  6 +-
 src/cmd/gofmt/rewrite.go                           |  2 +-
 src/cmd/internal/obj/arm/asm5.go                   |  2 +-
 src/cmd/internal/obj/arm64/a.out.go                |  6 +-
 src/cmd/internal/obj/arm64/asm7.go                 |  6 +-
 src/cmd/internal/obj/arm64/list7.go                |  4 +-
 src/cmd/internal/obj/arm64/obj7.go                 |  4 +-
 src/cmd/internal/obj/link.go                       |  2 +-
 src/cmd/internal/obj/objfile.go                    |  2 +-
 src/cmd/internal/obj/ppc64/obj9.go                 |  2 +-
 src/cmd/internal/obj/textflag.go                   |  4 +-
 src/cmd/internal/obj/util.go                       |  2 +-
 src/cmd/internal/obj/x86/asm6.go                   |  2 +-
 src/cmd/internal/obj/x86/obj6.go                   |  2 +-
 src/cmd/link/internal/amd64/asm.go                 |  6 +-
 src/cmd/link/internal/ld/ar.go                     |  4 +-
 src/cmd/link/internal/ld/data.go                   |  2 +-
 src/cmd/link/internal/ld/dwarf.go                  |  4 +-
 src/cmd/link/internal/ld/ldmacho.go                |  2 +-
 src/cmd/link/internal/ld/ldpe.go                   |  4 +-
 src/cmd/link/internal/ld/lib.go                    | 16 ++--
 src/cmd/link/internal/ld/macho.go                  | 10 +--
 src/cmd/link/internal/ld/pcln.go                   |  2 +-
 src/cmd/link/internal/ld/symtab.go                 |  2 +-
 src/cmd/link/internal/ppc64/asm.go                 | 14 ++--
 src/cmd/link/internal/x86/asm.go                   |  2 +-
 src/cmd/pprof/internal/profile/encode.go           |  2 +-
 src/cmd/pprof/internal/profile/legacy_profile.go   | 10 +--
 src/cmd/pprof/internal/profile/profile.go          |  4 +-
 src/cmd/pprof/internal/profile/prune.go            |  2 +-
 src/cmd/pprof/internal/report/report.go            |  2 +-
 src/cmd/pprof/internal/symbolz/symbolz.go          |  2 +-
 src/cmd/vet/cgo.go                                 |  4 +-
 src/cmd/vet/main.go                                |  2 +-
 src/cmd/vet/method.go                              |  6 +-
 src/cmd/vet/print.go                               |  2 +-
 src/cmd/yacc/testdata/expr/expr.y                  |  4 +-
 src/compress/flate/deflate.go                      |  4 +-
 src/compress/flate/deflate_test.go                 |  2 +-
 src/compress/flate/huffman_bit_writer.go           |  4 +-
 src/compress/flate/huffman_code.go                 |  8 +-
 src/compress/flate/inflate.go                      | 14 ++--
 src/compress/gzip/gunzip.go                        |  6 +-
 src/container/heap/heap.go                         |  2 +-
 src/crypto/aes/block.go                            |  2 +-
 src/crypto/cipher/cipher.go                        |  4 +-
 src/crypto/md5/md5.go                              |  2 +-
 src/crypto/rand/rand_unix.go                       |  2 +-
 src/crypto/rand/util.go                            |  2 +-
 src/crypto/rc4/rc4.go                              |  4 +-
 src/crypto/rsa/pss.go                              |  2 +-
 src/crypto/sha1/sha1.go                            |  2 +-
 src/crypto/sha1/sha1_test.go                       |  2 +-
 src/crypto/sha256/sha256.go                        |  2 +-
 src/crypto/sha256/sha256_test.go                   |  2 +-
 src/crypto/sha512/sha512.go                        |  2 +-
 src/crypto/sha512/sha512_test.go                   |  2 +-
 src/crypto/tls/conn.go                             |  2 +-
 src/crypto/tls/handshake_server.go                 |  2 +-
 src/crypto/tls/handshake_server_test.go            |  2 +-
 src/crypto/tls/key_agreement.go                    |  2 +-
 src/crypto/tls/tls_test.go                         |  2 +-
 src/crypto/x509/pem_decrypt.go                     |  2 +-
 src/crypto/x509/root_windows.go                    |  2 +-
 src/crypto/x509/verify.go                          |  2 +-
 src/database/sql/convert.go                        |  2 +-
 src/database/sql/driver/driver.go                  |  4 +-
 src/database/sql/driver/types.go                   |  2 +-
 src/database/sql/fakedb_test.go                    |  4 +-
 src/database/sql/sql.go                            | 20 ++---
 src/database/sql/sql_test.go                       |  2 +-
 src/debug/dwarf/buf.go                             |  6 +-
 src/debug/dwarf/entry.go                           |  8 +-
 src/debug/dwarf/open.go                            |  4 +-
 src/debug/dwarf/type.go                            |  6 +-
 src/debug/dwarf/type_test.go                       |  2 +-
 src/debug/dwarf/typeunit.go                        |  4 +-
 src/debug/elf/elf.go                               |  4 +-
 src/debug/gosym/pclntab.go                         |  2 +-
 src/debug/gosym/symtab.go                          |  6 +-
 src/encoding/ascii85/ascii85.go                    |  6 +-
 src/encoding/asn1/marshal.go                       |  2 +-
 src/encoding/base32/base32.go                      | 10 +--
 src/encoding/base64/base64.go                      | 10 +--
 src/encoding/binary/binary_test.go                 |  2 +-
 src/encoding/csv/reader.go                         | 22 +++---
 src/encoding/csv/writer.go                         |  2 +-
 src/encoding/gob/debug.go                          |  6 +-
 src/encoding/gob/decode.go                         | 18 ++---
 src/encoding/gob/decoder.go                        | 10 +--
 src/encoding/gob/encode.go                         | 18 ++---
 src/encoding/gob/encoder.go                        |  2 +-
 src/encoding/gob/encoder_test.go                   |  8 +-
 src/encoding/gob/error.go                          |  4 +-
 src/encoding/gob/example_interface_test.go         |  2 +-
 src/encoding/gob/example_test.go                   |  2 +-
 src/encoding/gob/gobencdec_test.go                 |  4 +-
 src/encoding/gob/type.go                           | 18 ++---
 src/encoding/hex/hex.go                            |  2 +-
 src/encoding/json/decode.go                        | 10 +--
 src/encoding/json/encode.go                        |  4 +-
 src/encoding/json/scanner.go                       |  2 +-
 src/encoding/json/stream.go                        |  2 +-
 src/encoding/pem/pem.go                            |  2 +-
 src/encoding/xml/marshal.go                        | 12 +--
 src/encoding/xml/read.go                           |  8 +-
 src/encoding/xml/xml.go                            |  6 +-
 src/expvar/expvar.go                               |  2 +-
 src/flag/flag.go                                   | 12 +--
 src/fmt/fmt_test.go                                |  2 +-
 src/fmt/format.go                                  |  2 +-
 src/fmt/scan.go                                    | 36 ++++-----
 src/fmt/scan_test.go                               |  2 +-
 src/go/ast/import.go                               |  2 +-
 src/go/ast/resolve.go                              |  2 +-
 src/go/build/build.go                              | 12 +--
 src/go/build/deps_test.go                          |  2 +-
 src/go/build/doc.go                                |  8 +-
 src/go/doc/comment.go                              |  2 +-
 src/go/doc/testdata/benchmark.go                   |  8 +-
 src/go/doc/testdata/testing.0.golden               |  4 +-
 src/go/doc/testdata/testing.1.golden               | 10 +--
 src/go/doc/testdata/testing.2.golden               |  4 +-
 src/go/doc/testdata/testing.go                     | 10 +--
 src/go/format/internal.go                          |  6 +-
 src/go/scanner/scanner.go                          |  2 +-
 src/go/types/initorder.go                          |  2 +-
 src/go/types/object.go                             |  2 +-
 src/go/types/package.go                            |  2 +-
 src/go/types/scope.go                              |  2 +-
 src/go/types/type.go                               |  2 +-
 src/html/template/error.go                         |  2 +-
 src/html/template/escape.go                        |  4 +-
 src/image/color/color.go                           |  2 +-
 src/image/gif/reader.go                            |  2 +-
 src/io/io.go                                       | 22 +++---
 src/io/ioutil/ioutil.go                            |  4 +-
 src/io/ioutil/tempfile.go                          |  8 +-
 src/io/multi.go                                    |  2 +-
 src/log/log.go                                     | 18 ++---
 src/log/syslog/syslog.go                           |  8 +-
 src/math/acosh.go                                  |  2 +-
 src/math/asinh.go                                  |  2 +-
 src/math/atanh.go                                  |  2 +-
 src/math/big/arith_test.go                         |  2 +-
 src/math/big/nat.go                                |  4 +-
 src/math/big/rat.go                                |  4 +-
 src/math/big/ratconv_test.go                       |  2 +-
 src/math/cmplx/sqrt.go                             |  2 +-
 src/math/erf.go                                    |  2 +-
 src/math/exp.go                                    |  2 +-
 src/math/expm1.go                                  |  2 +-
 src/math/gamma.go                                  |  2 +-
 src/math/j0.go                                     |  2 +-
 src/math/j1.go                                     |  2 +-
 src/math/jn.go                                     |  2 +-
 src/math/lgamma.go                                 |  2 +-
 src/math/log.go                                    |  2 +-
 src/math/log1p.go                                  |  2 +-
 src/math/modf.go                                   |  2 +-
 src/math/remainder.go                              |  2 +-
 src/math/sqrt.go                                   |  4 +-
 src/mime/mediatype.go                              |  4 +-
 src/mime/multipart/multipart.go                    |  8 +-
 src/mime/multipart/multipart_test.go               |  4 +-
 src/net/addrselect.go                              |  2 +-
 src/net/conf.go                                    |  2 +-
 src/net/dial_test.go                               |  2 +-
 src/net/dnsclient.go                               |  2 +-
 src/net/dnsconfig_unix.go                          |  2 +-
 src/net/dnsmsg.go                                  | 12 +--
 src/net/fd_unix.go                                 |  4 +-
 src/net/http/cgi/host.go                           |  2 +-
 src/net/http/client.go                             |  2 +-
 src/net/http/clientserver_test.go                  |  2 +-
 src/net/http/filetransport.go                      |  2 +-
 src/net/http/fs.go                                 | 10 +--
 src/net/http/h2_bundle.go                          | 12 +--
 src/net/http/header.go                             |  8 +-
 src/net/http/httptest/server.go                    |  4 +-
 src/net/http/httputil/dump.go                      |  4 +-
 src/net/http/httputil/persist.go                   |  2 +-
 src/net/http/httputil/reverseproxy.go              |  4 +-
 src/net/http/pprof/pprof.go                        |  6 +-
 src/net/http/request.go                            |  8 +-
 src/net/http/requestwrite_test.go                  |  2 +-
 src/net/http/response.go                           | 12 +--
 src/net/http/serve_test.go                         | 16 ++--
 src/net/http/server.go                             | 44 +++++------
 src/net/http/sniff.go                              |  4 +-
 src/net/http/transfer.go                           | 10 +--
 src/net/http/transport.go                          | 12 +--
 src/net/http/transport_test.go                     | 20 ++---
 src/net/interface.go                               |  2 +-
 src/net/interface_bsd.go                           |  4 +-
 src/net/interface_linux.go                         |  4 +-
 src/net/interface_stub.go                          |  4 +-
 src/net/interface_test.go                          |  2 +-
 src/net/interface_windows.go                       |  4 +-
 src/net/ip.go                                      |  2 +-
 src/net/iprawsock_plan9.go                         |  8 +-
 src/net/iprawsock_posix.go                         |  8 +-
 src/net/ipsock.go                                  |  4 +-
 src/net/ipsock_plan9.go                            |  4 +-
 src/net/ipsock_posix.go                            | 14 ++--
 src/net/lookup.go                                  | 10 +--
 src/net/net.go                                     |  2 +-
 src/net/rpc/client.go                              | 12 +--
 src/net/rpc/jsonrpc/server.go                      |  2 +-
 src/net/rpc/server.go                              | 16 ++--
 src/net/smtp/smtp.go                               |  8 +-
 src/net/sockopt_bsd.go                             |  2 +-
 src/net/sockopt_linux.go                           |  2 +-
 src/net/sockopt_solaris.go                         |  2 +-
 src/net/sockopt_windows.go                         |  2 +-
 src/net/tcpsock_plan9.go                           | 10 +--
 src/net/tcpsock_posix.go                           | 22 +++---
 src/net/textproto/header.go                        |  4 +-
 src/net/textproto/pipeline.go                      |  4 +-
 src/net/textproto/reader.go                        | 10 +--
 src/net/textproto/textproto.go                     |  2 +-
 src/net/textproto/writer.go                        |  2 +-
 src/net/udpsock_plan9.go                           | 10 +--
 src/net/udpsock_posix.go                           | 10 +--
 src/net/unixsock_plan9.go                          | 20 ++---
 src/net/unixsock_posix.go                          | 22 +++---
 src/net/url/url.go                                 | 10 +--
 src/os/doc.go                                      |  4 +-
 src/os/env.go                                      |  4 +-
 src/os/exec.go                                     |  6 +-
 src/os/exec/exec_test.go                           |  2 +-
 src/os/exec_posix.go                               |  2 +-
 src/os/file.go                                     |  2 +-
 src/os/file_plan9.go                               |  4 +-
 src/os/file_unix.go                                | 10 +--
 src/os/file_windows.go                             |  4 +-
 src/os/getwd.go                                    |  4 +-
 src/os/os_unix_test.go                             | 12 +--
 src/os/path.go                                     |  2 +-
 src/os/path_test.go                                |  2 +-
 src/os/pipe_test.go                                |  2 +-
 src/os/signal/signal.go                            |  2 +-
 src/os/stat_plan9.go                               |  2 +-
 src/os/stat_windows.go                             |  2 +-
 src/os/types.go                                    |  2 +-
 src/os/user/lookup_unix.go                         |  2 +-
 src/path/filepath/path.go                          |  4 +-
 src/path/filepath/path_test.go                     |  2 +-
 src/path/path.go                                   |  2 +-
 src/reflect/all_test.go                            |  4 +-
 src/reflect/deepequal.go                           |  2 +-
 src/reflect/type.go                                | 26 +++----
 src/reflect/value.go                               | 34 ++++----
 src/regexp/backtrack.go                            |  2 +-
 src/regexp/exec.go                                 |  2 +-
 src/regexp/exec_test.go                            | 14 ++--
 src/regexp/onepass.go                              |  2 +-
 src/regexp/regexp.go                               | 62 +++++++--------
 src/regexp/syntax/compile.go                       |  4 +-
 src/regexp/syntax/parse.go                         | 30 ++++----
 src/regexp/syntax/prog.go                          |  4 +-
 src/regexp/syntax/regexp.go                        |  2 +-
 src/regexp/syntax/simplify.go                      |  6 +-
 src/regexp/syntax/simplify_test.go                 |  4 +-
 src/runtime/alg.go                                 |  2 +-
 src/runtime/asm_386.s                              | 14 ++--
 src/runtime/asm_amd64.s                            | 16 ++--
 src/runtime/asm_amd64p32.s                         | 10 +--
 src/runtime/asm_arm.s                              |  8 +-
 src/runtime/asm_arm64.s                            |  8 +-
 src/runtime/asm_mips64x.s                          |  6 +-
 src/runtime/asm_ppc64x.h                           |  2 +-
 src/runtime/asm_ppc64x.s                           |  6 +-
 src/runtime/cgo/callbacks.go                       |  6 +-
 src/runtime/cgo/gcc_dragonfly_amd64.c              |  6 +-
 src/runtime/cgo/gcc_freebsd_arm.c                  |  2 +-
 src/runtime/cgo/gcc_linux_386.c                    |  2 +-
 src/runtime/cgo/gcc_linux_arm.c                    |  2 +-
 src/runtime/cgo/gcc_linux_arm64.c                  |  2 +-
 src/runtime/cgo/gcc_netbsd_386.c                   |  6 +-
 src/runtime/cgo/gcc_netbsd_amd64.c                 |  6 +-
 src/runtime/cgo/gcc_netbsd_arm.c                   |  6 +-
 src/runtime/cgo/iscgo.go                           |  4 +-
 src/runtime/cgo/mmap.go                            |  4 +-
 src/runtime/cgo_mmap.go                            |  6 +-
 src/runtime/cgocall.go                             | 36 ++++-----
 src/runtime/cgocheck.go                            | 10 +--
 src/runtime/chan.go                                | 16 ++--
 src/runtime/compiler.go                            |  2 +-
 src/runtime/cpuprof.go                             | 42 +++++-----
 src/runtime/cputicks.go                            |  2 +-
 src/runtime/crash_test.go                          |  4 +-
 src/runtime/debug.go                               |  2 +-
 src/runtime/defs2_linux.go                         |  2 +-
 src/runtime/extern.go                              |  8 +-
 src/runtime/hash_test.go                           | 16 ++--
 src/runtime/hashmap.go                             | 48 ++++++------
 src/runtime/hashmap_fast.go                        | 12 +--
 src/runtime/heapdump.go                            | 12 +--
 src/runtime/iface.go                               |  2 +-
 src/runtime/internal/atomic/asm_mips64x.s          |  4 +-
 src/runtime/internal/atomic/asm_ppc64x.s           |  4 +-
 src/runtime/internal/atomic/atomic_test.go         |  2 +-
 src/runtime/lock_futex.go                          |  2 +-
 src/runtime/lock_sema.go                           | 16 ++--
 src/runtime/malloc.go                              | 36 ++++-----
 src/runtime/mcache.go                              |  2 +-
 src/runtime/mcentral.go                            |  4 +-
 src/runtime/mem_bsd.go                             |  2 +-
 src/runtime/mem_linux.go                           |  2 +-
 src/runtime/memclr_arm.s                           |  2 +-
 src/runtime/memmove_386.s                          |  6 +-
 src/runtime/memmove_amd64.s                        |  6 +-
 src/runtime/memmove_arm.s                          |  2 +-
 src/runtime/memmove_nacl_amd64p32.s                |  2 +-
 src/runtime/memmove_plan9_386.s                    |  6 +-
 src/runtime/memmove_plan9_amd64.s                  |  6 +-
 src/runtime/mfinal.go                              |  8 +-
 src/runtime/mfixalloc.go                           |  2 +-
 src/runtime/mgc.go                                 |  4 +-
 src/runtime/mgcmark.go                             |  2 +-
 src/runtime/mgcwork.go                             |  6 +-
 src/runtime/mheap.go                               | 10 +--
 src/runtime/mmap.go                                |  2 +-
 src/runtime/mprof.go                               |  4 +-
 src/runtime/msan.go                                |  6 +-
 src/runtime/msize.go                               |  4 +-
 src/runtime/mstats.go                              |  4 +-
 src/runtime/netpoll_kqueue.go                      |  2 +-
 src/runtime/os1_darwin.go                          |  4 +-
 src/runtime/os1_dragonfly.go                       |  6 +-
 src/runtime/os1_freebsd.go                         |  2 +-
 src/runtime/os1_linux.go                           |  6 +-
 src/runtime/os1_nacl.go                            |  2 +-
 src/runtime/os1_netbsd.go                          | 10 +--
 src/runtime/os1_openbsd.go                         |  2 +-
 src/runtime/os1_plan9.go                           |  2 +-
 src/runtime/os3_solaris.go                         |  8 +-
 src/runtime/os_nacl.go                             |  2 +-
 src/runtime/os_windows.go                          |  2 +-
 src/runtime/panic.go                               | 18 ++---
 src/runtime/pprof/pprof.go                         | 18 ++---
 src/runtime/proc.go                                | 26 +++----
 src/runtime/rt0_linux_arm.s                        |  2 +-
 src/runtime/runtime1.go                            |  2 +-
 src/runtime/runtime2.go                            |  2 +-
 src/runtime/runtime_test.go                        |  4 +-
 src/runtime/select.go                              |  6 +-
 src/runtime/signal1_unix.go                        | 10 +--
 src/runtime/signal2_unix.go                        |  4 +-
 src/runtime/signal_386.go                          |  2 +-
 src/runtime/signal_amd64x.go                       |  2 +-
 src/runtime/signal_windows.go                      |  2 +-
 src/runtime/sigqueue.go                            |  6 +-
 src/runtime/sigqueue_plan9.go                      |  2 +-
 src/runtime/sqrt.go                                |  2 +-
 src/runtime/stack.go                               |  8 +-
 src/runtime/stack_test.go                          |  4 +-
 src/runtime/string_test.go                         |  2 +-
 src/runtime/symtab.go                              |  4 +-
 src/runtime/sys_darwin_386.s                       |  2 +-
 src/runtime/sys_dragonfly_amd64.s                  |  6 +-
 src/runtime/sys_linux_386.s                        |  2 +-
 src/runtime/sys_linux_amd64.s                      |  2 +-
 src/runtime/sys_linux_arm.s                        |  2 +-
 src/runtime/sys_netbsd_386.s                       |  2 +-
 src/runtime/sys_netbsd_amd64.s                     |  2 +-
 src/runtime/sys_openbsd_386.s                      |  2 +-
 src/runtime/sys_openbsd_amd64.s                    |  2 +-
 src/runtime/sys_x86.go                             |  8 +-
 src/runtime/textflag.h                             |  6 +-
 src/runtime/time.go                                |  2 +-
 src/runtime/traceback.go                           |  4 +-
 src/runtime/vlop_386.s                             |  2 +-
 src/runtime/vlop_arm.s                             |  2 +-
 src/runtime/vlrt.go                                |  2 +-
 src/sort/search.go                                 |  8 +-
 src/sort/search_test.go                            |  2 +-
 src/sort/sort.go                                   |  4 +-
 src/strconv/atof_test.go                           |  2 +-
 src/strconv/atoi.go                                |  6 +-
 src/strconv/atoi_test.go                           |  2 +-
 src/strconv/fp_test.go                             |  2 +-
 src/strconv/ftoa.go                                |  2 +-
 src/strconv/quote.go                               |  2 +-
 src/strings/compare_test.go                        |  2 +-
 src/strings/strings.go                             | 10 +--
 src/strings/strings_test.go                        |  2 +-
 src/sync/atomic/asm_arm.s                          |  2 +-
 src/sync/atomic/atomic_test.go                     |  2 +-
 src/sync/cond.go                                   |  6 +-
 src/sync/mutex.go                                  |  4 +-
 src/sync/once.go                                   |  4 +-
 src/sync/rwmutex.go                                |  4 +-
 src/sync/waitgroup.go                              |  4 +-
 src/syscall/exec_bsd.go                            |  2 +-
 src/syscall/exec_linux.go                          |  2 +-
 src/syscall/exec_plan9.go                          | 24 +++---
 src/syscall/exec_solaris.go                        |  2 +-
 src/syscall/exec_unix.go                           | 22 +++---
 src/syscall/syscall.go                             |  6 +-
 src/syscall/syscall_bsd.go                         |  2 +-
 src/syscall/syscall_darwin.go                      |  4 +-
 src/syscall/syscall_darwin_386.go                  |  2 +-
 src/syscall/syscall_darwin_amd64.go                |  2 +-
 src/syscall/syscall_darwin_arm.go                  |  2 +-
 src/syscall/syscall_darwin_arm64.go                |  2 +-
 src/syscall/syscall_dragonfly.go                   |  4 +-
 src/syscall/syscall_freebsd.go                     |  4 +-
 src/syscall/syscall_linux.go                       |  8 +-
 src/syscall/syscall_linux_386.go                   |  4 +-
 src/syscall/syscall_nacl.go                        |  2 +-
 src/syscall/syscall_solaris.go                     |  4 +-
 src/syscall/syscall_unix.go                        |  2 +-
 src/syscall/unzip_nacl.go                          |  2 +-
 src/testing/allocs.go                              |  2 +-
 src/testing/benchmark.go                           |  6 +-
 src/testing/iotest/reader.go                       |  2 +-
 src/testing/quick/quick.go                         |  4 +-
 src/testing/testing.go                             | 10 +--
 src/text/scanner/scanner.go                        |  4 +-
 src/text/template/exec.go                          |  4 +-
 src/text/template/funcs.go                         |  2 +-
 src/text/template/parse/parse.go                   |  2 +-
 src/text/template/parse/parse_test.go              |  2 +-
 src/time/format.go                                 |  6 +-
 src/time/sleep.go                                  |  2 +-
 src/time/tick.go                                   |  2 +-
 src/time/tick_test.go                              |  2 +-
 src/time/time.go                                   | 34 ++++----
 src/time/time_test.go                              |  2 +-
 src/time/zoneinfo_read.go                          |  4 +-
 src/time/zoneinfo_test.go                          |  2 +-
 src/unicode/graphic.go                             |  2 +-
 src/unicode/letter.go                              | 14 ++--
 src/unicode/maketables.go                          |  4 +-
 src/unicode/utf8/utf8.go                           |  6 +-
 src/unsafe/unsafe.go                               |  8 +-
 536 files changed, 1732 insertions(+), 1732 deletions(-)

diff --git a/src/archive/tar/writer.go b/src/archive/tar/writer.go
index 042638175c..600ee4be09 100644
--- a/src/archive/tar/writer.go
+++ b/src/archive/tar/writer.go
@@ -316,8 +316,8 @@ func (tw *Writer) writePAXHeader(hdr *Header, paxHeaders map[string]string) erro
 	// succeed, and seems harmless enough.
 	ext.ModTime = hdr.ModTime
 	// The spec asks that we namespace our pseudo files
-	// with the current pid.  However, this results in differing outputs
-	// for identical inputs.  As such, the constant 0 is now used instead.
+	// with the current pid. However, this results in differing outputs
+	// for identical inputs. As such, the constant 0 is now used instead.
 	// golang.org/issue/12358
 	dir, file := path.Split(hdr.Name)
 	fullName := path.Join(dir, "PaxHeaders.0", file)
diff --git a/src/bufio/bufio.go b/src/bufio/bufio.go
index 2925946c97..7cf395c6e6 100644
--- a/src/bufio/bufio.go
+++ b/src/bufio/bufio.go
@@ -234,7 +234,7 @@ func (b *Reader) ReadByte() (byte, error) {
 	return c, nil
 }
 
-// UnreadByte unreads the last byte.  Only the most recently read byte can be unread.
+// UnreadByte unreads the last byte. Only the most recently read byte can be unread.
 func (b *Reader) UnreadByte() error {
 	if b.lastByte < 0 || b.r == 0 && b.w > 0 {
 		return ErrInvalidUnreadByte
@@ -273,7 +273,7 @@ func (b *Reader) ReadRune() (r rune, size int, err error) {
 	return r, size, nil
 }
 
-// UnreadRune unreads the last rune.  If the most recent read operation on
+// UnreadRune unreads the last rune. If the most recent read operation on
 // the buffer was not a ReadRune, UnreadRune returns an error.  (In this
 // regard it is stricter than UnreadByte, which will unread the last byte
 // from any read operation.)
diff --git a/src/bytes/buffer.go b/src/bytes/buffer.go
index 1aed86924d..992a9585e7 100644
--- a/src/bytes/buffer.go
+++ b/src/bytes/buffer.go
@@ -44,7 +44,7 @@ var ErrTooLarge = errors.New("bytes.Buffer: too large")
 func (b *Buffer) Bytes() []byte { return b.buf[b.off:] }
 
 // String returns the contents of the unread portion of the buffer
-// as a string.  If the Buffer is a nil pointer, it returns "<nil>".
+// as a string. If the Buffer is a nil pointer, it returns "<nil>".
 func (b *Buffer) String() string {
 	if b == nil {
 		// Special case, useful in debugging.
@@ -145,7 +145,7 @@ func (b *Buffer) WriteString(s string) (n int, err error) {
 }
 
 // MinRead is the minimum slice size passed to a Read call by
-// Buffer.ReadFrom.  As long as the Buffer has at least MinRead bytes beyond
+// Buffer.ReadFrom. As long as the Buffer has at least MinRead bytes beyond
 // what is required to hold the contents of r, ReadFrom will not grow the
 // underlying buffer.
 const MinRead = 512
@@ -252,7 +252,7 @@ func (b *Buffer) WriteRune(r rune) (n int, err error) {
 }
 
 // Read reads the next len(p) bytes from the buffer or until the buffer
-// is drained.  The return value n is the number of bytes read.  If the
+// is drained. The return value n is the number of bytes read. If the
 // buffer has no data to return, err is io.EOF (unless len(p) is zero);
 // otherwise it is nil.
 func (b *Buffer) Read(p []byte) (n int, err error) {
@@ -347,7 +347,7 @@ func (b *Buffer) UnreadRune() error {
 }
 
 // UnreadByte unreads the last byte returned by the most recent
-// read operation.  If write has happened since the last read, UnreadByte
+// read operation. If write has happened since the last read, UnreadByte
 // returns an error.
 func (b *Buffer) UnreadByte() error {
 	if b.lastRead != opReadRune && b.lastRead != opRead {
@@ -400,7 +400,7 @@ func (b *Buffer) ReadString(delim byte) (line string, err error) {
 }
 
 // NewBuffer creates and initializes a new Buffer using buf as its initial
-// contents.  It is intended to prepare a Buffer to read existing data.  It
+// contents. It is intended to prepare a Buffer to read existing data. It
 // can also be used to size the internal buffer for writing. To do that,
 // buf should have the desired capacity but a length of zero.
 //
diff --git a/src/bytes/bytes.go b/src/bytes/bytes.go
index b86824087e..8a4409cb6b 100644
--- a/src/bytes/bytes.go
+++ b/src/bytes/bytes.go
@@ -164,7 +164,7 @@ func IndexRune(s []byte, r rune) int {
 
 // IndexAny interprets s as a sequence of UTF-8-encoded Unicode code points.
 // It returns the byte index of the first occurrence in s of any of the Unicode
-// code points in chars.  It returns -1 if chars is empty or if there is no code
+// code points in chars. It returns -1 if chars is empty or if there is no code
 // point in common.
 func IndexAny(s []byte, chars string) int {
 	if len(chars) > 0 {
@@ -188,8 +188,8 @@ func IndexAny(s []byte, chars string) int {
 }
 
 // LastIndexAny interprets s as a sequence of UTF-8-encoded Unicode code
-// points.  It returns the byte index of the last occurrence in s of any of
-// the Unicode code points in chars.  It returns -1 if chars is empty or if
+// points. It returns the byte index of the last occurrence in s of any of
+// the Unicode code points in chars. It returns -1 if chars is empty or if
 // there is no code point in common.
 func LastIndexAny(s []byte, chars string) int {
 	if len(chars) > 0 {
@@ -276,7 +276,7 @@ func Fields(s []byte) [][]byte {
 
 // FieldsFunc interprets s as a sequence of UTF-8-encoded Unicode code points.
 // It splits the slice s at each run of code points c satisfying f(c) and
-// returns a slice of subslices of s.  If all code points in s satisfy f(c), or
+// returns a slice of subslices of s. If all code points in s satisfy f(c), or
 // len(s) == 0, an empty slice is returned.
 // FieldsFunc makes no guarantees about the order in which it calls f(c).
 // If f does not return consistent results for a given c, FieldsFunc may crash.
@@ -352,12 +352,12 @@ func HasSuffix(s, suffix []byte) bool {
 
 // Map returns a copy of the byte slice s with all its characters modified
 // according to the mapping function. If mapping returns a negative value, the character is
-// dropped from the string with no replacement.  The characters in s and the
+// dropped from the string with no replacement. The characters in s and the
 // output are interpreted as UTF-8-encoded Unicode code points.
 func Map(mapping func(r rune) rune, s []byte) []byte {
 	// In the worst case, the slice can grow when mapped, making
-	// things unpleasant.  But it's so rare we barge in assuming it's
-	// fine.  It could also shrink but that falls out naturally.
+	// things unpleasant. But it's so rare we barge in assuming it's
+	// fine. It could also shrink but that falls out naturally.
 	maxbytes := len(s) // length of b
 	nbytes := 0        // number of bytes encoded in b
 	b := make([]byte, maxbytes)
@@ -697,7 +697,7 @@ func EqualFold(s, t []byte) bool {
 			return false
 		}
 
-		// General case.  SimpleFold(x) returns the next equivalent rune > x
+		// General case. SimpleFold(x) returns the next equivalent rune > x
 		// or wraps around to smaller values.
 		r := unicode.SimpleFold(sr)
 		for r != sr && r < tr {
@@ -709,6 +709,6 @@ func EqualFold(s, t []byte) bool {
 		return false
 	}
 
-	// One string is empty.  Are both?
+	// One string is empty. Are both?
 	return len(s) == len(t)
 }
diff --git a/src/bytes/bytes_test.go b/src/bytes/bytes_test.go
index a412dc89b9..f158098f9b 100644
--- a/src/bytes/bytes_test.go
+++ b/src/bytes/bytes_test.go
@@ -113,7 +113,7 @@ func TestEqualExhaustive(t *testing.T) {
 	}
 }
 
-// make sure Equal returns false for minimally different strings.  The data
+// make sure Equal returns false for minimally different strings. The data
 // is all zeros except for a single one in one location.
 func TestNotEqual(t *testing.T) {
 	var size = 128
@@ -797,7 +797,7 @@ func TestMap(t *testing.T) {
 	// Run a couple of awful growth/shrinkage tests
 	a := tenRunes('a')
 
-	// 1.  Grow.  This triggers two reallocations in Map.
+	// 1.  Grow. This triggers two reallocations in Map.
 	maxRune := func(r rune) rune { return unicode.MaxRune }
 	m := Map(maxRune, []byte(a))
 	expect := tenRunes(unicode.MaxRune)
diff --git a/src/bytes/compare_test.go b/src/bytes/compare_test.go
index f2d81d5310..35088a1b2e 100644
--- a/src/bytes/compare_test.go
+++ b/src/bytes/compare_test.go
@@ -62,7 +62,7 @@ func TestCompareBytes(t *testing.T) {
 	a := make([]byte, n+1)
 	b := make([]byte, n+1)
 	for len := 0; len < 128; len++ {
-		// randomish but deterministic data.  No 0 or 255.
+		// randomish but deterministic data. No 0 or 255.
 		for i := 0; i < len; i++ {
 			a[i] = byte(1 + 31*i%254)
 			b[i] = byte(1 + 31*i%254)
diff --git a/src/bytes/equal_test.go b/src/bytes/equal_test.go
index 1bf19a74b8..9fdead8a60 100644
--- a/src/bytes/equal_test.go
+++ b/src/bytes/equal_test.go
@@ -14,11 +14,11 @@ import (
 )
 
 // This file tests the situation where memeq is checking
-// data very near to a page boundary.  We want to make sure
+// data very near to a page boundary. We want to make sure
 // equal does not read across the boundary and cause a page
 // fault where it shouldn't.
 
-// This test runs only on linux.  The code being tested is
+// This test runs only on linux. The code being tested is
 // not OS-specific, so it does not need to be tested on all
 // operating systems.
 
diff --git a/src/cmd/cgo/ast.go b/src/cmd/cgo/ast.go
index ef72c4f66a..2859d59750 100644
--- a/src/cmd/cgo/ast.go
+++ b/src/cmd/cgo/ast.go
@@ -40,7 +40,7 @@ func sourceLine(n ast.Node) int {
 }
 
 // ReadGo populates f with information learned from reading the
-// Go source file with the given file name.  It gathers the C preamble
+// Go source file with the given file name. It gathers the C preamble
 // attached to the import "C" comment, a list of references to C.xxx,
 // a list of exported functions, and the actual AST, to be rewritten and
 // printed.
diff --git a/src/cmd/cgo/gcc.go b/src/cmd/cgo/gcc.go
index 8d8349a635..b2835a495f 100644
--- a/src/cmd/cgo/gcc.go
+++ b/src/cmd/cgo/gcc.go
@@ -83,7 +83,7 @@ func (f *File) DiscardCgoDirectives() {
 	f.Preamble = strings.Join(linesOut, "\n")
 }
 
-// addToFlag appends args to flag.  All flags are later written out onto the
+// addToFlag appends args to flag. All flags are later written out onto the
 // _cgo_flags file for the build system to use.
 func (p *Package) addToFlag(flag string, args []string) {
 	p.CgoFlags[flag] = append(p.CgoFlags[flag], args...)
@@ -99,7 +99,7 @@ func (p *Package) addToFlag(flag string, args []string) {
 // Single quotes and double quotes are recognized to prevent splitting within the
 // quoted region, and are removed from the resulting substrings. If a quote in s
 // isn't closed err will be set and r will have the unclosed argument as the
-// last element.  The backslash is used for escaping.
+// last element. The backslash is used for escaping.
 //
 // For example, the following string:
 //
@@ -236,7 +236,7 @@ func (p *Package) guessKinds(f *File) []*Name {
 			if isConst {
 				n.Kind = "const"
 				// Turn decimal into hex, just for consistency
-				// with enum-derived constants.  Otherwise
+				// with enum-derived constants. Otherwise
 				// in the cgo -godefs output half the constants
 				// are in hex and half are in whatever the #define used.
 				i, err := strconv.ParseInt(n.Define, 0, 64)
@@ -385,7 +385,7 @@ func (p *Package) guessKinds(f *File) []*Name {
 	if nerrors > 0 {
 		// Check if compiling the preamble by itself causes any errors,
 		// because the messages we've printed out so far aren't helpful
-		// to users debugging preamble mistakes.  See issue 8442.
+		// to users debugging preamble mistakes. See issue 8442.
 		preambleErrors := p.gccErrors([]byte(f.Preamble))
 		if len(preambleErrors) > 0 {
 			error_(token.NoPos, "\n%s errors for preamble:\n%s", p.gccBaseCmd()[0], preambleErrors)
@@ -403,7 +403,7 @@ func (p *Package) guessKinds(f *File) []*Name {
 // being referred to as C.xxx.
 func (p *Package) loadDWARF(f *File, names []*Name) {
 	// Extract the types from the DWARF section of an object
-	// from a well-formed C program.  Gcc only generates DWARF info
+	// from a well-formed C program. Gcc only generates DWARF info
 	// for symbols in the object file, so it is not enough to print the
 	// preamble and hope the symbols we care about will be there.
 	// Instead, emit
@@ -421,7 +421,7 @@ func (p *Package) loadDWARF(f *File, names []*Name) {
 	}
 
 	// Apple's LLVM-based gcc does not include the enumeration
-	// names and values in its DWARF debug output.  In case we're
+	// names and values in its DWARF debug output. In case we're
 	// using such a gcc, create a data block initialized with the values.
 	// We can read them out of the object file.
 	fmt.Fprintf(&b, "long long __cgodebug_data[] = {\n")
@@ -594,7 +594,7 @@ func (p *Package) rewriteCalls(f *File) {
 	}
 }
 
-// rewriteCall rewrites one call to add pointer checks.  We replace
+// rewriteCall rewrites one call to add pointer checks. We replace
 // each pointer argument x with _cgoCheckPointer(x).(T).
 func (p *Package) rewriteCall(f *File, call *ast.CallExpr, name *Name) {
 	for i, param := range name.FuncType.Params {
@@ -642,13 +642,13 @@ func (p *Package) rewriteCall(f *File, call *ast.CallExpr, name *Name) {
 		} else {
 			// In order for the type assertion to succeed,
 			// we need it to match the actual type of the
-			// argument.  The only type we have is the
-			// type of the function parameter.  We know
+			// argument. The only type we have is the
+			// type of the function parameter. We know
 			// that the argument type must be assignable
 			// to the function parameter type, or the code
 			// would not compile, but there is nothing
 			// requiring that the types be exactly the
-			// same.  Add a type conversion to the
+			// same. Add a type conversion to the
 			// argument so that the type assertion will
 			// succeed.
 			c.Args[0] = &ast.CallExpr{
@@ -675,7 +675,7 @@ func (p *Package) needsPointerCheck(f *File, t ast.Expr) bool {
 	return p.hasPointer(f, t, true)
 }
 
-// hasPointer is used by needsPointerCheck.  If top is true it returns
+// hasPointer is used by needsPointerCheck. If top is true it returns
 // whether t is or contains a pointer that might point to a pointer.
 // If top is false it returns whether t is or contains a pointer.
 // f may be nil.
@@ -732,7 +732,7 @@ func (p *Package) hasPointer(f *File, t ast.Expr, top bool) bool {
 		if goTypes[t.Name] != nil {
 			return false
 		}
-		// We can't figure out the type.  Conservative
+		// We can't figure out the type. Conservative
 		// approach is to assume it has a pointer.
 		return true
 	case *ast.SelectorExpr:
@@ -750,7 +750,7 @@ func (p *Package) hasPointer(f *File, t ast.Expr, top bool) bool {
 		if name != nil && name.Kind == "type" && name.Type != nil && name.Type.Go != nil {
 			return p.hasPointer(f, name.Type.Go, top)
 		}
-		// We can't figure out the type.  Conservative
+		// We can't figure out the type. Conservative
 		// approach is to assume it has a pointer.
 		return true
 	default:
@@ -760,14 +760,14 @@ func (p *Package) hasPointer(f *File, t ast.Expr, top bool) bool {
 }
 
 // checkAddrArgs tries to add arguments to the call of
-// _cgoCheckPointer when the argument is an address expression.  We
+// _cgoCheckPointer when the argument is an address expression. We
 // pass true to mean that the argument is an address operation of
 // something other than a slice index, which means that it's only
 // necessary to check the specific element pointed to, not the entire
-// object.  This is for &s.f, where f is a field in a struct.  We can
+// object. This is for &s.f, where f is a field in a struct. We can
 // pass a slice or array, meaning that we should check the entire
 // slice or array but need not check any other part of the object.
-// This is for &s.a[i], where we need to check all of a.  However, we
+// This is for &s.a[i], where we need to check all of a. However, we
 // only pass the slice or array if we can refer to it without side
 // effects.
 func (p *Package) checkAddrArgs(f *File, args []ast.Expr, x ast.Expr) []ast.Expr {
@@ -786,7 +786,7 @@ func (p *Package) checkAddrArgs(f *File, args []ast.Expr, x ast.Expr) []ast.Expr
 	index, ok := u.X.(*ast.IndexExpr)
 	if !ok {
 		// This is the address of something that is not an
-		// index expression.  We only need to examine the
+		// index expression. We only need to examine the
 		// single value to which it points.
 		// TODO: what if true is shadowed?
 		return append(args, ast.NewIdent("true"))
@@ -853,10 +853,10 @@ func (p *Package) isType(t ast.Expr) bool {
 	return false
 }
 
-// unsafeCheckPointerName is given the Go version of a C type.  If the
+// unsafeCheckPointerName is given the Go version of a C type. If the
 // type uses unsafe.Pointer, we arrange to build a version of
-// _cgoCheckPointer that returns that type.  This avoids using a type
-// assertion to unsafe.Pointer in our copy of user code.  We return
+// _cgoCheckPointer that returns that type. This avoids using a type
+// assertion to unsafe.Pointer in our copy of user code. We return
 // the name of the _cgoCheckPointer function we are going to build, or
 // the empty string if the type does not use unsafe.Pointer.
 func (p *Package) unsafeCheckPointerName(t ast.Expr) string {
@@ -906,7 +906,7 @@ func (p *Package) unsafeCheckPointerNameIndex(i int) string {
 
 // rewriteRef rewrites all the C.xxx references in f.AST to refer to the
 // Go equivalents, now that we have figured out the meaning of all
-// the xxx.  In *godefs mode, rewriteRef replaces the names
+// the xxx. In *godefs mode, rewriteRef replaces the names
 // with full definitions instead of mangled names.
 func (p *Package) rewriteRef(f *File) {
 	// Keep a list of all the functions, to remove the ones
@@ -929,7 +929,7 @@ func (p *Package) rewriteRef(f *File) {
 
 	// Now that we have all the name types filled in,
 	// scan through the Refs to identify the ones that
-	// are trying to do a ,err call.  Also check that
+	// are trying to do a ,err call. Also check that
 	// functions are only used in calls.
 	for _, r := range f.Ref {
 		if r.Name.Kind == "const" && r.Name.Const == "" {
@@ -987,7 +987,7 @@ func (p *Package) rewriteRef(f *File) {
 					f.Name[fpName] = name
 				}
 				r.Name = name
-				// Rewrite into call to _Cgo_ptr to prevent assignments.  The _Cgo_ptr
+				// Rewrite into call to _Cgo_ptr to prevent assignments. The _Cgo_ptr
 				// function is defined in out.go and simply returns its argument. See
 				// issue 7757.
 				expr = &ast.CallExpr{
@@ -1155,7 +1155,7 @@ func (p *Package) gccDebug(stdin []byte) (*dwarf.Data, binary.ByteOrder, []byte)
 			for i := range f.Symtab.Syms {
 				s := &f.Symtab.Syms[i]
 				if isDebugData(s.Name) {
-					// Found it.  Now find data section.
+					// Found it. Now find data section.
 					if i := int(s.Sect) - 1; 0 <= i && i < len(f.Sections) {
 						sect := f.Sections[i]
 						if sect.Addr <= s.Value && s.Value < sect.Addr+sect.Size {
@@ -1182,7 +1182,7 @@ func (p *Package) gccDebug(stdin []byte) (*dwarf.Data, binary.ByteOrder, []byte)
 			for i := range symtab {
 				s := &symtab[i]
 				if isDebugData(s.Name) {
-					// Found it.  Now find data section.
+					// Found it. Now find data section.
 					if i := int(s.Section); 0 <= i && i < len(f.Sections) {
 						sect := f.Sections[i]
 						if sect.Addr <= s.Value && s.Value < sect.Addr+sect.Size {
@@ -1235,7 +1235,7 @@ func (p *Package) gccDefines(stdin []byte) string {
 }
 
 // gccErrors runs gcc over the C program stdin and returns
-// the errors that gcc prints.  That is, this function expects
+// the errors that gcc prints. That is, this function expects
 // gcc to fail.
 func (p *Package) gccErrors(stdin []byte) string {
 	// TODO(rsc): require failure
@@ -1375,7 +1375,7 @@ var dwarfToName = map[string]string{
 
 const signedDelta = 64
 
-// String returns the current type representation.  Format arguments
+// String returns the current type representation. Format arguments
 // are assembled within this method so that any changes in mutable
 // values are taken into account.
 func (tr *TypeRepr) String() string {
@@ -1815,7 +1815,7 @@ func (c *typeConv) FuncArg(dtype dwarf.Type, pos token.Pos) *Type {
 		}
 	case *dwarf.TypedefType:
 		// C has much more relaxed rules than Go for
-		// implicit type conversions.  When the parameter
+		// implicit type conversions. When the parameter
 		// is type T defined as *X, simulate a little of the
 		// laxness of C by making the argument *X instead of T.
 		if ptr, ok := base(dt.Type).(*dwarf.PtrType); ok {
@@ -1831,7 +1831,7 @@ func (c *typeConv) FuncArg(dtype dwarf.Type, pos token.Pos) *Type {
 			}
 
 			// Remember the C spelling, in case the struct
-			// has __attribute__((unavailable)) on it.  See issue 2888.
+			// has __attribute__((unavailable)) on it. See issue 2888.
 			t.Typedef = dt.Name
 		}
 	}
@@ -1846,7 +1846,7 @@ func (c *typeConv) FuncType(dtype *dwarf.FuncType, pos token.Pos) *FuncType {
 	for i, f := range dtype.ParamType {
 		// gcc's DWARF generator outputs a single DotDotDotType parameter for
 		// function pointers that specify no parameters (e.g. void
-		// (*__cgo_0)()).  Treat this special case as void.  This case is
+		// (*__cgo_0)()).  Treat this special case as void. This case is
 		// invalid according to ISO C anyway (i.e. void (*__cgo_1)(...) is not
 		// legal).
 		if _, ok := f.(*dwarf.DotDotDotType); ok && i == 0 {
@@ -1917,8 +1917,8 @@ func (c *typeConv) Struct(dt *dwarf.StructType, pos token.Pos) (expr *ast.Struct
 	off := int64(0)
 
 	// Rename struct fields that happen to be named Go keywords into
-	// _{keyword}.  Create a map from C ident -> Go ident.  The Go ident will
-	// be mangled.  Any existing identifier that already has the same name on
+	// _{keyword}.  Create a map from C ident -> Go ident. The Go ident will
+	// be mangled. Any existing identifier that already has the same name on
 	// the C-side will cause the Go-mangled version to be prefixed with _.
 	// (e.g. in a struct with fields '_type' and 'type', the latter would be
 	// rendered as '__type' in Go).
@@ -1958,7 +1958,7 @@ func (c *typeConv) Struct(dt *dwarf.StructType, pos token.Pos) (expr *ast.Struct
 
 		// In godefs mode, if this field is a C11
 		// anonymous union then treat the first field in the
-		// union as the field in the struct.  This handles
+		// union as the field in the struct. This handles
 		// cases like the glibc <sys/resource.h> file; see
 		// issue 6677.
 		if *godefs {
@@ -2082,7 +2082,7 @@ func godefsFields(fld []*ast.Field) {
 }
 
 // fieldPrefix returns the prefix that should be removed from all the
-// field names when generating the C or Go code.  For generated
+// field names when generating the C or Go code. For generated
 // C, we leave the names as is (tv_sec, tv_usec), since that's what
 // people are used to seeing in C.  For generated Go code, such as
 // package syscall's data structures, we drop a common prefix
@@ -2092,7 +2092,7 @@ func fieldPrefix(fld []*ast.Field) string {
 	for _, f := range fld {
 		for _, n := range f.Names {
 			// Ignore field names that don't have the prefix we're
-			// looking for.  It is common in C headers to have fields
+			// looking for. It is common in C headers to have fields
 			// named, say, _pad in an otherwise prefixed header.
 			// If the struct has 3 fields tv_sec, tv_usec, _pad1, then we
 			// still want to remove the tv_ prefix.
diff --git a/src/cmd/cgo/main.go b/src/cmd/cgo/main.go
index a8a87c5980..5e863549d6 100644
--- a/src/cmd/cgo/main.go
+++ b/src/cmd/cgo/main.go
@@ -190,9 +190,9 @@ func main() {
 
 	if *dynobj != "" {
 		// cgo -dynimport is essentially a separate helper command
-		// built into the cgo binary.  It scans a gcc-produced executable
+		// built into the cgo binary. It scans a gcc-produced executable
 		// and dumps information about the imported symbols and the
-		// imported libraries.  The 'go build' rules for cgo prepare an
+		// imported libraries. The 'go build' rules for cgo prepare an
 		// appropriate executable and then use its import information
 		// instead of needing to make the linkers duplicate all the
 		// specialized knowledge gcc has about where to look for imported
diff --git a/src/cmd/cgo/out.go b/src/cmd/cgo/out.go
index bd41f8800c..40c76b52e4 100644
--- a/src/cmd/cgo/out.go
+++ b/src/cmd/cgo/out.go
@@ -55,7 +55,7 @@ func (p *Package) writeDefs() {
 		fmt.Fprintf(fm, "char* _cgo_topofstack(void) { return (char*)0; }\n")
 	} else {
 		// If we're not importing runtime/cgo, we *are* runtime/cgo,
-		// which provides these functions.  We just need a prototype.
+		// which provides these functions. We just need a prototype.
 		fmt.Fprintf(fm, "void crosscall2(void(*fn)(void*, int), void *a, int c);\n")
 		fmt.Fprintf(fm, "void _cgo_wait_runtime_init_done();\n")
 	}
@@ -592,7 +592,7 @@ func (p *Package) writeOutputFunc(fgcc *os.File, n *Name) {
 		// the Go equivalents had good type params.
 		// However, our version of the type omits the magic
 		// words const and volatile, which can provoke
-		// C compiler warnings.  Silence them by casting
+		// C compiler warnings. Silence them by casting
 		// all pointers to void*.  (Eventually that will produce
 		// other warnings.)
 		if c := t.C.String(); c[len(c)-1] == '*' {
@@ -616,8 +616,8 @@ func (p *Package) writeOutputFunc(fgcc *os.File, n *Name) {
 	fmt.Fprintf(fgcc, "\n")
 }
 
-// Write out a wrapper for a function when using gccgo.  This is a
-// simple wrapper that just calls the real function.  We only need a
+// Write out a wrapper for a function when using gccgo. This is a
+// simple wrapper that just calls the real function. We only need a
 // wrapper to support static functions in the prologue--without a
 // wrapper, we can't refer to the function, since the reference is in
 // a different file.
@@ -707,7 +707,7 @@ func (p *Package) writeExports(fgo2, fm, fgcc, fgcch io.Writer) {
 		fn := exp.Func
 
 		// Construct a gcc struct matching the gc argument and
-		// result frame.  The gcc struct will be compiled with
+		// result frame. The gcc struct will be compiled with
 		// __attribute__((packed)) so all padding must be accounted
 		// for explicitly.
 		ctype := "struct {\n"
diff --git a/src/cmd/cgo/util.go b/src/cmd/cgo/util.go
index dd8116e926..4f5c48864e 100644
--- a/src/cmd/cgo/util.go
+++ b/src/cmd/cgo/util.go
@@ -84,7 +84,7 @@ func lineno(pos token.Pos) string {
 // Die with an error message.
 func fatalf(msg string, args ...interface{}) {
 	// If we've already printed other errors, they might have
-	// caused the fatal condition.  Assume they're enough.
+	// caused the fatal condition. Assume they're enough.
 	if nerrors == 0 {
 		fmt.Fprintf(os.Stderr, msg+"\n", args...)
 	}
diff --git a/src/cmd/compile/internal/amd64/peep.go b/src/cmd/compile/internal/amd64/peep.go
index 810214504f..b24c92cf69 100644
--- a/src/cmd/compile/internal/amd64/peep.go
+++ b/src/cmd/compile/internal/amd64/peep.go
@@ -252,14 +252,14 @@ loop1:
 	// MOVLQZX removal.
 	// The MOVLQZX exists to avoid being confused for a
 	// MOVL that is just copying 32-bit data around during
-	// copyprop.  Now that copyprop is done, remov MOVLQZX R1, R2
+	// copyprop. Now that copyprop is done, remov MOVLQZX R1, R2
 	// if it is dominated by an earlier ADDL/MOVL/etc into R1 that
 	// will have already cleared the high bits.
 	//
 	// MOVSD removal.
 	// We never use packed registers, so a MOVSD between registers
 	// can be replaced by MOVAPD, which moves the pair of float64s
-	// instead of just the lower one.  We only use the lower one, but
+	// instead of just the lower one. We only use the lower one, but
 	// the processor can do better if we do moves using both.
 	for r := (*gc.Flow)(g.Start); r != nil; r = r.Link {
 		p = r.Prog
diff --git a/src/cmd/compile/internal/arm/cgen64.go b/src/cmd/compile/internal/arm/cgen64.go
index d46d5a8660..9cda561069 100644
--- a/src/cmd/compile/internal/arm/cgen64.go
+++ b/src/cmd/compile/internal/arm/cgen64.go
@@ -126,7 +126,7 @@ func cgen64(n *gc.Node, res *gc.Node) {
 	var ah gc.Node
 	gc.Regalloc(&ah, hi1.Type, nil)
 
-	// Do op.  Leave result in ah:al.
+	// Do op. Leave result in ah:al.
 	switch n.Op {
 	default:
 		gc.Fatalf("cgen64: not implemented: %v\n", n)
diff --git a/src/cmd/compile/internal/arm64/cgen.go b/src/cmd/compile/internal/arm64/cgen.go
index a7f1c18b55..e8a5c14761 100644
--- a/src/cmd/compile/internal/arm64/cgen.go
+++ b/src/cmd/compile/internal/arm64/cgen.go
@@ -129,7 +129,7 @@ func blockcopy(n, res *gc.Node, osrc, odst, w int64) {
 		// TODO(austin): Instead of generating ADD $-8,R8; ADD
 		// $-8,R7; n*(MOVDU 8(R8),R9; MOVDU R9,8(R7);) just
 		// generate the offsets directly and eliminate the
-		// ADDs.  That will produce shorter, more
+		// ADDs. That will produce shorter, more
 		// pipeline-able code.
 		var p *obj.Prog
 		for ; c > 0; c-- {
diff --git a/src/cmd/compile/internal/big/arith_test.go b/src/cmd/compile/internal/big/arith_test.go
index f46a494f17..ea8e82d0b6 100644
--- a/src/cmd/compile/internal/big/arith_test.go
+++ b/src/cmd/compile/internal/big/arith_test.go
@@ -442,7 +442,7 @@ func benchmarkBitLenN(b *testing.B, nbits uint) {
 	}
 }
 
-// Individual bitLen tests.  Numbers chosen to examine both sides
+// Individual bitLen tests. Numbers chosen to examine both sides
 // of powers-of-two boundaries.
 func BenchmarkBitLen0(b *testing.B)  { benchmarkBitLenN(b, 0) }
 func BenchmarkBitLen1(b *testing.B)  { benchmarkBitLenN(b, 1) }
diff --git a/src/cmd/compile/internal/big/nat.go b/src/cmd/compile/internal/big/nat.go
index 79cf6e07f7..7668b6481b 100644
--- a/src/cmd/compile/internal/big/nat.go
+++ b/src/cmd/compile/internal/big/nat.go
@@ -647,7 +647,7 @@ func trailingZeroBits(x Word) uint {
 	// x & -x leaves only the right-most bit set in the word. Let k be the
 	// index of that bit. Since only a single bit is set, the value is two
 	// to the power of k. Multiplying by a power of two is equivalent to
-	// left shifting, in this case by k bits.  The de Bruijn constant is
+	// left shifting, in this case by k bits. The de Bruijn constant is
 	// such that all six bit, consecutive substrings are distinct.
 	// Therefore, if we have a left shifted version of this constant we can
 	// find by how many bits it was shifted by looking at which six bit
@@ -1018,7 +1018,7 @@ func (z nat) expNNWindowed(x, y, m nat) nat {
 		for j := 0; j < _W; j += n {
 			if i != len(y)-1 || j != 0 {
 				// Unrolled loop for significant performance
-				// gain.  Use go test -bench=".*" in crypto/rsa
+				// gain. Use go test -bench=".*" in crypto/rsa
 				// to check performance before making changes.
 				zz = zz.mul(z, z)
 				zz, z = z, zz
diff --git a/src/cmd/compile/internal/big/rat.go b/src/cmd/compile/internal/big/rat.go
index 2cd9ed0938..56ce33d882 100644
--- a/src/cmd/compile/internal/big/rat.go
+++ b/src/cmd/compile/internal/big/rat.go
@@ -63,7 +63,7 @@ func (z *Rat) SetFloat64(f float64) *Rat {
 
 // quotToFloat32 returns the non-negative float32 value
 // nearest to the quotient a/b, using round-to-even in
-// halfway cases.  It does not mutate its arguments.
+// halfway cases. It does not mutate its arguments.
 // Preconditions: b is non-zero; a and b have no common factors.
 func quotToFloat32(a, b nat) (f float32, exact bool) {
 	const (
@@ -161,7 +161,7 @@ func quotToFloat32(a, b nat) (f float32, exact bool) {
 
 // quotToFloat64 returns the non-negative float64 value
 // nearest to the quotient a/b, using round-to-even in
-// halfway cases.  It does not mutate its arguments.
+// halfway cases. It does not mutate its arguments.
 // Preconditions: b is non-zero; a and b have no common factors.
 func quotToFloat64(a, b nat) (f float64, exact bool) {
 	const (
diff --git a/src/cmd/compile/internal/big/ratconv_test.go b/src/cmd/compile/internal/big/ratconv_test.go
index da2fdab4ca..17bda47637 100644
--- a/src/cmd/compile/internal/big/ratconv_test.go
+++ b/src/cmd/compile/internal/big/ratconv_test.go
@@ -137,7 +137,7 @@ func TestFloatString(t *testing.T) {
 	}
 }
 
-// Test inputs to Rat.SetString.  The prefix "long:" causes the test
+// Test inputs to Rat.SetString. The prefix "long:" causes the test
 // to be skipped in --test.short mode.  (The threshold is about 500us.)
 var float64inputs = []string{
 	// Constants plundered from strconv/testfp.txt.
diff --git a/src/cmd/compile/internal/gc/alg.go b/src/cmd/compile/internal/gc/alg.go
index a0ff4890c1..36cd1198a0 100644
--- a/src/cmd/compile/internal/gc/alg.go
+++ b/src/cmd/compile/internal/gc/alg.go
@@ -406,7 +406,7 @@ func geneq(sym *Sym, t *Type) {
 
 		// An array of pure memory would be handled by the
 		// standard memequal, so the element type must not be
-		// pure memory.  Even if we unrolled the range loop,
+		// pure memory. Even if we unrolled the range loop,
 		// each iteration would be a function call, so don't bother
 		// unrolling.
 		nrange := Nod(ORANGE, nil, Nod(OIND, np, nil))
diff --git a/src/cmd/compile/internal/gc/align.go b/src/cmd/compile/internal/gc/align.go
index 812a8cb150..f0122aff97 100644
--- a/src/cmd/compile/internal/gc/align.go
+++ b/src/cmd/compile/internal/gc/align.go
@@ -86,9 +86,9 @@ func widstruct(errtype *Type, t *Type, o int64, flag int) int64 {
 	}
 
 	// For nonzero-sized structs which end in a zero-sized thing, we add
-	// an extra byte of padding to the type.  This padding ensures that
+	// an extra byte of padding to the type. This padding ensures that
 	// taking the address of the zero-sized thing can't manufacture a
-	// pointer to the next object in the heap.  See issue 9401.
+	// pointer to the next object in the heap. See issue 9401.
 	if flag == 1 && o > starto && o == lastzero {
 		o++
 	}
diff --git a/src/cmd/compile/internal/gc/bimport.go b/src/cmd/compile/internal/gc/bimport.go
index 5c2ffa6888..8ec6300245 100644
--- a/src/cmd/compile/internal/gc/bimport.go
+++ b/src/cmd/compile/internal/gc/bimport.go
@@ -248,7 +248,7 @@ func (p *importer) typ() *Type {
 			// (comment from go.y)
 			// inl.C's inlnode in on a dotmeth node expects to find the inlineable body as
 			// (dotmeth's type).Nname.Inl, and dotmeth's type has been pulled
-			// out by typecheck's lookdot as this $$.ttype.  So by providing
+			// out by typecheck's lookdot as this $$.ttype. So by providing
 			// this back link here we avoid special casing there.
 			n.Type.Nname = n
 
diff --git a/src/cmd/compile/internal/gc/builtin/runtime.go b/src/cmd/compile/internal/gc/builtin/runtime.go
index 0fe6242e74..4286f361b8 100644
--- a/src/cmd/compile/internal/gc/builtin/runtime.go
+++ b/src/cmd/compile/internal/gc/builtin/runtime.go
@@ -3,7 +3,7 @@
 // license that can be found in the LICENSE file.
 
 // NOTE: If you change this file you must run "go generate"
-// to update builtin.go.  This is not done automatically
+// to update builtin.go. This is not done automatically
 // to avoid depending on having a working compiler binary.
 
 // +build ignore
diff --git a/src/cmd/compile/internal/gc/builtin/unsafe.go b/src/cmd/compile/internal/gc/builtin/unsafe.go
index a7fc8aa53e..6e25db65cc 100644
--- a/src/cmd/compile/internal/gc/builtin/unsafe.go
+++ b/src/cmd/compile/internal/gc/builtin/unsafe.go
@@ -3,7 +3,7 @@
 // license that can be found in the LICENSE file.
 
 // NOTE: If you change this file you must run "go generate"
-// to update builtin.go.  This is not done automatically
+// to update builtin.go. This is not done automatically
 // to avoid depending on having a working compiler binary.
 
 // +build ignore
diff --git a/src/cmd/compile/internal/gc/cgen.go b/src/cmd/compile/internal/gc/cgen.go
index 74f61129c2..df30100b10 100644
--- a/src/cmd/compile/internal/gc/cgen.go
+++ b/src/cmd/compile/internal/gc/cgen.go
@@ -2296,7 +2296,7 @@ func sgen_wb(n *Node, ns *Node, w int64, wb bool) {
 
 	if osrc != -1000 && odst != -1000 && (osrc == 1000 || odst == 1000) || wb && osrc != -1000 {
 		// osrc and odst both on stack, and at least one is in
-		// an unknown position.  Could generate code to test
+		// an unknown position. Could generate code to test
 		// for forward/backward copy, but instead just copy
 		// to a temporary location first.
 		//
diff --git a/src/cmd/compile/internal/gc/dcl.go b/src/cmd/compile/internal/gc/dcl.go
index 52ada12f86..f68cffb33e 100644
--- a/src/cmd/compile/internal/gc/dcl.go
+++ b/src/cmd/compile/internal/gc/dcl.go
@@ -167,7 +167,7 @@ func declare(n *Node, ctxt Class) {
 	n.Lineno = int32(parserline())
 	s := n.Sym
 
-	// kludgy: typecheckok means we're past parsing.  Eg genwrapper may declare out of package names later.
+	// kludgy: typecheckok means we're past parsing. Eg genwrapper may declare out of package names later.
 	if importpkg == nil && !typecheckok && s.Pkg != localpkg {
 		Yyerror("cannot declare name %v", s)
 	}
@@ -1021,7 +1021,7 @@ func embedded(s *Sym, pkg *Pkg) *Node {
 		CenterDot = 0xB7
 	)
 	// Names sometimes have disambiguation junk
-	// appended after a center dot.  Discard it when
+	// appended after a center dot. Discard it when
 	// making the name for the embedded struct field.
 	name := s.Name
 
diff --git a/src/cmd/compile/internal/gc/esc.go b/src/cmd/compile/internal/gc/esc.go
index e26cbb372b..7ba377b200 100644
--- a/src/cmd/compile/internal/gc/esc.go
+++ b/src/cmd/compile/internal/gc/esc.go
@@ -15,7 +15,7 @@ import (
 // or single non-recursive functions, bottom up.
 //
 // Finding these sets is finding strongly connected components
-// in the static call graph.  The algorithm for doing that is taken
+// in the static call graph. The algorithm for doing that is taken
 // from Sedgewick, Algorithms, Second Edition, p. 482, with two
 // adaptations.
 //
@@ -168,7 +168,7 @@ func (v *bottomUpVisitor) visitcode(n *Node, min uint32) uint32 {
 //
 // First escfunc, esc and escassign recurse over the ast of each
 // function to dig out flow(dst,src) edges between any
-// pointer-containing nodes and store them in dst->escflowsrc.  For
+// pointer-containing nodes and store them in dst->escflowsrc. For
 // variables assigned to a variable in an outer scope or used as a
 // return value, they store a flow(theSink, src) edge to a fake node
 // 'the Sink'.  For variables referenced in closures, an edge
@@ -180,7 +180,7 @@ func (v *bottomUpVisitor) visitcode(n *Node, min uint32) uint32 {
 // parameters it can reach as leaking.
 //
 // If a value's address is taken but the address does not escape,
-// then the value can stay on the stack.  If the value new(T) does
+// then the value can stay on the stack. If the value new(T) does
 // not escape, then new(T) can be rewritten into a stack allocation.
 // The same is true of slice literals.
 //
@@ -340,7 +340,7 @@ func (e *EscState) track(n *Node) {
 }
 
 // Escape constants are numbered in order of increasing "escapiness"
-// to help make inferences be monotonic.  With the exception of
+// to help make inferences be monotonic. With the exception of
 // EscNever which is sticky, eX < eY means that eY is more exposed
 // than eX, and hence replaces it in a conservative analysis.
 const (
@@ -378,7 +378,7 @@ func escMax(e, etype uint16) uint16 {
 }
 
 // For each input parameter to a function, the escapeReturnEncoding describes
-// how the parameter may leak to the function's outputs.  This is currently the
+// how the parameter may leak to the function's outputs. This is currently the
 // "level" of the leak where level is 0 or larger (negative level means stored into
 // something whose address is returned -- but that implies stored into the heap,
 // hence EscHeap, which means that the details are not currently relevant. )
@@ -524,7 +524,7 @@ func escfunc(e *EscState, func_ *Node) {
 
 // Mark labels that have no backjumps to them as not increasing e->loopdepth.
 // Walk hasn't generated (goto|label)->left->sym->label yet, so we'll cheat
-// and set it to one of the following two.  Then in esc we'll clear it again.
+// and set it to one of the following two. Then in esc we'll clear it again.
 var looping Label
 
 var nonlooping Label
@@ -1099,7 +1099,7 @@ func escassign(e *EscState, dst *Node, src *Node) {
 
 		// Might be pointer arithmetic, in which case
 	// the operands flow into the result.
-	// TODO(rsc): Decide what the story is here.  This is unsettling.
+	// TODO(rsc): Decide what the story is here. This is unsettling.
 	case OADD,
 		OSUB,
 		OOR,
@@ -1128,7 +1128,7 @@ func escassign(e *EscState, dst *Node, src *Node) {
 //  flow are 000, 001, 010, 011  and EEEE is computed Esc bits.
 // Note width of xxx depends on value of constant
 // bitsPerOutputInTag -- expect 2 or 3, so in practice the
-// tag cache array is 64 or 128 long.  Some entries will
+// tag cache array is 64 or 128 long. Some entries will
 // never be populated.
 var tags [1 << (bitsPerOutputInTag + EscReturnBits)]string
 
@@ -1290,7 +1290,7 @@ func (e *EscState) addDereference(n *Node) *Node {
 	if Istype(t, Tptr) {
 		// This should model our own sloppy use of OIND to encode
 		// decreasing levels of indirection; i.e., "indirecting" an array
-		// might yield the type of an element.  To be enhanced...
+		// might yield the type of an element. To be enhanced...
 		t = t.Type
 	}
 	ind.Type = t
@@ -1419,7 +1419,7 @@ func esccall(e *EscState, n *Node, up *Node) {
 			fmt.Printf("%v::esccall:: %v in recursive group\n", Ctxt.Line(int(lineno)), Nconv(n, obj.FmtShort))
 		}
 
-		// function in same mutually recursive group.  Incorporate into flow graph.
+		// function in same mutually recursive group. Incorporate into flow graph.
 		//		print("esc local fn: %N\n", fn->ntype);
 		if fn.Name.Defn.Esc == EscFuncUnknown || nE.Escretval != nil {
 			Fatalf("graph inconsistency")
@@ -1469,7 +1469,7 @@ func esccall(e *EscState, n *Node, up *Node) {
 		return
 	}
 
-	// Imported or completely analyzed function.  Use the escape tags.
+	// Imported or completely analyzed function. Use the escape tags.
 	if nE.Escretval != nil {
 		Fatalf("esc already decorated call %v\n", Nconv(n, obj.FmtSign))
 	}
diff --git a/src/cmd/compile/internal/gc/fmt.go b/src/cmd/compile/internal/gc/fmt.go
index 8864b57f5d..cf9ffc1fd1 100644
--- a/src/cmd/compile/internal/gc/fmt.go
+++ b/src/cmd/compile/internal/gc/fmt.go
@@ -69,7 +69,7 @@ var fmtbody bool
 // E.g. for %S:	%+S %#S %-S	print an identifier properly qualified for debug/export/internal mode.
 //
 // The mode flags  +, - and # are sticky, meaning they persist through
-// recursions of %N, %T and %S, but not the h and l flags.  The u flag is
+// recursions of %N, %T and %S, but not the h and l flags. The u flag is
 // sticky only on %T recursions and only used in %-/Sym mode.
 
 //
@@ -796,7 +796,7 @@ func stmtfmt(n *Node) string {
 
 	// some statements allow for an init, but at most one,
 	// but we may have an arbitrary number added, eg by typecheck
-	// and inlining.  If it doesn't fit the syntax, emit an enclosing
+	// and inlining. If it doesn't fit the syntax, emit an enclosing
 	// block starting with the init statements.
 
 	// if we can just say "for" n->ninit; ... then do so
diff --git a/src/cmd/compile/internal/gc/global_test.go b/src/cmd/compile/internal/gc/global_test.go
index bd1391d9ad..54d3ed1b7d 100644
--- a/src/cmd/compile/internal/gc/global_test.go
+++ b/src/cmd/compile/internal/gc/global_test.go
@@ -17,7 +17,7 @@ import (
 )
 
 // Make sure "hello world" does not link in all the
-// fmt.scanf routines.  See issue 6853.
+// fmt.scanf routines. See issue 6853.
 func TestScanfRemoval(t *testing.T) {
 	testenv.MustHaveGoBuild(t)
 
@@ -64,7 +64,7 @@ func main() {
 	}
 }
 
-// Make sure -S prints assembly code.  See issue 14515.
+// Make sure -S prints assembly code. See issue 14515.
 func TestDashS(t *testing.T) {
 	testenv.MustHaveGoBuild(t)
 
@@ -99,7 +99,7 @@ func main() {
 
 	patterns := []string{
 		// It is hard to look for actual instructions in an
-		// arch-independent way.  So we'll just look for
+		// arch-independent way. So we'll just look for
 		// pseudo-ops that are arch-independent.
 		"\tTEXT\t",
 		"\tFUNCDATA\t",
diff --git a/src/cmd/compile/internal/gc/inl.go b/src/cmd/compile/internal/gc/inl.go
index 84065658ae..5b8a533666 100644
--- a/src/cmd/compile/internal/gc/inl.go
+++ b/src/cmd/compile/internal/gc/inl.go
@@ -43,7 +43,7 @@ var inlretlabel *Node // target of the goto substituted in place of a return
 
 var inlretvars *NodeList // temp out variables
 
-// Get the function's package.  For ordinary functions it's on the ->sym, but for imported methods
+// Get the function's package. For ordinary functions it's on the ->sym, but for imported methods
 // the ->sym can be re-used in the local package, so peel it off the receiver's type.
 func fnpkg(fn *Node) *Pkg {
 	if fn.Type.Thistuple != 0 {
@@ -63,7 +63,7 @@ func fnpkg(fn *Node) *Pkg {
 	return fn.Sym.Pkg
 }
 
-// Lazy typechecking of imported bodies.  For local functions, caninl will set ->typecheck
+// Lazy typechecking of imported bodies. For local functions, caninl will set ->typecheck
 // because they're a copy of an already checked body.
 func typecheckinl(fn *Node) {
 	lno := int(setlineno(fn))
@@ -300,7 +300,7 @@ func inlcopyslice(ll []*Node) []*Node {
 }
 
 // Inlcalls/nodelist/node walks fn's statements and expressions and substitutes any
-// calls made to inlineable functions.  This is the external entry point.
+// calls made to inlineable functions. This is the external entry point.
 func inlcalls(fn *Node) {
 	savefn := Curfn
 	Curfn = fn
@@ -358,7 +358,7 @@ func inlnodeslice(l []*Node) {
 }
 
 // inlnode recurses over the tree to find inlineable calls, which will
-// be turned into OINLCALLs by mkinlcall.  When the recursion comes
+// be turned into OINLCALLs by mkinlcall. When the recursion comes
 // back up will examine left, right, list, rlist, ninit, ntest, nincr,
 // nbody and nelse and use one of the 4 inlconv/glue functions above
 // to turn the OINLCALL into an expression, a statement, or patch it
@@ -881,7 +881,7 @@ func inlvar(var_ *Node) *Node {
 
 	// This may no longer be necessary now that we run escape analysis
 	// after wrapper generation, but for 1.5 this is conservatively left
-	// unchanged.  See bugs 11053 and 9537.
+	// unchanged. See bugs 11053 and 9537.
 	if var_.Esc == EscHeap {
 		addrescapes(n)
 	}
diff --git a/src/cmd/compile/internal/gc/order.go b/src/cmd/compile/internal/gc/order.go
index 7f59e2cafc..88a19f9015 100644
--- a/src/cmd/compile/internal/gc/order.go
+++ b/src/cmd/compile/internal/gc/order.go
@@ -10,7 +10,7 @@ import (
 )
 
 // Rewrite tree to use separate statements to enforce
-// order of evaluation.  Makes walk easier, because it
+// order of evaluation. Makes walk easier, because it
 // can (after this runs) reorder at will within an expression.
 //
 // Rewrite x op= y into x = x op y.
diff --git a/src/cmd/compile/internal/gc/parser.go b/src/cmd/compile/internal/gc/parser.go
index 983ffa356f..a485fa181a 100644
--- a/src/cmd/compile/internal/gc/parser.go
+++ b/src/cmd/compile/internal/gc/parser.go
@@ -2011,7 +2011,7 @@ func (p *parser) hidden_fndcl() *Node {
 
 		// inl.C's inlnode in on a dotmeth node expects to find the inlineable body as
 		// (dotmeth's type).Nname.Inl, and dotmeth's type has been pulled
-		// out by typecheck's lookdot as this $$.ttype.  So by providing
+		// out by typecheck's lookdot as this $$.ttype. So by providing
 		// this back link here we avoid special casing there.
 		ss.Type.Nname = ss
 		return ss
diff --git a/src/cmd/compile/internal/gc/plive.go b/src/cmd/compile/internal/gc/plive.go
index 78872c1af2..384261b05e 100644
--- a/src/cmd/compile/internal/gc/plive.go
+++ b/src/cmd/compile/internal/gc/plive.go
@@ -29,7 +29,7 @@ const (
 
 // An ordinary basic block.
 //
-// Instructions are threaded together in a doubly-linked list.  To iterate in
+// Instructions are threaded together in a doubly-linked list. To iterate in
 // program order follow the link pointer from the first node and stop after the
 // last node has been visited
 //
@@ -122,7 +122,7 @@ func addedge(from *BasicBlock, to *BasicBlock) {
 }
 
 // Inserts prev before curr in the instruction
-// stream.  Any control flow, such as branches or fall-throughs, that target the
+// stream. Any control flow, such as branches or fall-throughs, that target the
 // existing instruction are adjusted to target the new instruction.
 func splicebefore(lv *Liveness, bb *BasicBlock, prev *obj.Prog, curr *obj.Prog) {
 	// There may be other instructions pointing at curr,
@@ -181,9 +181,9 @@ func printblock(bb *BasicBlock) {
 	}
 }
 
-// Iterates over a basic block applying a callback to each instruction.  There
-// are two criteria for termination.  If the end of basic block is reached a
-// value of zero is returned.  If the callback returns a non-zero value, the
+// Iterates over a basic block applying a callback to each instruction. There
+// are two criteria for termination. If the end of basic block is reached a
+// value of zero is returned. If the callback returns a non-zero value, the
 // iteration is stopped and the value of the callback is returned.
 func blockany(bb *BasicBlock, f func(*obj.Prog) bool) bool {
 	for p := bb.last; p != nil; p = p.Opt.(*obj.Prog) {
@@ -244,7 +244,7 @@ func getvariables(fn *Node) []*Node {
 	return result
 }
 
-// A pretty printer for control flow graphs.  Takes an array of BasicBlock*s.
+// A pretty printer for control flow graphs. Takes an array of BasicBlock*s.
 func printcfg(cfg []*BasicBlock) {
 	for _, bb := range cfg {
 		printblock(bb)
@@ -252,7 +252,7 @@ func printcfg(cfg []*BasicBlock) {
 }
 
 // Assigns a reverse post order number to each connected basic block using the
-// standard algorithm.  Unconnected blocks will not be affected.
+// standard algorithm. Unconnected blocks will not be affected.
 func reversepostorder(root *BasicBlock, rpo *int32) {
 	root.mark = VISITED
 	for _, bb := range root.succ {
@@ -272,7 +272,7 @@ func (x blockrpocmp) Len() int           { return len(x) }
 func (x blockrpocmp) Swap(i, j int)      { x[i], x[j] = x[j], x[i] }
 func (x blockrpocmp) Less(i, j int) bool { return x[i].rpo < x[j].rpo }
 
-// A pattern matcher for call instructions.  Returns true when the instruction
+// A pattern matcher for call instructions. Returns true when the instruction
 // is a call to a specific package qualified function name.
 func iscall(prog *obj.Prog, name *obj.LSym) bool {
 	if prog == nil {
@@ -340,8 +340,8 @@ func isdeferreturn(prog *obj.Prog) bool {
 }
 
 // Walk backwards from a runtime·selectgo call up to its immediately dominating
-// runtime·newselect call.  Any successor nodes of communication clause nodes
-// are implicit successors of the runtime·selectgo call node.  The goal of this
+// runtime·newselect call. Any successor nodes of communication clause nodes
+// are implicit successors of the runtime·selectgo call node. The goal of this
 // analysis is to add these missing edges to complete the control flow graph.
 func addselectgosucc(selectgo *BasicBlock) {
 	var succ *BasicBlock
@@ -379,7 +379,7 @@ func addselectgosucc(selectgo *BasicBlock) {
 	}
 }
 
-// The entry point for the missing selectgo control flow algorithm.  Takes an
+// The entry point for the missing selectgo control flow algorithm. Takes an
 // array of BasicBlock*s containing selectgo calls.
 func fixselectgo(selectgo []*BasicBlock) {
 	for _, bb := range selectgo {
@@ -387,15 +387,15 @@ func fixselectgo(selectgo []*BasicBlock) {
 	}
 }
 
-// Constructs a control flow graph from a sequence of instructions.  This
+// Constructs a control flow graph from a sequence of instructions. This
 // procedure is complicated by various sources of implicit control flow that are
-// not accounted for using the standard cfg construction algorithm.  Returns an
+// not accounted for using the standard cfg construction algorithm. Returns an
 // array of BasicBlock*s in control flow graph form (basic blocks ordered by
 // their RPO number).
 func newcfg(firstp *obj.Prog) []*BasicBlock {
-	// Reset the opt field of each prog to nil.  In the first and second
+	// Reset the opt field of each prog to nil. In the first and second
 	// passes, instructions that are labels temporarily use the opt field to
-	// point to their basic block.  In the third pass, the opt field reset
+	// point to their basic block. In the third pass, the opt field reset
 	// to point to the predecessor of an instruction in its basic block.
 	for p := firstp; p != nil; p = p.Link {
 		p.Opt = nil
@@ -436,7 +436,7 @@ func newcfg(firstp *obj.Prog) []*BasicBlock {
 	}
 
 	// Loop through all basic blocks maximally growing the list of
-	// contained instructions until a label is reached.  Add edges
+	// contained instructions until a label is reached. Add edges
 	// for branches and fall-through instructions.
 	for _, bb := range cfg {
 		for p := bb.last; p != nil && p.As != obj.AEND; p = p.Link {
@@ -448,7 +448,7 @@ func newcfg(firstp *obj.Prog) []*BasicBlock {
 			// Stop before an unreachable RET, to avoid creating
 			// unreachable control flow nodes.
 			if p.Link != nil && p.Link.As == obj.ARET && p.Link.Mode == 1 {
-				// TODO: remove after SSA is done.  SSA does not
+				// TODO: remove after SSA is done. SSA does not
 				// generate any unreachable RET instructions.
 				break
 			}
@@ -472,7 +472,7 @@ func newcfg(firstp *obj.Prog) []*BasicBlock {
 	}
 
 	// Add back links so the instructions in a basic block can be traversed
-	// backward.  This is the final state of the instruction opt field.
+	// backward. This is the final state of the instruction opt field.
 	for _, bb := range cfg {
 		p := bb.first
 		var prev *obj.Prog
@@ -500,13 +500,13 @@ func newcfg(firstp *obj.Prog) []*BasicBlock {
 	rpo := int32(len(cfg))
 	reversepostorder(bb, &rpo)
 
-	// Sort the basic blocks by their depth first number.  The
+	// Sort the basic blocks by their depth first number. The
 	// array is now a depth-first spanning tree with the first
 	// node being the root.
 	sort.Sort(blockrpocmp(cfg))
 
 	// Unreachable control flow nodes are indicated by a -1 in the rpo
-	// field.  If we see these nodes something must have gone wrong in an
+	// field. If we see these nodes something must have gone wrong in an
 	// upstream compilation phase.
 	bb = cfg[0]
 	if bb.rpo == -1 {
@@ -536,7 +536,7 @@ func isfunny(n *Node) bool {
 }
 
 // Computes the effects of an instruction on a set of
-// variables.  The vars argument is an array of Node*s.
+// variables. The vars argument is an array of Node*s.
 //
 // The output vectors give bits for variables:
 //	uevar - used by this instruction
@@ -555,8 +555,8 @@ func progeffects(prog *obj.Prog, vars []*Node, uevar Bvec, varkill Bvec, avarini
 	bvresetall(avarinit)
 
 	if prog.As == obj.ARET {
-		// Return instructions implicitly read all the arguments.  For
-		// the sake of correctness, out arguments must be read.  For the
+		// Return instructions implicitly read all the arguments. For
+		// the sake of correctness, out arguments must be read. For the
 		// sake of backtrace quality, we read in arguments as well.
 		//
 		// A return instruction with a p->to is a tail return, which brings
@@ -676,7 +676,7 @@ Next:
 }
 
 // Constructs a new liveness structure used to hold the global state of the
-// liveness computation.  The cfg argument is an array of BasicBlock*s and the
+// liveness computation. The cfg argument is an array of BasicBlock*s and the
 // vars argument is an array of Node*s.
 func newliveness(fn *Node, ptxt *obj.Prog, cfg []*BasicBlock, vars []*Node) *Liveness {
 	result := new(Liveness)
@@ -721,7 +721,7 @@ func printeffects(p *obj.Prog, uevar Bvec, varkill Bvec, avarinit Bvec) {
 	fmt.Printf("\n")
 }
 
-// Pretty print a variable node.  Uses Pascal like conventions for pointers and
+// Pretty print a variable node. Uses Pascal like conventions for pointers and
 // addresses to avoid confusing the C like conventions used in the node variable
 // names.
 func printnode(node *Node) {
@@ -736,7 +736,7 @@ func printnode(node *Node) {
 	fmt.Printf(" %v%s%s", node, p, a)
 }
 
-// Pretty print a list of variables.  The vars argument is an array of Node*s.
+// Pretty print a list of variables. The vars argument is an array of Node*s.
 func printvars(name string, bv Bvec, vars []*Node) {
 	fmt.Printf("%s:", name)
 	for i, node := range vars {
@@ -850,10 +850,10 @@ func checkprog(fn *Node, p *obj.Prog) {
 	}
 }
 
-// Check instruction invariants.  We assume that the nodes corresponding to the
+// Check instruction invariants. We assume that the nodes corresponding to the
 // sources and destinations of memory operations will be declared in the
-// function.  This is not strictly true, as is the case for the so-called funny
-// nodes and there are special cases to skip over that stuff.  The analysis will
+// function. This is not strictly true, as is the case for the so-called funny
+// nodes and there are special cases to skip over that stuff. The analysis will
 // fail if this invariant blindly changes.
 func checkptxt(fn *Node, firstp *obj.Prog) {
 	if debuglive == 0 {
@@ -931,7 +931,7 @@ func onebitwalktype1(t *Type, xoffset *int64, bv Bvec) {
 
 	case TARRAY:
 		// The value of t->bound is -1 for slices types and >=0 for
-		// for fixed array types.  All other values are invalid.
+		// for fixed array types. All other values are invalid.
 		if t.Bound < -1 {
 			Fatalf("onebitwalktype1: invalid bound, %v", t)
 		}
@@ -975,8 +975,8 @@ func argswords() int32 {
 	return int32(Curfn.Type.Argwid / int64(Widthptr))
 }
 
-// Generates live pointer value maps for arguments and local variables.  The
-// this argument and the in arguments are always assumed live.  The vars
+// Generates live pointer value maps for arguments and local variables. The
+// this argument and the in arguments are always assumed live. The vars
 // argument is an array of Node*s.
 func onebitlivepointermap(lv *Liveness, liveout Bvec, vars []*Node, args Bvec, locals Bvec) {
 	var node *Node
@@ -1046,7 +1046,7 @@ func issafepoint(prog *obj.Prog) bool {
 	return prog.As == obj.ATEXT || prog.As == obj.ACALL
 }
 
-// Initializes the sets for solving the live variables.  Visits all the
+// Initializes the sets for solving the live variables. Visits all the
 // instructions in each basic block to summarizes the information at each basic
 // block
 func livenessprologue(lv *Liveness) {
@@ -1140,15 +1140,15 @@ func livenesssolve(lv *Liveness) {
 		}
 	}
 
-	// Iterate through the blocks in reverse round-robin fashion.  A work
-	// queue might be slightly faster.  As is, the number of iterations is
+	// Iterate through the blocks in reverse round-robin fashion. A work
+	// queue might be slightly faster. As is, the number of iterations is
 	// so low that it hardly seems to be worth the complexity.
 	change = 1
 
 	for change != 0 {
 		change = 0
 
-		// Walk blocks in the general direction of propagation.  This
+		// Walk blocks in the general direction of propagation. This
 		// improves convergence.
 		for i := len(lv.cfg) - 1; i >= 0; i-- {
 			bb := lv.cfg[i]
@@ -1714,10 +1714,10 @@ func livenessprintdebug(lv *Liveness) {
 	fmt.Printf("\n")
 }
 
-// Dumps an array of bitmaps to a symbol as a sequence of uint32 values.  The
-// first word dumped is the total number of bitmaps.  The second word is the
-// length of the bitmaps.  All bitmaps are assumed to be of equal length.  The
-// words that are followed are the raw bitmap words.  The arr argument is an
+// Dumps an array of bitmaps to a symbol as a sequence of uint32 values. The
+// first word dumped is the total number of bitmaps. The second word is the
+// length of the bitmaps. All bitmaps are assumed to be of equal length. The
+// words that are followed are the raw bitmap words. The arr argument is an
 // array of Node*s.
 func onebitwritesymbol(arr []Bvec, sym *Sym) {
 	var i int
@@ -1759,7 +1759,7 @@ func printprog(p *obj.Prog) {
 	}
 }
 
-// Entry pointer for liveness analysis.  Constructs a complete CFG, solves for
+// Entry pointer for liveness analysis. Constructs a complete CFG, solves for
 // the liveness of pointer variables in the function, and emits a runtime data
 // structure read by the garbage collector.
 func liveness(fn *Node, firstp *obj.Prog, argssym *Sym, livesym *Sym) {
diff --git a/src/cmd/compile/internal/gc/reflect.go b/src/cmd/compile/internal/gc/reflect.go
index 43c6db0a00..3cf480efd4 100644
--- a/src/cmd/compile/internal/gc/reflect.go
+++ b/src/cmd/compile/internal/gc/reflect.go
@@ -42,7 +42,7 @@ func siglt(a, b *Sig) bool {
 }
 
 // Builds a type representing a Bucket structure for
-// the given map type.  This type is not visible to users -
+// the given map type. This type is not visible to users -
 // we include only enough information to generate a correct GC
 // program for it.
 // Make sure this stays in sync with ../../../../runtime/hashmap.go!
@@ -421,7 +421,7 @@ func dimportpath(p *Pkg) {
 	}
 
 	// If we are compiling the runtime package, there are two runtime packages around
-	// -- localpkg and Runtimepkg.  We don't want to produce import path symbols for
+	// -- localpkg and Runtimepkg. We don't want to produce import path symbols for
 	// both of them, so just produce one for localpkg.
 	if myimportpath == "runtime" && p == Runtimepkg {
 		return
diff --git a/src/cmd/compile/internal/gc/ssa.go b/src/cmd/compile/internal/gc/ssa.go
index 03ff17eb01..1033cd9226 100644
--- a/src/cmd/compile/internal/gc/ssa.go
+++ b/src/cmd/compile/internal/gc/ssa.go
@@ -245,7 +245,7 @@ type state struct {
 	// *Node is the unique identifier (an ONAME Node) for the variable.
 	vars map[*Node]*ssa.Value
 
-	// all defined variables at the end of each block.  Indexed by block ID.
+	// all defined variables at the end of each block. Indexed by block ID.
 	defvars []map[*Node]*ssa.Value
 
 	// addresses of PPARAM and PPARAMOUT variables.
@@ -254,12 +254,12 @@ type state struct {
 	// symbols for PEXTERN, PAUTO and PPARAMOUT variables so they can be reused.
 	varsyms map[*Node]interface{}
 
-	// starting values.  Memory, stack pointer, and globals pointer
+	// starting values. Memory, stack pointer, and globals pointer
 	startmem *ssa.Value
 	sp       *ssa.Value
 	sb       *ssa.Value
 
-	// line number stack.  The current line number is top of stack
+	// line number stack. The current line number is top of stack
 	line []int32
 
 	// list of panic calls by function name and line number.
@@ -269,7 +269,7 @@ type state struct {
 	// list of FwdRef values.
 	fwdRefs []*ssa.Value
 
-	// list of PPARAMOUT (return) variables.  Does not include PPARAM|PHEAP vars.
+	// list of PPARAMOUT (return) variables. Does not include PPARAM|PHEAP vars.
 	returns []*Node
 
 	cgoUnsafeArgs bool
@@ -339,7 +339,7 @@ func (s *state) startBlock(b *ssa.Block) {
 }
 
 // endBlock marks the end of generating code for the current block.
-// Returns the (former) current block.  Returns nil if there is no current
+// Returns the (former) current block. Returns nil if there is no current
 // block, i.e. if no code flows to the current execution point.
 func (s *state) endBlock() *ssa.Block {
 	b := s.curBlock
@@ -540,7 +540,7 @@ func (s *state) stmt(n *Node) {
 			b.Kind = ssa.BlockExit
 			b.Control = m
 			// TODO: never rewrite OPANIC to OCALLFUNC in the
-			// first place.  Need to wait until all backends
+			// first place. Need to wait until all backends
 			// go through SSA.
 		}
 	case ODEFER:
@@ -653,8 +653,8 @@ func (s *state) stmt(n *Node) {
 		rhs := n.Right
 		if rhs != nil && (rhs.Op == OSTRUCTLIT || rhs.Op == OARRAYLIT) {
 			// All literals with nonzero fields have already been
-			// rewritten during walk.  Any that remain are just T{}
-			// or equivalents.  Use the zero value.
+			// rewritten during walk. Any that remain are just T{}
+			// or equivalents. Use the zero value.
 			if !iszero(rhs) {
 				Fatalf("literal with nonzero value in SSA: %v", rhs)
 			}
@@ -891,10 +891,10 @@ func (s *state) stmt(n *Node) {
 }
 
 // exit processes any code that needs to be generated just before returning.
-// It returns a BlockRet block that ends the control flow.  Its control value
+// It returns a BlockRet block that ends the control flow. Its control value
 // will be set to the final memory state.
 func (s *state) exit() *ssa.Block {
-	// Run exit code.  Typically, this code copies heap-allocated PPARAMOUT
+	// Run exit code. Typically, this code copies heap-allocated PPARAMOUT
 	// variables back to the stack.
 	s.stmts(s.exitCode)
 
@@ -906,7 +906,7 @@ func (s *state) exit() *ssa.Block {
 		s.vars[&memVar] = s.newValue1A(ssa.OpVarDef, ssa.TypeMem, n, s.mem())
 		s.vars[&memVar] = s.newValue3I(ssa.OpStore, ssa.TypeMem, n.Type.Size(), addr, val, s.mem())
 		// TODO: if val is ever spilled, we'd like to use the
-		// PPARAMOUT slot for spilling it.  That won't happen
+		// PPARAMOUT slot for spilling it. That won't happen
 		// currently.
 	}
 
@@ -1382,7 +1382,7 @@ func (s *state) expr(n *Node) *ssa.Value {
 		case CTBOOL:
 			v := s.constBool(n.Val().U.(bool))
 			// For some reason the frontend gets the line numbers of
-			// CTBOOL literals totally wrong.  Fix it here by grabbing
+			// CTBOOL literals totally wrong. Fix it here by grabbing
 			// the line number of the enclosing AST node.
 			if len(s.line) >= 2 {
 				v.Line = s.line[len(s.line)-2]
@@ -1925,7 +1925,7 @@ func (s *state) expr(n *Node) *ssa.Value {
 		tab := s.expr(n.Left)
 		data := s.expr(n.Right)
 		// The frontend allows putting things like struct{*byte} in
-		// the data portion of an eface.  But we don't want struct{*byte}
+		// the data portion of an eface. But we don't want struct{*byte}
 		// as a register type because (among other reasons) the liveness
 		// analysis is confused by the "fat" variables that result from
 		// such types being spilled.
@@ -2037,7 +2037,7 @@ func (s *state) expr(n *Node) *ssa.Value {
 		r := s.rtcall(growslice, true, []*Type{pt, Types[TINT], Types[TINT]}, taddr, p, l, c, nl)
 
 		s.vars[&ptrVar] = r[0]
-		// Note: we don't need to read r[1], the result's length.  It will be nl.
+		// Note: we don't need to read r[1], the result's length. It will be nl.
 		// (or maybe we should, we just have to spill/restore nl otherwise?)
 		s.vars[&capVar] = r[2]
 		b = s.endBlock()
@@ -2106,7 +2106,7 @@ func (s *state) condBranch(cond *Node, yes, no *ssa.Block, likely int8) {
 		return
 		// Note: if likely==1, then both recursive calls pass 1.
 		// If likely==-1, then we don't have enough information to decide
-		// whether the first branch is likely or not.  So we pass 0 for
+		// whether the first branch is likely or not. So we pass 0 for
 		// the likeliness of the first branch.
 		// TODO: have the frontend give us branch prediction hints for
 		// OANDAND and OOROR nodes (if it ever has such info).
@@ -2191,7 +2191,7 @@ func (s *state) assign(left *Node, right *ssa.Value, wb, deref bool, line int32)
 		s.addNamedValue(left, right)
 		return
 	}
-	// Left is not ssa-able.  Compute its address.
+	// Left is not ssa-able. Compute its address.
 	addr := s.addr(left, false)
 	if left.Op == ONAME {
 		s.vars[&memVar] = s.newValue1A(ssa.OpVarDef, ssa.TypeMem, left, s.mem())
@@ -2333,7 +2333,7 @@ func (s *state) call(n *Node, k callKind) *ssa.Value {
 	dowidth(fn.Type)
 	stksize := fn.Type.Argwid // includes receiver
 
-	// Run all argument assignments.  The arg slots have already
+	// Run all argument assignments. The arg slots have already
 	// been offset by the appropriate amount (+2*widthptr for go/defer,
 	// +widthptr for interface calls).
 	// For OCALLMETH, the receiver is set in these statements.
@@ -2462,12 +2462,12 @@ func (s *state) addr(n *Node, bounded bool) *ssa.Value {
 			return nil
 		case PAUTO:
 			// We need to regenerate the address of autos
-			// at every use.  This prevents LEA instructions
+			// at every use. This prevents LEA instructions
 			// from occurring before the corresponding VarDef
 			// op and confusing the liveness analysis into thinking
 			// the variable is live at function entry.
 			// TODO: I'm not sure if this really works or we're just
-			// getting lucky.  We might need a real dependency edge
+			// getting lucky. We might need a real dependency edge
 			// between vardef and addr ops.
 			aux := &ssa.AutoSymbol{Typ: n.Type, Node: n}
 			return s.newValue1A(ssa.OpAddr, t, aux, s.sp)
@@ -2599,7 +2599,7 @@ func (s *state) canSSA(n *Node) bool {
 func canSSAType(t *Type) bool {
 	dowidth(t)
 	if t.Width > int64(4*Widthptr) {
-		// 4*Widthptr is an arbitrary constant.  We want it
+		// 4*Widthptr is an arbitrary constant. We want it
 		// to be at least 3*Widthptr so slices can be registerized.
 		// Too big and we'll introduce too much register pressure.
 		return false
@@ -2647,7 +2647,7 @@ func (s *state) nilCheck(ptr *ssa.Value) {
 	s.startBlock(bNext)
 }
 
-// boundsCheck generates bounds checking code.  Checks if 0 <= idx < len, branches to exit if not.
+// boundsCheck generates bounds checking code. Checks if 0 <= idx < len, branches to exit if not.
 // Starts a new block on return.
 func (s *state) boundsCheck(idx, len *ssa.Value) {
 	if Debug['B'] != 0 {
@@ -2661,7 +2661,7 @@ func (s *state) boundsCheck(idx, len *ssa.Value) {
 	s.check(cmp, Panicindex)
 }
 
-// sliceBoundsCheck generates slice bounds checking code.  Checks if 0 <= idx <= len, branches to exit if not.
+// sliceBoundsCheck generates slice bounds checking code. Checks if 0 <= idx <= len, branches to exit if not.
 // Starts a new block on return.
 func (s *state) sliceBoundsCheck(idx, len *ssa.Value) {
 	if Debug['B'] != 0 {
@@ -2701,7 +2701,7 @@ func (s *state) check(cmp *ssa.Value, fn *Node) {
 // Returns a slice of results of the given result types.
 // The call is added to the end of the current block.
 // If returns is false, the block is marked as an exit block.
-// If returns is true, the block is marked as a call block.  A new block
+// If returns is true, the block is marked as a call block. A new block
 // is started to load the return values.
 func (s *state) rtcall(fn *Node, returns bool, results []*Type, args ...*ssa.Value) []*ssa.Value {
 	// Write args to the stack
@@ -2773,7 +2773,7 @@ func (s *state) insertWBmove(t *Type, left, right *ssa.Value, line int32) {
 
 	aux := &ssa.ExternSymbol{Types[TBOOL], syslook("writeBarrier", 0).Sym}
 	flagaddr := s.newValue1A(ssa.OpAddr, Ptrto(Types[TUINT32]), aux, s.sb)
-	// TODO: select the .enabled field.  It is currently first, so not needed for now.
+	// TODO: select the .enabled field. It is currently first, so not needed for now.
 	// Load word, test byte, avoiding partial register write from load byte.
 	flag := s.newValue2(ssa.OpLoad, Types[TUINT32], flagaddr, s.mem())
 	flag = s.newValue1(ssa.OpTrunc64to8, Types[TBOOL], flag)
@@ -2818,7 +2818,7 @@ func (s *state) insertWBstore(t *Type, left, right *ssa.Value, line int32) {
 
 	aux := &ssa.ExternSymbol{Types[TBOOL], syslook("writeBarrier", 0).Sym}
 	flagaddr := s.newValue1A(ssa.OpAddr, Ptrto(Types[TUINT32]), aux, s.sb)
-	// TODO: select the .enabled field.  It is currently first, so not needed for now.
+	// TODO: select the .enabled field. It is currently first, so not needed for now.
 	// Load word, test byte, avoiding partial register write from load byte.
 	flag := s.newValue2(ssa.OpLoad, Types[TUINT32], flagaddr, s.mem())
 	flag = s.newValue1(ssa.OpTrunc64to8, Types[TBOOL], flag)
@@ -3018,7 +3018,7 @@ func (s *state) slice(t *Type, v, i, j, k *ssa.Value) (p, l, c *ssa.Value) {
 	var rcap *ssa.Value
 	switch {
 	case t.IsString():
-		// Capacity of the result is unimportant.  However, we use
+		// Capacity of the result is unimportant. However, we use
 		// rcap to test if we've generated a zero-length slice.
 		// Use length of strings for that.
 		rcap = rlen
@@ -3123,13 +3123,13 @@ func (s *state) uintTofloat(cvttab *u2fcvtTab, n *Node, x *ssa.Value, ft, tt *Ty
 	// Code borrowed from old code generator.
 	// What's going on: large 64-bit "unsigned" looks like
 	// negative number to hardware's integer-to-float
-	// conversion.  However, because the mantissa is only
+	// conversion. However, because the mantissa is only
 	// 63 bits, we don't need the LSB, so instead we do an
 	// unsigned right shift (divide by two), convert, and
-	// double.  However, before we do that, we need to be
+	// double. However, before we do that, we need to be
 	// sure that we do not lose a "1" if that made the
-	// difference in the resulting rounding.  Therefore, we
-	// preserve it, and OR (not ADD) it back in.  The case
+	// difference in the resulting rounding. Therefore, we
+	// preserve it, and OR (not ADD) it back in. The case
 	// that matters is when the eleven discarded bits are
 	// equal to 10000000001; that rounds up, and the 1 cannot
 	// be lost else it would round down if the LSB of the
@@ -3470,15 +3470,15 @@ func (s *state) mem() *ssa.Value {
 }
 
 func (s *state) linkForwardReferences() {
-	// Build SSA graph.  Each variable on its first use in a basic block
+	// Build SSA graph. Each variable on its first use in a basic block
 	// leaves a FwdRef in that block representing the incoming value
-	// of that variable.  This function links that ref up with possible definitions,
-	// inserting Phi values as needed.  This is essentially the algorithm
+	// of that variable. This function links that ref up with possible definitions,
+	// inserting Phi values as needed. This is essentially the algorithm
 	// described by Braun, Buchwald, Hack, Leißa, Mallon, and Zwinkau:
 	// http://pp.info.uni-karlsruhe.de/uploads/publikationen/braun13cc.pdf
 	// Differences:
 	//   - We use FwdRef nodes to postpone phi building until the CFG is
-	//     completely built.  That way we can avoid the notion of "sealed"
+	//     completely built. That way we can avoid the notion of "sealed"
 	//     blocks.
 	//   - Phi optimization is a separate pass (in ../ssa/phielim.go).
 	for len(s.fwdRefs) > 0 {
@@ -3501,7 +3501,7 @@ func (s *state) resolveFwdRef(v *ssa.Value) {
 			v.Aux = name
 			return
 		}
-		// Not SSAable.  Load it.
+		// Not SSAable. Load it.
 		addr := s.decladdrs[name]
 		if addr == nil {
 			// TODO: closure args reach here.
@@ -3527,7 +3527,7 @@ func (s *state) resolveFwdRef(v *ssa.Value) {
 		args = append(args, s.lookupVarOutgoing(p, v.Type, name, v.Line))
 	}
 
-	// Decide if we need a phi or not.  We need a phi if there
+	// Decide if we need a phi or not. We need a phi if there
 	// are two different args (which are both not v).
 	var w *ssa.Value
 	for _, a := range args {
@@ -3548,7 +3548,7 @@ func (s *state) resolveFwdRef(v *ssa.Value) {
 	if w == nil {
 		s.Fatalf("no witness for reachable phi %s", v)
 	}
-	// One witness.  Make v a copy of w.
+	// One witness. Make v a copy of w.
 	v.Op = ssa.OpCopy
 	v.AddArg(w)
 }
@@ -3560,7 +3560,7 @@ func (s *state) lookupVarOutgoing(b *ssa.Block, t ssa.Type, name *Node, line int
 		return v
 	}
 	// The variable is not defined by b and we haven't
-	// looked it up yet.  Generate a FwdRef for the variable and return that.
+	// looked it up yet. Generate a FwdRef for the variable and return that.
 	v := b.NewValue0A(line, ssa.OpFwdRef, t, name)
 	s.fwdRefs = append(s.fwdRefs, v)
 	m[name] = v
@@ -3740,7 +3740,7 @@ func genssa(f *ssa.Func, ptxt *obj.Prog, gcargs, gclocals *Sym) {
 	gcsymdup(gcargs)
 	gcsymdup(gclocals)
 
-	// Add frame prologue.  Zero ambiguously live variables.
+	// Add frame prologue. Zero ambiguously live variables.
 	Thearch.Defframe(ptxt)
 	if Debug['f'] != 0 {
 		frame(0)
@@ -4115,7 +4115,7 @@ func (s *genState) genValue(v *ssa.Value) {
 		if v.AuxInt2Int64() == -1<<31 || x == r {
 			if x != r {
 				// This code compensates for the fact that the register allocator
-				// doesn't understand 2-address instructions yet.  TODO: fix that.
+				// doesn't understand 2-address instructions yet. TODO: fix that.
 				p := Prog(moveByType(v.Type))
 				p.From.Type = obj.TYPE_REG
 				p.From.Reg = x
@@ -4183,7 +4183,7 @@ func (s *genState) genValue(v *ssa.Value) {
 		ssa.OpAMD64SARBconst, ssa.OpAMD64ROLQconst, ssa.OpAMD64ROLLconst, ssa.OpAMD64ROLWconst,
 		ssa.OpAMD64ROLBconst:
 		// This code compensates for the fact that the register allocator
-		// doesn't understand 2-address instructions yet.  TODO: fix that.
+		// doesn't understand 2-address instructions yet. TODO: fix that.
 		x := regnum(v.Args[0])
 		r := regnum(v)
 		if x != r {
@@ -4943,7 +4943,7 @@ func (s *state) extendIndex(v *ssa.Value) *ssa.Value {
 		return v
 	}
 	if size > s.config.IntSize {
-		// TODO: truncate 64-bit indexes on 32-bit pointer archs.  We'd need to test
+		// TODO: truncate 64-bit indexes on 32-bit pointer archs. We'd need to test
 		// the high word and branch to out-of-bounds failure if it is not 0.
 		s.Unimplementedf("64->32 index truncation not implemented")
 		return v
@@ -5089,7 +5089,7 @@ func moveByType(t ssa.Type) int {
 }
 
 // regnum returns the register (in cmd/internal/obj numbering) to
-// which v has been allocated.  Panics if v is not assigned to a
+// which v has been allocated. Panics if v is not assigned to a
 // register.
 // TODO: Make this panic again once it stops happening routinely.
 func regnum(v *ssa.Value) int16 {
diff --git a/src/cmd/compile/internal/gc/subr.go b/src/cmd/compile/internal/gc/subr.go
index 204962ca85..ce1a317530 100644
--- a/src/cmd/compile/internal/gc/subr.go
+++ b/src/cmd/compile/internal/gc/subr.go
@@ -739,7 +739,7 @@ func eqtype1(t1 *Type, t2 *Type, assumed_equal *TypePairList) bool {
 	}
 	if t1.Sym != nil || t2.Sym != nil {
 		// Special case: we keep byte and uint8 separate
-		// for error messages.  Treat them as equal.
+		// for error messages. Treat them as equal.
 		switch t1.Etype {
 		case TUINT8:
 			if (t1 == Types[TUINT8] || t1 == bytetype) && (t2 == Types[TUINT8] || t2 == bytetype) {
@@ -997,7 +997,7 @@ func convertop(src *Type, dst *Type, why *string) Op {
 	}
 
 	// The rules for interfaces are no different in conversions
-	// than assignments.  If interfaces are involved, stop now
+	// than assignments. If interfaces are involved, stop now
 	// with the good message from assignop.
 	// Otherwise clear the error.
 	if src.Etype == TINTER || dst.Etype == TINTER {
@@ -2684,8 +2684,8 @@ func ngotype(n *Node) *Sym {
 }
 
 // Convert raw string to the prefix that will be used in the symbol
-// table.  All control characters, space, '%' and '"', as well as
-// non-7-bit clean bytes turn into %xx.  The period needs escaping
+// table. All control characters, space, '%' and '"', as well as
+// non-7-bit clean bytes turn into %xx. The period needs escaping
 // only in the last segment of the path, and it makes for happier
 // users if we escape that as little as possible.
 //
diff --git a/src/cmd/compile/internal/gc/testdata/addressed_ssa.go b/src/cmd/compile/internal/gc/testdata/addressed_ssa.go
index f9f459360b..98003fe48f 100644
--- a/src/cmd/compile/internal/gc/testdata/addressed_ssa.go
+++ b/src/cmd/compile/internal/gc/testdata/addressed_ssa.go
@@ -143,7 +143,7 @@ func (v V) val() int64 {
 // address taken to force heap allocation, and then based on
 // the value of which a pair of those locals are copied in
 // various ways to the two results y, and z, which are also
-// addressed.  Which is expected to be one of 11-13, 21-23, 31, 32,
+// addressed. Which is expected to be one of 11-13, 21-23, 31, 32,
 // and y.val() should be equal to which and y.p.val() should
 // be equal to z.val().  Also, x(.p)**8 == x; that is, the
 // autos are all linked into a ring.
diff --git a/src/cmd/compile/internal/gc/testdata/gen/arithBoundaryGen.go b/src/cmd/compile/internal/gc/testdata/gen/arithBoundaryGen.go
index 7c7d721a23..be0aad5ff8 100644
--- a/src/cmd/compile/internal/gc/testdata/gen/arithBoundaryGen.go
+++ b/src/cmd/compile/internal/gc/testdata/gen/arithBoundaryGen.go
@@ -3,7 +3,7 @@
 // license that can be found in the LICENSE file.
 
 // This program generates a test to verify that the standard arithmetic
-// operators properly handle some special cases.  The test file should be
+// operators properly handle some special cases. The test file should be
 // generated with a known working version of go.
 // launch with `go run arithBoundaryGen.go` a file called arithBoundary_ssa.go
 // will be written into the parent directory containing the tests
diff --git a/src/cmd/compile/internal/gc/testdata/gen/arithConstGen.go b/src/cmd/compile/internal/gc/testdata/gen/arithConstGen.go
index 34e54ad08a..b32a59d514 100644
--- a/src/cmd/compile/internal/gc/testdata/gen/arithConstGen.go
+++ b/src/cmd/compile/internal/gc/testdata/gen/arithConstGen.go
@@ -3,7 +3,7 @@
 // license that can be found in the LICENSE file.
 
 // This program generates a test to verify that the standard arithmetic
-// operators properly handle const cases.  The test file should be
+// operators properly handle const cases. The test file should be
 // generated with a known working version of go.
 // launch with `go run arithConstGen.go` a file called arithConst_ssa.go
 // will be written into the parent directory containing the tests
diff --git a/src/cmd/compile/internal/gc/testdata/loadstore_ssa.go b/src/cmd/compile/internal/gc/testdata/loadstore_ssa.go
index e0b0b4dfab..df51921e0c 100644
--- a/src/cmd/compile/internal/gc/testdata/loadstore_ssa.go
+++ b/src/cmd/compile/internal/gc/testdata/loadstore_ssa.go
@@ -42,7 +42,7 @@ func testStoreSize_ssa(p *uint16, q *uint16, v uint32) {
 	switch {
 	}
 	// Test to make sure that (Store ptr (Trunc32to16 val) mem)
-	// does not end up as a 32-bit store.  It must stay a 16 bit store
+	// does not end up as a 32-bit store. It must stay a 16 bit store
 	// even when Trunc32to16 is rewritten to be a nop.
 	// To ensure that we get rewrite the Trunc32to16 before
 	// we rewrite the Store, we force the truncate into an
diff --git a/src/cmd/compile/internal/gc/testdata/phi_ssa.go b/src/cmd/compile/internal/gc/testdata/phi_ssa.go
index e855070fc3..6469bfea44 100644
--- a/src/cmd/compile/internal/gc/testdata/phi_ssa.go
+++ b/src/cmd/compile/internal/gc/testdata/phi_ssa.go
@@ -85,7 +85,7 @@ func foo() int32 {
 		z = int32(data2[25])
 	}
 	// Lots of phis of the form phi(int32,int64) of type int32 happen here.
-	// Some will be stack phis.  For those stack phis, make sure the spill
+	// Some will be stack phis. For those stack phis, make sure the spill
 	// of the second argument uses the phi's width (4 bytes), not its width
 	// (8 bytes).  Otherwise, a random stack slot gets clobbered.
 
diff --git a/src/cmd/compile/internal/gc/testdata/unsafe_ssa.go b/src/cmd/compile/internal/gc/testdata/unsafe_ssa.go
index d074eb1d5e..a3d9dbcc39 100644
--- a/src/cmd/compile/internal/gc/testdata/unsafe_ssa.go
+++ b/src/cmd/compile/internal/gc/testdata/unsafe_ssa.go
@@ -30,7 +30,7 @@ func f_ssa() *[8]uint {
 	} else {
 		x = 0
 	}
-	// Clobber the global pointer.  The only live ref
+	// Clobber the global pointer. The only live ref
 	// to the allocated object is now x.
 	a = nil
 
@@ -66,7 +66,7 @@ func g_ssa() *[7]uint {
 	} else {
 		x = 0
 	}
-	// Clobber the global pointer.  The only live ref
+	// Clobber the global pointer. The only live ref
 	// to the allocated object is now x.
 	a = nil
 
diff --git a/src/cmd/compile/internal/gc/type.go b/src/cmd/compile/internal/gc/type.go
index f09094ce23..0f7842c5b2 100644
--- a/src/cmd/compile/internal/gc/type.go
+++ b/src/cmd/compile/internal/gc/type.go
@@ -117,7 +117,7 @@ func (t *Type) cmp(x *Type) ssa.Cmp {
 
 	if t.Sym != nil || x.Sym != nil {
 		// Special case: we keep byte and uint8 separate
-		// for error messages.  Treat them as equal.
+		// for error messages. Treat them as equal.
 		switch t.Etype {
 		case TUINT8:
 			if (t == Types[TUINT8] || t == bytetype) && (x == Types[TUINT8] || x == bytetype) {
diff --git a/src/cmd/compile/internal/gc/typecheck.go b/src/cmd/compile/internal/gc/typecheck.go
index 102235f94e..f912061423 100644
--- a/src/cmd/compile/internal/gc/typecheck.go
+++ b/src/cmd/compile/internal/gc/typecheck.go
@@ -2840,7 +2840,7 @@ func keydup(n *Node, hash map[uint32][]*Node) {
 				cmp.Right = a.Left
 				evconst(&cmp)
 				if cmp.Op == OLITERAL {
-					// Sometimes evconst fails.  See issue 12536.
+					// Sometimes evconst fails. See issue 12536.
 					b = cmp.Val().U.(bool)
 				}
 			}
@@ -3074,7 +3074,7 @@ func typecheckcomplit(np **Node) {
 					Yyerror("implicit assignment of unexported field '%s' in %v literal", s.Name, t)
 				}
 
-				// No pushtype allowed here.  Must name fields for that.
+				// No pushtype allowed here. Must name fields for that.
 				ll.N = assignconv(ll.N, f.Type, "field value")
 
 				ll.N = Nod(OKEY, newname(f.Sym), ll.N)
@@ -3114,7 +3114,7 @@ func typecheckcomplit(np **Node) {
 				}
 
 				// Sym might have resolved to name in other top-level
-				// package, because of import dot.  Redirect to correct sym
+				// package, because of import dot. Redirect to correct sym
 				// before we do the lookup.
 				if s.Pkg != localpkg && exportname(s.Name) {
 					s1 = Lookup(s.Name)
@@ -3136,7 +3136,7 @@ func typecheckcomplit(np **Node) {
 				fielddup(newname(s), hash)
 				r = l.Right
 
-				// No pushtype allowed here.  Tried and rejected.
+				// No pushtype allowed here. Tried and rejected.
 				typecheck(&r, Erv)
 
 				l.Right = assignconv(r, f.Type, "field value")
@@ -3504,7 +3504,7 @@ func domethod(n *Node) {
 	//	}
 	// then even though I.M looks like it doesn't care about the
 	// value of its argument, a specific implementation of I may
-	// care.  The _ would suppress the assignment to that argument
+	// care. The _ would suppress the assignment to that argument
 	// while generating a call, so remove it.
 	for t := getinargx(nt.Type).Type; t != nil; t = t.Down {
 		if t.Sym != nil && t.Sym.Name == "_" {
diff --git a/src/cmd/compile/internal/gc/walk.go b/src/cmd/compile/internal/gc/walk.go
index 3e67f50620..04dac7ca2c 100644
--- a/src/cmd/compile/internal/gc/walk.go
+++ b/src/cmd/compile/internal/gc/walk.go
@@ -2788,7 +2788,7 @@ func appendslice(n *Node, init **NodeList) *Node {
 
 	// walkexprlistsafe will leave OINDEX (s[n]) alone if both s
 	// and n are name or literal, but those may index the slice we're
-	// modifying here.  Fix explicitly.
+	// modifying here. Fix explicitly.
 	for l := n.List; l != nil; l = l.Next {
 		l.N = cheapexpr(l.N, init)
 	}
@@ -2907,7 +2907,7 @@ func walkappend(n *Node, init **NodeList, dst *Node) *Node {
 
 	// walkexprlistsafe will leave OINDEX (s[n]) alone if both s
 	// and n are name or literal, but those may index the slice we're
-	// modifying here.  Fix explicitly.
+	// modifying here. Fix explicitly.
 	// Using cheapexpr also makes sure that the evaluation
 	// of all arguments (and especially any panics) happen
 	// before we begin to modify the slice in a visible way.
@@ -3241,7 +3241,7 @@ func walkcompare(np **Node, init **NodeList) {
 		return
 	}
 
-	// Chose not to inline.  Call equality function directly.
+	// Chose not to inline. Call equality function directly.
 	var needsize int
 	call := Nod(OCALL, eqfor(t, &needsize), nil)
 
diff --git a/src/cmd/compile/internal/mips64/cgen.go b/src/cmd/compile/internal/mips64/cgen.go
index 434bfc73cb..bdcb565839 100644
--- a/src/cmd/compile/internal/mips64/cgen.go
+++ b/src/cmd/compile/internal/mips64/cgen.go
@@ -129,7 +129,7 @@ func blockcopy(n, res *gc.Node, osrc, odst, w int64) {
 		// TODO: Instead of generating ADDV $-8,R8; ADDV
 		// $-8,R7; n*(MOVV 8(R8),R9; ADDV $8,R8; MOVV R9,8(R7);
 		// ADDV $8,R7;) just generate the offsets directly and
-		// eliminate the ADDs.  That will produce shorter, more
+		// eliminate the ADDs. That will produce shorter, more
 		// pipeline-able code.
 		var p *obj.Prog
 		for ; c > 0; c-- {
diff --git a/src/cmd/compile/internal/mips64/peep.go b/src/cmd/compile/internal/mips64/peep.go
index f97be60a2a..bf8a4ca979 100644
--- a/src/cmd/compile/internal/mips64/peep.go
+++ b/src/cmd/compile/internal/mips64/peep.go
@@ -62,7 +62,7 @@ loop1:
 		// distinguish between moves that moves that *must*
 		// sign/zero extend and moves that don't care so they
 		// can eliminate moves that don't care without
-		// breaking moves that do care.  This might let us
+		// breaking moves that do care. This might let us
 		// simplify or remove the next peep loop, too.
 		if p.As == mips.AMOVV || p.As == mips.AMOVF || p.As == mips.AMOVD {
 			if regtyp(&p.To) {
@@ -697,7 +697,7 @@ func copyu(p *obj.Prog, v *obj.Addr, s *obj.Addr) int {
 // copyas returns 1 if a and v address the same register.
 //
 // If a is the from operand, this means this operation reads the
-// register in v.  If a is the to operand, this means this operation
+// register in v. If a is the to operand, this means this operation
 // writes the register in v.
 func copyas(a *obj.Addr, v *obj.Addr) bool {
 	if regtyp(v) {
@@ -714,7 +714,7 @@ func copyas(a *obj.Addr, v *obj.Addr) bool {
 // same register as v.
 //
 // If a is the from operand, this means this operation reads the
-// register in v.  If a is the to operand, this means the operation
+// register in v. If a is the to operand, this means the operation
 // either reads or writes the register in v (if !copyas(a, v), then
 // the operation reads the register in v).
 func copyau(a *obj.Addr, v *obj.Addr) bool {
diff --git a/src/cmd/compile/internal/ppc64/cgen.go b/src/cmd/compile/internal/ppc64/cgen.go
index 740e64cc83..aea09503a8 100644
--- a/src/cmd/compile/internal/ppc64/cgen.go
+++ b/src/cmd/compile/internal/ppc64/cgen.go
@@ -123,7 +123,7 @@ func blockcopy(n, res *gc.Node, osrc, odst, w int64) {
 		// TODO(austin): Instead of generating ADD $-8,R8; ADD
 		// $-8,R7; n*(MOVDU 8(R8),R9; MOVDU R9,8(R7);) just
 		// generate the offsets directly and eliminate the
-		// ADDs.  That will produce shorter, more
+		// ADDs. That will produce shorter, more
 		// pipeline-able code.
 		var p *obj.Prog
 		for ; c > 0; c-- {
diff --git a/src/cmd/compile/internal/ppc64/gsubr.go b/src/cmd/compile/internal/ppc64/gsubr.go
index 534ea6290a..ca8be50632 100644
--- a/src/cmd/compile/internal/ppc64/gsubr.go
+++ b/src/cmd/compile/internal/ppc64/gsubr.go
@@ -42,9 +42,9 @@ var resvd = []int{
 	ppc64.REGZERO,
 	ppc64.REGSP, // reserved for SP
 	// We need to preserve the C ABI TLS pointer because sigtramp
-	// may happen during C code and needs to access the g.  C
+	// may happen during C code and needs to access the g. C
 	// clobbers REGG, so if Go were to clobber REGTLS, sigtramp
-	// won't know which convention to use.  By preserving REGTLS,
+	// won't know which convention to use. By preserving REGTLS,
 	// we can just retrieve g from TLS when we aren't sure.
 	ppc64.REGTLS,
 
diff --git a/src/cmd/compile/internal/ppc64/opt.go b/src/cmd/compile/internal/ppc64/opt.go
index 99d2585d00..4f81aa9c1e 100644
--- a/src/cmd/compile/internal/ppc64/opt.go
+++ b/src/cmd/compile/internal/ppc64/opt.go
@@ -5,7 +5,7 @@
 package ppc64
 
 // Many Power ISA arithmetic and logical instructions come in four
-// standard variants.  These bits let us map between variants.
+// standard variants. These bits let us map between variants.
 const (
 	V_CC = 1 << 0 // xCC (affect CR field 0 flags)
 	V_V  = 1 << 1 // xV (affect SO and OV flags)
diff --git a/src/cmd/compile/internal/ppc64/peep.go b/src/cmd/compile/internal/ppc64/peep.go
index 1ff3109a49..dfd023c766 100644
--- a/src/cmd/compile/internal/ppc64/peep.go
+++ b/src/cmd/compile/internal/ppc64/peep.go
@@ -62,7 +62,7 @@ loop1:
 		// distinguish between moves that moves that *must*
 		// sign/zero extend and moves that don't care so they
 		// can eliminate moves that don't care without
-		// breaking moves that do care.  This might let us
+		// breaking moves that do care. This might let us
 		// simplify or remove the next peep loop, too.
 		if p.As == ppc64.AMOVD || p.As == ppc64.AFMOVD {
 			if regtyp(&p.To) {
@@ -962,7 +962,7 @@ func copyu(p *obj.Prog, v *obj.Addr, s *obj.Addr) int {
 // copyas returns 1 if a and v address the same register.
 //
 // If a is the from operand, this means this operation reads the
-// register in v.  If a is the to operand, this means this operation
+// register in v. If a is the to operand, this means this operation
 // writes the register in v.
 func copyas(a *obj.Addr, v *obj.Addr) bool {
 	if regtyp(v) {
@@ -979,7 +979,7 @@ func copyas(a *obj.Addr, v *obj.Addr) bool {
 // same register as v.
 //
 // If a is the from operand, this means this operation reads the
-// register in v.  If a is the to operand, this means the operation
+// register in v. If a is the to operand, this means the operation
 // either reads or writes the register in v (if !copyas(a, v), then
 // the operation reads the register in v).
 func copyau(a *obj.Addr, v *obj.Addr) bool {
diff --git a/src/cmd/compile/internal/ppc64/prog.go b/src/cmd/compile/internal/ppc64/prog.go
index efeff86dca..4cf10d04a9 100644
--- a/src/cmd/compile/internal/ppc64/prog.go
+++ b/src/cmd/compile/internal/ppc64/prog.go
@@ -180,8 +180,8 @@ func proginfo(p *obj.Prog) {
 	}
 }
 
-// Instruction variants table.  Initially this contains entries only
-// for the "base" form of each instruction.  On the first call to
+// Instruction variants table. Initially this contains entries only
+// for the "base" form of each instruction. On the first call to
 // as2variant or variant2as, we'll add the variants to the table.
 var varianttable = [ppc64.ALAST][4]int{
 	ppc64.AADD:     {ppc64.AADD, ppc64.AADDCC, ppc64.AADDV, ppc64.AADDVCC},
diff --git a/src/cmd/compile/internal/ssa/block.go b/src/cmd/compile/internal/ssa/block.go
index 7641811a5f..2e520da050 100644
--- a/src/cmd/compile/internal/ssa/block.go
+++ b/src/cmd/compile/internal/ssa/block.go
@@ -8,29 +8,29 @@ import "fmt"
 
 // Block represents a basic block in the control flow graph of a function.
 type Block struct {
-	// A unique identifier for the block.  The system will attempt to allocate
+	// A unique identifier for the block. The system will attempt to allocate
 	// these IDs densely, but no guarantees.
 	ID ID
 
 	// The kind of block this is.
 	Kind BlockKind
 
-	// Subsequent blocks, if any.  The number and order depend on the block kind.
+	// Subsequent blocks, if any. The number and order depend on the block kind.
 	// All successors must be distinct (to make phi values in successors unambiguous).
 	Succs []*Block
 
 	// Inverse of successors.
 	// The order is significant to Phi nodes in the block.
 	Preds []*Block
-	// TODO: predecessors is a pain to maintain.  Can we somehow order phi
+	// TODO: predecessors is a pain to maintain. Can we somehow order phi
 	// arguments by block id and have this field computed explicitly when needed?
 
-	// A value that determines how the block is exited.  Its value depends on the kind
-	// of the block.  For instance, a BlockIf has a boolean control value and BlockExit
+	// A value that determines how the block is exited. Its value depends on the kind
+	// of the block. For instance, a BlockIf has a boolean control value and BlockExit
 	// has a memory control value.
 	Control *Value
 
-	// Auxiliary info for the block.  Its value depends on the Kind.
+	// Auxiliary info for the block. Its value depends on the Kind.
 	Aux interface{}
 
 	// The unordered set of Values that define the operation of this block.
@@ -97,7 +97,7 @@ func (b *Block) LongString() string {
 	return s
 }
 
-// AddEdgeTo adds an edge from block b to block c.  Used during building of the
+// AddEdgeTo adds an edge from block b to block c. Used during building of the
 // SSA graph; do not use on an already-completed SSA graph.
 func (b *Block) AddEdgeTo(c *Block) {
 	b.Succs = append(b.Succs, c)
diff --git a/src/cmd/compile/internal/ssa/check.go b/src/cmd/compile/internal/ssa/check.go
index 54f774004e..7243cdc310 100644
--- a/src/cmd/compile/internal/ssa/check.go
+++ b/src/cmd/compile/internal/ssa/check.go
@@ -33,7 +33,7 @@ func checkFunc(f *Func) {
 		// If the conditional is true, does v get the value of a or b?
 		// We could solve this other ways, but the easiest is just to
 		// require (by possibly adding empty control-flow blocks) that
-		// all successors are distinct.  They will need to be distinct
+		// all successors are distinct. They will need to be distinct
 		// anyway for register allocation (duplicate successors implies
 		// the existence of critical edges).
 		// After regalloc we can allow non-distinct predecessors.
diff --git a/src/cmd/compile/internal/ssa/compile.go b/src/cmd/compile/internal/ssa/compile.go
index f68819c3c2..5a13b147fc 100644
--- a/src/cmd/compile/internal/ssa/compile.go
+++ b/src/cmd/compile/internal/ssa/compile.go
@@ -114,9 +114,9 @@ type pass struct {
 
 // PhaseOption sets the specified flag in the specified ssa phase,
 // returning empty string if this was successful or a string explaining
-// the error if it was not.  A version of the phase name with "_"
+// the error if it was not. A version of the phase name with "_"
 // replaced by " " is also checked for a match.
-// See gc/lex.go for dissection of the option string.  Example use:
+// See gc/lex.go for dissection of the option string. Example use:
 // GO_GCFLAGS=-d=ssa/generic_cse/time,ssa/generic_cse/stats,ssa/generic_cse/debug=3 ./make.bash ...
 //
 func PhaseOption(phase, flag string, val int) string {
@@ -189,7 +189,7 @@ var passes = [...]pass{
 
 // Double-check phase ordering constraints.
 // This code is intended to document the ordering requirements
-// between different phases.  It does not override the passes
+// between different phases. It does not override the passes
 // list above.
 type constraint struct {
 	a, b string // a must come before b
diff --git a/src/cmd/compile/internal/ssa/config.go b/src/cmd/compile/internal/ssa/config.go
index 8657509c5c..7d345ae280 100644
--- a/src/cmd/compile/internal/ssa/config.go
+++ b/src/cmd/compile/internal/ssa/config.go
@@ -24,7 +24,7 @@ type Config struct {
 	optimize   bool                       // Do optimization
 	curFunc    *Func
 
-	// TODO: more stuff.  Compiler flags of interest, ...
+	// TODO: more stuff. Compiler flags of interest, ...
 
 	// Given an environment variable used for debug hash match,
 	// what file (if any) receives the yes/no logging?
@@ -95,7 +95,7 @@ type Frontend interface {
 	Line(int32) string
 }
 
-// interface used to hold *gc.Node.  We'd use *gc.Node directly but
+// interface used to hold *gc.Node. We'd use *gc.Node directly but
 // that would lead to an import cycle.
 type GCNode interface {
 	Typ() Type
diff --git a/src/cmd/compile/internal/ssa/cse.go b/src/cmd/compile/internal/ssa/cse.go
index c44748535b..817ee4b341 100644
--- a/src/cmd/compile/internal/ssa/cse.go
+++ b/src/cmd/compile/internal/ssa/cse.go
@@ -14,7 +14,7 @@ const (
 )
 
 // cse does common-subexpression elimination on the Function.
-// Values are just relinked, nothing is deleted.  A subsequent deadcode
+// Values are just relinked, nothing is deleted. A subsequent deadcode
 // pass is required to actually remove duplicate expressions.
 func cse(f *Func) {
 	// Two values are equivalent if they satisfy the following definition:
@@ -82,7 +82,7 @@ func cse(f *Func) {
 	}
 
 	// Find an equivalence class where some members of the class have
-	// non-equivalent arguments.  Split the equivalence class appropriately.
+	// non-equivalent arguments. Split the equivalence class appropriately.
 	// Repeat until we can't find any more splits.
 	for {
 		changed := false
@@ -117,7 +117,7 @@ func cse(f *Func) {
 					changed = true
 					continue eqloop
 				}
-				// v and w are equivalent.  Keep w in e.
+				// v and w are equivalent. Keep w in e.
 				j++
 			}
 			partition[i] = e
@@ -135,7 +135,7 @@ func cse(f *Func) {
 	idom := dominators(f)
 	sdom := newSparseTree(f, idom)
 
-	// Compute substitutions we would like to do.  We substitute v for w
+	// Compute substitutions we would like to do. We substitute v for w
 	// if v and w are in the same equivalence class and v dominates w.
 	rewrite := make([]*Value, f.NumValues())
 	for _, e := range partition {
@@ -191,7 +191,7 @@ func cse(f *Func) {
 	}
 }
 
-// An eqclass approximates an equivalence class.  During the
+// An eqclass approximates an equivalence class. During the
 // algorithm it may represent the union of several of the
 // final equivalence classes.
 type eqclass []*Value
@@ -207,7 +207,7 @@ type eqclass []*Value
 //  - first two arg's opcodes and auxint
 //  - NOT first two arg's aux; that can break CSE.
 // partitionValues returns a list of equivalence classes, each
-// being a sorted by ID list of *Values.  The eqclass slices are
+// being a sorted by ID list of *Values. The eqclass slices are
 // backed by the same storage as the input slice.
 // Equivalence classes of size 1 are ignored.
 func partitionValues(a []*Value, auxIDs auxmap) []eqclass {
diff --git a/src/cmd/compile/internal/ssa/deadcode.go b/src/cmd/compile/internal/ssa/deadcode.go
index a33de438e2..819f6de247 100644
--- a/src/cmd/compile/internal/ssa/deadcode.go
+++ b/src/cmd/compile/internal/ssa/deadcode.go
@@ -84,9 +84,9 @@ func liveValues(f *Func, reachable []bool) []bool {
 
 // deadcode removes dead code from f.
 func deadcode(f *Func) {
-	// deadcode after regalloc is forbidden for now.  Regalloc
+	// deadcode after regalloc is forbidden for now. Regalloc
 	// doesn't quite generate legal SSA which will lead to some
-	// required moves being eliminated.  See the comment at the
+	// required moves being eliminated. See the comment at the
 	// top of regalloc.go for details.
 	if f.RegAlloc != nil {
 		f.Fatalf("deadcode after regalloc")
@@ -164,7 +164,7 @@ func deadcode(f *Func) {
 	}
 	f.Names = f.Names[:i]
 
-	// Remove dead values from blocks' value list.  Return dead
+	// Remove dead values from blocks' value list. Return dead
 	// values to the allocator.
 	for _, b := range f.Blocks {
 		i := 0
@@ -184,7 +184,7 @@ func deadcode(f *Func) {
 		b.Values = b.Values[:i]
 	}
 
-	// Remove unreachable blocks.  Return dead blocks to allocator.
+	// Remove unreachable blocks. Return dead blocks to allocator.
 	i = 0
 	for _, b := range f.Blocks {
 		if reachable[b.ID] {
@@ -235,11 +235,11 @@ func (b *Block) removePred(p *Block) {
 		v.Args[n] = nil // aid GC
 		v.Args = v.Args[:n]
 		phielimValue(v)
-		// Note: this is trickier than it looks.  Replacing
+		// Note: this is trickier than it looks. Replacing
 		// a Phi with a Copy can in general cause problems because
 		// Phi and Copy don't have exactly the same semantics.
 		// Phi arguments always come from a predecessor block,
-		// whereas copies don't.  This matters in loops like:
+		// whereas copies don't. This matters in loops like:
 		// 1: x = (Phi y)
 		//    y = (Add x 1)
 		//    goto 1
@@ -253,15 +253,15 @@ func (b *Block) removePred(p *Block) {
 		// will barf on it.
 		//
 		// Fortunately, this situation can only happen for dead
-		// code loops.  We know the code we're working with is
+		// code loops. We know the code we're working with is
 		// not dead, so we're ok.
 		// Proof: If we have a potential bad cycle, we have a
 		// situation like this:
 		//   x = (Phi z)
 		//   y = (op1 x ...)
 		//   z = (op2 y ...)
-		// Where opX are not Phi ops.  But such a situation
-		// implies a cycle in the dominator graph.  In the
+		// Where opX are not Phi ops. But such a situation
+		// implies a cycle in the dominator graph. In the
 		// example, x.Block dominates y.Block, y.Block dominates
 		// z.Block, and z.Block dominates x.Block (treating
 		// "dominates" as reflexive).  Cycles in the dominator
diff --git a/src/cmd/compile/internal/ssa/deadstore.go b/src/cmd/compile/internal/ssa/deadstore.go
index bad0e0096f..20e8368cd5 100644
--- a/src/cmd/compile/internal/ssa/deadstore.go
+++ b/src/cmd/compile/internal/ssa/deadstore.go
@@ -7,7 +7,7 @@ package ssa
 // dse does dead-store elimination on the Function.
 // Dead stores are those which are unconditionally followed by
 // another store to the same location, with no intervening load.
-// This implementation only works within a basic block.  TODO: use something more global.
+// This implementation only works within a basic block. TODO: use something more global.
 func dse(f *Func) {
 	var stores []*Value
 	loadUse := f.newSparseSet(f.NumValues())
@@ -17,7 +17,7 @@ func dse(f *Func) {
 	shadowed := f.newSparseSet(f.NumValues())
 	defer f.retSparseSet(shadowed)
 	for _, b := range f.Blocks {
-		// Find all the stores in this block.  Categorize their uses:
+		// Find all the stores in this block. Categorize their uses:
 		//  loadUse contains stores which are used by a subsequent load.
 		//  storeUse contains stores which are used by a subsequent store.
 		loadUse.clear()
@@ -67,9 +67,9 @@ func dse(f *Func) {
 			b.Fatalf("no last store found - cycle?")
 		}
 
-		// Walk backwards looking for dead stores.  Keep track of shadowed addresses.
+		// Walk backwards looking for dead stores. Keep track of shadowed addresses.
 		// An "address" is an SSA Value which encodes both the address and size of
-		// the write.  This code will not remove dead stores to the same address
+		// the write. This code will not remove dead stores to the same address
 		// of different types.
 		shadowed.clear()
 		v := last
diff --git a/src/cmd/compile/internal/ssa/deadstore_test.go b/src/cmd/compile/internal/ssa/deadstore_test.go
index 9ded8bd6e6..c38f1cdbaf 100644
--- a/src/cmd/compile/internal/ssa/deadstore_test.go
+++ b/src/cmd/compile/internal/ssa/deadstore_test.go
@@ -65,7 +65,7 @@ func TestDeadStorePhi(t *testing.T) {
 }
 
 func TestDeadStoreTypes(t *testing.T) {
-	// Make sure a narrow store can't shadow a wider one.  We test an even
+	// Make sure a narrow store can't shadow a wider one. We test an even
 	// stronger restriction, that one store can't shadow another unless the
 	// types of the address fields are identical (where identicalness is
 	// decided by the CSE pass).
diff --git a/src/cmd/compile/internal/ssa/dom.go b/src/cmd/compile/internal/ssa/dom.go
index 2d53b5a957..7de8c354a1 100644
--- a/src/cmd/compile/internal/ssa/dom.go
+++ b/src/cmd/compile/internal/ssa/dom.go
@@ -16,7 +16,7 @@ const (
 // of a control-flow graph.
 
 // postorder computes a postorder traversal ordering for the
-// basic blocks in f.  Unreachable blocks will not appear.
+// basic blocks in f. Unreachable blocks will not appear.
 func postorder(f *Func) []*Block {
 	mark := make([]byte, f.NumBlocks())
 
@@ -31,12 +31,12 @@ func postorder(f *Func) []*Block {
 		b := s[len(s)-1]
 		switch mark[b.ID] {
 		case explored:
-			// Children have all been visited.  Pop & output block.
+			// Children have all been visited. Pop & output block.
 			s = s[:len(s)-1]
 			mark[b.ID] = done
 			order = append(order, b)
 		case notExplored:
-			// Children have not been visited yet.  Mark as explored
+			// Children have not been visited yet. Mark as explored
 			// and queue any children we haven't seen yet.
 			mark[b.ID] = explored
 			for _, c := range b.Succs {
@@ -140,9 +140,9 @@ func (f *Func) dfs(entries []*Block, succFn linkedBlocks, dfnum, order, parent [
 	return
 }
 
-// dominators computes the dominator tree for f.  It returns a slice
+// dominators computes the dominator tree for f. It returns a slice
 // which maps block ID to the immediate dominator of that block.
-// Unreachable blocks map to nil.  The entry block maps to nil.
+// Unreachable blocks map to nil. The entry block maps to nil.
 func dominators(f *Func) []*Block {
 	preds := func(b *Block) []*Block { return b.Preds }
 	succs := func(b *Block) []*Block { return b.Succs }
@@ -298,9 +298,9 @@ func eval(v ID, ancestor []ID, semi []ID, dfnum []ID, best []ID) ID {
 	return best[v]
 }
 
-// dominators computes the dominator tree for f.  It returns a slice
+// dominators computes the dominator tree for f. It returns a slice
 // which maps block ID to the immediate dominator of that block.
-// Unreachable blocks map to nil.  The entry block maps to nil.
+// Unreachable blocks map to nil. The entry block maps to nil.
 func dominatorsSimple(f *Func) []*Block {
 	// A simple algorithm for now
 	// Cooper, Harvey, Kennedy
diff --git a/src/cmd/compile/internal/ssa/flagalloc.go b/src/cmd/compile/internal/ssa/flagalloc.go
index 7ed1fe5908..b9a974155e 100644
--- a/src/cmd/compile/internal/ssa/flagalloc.go
+++ b/src/cmd/compile/internal/ssa/flagalloc.go
@@ -7,18 +7,18 @@ package ssa
 const flagRegMask = regMask(1) << 33 // TODO: arch-specific
 
 // flagalloc allocates the flag register among all the flag-generating
-// instructions.  Flag values are recomputed if they need to be
+// instructions. Flag values are recomputed if they need to be
 // spilled/restored.
 func flagalloc(f *Func) {
 	// Compute the in-register flag value we want at the end of
-	// each block.  This is basically a best-effort live variable
+	// each block. This is basically a best-effort live variable
 	// analysis, so it can be much simpler than a full analysis.
 	// TODO: do we really need to keep flag values live across blocks?
 	// Could we force the flags register to be unused at basic block
 	// boundaries?  Then we wouldn't need this computation.
 	end := make([]*Value, f.NumBlocks())
 	for n := 0; n < 2; n++ {
-		// Walk blocks backwards.  Poor-man's postorder traversal.
+		// Walk blocks backwards. Poor-man's postorder traversal.
 		for i := len(f.Blocks) - 1; i >= 0; i-- {
 			b := f.Blocks[i]
 			// Walk values backwards to figure out what flag
@@ -117,7 +117,7 @@ func flagalloc(f *Func) {
 			// subsequent blocks.
 			_ = v.copyInto(b)
 			// Note: this flag generator is not properly linked up
-			// with the flag users.  This breaks the SSA representation.
+			// with the flag users. This breaks the SSA representation.
 			// We could fix up the users with another pass, but for now
 			// we'll just leave it.  (Regalloc has the same issue for
 			// standard regs, and it runs next.)
diff --git a/src/cmd/compile/internal/ssa/func.go b/src/cmd/compile/internal/ssa/func.go
index 7cc5f6c8d9..b648832d64 100644
--- a/src/cmd/compile/internal/ssa/func.go
+++ b/src/cmd/compile/internal/ssa/func.go
@@ -10,7 +10,7 @@ import (
 )
 
 // A Func represents a Go func declaration (or function literal) and
-// its body.  This package compiles each Func independently.
+// its body. This package compiles each Func independently.
 type Func struct {
 	Config     *Config     // architecture information
 	pass       *pass       // current pass information (name, options, etc.)
@@ -29,7 +29,7 @@ type Func struct {
 
 	// map from LocalSlot to set of Values that we want to store in that slot.
 	NamedValues map[LocalSlot][]*Value
-	// Names is a copy of NamedValues.Keys.  We keep a separate list
+	// Names is a copy of NamedValues.Keys. We keep a separate list
 	// of keys to make iteration order deterministic.
 	Names []LocalSlot
 
@@ -109,7 +109,7 @@ func (f *Func) logStat(key string, args ...interface{}) {
 	f.Config.Warnl(int(f.Entry.Line), "\t%s\t%s%s\t%s", f.pass.name, key, value, f.Name)
 }
 
-// freeValue frees a value.  It must no longer be referenced.
+// freeValue frees a value. It must no longer be referenced.
 func (f *Func) freeValue(v *Value) {
 	if v.Block == nil {
 		f.Fatalf("trying to free an already freed value")
@@ -177,7 +177,7 @@ func (b *Block) NewValue0I(line int32, op Op, t Type, auxint int64) *Value {
 // NewValue returns a new value in the block with no arguments and an aux value.
 func (b *Block) NewValue0A(line int32, op Op, t Type, aux interface{}) *Value {
 	if _, ok := aux.(int64); ok {
-		// Disallow int64 aux values.  They should be in the auxint field instead.
+		// Disallow int64 aux values. They should be in the auxint field instead.
 		// Maybe we want to allow this at some point, but for now we disallow it
 		// to prevent errors like using NewValue1A instead of NewValue1I.
 		b.Fatalf("aux field has int64 type op=%s type=%s aux=%v", op, t, aux)
diff --git a/src/cmd/compile/internal/ssa/gen/AMD64.rules b/src/cmd/compile/internal/ssa/gen/AMD64.rules
index 167ec82d18..25a8861130 100644
--- a/src/cmd/compile/internal/ssa/gen/AMD64.rules
+++ b/src/cmd/compile/internal/ssa/gen/AMD64.rules
@@ -3,8 +3,8 @@
 // license that can be found in the LICENSE file.
 
 // x86 register conventions:
-//  - Integer types live in the low portion of registers.  Upper portions are junk.
-//  - Boolean types use the low-order byte of a register.  Upper bytes are junk.
+//  - Integer types live in the low portion of registers. Upper portions are junk.
+//  - Boolean types use the low-order byte of a register. Upper bytes are junk.
 //  - We do not use AH,BH,CH,DH registers.
 //  - Floating-point types will live in the low natural slot of an sse2 register.
 //    Unused portions are junk.
@@ -335,7 +335,7 @@
 //	ADDQ	$16, SI
 //	MOVUPS	X0, (DI)
 //	ADDQ	$16, DI
-// and 64 is the number of such blocks.  See src/runtime/duff_amd64.s:duffcopy.
+// and 64 is the number of such blocks. See src/runtime/duff_amd64.s:duffcopy.
 
 // Large copying uses REP MOVSQ.
 (Move [size] dst src mem) && size > 16*64 && size%8 == 0 ->
@@ -529,7 +529,7 @@
 
 // Note: the word and byte shifts keep the low 5 bits (not the low 4 or 3 bits)
 // because the x86 instructions are defined to use all 5 bits of the shift even
-// for the small shifts.  I don't think we'll ever generate a weird shift (e.g.
+// for the small shifts. I don't think we'll ever generate a weird shift (e.g.
 // (SHLW x (MOVWconst [24])), but just in case.
 
 (CMPQ x (MOVQconst [c])) && is32Bit(c) -> (CMPQconst x [c])
@@ -598,7 +598,7 @@
 
 // sign extended loads
 // Note: The combined instruction must end up in the same block
-// as the original load.  If not, we end up making a value with
+// as the original load. If not, we end up making a value with
 // memory type live in two different blocks, which can lead to
 // multiple memory values alive simultaneously.
 (MOVBQSX (MOVBload [off] {sym} ptr mem)) -> @v.Args[0].Block (MOVBQSXload <v.Type> [off] {sym} ptr mem)
diff --git a/src/cmd/compile/internal/ssa/gen/AMD64Ops.go b/src/cmd/compile/internal/ssa/gen/AMD64Ops.go
index af08d18978..59a94c887e 100644
--- a/src/cmd/compile/internal/ssa/gen/AMD64Ops.go
+++ b/src/cmd/compile/internal/ssa/gen/AMD64Ops.go
@@ -141,7 +141,7 @@ func init() {
 	// Suffixes encode the bit width of various instructions.
 	// Q = 64 bit, L = 32 bit, W = 16 bit, B = 8 bit
 
-	// TODO: 2-address instructions.  Mark ops as needing matching input/output regs.
+	// TODO: 2-address instructions. Mark ops as needing matching input/output regs.
 	var AMD64ops = []opData{
 		// fp ops
 		{name: "ADDSS", argLength: 2, reg: fp21, asm: "ADDSS"},    // fp32 add
@@ -500,12 +500,12 @@ func init() {
 		// arg0=ptr/int arg1=mem, output=int/ptr
 		{name: "MOVQconvert", argLength: 2, reg: gp11nf, asm: "MOVQ"},
 
-		// Constant flag values.  For any comparison, there are 5 possible
+		// Constant flag values. For any comparison, there are 5 possible
 		// outcomes: the three from the signed total order (<,==,>) and the
-		// three from the unsigned total order.  The == cases overlap.
+		// three from the unsigned total order. The == cases overlap.
 		// Note: there's a sixth "unordered" outcome for floating-point
 		// comparisons, but we don't use such a beast yet.
-		// These ops are for temporary use by rewrite rules.  They
+		// These ops are for temporary use by rewrite rules. They
 		// cannot appear in the generated assembly.
 		{name: "FlagEQ"},     // equal
 		{name: "FlagLT_ULT"}, // signed < and unsigned <
diff --git a/src/cmd/compile/internal/ssa/gen/generic.rules b/src/cmd/compile/internal/ssa/gen/generic.rules
index 11c7b9d7a1..5c23fdf614 100644
--- a/src/cmd/compile/internal/ssa/gen/generic.rules
+++ b/src/cmd/compile/internal/ssa/gen/generic.rules
@@ -643,7 +643,7 @@
     (Arg <t.FieldType(3)> {n} [off+t.FieldOff(3)]))
 
 // strength reduction of divide by a constant.
-// Note: frontend does <=32 bits.  We only need to do 64 bits here.
+// Note: frontend does <=32 bits. We only need to do 64 bits here.
 // TODO: Do them all here?
 
 // Div/mod by 1.  Currently handled by frontend.
diff --git a/src/cmd/compile/internal/ssa/gen/genericOps.go b/src/cmd/compile/internal/ssa/gen/genericOps.go
index 31e45c45ea..f1ab468b21 100644
--- a/src/cmd/compile/internal/ssa/gen/genericOps.go
+++ b/src/cmd/compile/internal/ssa/gen/genericOps.go
@@ -6,7 +6,7 @@ package main
 
 var genericOps = []opData{
 	// 2-input arithmetic
-	// Types must be consistent with Go typing.  Add, for example, must take two values
+	// Types must be consistent with Go typing. Add, for example, must take two values
 	// of the same type and produces that same type.
 	{name: "Add8", argLength: 2, commutative: true}, // arg0 + arg1
 	{name: "Add16", argLength: 2, commutative: true},
@@ -250,7 +250,7 @@ var genericOps = []opData{
 	// arg0=ptr/int arg1=mem, output=int/ptr
 	{name: "Convert", argLength: 2},
 
-	// constants.  Constant values are stored in the aux or
+	// constants. Constant values are stored in the aux or
 	// auxint fields.
 	{name: "ConstBool", aux: "Bool"},     // auxint is 0 for false and 1 for true
 	{name: "ConstString", aux: "String"}, // value is aux.(string)
@@ -270,7 +270,7 @@ var genericOps = []opData{
 
 	// The address of a variable.  arg0 is the base pointer (SB or SP, depending
 	// on whether it is a global or stack variable).  The Aux field identifies the
-	// variable.  It will be either an *ExternSymbol (with arg0=SB), *ArgSymbol (arg0=SP),
+	// variable. It will be either an *ExternSymbol (with arg0=SB), *ArgSymbol (arg0=SP),
 	// or *AutoSymbol (arg0=SP).
 	{name: "Addr", argLength: 1, aux: "Sym"}, // Address of a variable.  Arg0=SP or SB.  Aux identifies the variable.
 
@@ -284,8 +284,8 @@ var genericOps = []opData{
 	{name: "Move", argLength: 3, aux: "Int64"},              // arg0=destptr, arg1=srcptr, arg2=mem, auxint=size.  Returns memory.
 	{name: "Zero", argLength: 2, aux: "Int64"},              // arg0=destptr, arg1=mem, auxint=size. Returns memory.
 
-	// Function calls.  Arguments to the call have already been written to the stack.
-	// Return values appear on the stack.  The method receiver, if any, is treated
+	// Function calls. Arguments to the call have already been written to the stack.
+	// Return values appear on the stack. The method receiver, if any, is treated
 	// as a phantom first argument.
 	{name: "ClosureCall", argLength: 3, aux: "Int64"}, // arg0=code pointer, arg1=context ptr, arg2=memory.  auxint=arg size.  Returns memory.
 	{name: "StaticCall", argLength: 1, aux: "SymOff"}, // call function aux.(*gc.Sym), arg0=memory.  auxint=arg size.  Returns memory.
@@ -368,17 +368,17 @@ var genericOps = []opData{
 	{name: "StructMake4", argLength: 4},                // arg0..3=field0..3.  Returns struct.
 	{name: "StructSelect", argLength: 1, aux: "Int64"}, // arg0=struct, auxint=field index.  Returns the auxint'th field.
 
-	// Spill&restore ops for the register allocator.  These are
+	// Spill&restore ops for the register allocator. These are
 	// semantically identical to OpCopy; they do not take/return
-	// stores like regular memory ops do.  We can get away without memory
+	// stores like regular memory ops do. We can get away without memory
 	// args because we know there is no aliasing of spill slots on the stack.
 	{name: "StoreReg", argLength: 1},
 	{name: "LoadReg", argLength: 1},
 
-	// Used during ssa construction.  Like Copy, but the arg has not been specified yet.
+	// Used during ssa construction. Like Copy, but the arg has not been specified yet.
 	{name: "FwdRef"},
 
-	// Unknown value.  Used for Values whose values don't matter because they are dead code.
+	// Unknown value. Used for Values whose values don't matter because they are dead code.
 	{name: "Unknown"},
 
 	{name: "VarDef", argLength: 1, aux: "Sym", typ: "Mem"}, // aux is a *gc.Node of a variable that is about to be initialized.  arg0=mem, returns mem
diff --git a/src/cmd/compile/internal/ssa/gen/main.go b/src/cmd/compile/internal/ssa/gen/main.go
index 660511e46c..2736ed72f7 100644
--- a/src/cmd/compile/internal/ssa/gen/main.go
+++ b/src/cmd/compile/internal/ssa/gen/main.go
@@ -149,8 +149,8 @@ func genOp() {
 			}
 			fmt.Fprintln(w, "reg:regInfo{")
 
-			// Compute input allocation order.  We allocate from the
-			// most to the least constrained input.  This order guarantees
+			// Compute input allocation order. We allocate from the
+			// most to the least constrained input. This order guarantees
 			// that we will always be able to find a register.
 			var s []intPair
 			for i, r := range v.reg.inputs {
diff --git a/src/cmd/compile/internal/ssa/gen/rulegen.go b/src/cmd/compile/internal/ssa/gen/rulegen.go
index e3e3efac41..61a420270f 100644
--- a/src/cmd/compile/internal/ssa/gen/rulegen.go
+++ b/src/cmd/compile/internal/ssa/gen/rulegen.go
@@ -39,8 +39,8 @@ import (
 // variable ::= some token
 // opcode   ::= one of the opcodes from ../op.go (without the Op prefix)
 
-// extra conditions is just a chunk of Go that evaluates to a boolean.  It may use
-// variables declared in the matching sexpr.  The variable "v" is predefined to be
+// extra conditions is just a chunk of Go that evaluates to a boolean. It may use
+// variables declared in the matching sexpr. The variable "v" is predefined to be
 // the value matched by the entire rule.
 
 // If multiple rules match, the first one in file order is selected.
@@ -93,8 +93,8 @@ func genRules(arch arch) {
 		lineno++
 		line := scanner.Text()
 		if i := strings.Index(line, "//"); i >= 0 {
-			// Remove comments.  Note that this isn't string safe, so
-			// it will truncate lines with // inside strings.  Oh well.
+			// Remove comments. Note that this isn't string safe, so
+			// it will truncate lines with // inside strings. Oh well.
 			line = line[:i]
 		}
 		rule += " " + line
@@ -159,7 +159,7 @@ func genRules(arch arch) {
 	fmt.Fprintf(w, "return false\n")
 	fmt.Fprintf(w, "}\n")
 
-	// Generate a routine per op.  Note that we don't make one giant routine
+	// Generate a routine per op. Note that we don't make one giant routine
 	// because it is too big for some compilers.
 	for _, op := range ops {
 		fmt.Fprintf(w, "func rewriteValue%s_%s(v *Value, config *Config) bool {\n", arch.name, opName(op, arch))
@@ -190,7 +190,7 @@ func genRules(arch arch) {
 		fmt.Fprintf(w, "}\n")
 	}
 
-	// Generate block rewrite function.  There are only a few block types
+	// Generate block rewrite function. There are only a few block types
 	// so we can make this one function with a switch.
 	fmt.Fprintf(w, "func rewriteBlock%s(b *Block) bool {\n", arch.name)
 	fmt.Fprintf(w, "switch b.Kind {\n")
@@ -229,7 +229,7 @@ func genRules(arch arch) {
 				fmt.Fprintf(w, "if !(%s) {\nbreak\n}\n", cond)
 			}
 
-			// Rule matches.  Generate result.
+			// Rule matches. Generate result.
 			t := split(result[1 : len(result)-1]) // remove parens, then split
 			newsuccs := t[2:]
 
@@ -316,7 +316,7 @@ func genMatch(w io.Writer, arch arch, match string) {
 func genMatch0(w io.Writer, arch arch, match, v string, m map[string]string, top bool) {
 	if match[0] != '(' {
 		if _, ok := m[match]; ok {
-			// variable already has a definition.  Check whether
+			// variable already has a definition. Check whether
 			// the old definition and the new definition match.
 			// For example, (add x x).  Equality is just pointer equality
 			// on Values (so cse is important to do before lowering).
@@ -332,7 +332,7 @@ func genMatch0(w io.Writer, arch arch, match, v string, m map[string]string, top
 		return
 	}
 
-	// split body up into regions.  Split by spaces/tabs, except those
+	// split body up into regions. Split by spaces/tabs, except those
 	// contained in () or {}.
 	s := split(match[1 : len(match)-1]) // remove parens, then split
 
@@ -348,7 +348,7 @@ func genMatch0(w io.Writer, arch arch, match, v string, m map[string]string, top
 			// type restriction
 			t := a[1 : len(a)-1] // remove <>
 			if !isVariable(t) {
-				// code.  We must match the results of this code.
+				// code. We must match the results of this code.
 				fmt.Fprintf(w, "if %s.Type != %s {\nbreak\n}\n", v, t)
 			} else {
 				// variable
diff --git a/src/cmd/compile/internal/ssa/likelyadjust.go b/src/cmd/compile/internal/ssa/likelyadjust.go
index 6ce8705272..b01651971f 100755
--- a/src/cmd/compile/internal/ssa/likelyadjust.go
+++ b/src/cmd/compile/internal/ssa/likelyadjust.go
@@ -76,7 +76,7 @@ func describeBranchPrediction(f *Func, b *Block, likely, not int8, prediction Br
 func likelyadjust(f *Func) {
 	// The values assigned to certain and local only matter
 	// in their rank order.  0 is default, more positive
-	// is less likely.  It's possible to assign a negative
+	// is less likely. It's possible to assign a negative
 	// unlikeliness (though not currently the case).
 	certain := make([]int8, f.NumBlocks()) // In the long run, all outcomes are at least this bad. Mainly for Exit
 	local := make([]int8, f.NumBlocks())   // for our immediate predecessors.
@@ -113,7 +113,7 @@ func likelyadjust(f *Func) {
 				// Notice that this can act like a "reset" on unlikeliness at loops; the
 				// default "everything returns" unlikeliness is erased by min with the
 				// backedge likeliness; however a loop with calls on every path will be
-				// tagged with call cost.  Net effect is that loop entry is favored.
+				// tagged with call cost. Net effect is that loop entry is favored.
 				b0 := b.Succs[0].ID
 				b1 := b.Succs[1].ID
 				certain[b.ID] = min8(certain[b0], certain[b1])
@@ -204,7 +204,7 @@ func (l *loop) LongString() string {
 
 // nearestOuterLoop returns the outer loop of loop most nearly
 // containing block b; the header must dominate b.  loop itself
-// is assumed to not be that loop.  For acceptable performance,
+// is assumed to not be that loop. For acceptable performance,
 // we're relying on loop nests to not be terribly deep.
 func (l *loop) nearestOuterLoop(sdom sparseTree, b *Block) *loop {
 	var o *loop
diff --git a/src/cmd/compile/internal/ssa/magic.go b/src/cmd/compile/internal/ssa/magic.go
index a8e84d5c93..f6297fdfa5 100644
--- a/src/cmd/compile/internal/ssa/magic.go
+++ b/src/cmd/compile/internal/ssa/magic.go
@@ -6,7 +6,7 @@ package ssa
 
 // A copy of the code in ../gc/subr.go.
 // We can't use it directly because it would generate
-// an import cycle.  TODO: move to a common support package.
+// an import cycle. TODO: move to a common support package.
 
 // argument passing to/from
 // smagic and umagic
diff --git a/src/cmd/compile/internal/ssa/nilcheck.go b/src/cmd/compile/internal/ssa/nilcheck.go
index f8caa7b042..ccd443197a 100644
--- a/src/cmd/compile/internal/ssa/nilcheck.go
+++ b/src/cmd/compile/internal/ssa/nilcheck.go
@@ -43,7 +43,7 @@ func nilcheckelim(f *Func) {
 	work = append(work, bp{block: f.Entry})
 
 	// map from value ID to bool indicating if value is known to be non-nil
-	// in the current dominator path being walked.  This slice is updated by
+	// in the current dominator path being walked. This slice is updated by
 	// walkStates to maintain the known non-nil values.
 	nonNilValues := make([]bool, f.NumValues())
 
diff --git a/src/cmd/compile/internal/ssa/op.go b/src/cmd/compile/internal/ssa/op.go
index 7b2a8f8f04..d64a41ed45 100644
--- a/src/cmd/compile/internal/ssa/op.go
+++ b/src/cmd/compile/internal/ssa/op.go
@@ -52,7 +52,7 @@ const (
 	auxSymValAndOff         // aux is a symbol, auxInt is a ValAndOff
 )
 
-// A ValAndOff is used by the several opcodes.  It holds
+// A ValAndOff is used by the several opcodes. It holds
 // both a value and a pointer offset.
 // A ValAndOff is intended to be encoded into an AuxInt field.
 // The zero ValAndOff encodes a value of 0 and an offset of 0.
diff --git a/src/cmd/compile/internal/ssa/phielim.go b/src/cmd/compile/internal/ssa/phielim.go
index d69449ee21..0461e6e079 100644
--- a/src/cmd/compile/internal/ssa/phielim.go
+++ b/src/cmd/compile/internal/ssa/phielim.go
@@ -5,8 +5,8 @@
 package ssa
 
 // phielim eliminates redundant phi values from f.
-// A phi is redundant if its arguments are all equal.  For
-// purposes of counting, ignore the phi itself.  Both of
+// A phi is redundant if its arguments are all equal. For
+// purposes of counting, ignore the phi itself. Both of
 // these phis are redundant:
 //   v = phi(x,x,x)
 //   v = phi(x,v,x,v)
@@ -58,8 +58,8 @@ func phielimValue(v *Value) bool {
 	}
 
 	if w == nil {
-		// v references only itself.  It must be in
-		// a dead code loop.  Don't bother modifying it.
+		// v references only itself. It must be in
+		// a dead code loop. Don't bother modifying it.
 		return false
 	}
 	v.Op = OpCopy
diff --git a/src/cmd/compile/internal/ssa/regalloc.go b/src/cmd/compile/internal/ssa/regalloc.go
index e900a3cfb8..f9680e4202 100644
--- a/src/cmd/compile/internal/ssa/regalloc.go
+++ b/src/cmd/compile/internal/ssa/regalloc.go
@@ -4,9 +4,9 @@
 
 // Register allocation.
 //
-// We use a version of a linear scan register allocator.  We treat the
+// We use a version of a linear scan register allocator. We treat the
 // whole function as a single long basic block and run through
-// it using a greedy register allocator.  Then all merge edges
+// it using a greedy register allocator. Then all merge edges
 // (those targeting a block with len(Preds)>1) are processed to
 // shuffle data into the place that the target of the edge expects.
 //
@@ -15,7 +15,7 @@
 // value whose next use is farthest in the future.
 //
 // The register allocator requires that a block is not scheduled until
-// at least one of its predecessors have been scheduled.  The most recent
+// at least one of its predecessors have been scheduled. The most recent
 // such predecessor provides the starting register state for a block.
 //
 // It also requires that there are no critical edges (critical =
@@ -29,28 +29,28 @@
 // For every value, we generate a spill immediately after the value itself.
 //     x = Op y z    : AX
 //     x2 = StoreReg x
-// While AX still holds x, any uses of x will use that value.  When AX is needed
+// While AX still holds x, any uses of x will use that value. When AX is needed
 // for another value, we simply reuse AX.  Spill code has already been generated
-// so there is no code generated at "spill" time.  When x is referenced
+// so there is no code generated at "spill" time. When x is referenced
 // subsequently, we issue a load to restore x to a register using x2 as
 //  its argument:
 //    x3 = Restore x2 : CX
 // x3 can then be used wherever x is referenced again.
 // If the spill (x2) is never used, it will be removed at the end of regalloc.
 //
-// Phi values are special, as always.  We define two kinds of phis, those
+// Phi values are special, as always. We define two kinds of phis, those
 // where the merge happens in a register (a "register" phi) and those where
 // the merge happens in a stack location (a "stack" phi).
 //
 // A register phi must have the phi and all of its inputs allocated to the
-// same register.  Register phis are spilled similarly to regular ops:
+// same register. Register phis are spilled similarly to regular ops:
 //     b1: y = ... : AX        b2: z = ... : AX
 //         goto b3                 goto b3
 //     b3: x = phi(y, z) : AX
 //         x2 = StoreReg x
 //
 // A stack phi must have the phi and all of its inputs allocated to the same
-// stack location.  Stack phis start out life already spilled - each phi
+// stack location. Stack phis start out life already spilled - each phi
 // input must be a store (using StoreReg) at the end of the corresponding
 // predecessor block.
 //     b1: y = ... : AX        b2: z = ... : BX
@@ -64,12 +64,12 @@
 // TODO
 
 // Use an affinity graph to mark two values which should use the
-// same register.  This affinity graph will be used to prefer certain
-// registers for allocation.  This affinity helps eliminate moves that
+// same register. This affinity graph will be used to prefer certain
+// registers for allocation. This affinity helps eliminate moves that
 // are required for phi implementations and helps generate allocations
 // for 2-register architectures.
 
-// Note: regalloc generates a not-quite-SSA output.  If we have:
+// Note: regalloc generates a not-quite-SSA output. If we have:
 //
 //             b1: x = ... : AX
 //                 x2 = StoreReg x
@@ -85,8 +85,8 @@
 // add a x4:CX->BX copy at the end of b4.
 // But the definition of x3 doesn't dominate b2.  We should really
 // insert a dummy phi at the start of b2 (x5=phi(x3,x4):BX) to keep
-// SSA form.  For now, we ignore this problem as remaining in strict
-// SSA form isn't needed after regalloc.  We'll just leave the use
+// SSA form. For now, we ignore this problem as remaining in strict
+// SSA form isn't needed after regalloc. We'll just leave the use
 // of x3 not dominated by the definition of x3, and the CX->BX copy
 // will have no use (so don't run deadcode after regalloc!).
 // TODO: maybe we should introduce these extra phis?
@@ -102,7 +102,7 @@ import (
 const regDebug = false // TODO: compiler flag
 const logSpills = false
 
-// regalloc performs register allocation on f.  It sets f.RegAlloc
+// regalloc performs register allocation on f. It sets f.RegAlloc
 // to the resulting allocation.
 func regalloc(f *Func) {
 	var s regAllocState
@@ -276,7 +276,7 @@ type startReg struct {
 	vid ID // pre-regalloc value needed in this register
 }
 
-// freeReg frees up register r.  Any current user of r is kicked out.
+// freeReg frees up register r. Any current user of r is kicked out.
 func (s *regAllocState) freeReg(r register) {
 	v := s.regs[r].v
 	if v == nil {
@@ -355,18 +355,18 @@ func (s *regAllocState) allocReg(v *Value, mask regMask) register {
 		return pickReg(mask)
 	}
 
-	// Pick a value to spill.  Spill the value with the
+	// Pick a value to spill. Spill the value with the
 	// farthest-in-the-future use.
 	// TODO: Prefer registers with already spilled Values?
 	// TODO: Modify preference using affinity graph.
 	// TODO: if a single value is in multiple registers, spill one of them
 	// before spilling a value in just a single register.
 
-	// SP and SB are allocated specially.  No regular value should
+	// SP and SB are allocated specially. No regular value should
 	// be allocated to them.
 	mask &^= 1<<4 | 1<<32
 
-	// Find a register to spill.  We spill the register containing the value
+	// Find a register to spill. We spill the register containing the value
 	// whose next use is as far in the future as possible.
 	// https://en.wikipedia.org/wiki/Page_replacement_algorithm#The_theoretically_optimal_page_replacement_algorithm
 	var r register
@@ -378,7 +378,7 @@ func (s *regAllocState) allocReg(v *Value, mask regMask) register {
 		v := s.regs[t].v
 		if n := s.values[v.ID].uses.dist; n > maxuse {
 			// v's next use is farther in the future than any value
-			// we've seen so far.  A new best spill candidate.
+			// we've seen so far. A new best spill candidate.
 			r = t
 			maxuse = n
 		}
@@ -476,7 +476,7 @@ func (s *regAllocState) init(f *Func) {
 	}
 	s.computeLive()
 
-	// Compute block order.  This array allows us to distinguish forward edges
+	// Compute block order. This array allows us to distinguish forward edges
 	// from backward edges and compute how far they go.
 	blockOrder := make([]int32, f.NumBlocks())
 	for i, b := range f.Blocks {
@@ -589,7 +589,7 @@ func (s *regAllocState) regalloc(f *Func) {
 			liveSet.remove(v.ID)
 			if v.Op == OpPhi {
 				// Remove v from the live set, but don't add
-				// any inputs.  This is the state the len(b.Preds)>1
+				// any inputs. This is the state the len(b.Preds)>1
 				// case below desires; it wants to process phis specially.
 				continue
 			}
@@ -653,7 +653,7 @@ func (s *regAllocState) regalloc(f *Func) {
 				}
 			}
 		} else {
-			// This is the complicated case.  We have more than one predecessor,
+			// This is the complicated case. We have more than one predecessor,
 			// which means we may have Phi ops.
 
 			// Copy phi ops into new schedule.
@@ -674,7 +674,7 @@ func (s *regAllocState) regalloc(f *Func) {
 				}
 			}
 
-			// Decide on registers for phi ops.  Use the registers determined
+			// Decide on registers for phi ops. Use the registers determined
 			// by the primary predecessor if we can.
 			// TODO: pick best of (already processed) predecessors?
 			// Majority vote?  Deepest nesting level?
@@ -728,7 +728,7 @@ func (s *regAllocState) regalloc(f *Func) {
 				}
 			}
 
-			// Set registers for phis.  Add phi spill code.
+			// Set registers for phis. Add phi spill code.
 			for i, v := range phis {
 				if !s.values[v.ID].needReg {
 					continue
@@ -861,8 +861,8 @@ func (s *regAllocState) regalloc(f *Func) {
 				continue
 			}
 			if v.Op == OpArg {
-				// Args are "pre-spilled" values.  We don't allocate
-				// any register here.  We just set up the spill pointer to
+				// Args are "pre-spilled" values. We don't allocate
+				// any register here. We just set up the spill pointer to
 				// point at itself and any later user will restore it to use it.
 				s.values[v.ID].spill = v
 				s.values[v.ID].spillUsed = true // use is guaranteed
@@ -886,7 +886,7 @@ func (s *regAllocState) regalloc(f *Func) {
 				continue
 			}
 
-			// Move arguments to registers.  Process in an ordering defined
+			// Move arguments to registers. Process in an ordering defined
 			// by the register specification (most constrained first).
 			args = append(args[:0], v.Args...)
 			for _, i := range regspec.inputs {
@@ -926,7 +926,7 @@ func (s *regAllocState) regalloc(f *Func) {
 			}
 			b.Values = append(b.Values, v)
 
-			// Issue a spill for this value.  We issue spills unconditionally,
+			// Issue a spill for this value. We issue spills unconditionally,
 			// then at the end of regalloc delete the ones we never use.
 			// TODO: schedule the spill at a point that dominates all restores.
 			// The restore may be off in an unlikely branch somewhere and it
@@ -1002,7 +1002,7 @@ func (s *regAllocState) regalloc(f *Func) {
 
 		// If a value is live at the end of the block and
 		// isn't in a register, remember that its spill location
-		// is live.  We need to remember this information so that
+		// is live. We need to remember this information so that
 		// the liveness analysis in stackalloc is correct.
 		for _, e := range s.live[b.ID] {
 			if s.values[e.ID].regs != 0 {
@@ -1201,7 +1201,7 @@ func (e *edgeState) process() {
 			}
 		}
 		if i < len(dsts) {
-			// Made some progress.  Go around again.
+			// Made some progress. Go around again.
 			dsts = dsts[:i]
 
 			// Append any extras destinations we generated.
@@ -1210,7 +1210,7 @@ func (e *edgeState) process() {
 			continue
 		}
 
-		// We made no progress.  That means that any
+		// We made no progress. That means that any
 		// remaining unsatisfied moves are in simple cycles.
 		// For example, A -> B -> C -> D -> A.
 		//   A ----> B
@@ -1229,7 +1229,7 @@ func (e *edgeState) process() {
 		// When we resume the outer loop, the A->B move can now proceed,
 		// and eventually the whole cycle completes.
 
-		// Copy any cycle location to a temp register.  This duplicates
+		// Copy any cycle location to a temp register. This duplicates
 		// one of the cycle entries, allowing the just duplicated value
 		// to be overwritten and the cycle to proceed.
 		loc := dsts[0].loc
@@ -1248,7 +1248,7 @@ func (e *edgeState) process() {
 	}
 }
 
-// processDest generates code to put value vid into location loc.  Returns true
+// processDest generates code to put value vid into location loc. Returns true
 // if progress was made.
 func (e *edgeState) processDest(loc Location, vid ID, splice **Value) bool {
 	occupant := e.contents[loc]
@@ -1258,7 +1258,7 @@ func (e *edgeState) processDest(loc Location, vid ID, splice **Value) bool {
 		if splice != nil {
 			*splice = occupant.c
 		}
-		// Note: if splice==nil then c will appear dead.  This is
+		// Note: if splice==nil then c will appear dead. This is
 		// non-SSA formed code, so be careful after this pass not to run
 		// deadcode elimination.
 		return true
@@ -1306,7 +1306,7 @@ func (e *edgeState) processDest(loc Location, vid ID, splice **Value) bool {
 		if dstReg {
 			x = v.copyInto(e.p)
 		} else {
-			// Rematerialize into stack slot.  Need a free
+			// Rematerialize into stack slot. Need a free
 			// register to accomplish this.
 			e.erase(loc) // see pre-clobber comment below
 			r := e.findRegFor(v.Type)
@@ -1330,15 +1330,15 @@ func (e *edgeState) processDest(loc Location, vid ID, splice **Value) bool {
 			if dstReg {
 				x = e.p.NewValue1(c.Line, OpLoadReg, c.Type, c)
 			} else {
-				// mem->mem.  Use temp register.
+				// mem->mem. Use temp register.
 
-				// Pre-clobber destination.  This avoids the
+				// Pre-clobber destination. This avoids the
 				// following situation:
 				//   - v is currently held in R0 and stacktmp0.
 				//   - We want to copy stacktmp1 to stacktmp0.
 				//   - We choose R0 as the temporary register.
 				// During the copy, both R0 and stacktmp0 are
-				// clobbered, losing both copies of v.  Oops!
+				// clobbered, losing both copies of v. Oops!
 				// Erasing the destination early means R0 will not
 				// be chosen as the temp register, as it will then
 				// be the last copy of v.
@@ -1438,7 +1438,7 @@ func (e *edgeState) findRegFor(typ Type) Location {
 		m = e.s.compatRegs(e.s.f.Config.fe.TypeInt64())
 	}
 
-	// Pick a register.  In priority order:
+	// Pick a register. In priority order:
 	// 1) an unused register
 	// 2) a non-unique register not holding a final value
 	// 3) a non-unique register
@@ -1455,9 +1455,9 @@ func (e *edgeState) findRegFor(typ Type) Location {
 		return &registers[pickReg(x)]
 	}
 
-	// No register is available.  Allocate a temp location to spill a register to.
+	// No register is available. Allocate a temp location to spill a register to.
 	// The type of the slot is immaterial - it will not be live across
-	// any safepoint.  Just use a type big enough to hold any register.
+	// any safepoint. Just use a type big enough to hold any register.
 	typ = e.s.f.Config.fe.TypeInt64()
 	t := LocalSlot{e.s.f.Config.fe.Auto(typ), typ, 0}
 	// TODO: reuse these slots.
@@ -1471,7 +1471,7 @@ func (e *edgeState) findRegFor(typ Type) Location {
 				if regDebug {
 					fmt.Printf("  SPILL %s->%s %s\n", r.Name(), t.Name(), x.LongString())
 				}
-				// r will now be overwritten by the caller.  At some point
+				// r will now be overwritten by the caller. At some point
 				// later, the newly saved value will be moved back to its
 				// final destination in processDest.
 				return r
@@ -1508,10 +1508,10 @@ type liveInfo struct {
 }
 
 // computeLive computes a map from block ID to a list of value IDs live at the end
-// of that block.  Together with the value ID is a count of how many instructions
-// to the next use of that value.  The resulting map is stored at s.live.
+// of that block. Together with the value ID is a count of how many instructions
+// to the next use of that value. The resulting map is stored at s.live.
 // TODO: this could be quadratic if lots of variables are live across lots of
-// basic blocks.  Figure out a way to make this function (or, more precisely, the user
+// basic blocks. Figure out a way to make this function (or, more precisely, the user
 // of this function) require only linear size & time.
 func (s *regAllocState) computeLive() {
 	f := s.f
diff --git a/src/cmd/compile/internal/ssa/rewrite.go b/src/cmd/compile/internal/ssa/rewrite.go
index 60509d214e..86f3c2010e 100644
--- a/src/cmd/compile/internal/ssa/rewrite.go
+++ b/src/cmd/compile/internal/ssa/rewrite.go
@@ -105,7 +105,7 @@ func addOff(x, y int64) int64 {
 	return z
 }
 
-// mergeSym merges two symbolic offsets.  There is no real merging of
+// mergeSym merges two symbolic offsets. There is no real merging of
 // offsets, we just pick the non-nil one.
 func mergeSym(x, y interface{}) interface{} {
 	if x == nil {
diff --git a/src/cmd/compile/internal/ssa/schedule.go b/src/cmd/compile/internal/ssa/schedule.go
index dd0a42a5dd..f47f93c5c0 100644
--- a/src/cmd/compile/internal/ssa/schedule.go
+++ b/src/cmd/compile/internal/ssa/schedule.go
@@ -15,10 +15,10 @@ const (
 	ScoreCount // not a real score
 )
 
-// Schedule the Values in each Block.  After this phase returns, the
+// Schedule the Values in each Block. After this phase returns, the
 // order of b.Values matters and is the order in which those values
-// will appear in the assembly output.  For now it generates a
-// reasonable valid schedule using a priority queue.  TODO(khr):
+// will appear in the assembly output. For now it generates a
+// reasonable valid schedule using a priority queue. TODO(khr):
 // schedule smarter.
 func schedule(f *Func) {
 	// For each value, the number of times it is used in the block
@@ -28,7 +28,7 @@ func schedule(f *Func) {
 	// "priority" for a value
 	score := make([]uint8, f.NumValues())
 
-	// scheduling order.  We queue values in this list in reverse order.
+	// scheduling order. We queue values in this list in reverse order.
 	var order []*Value
 
 	// priority queue of legally schedulable (0 unscheduled uses) values
@@ -36,7 +36,7 @@ func schedule(f *Func) {
 
 	// maps mem values to the next live memory value
 	nextMem := make([]*Value, f.NumValues())
-	// additional pretend arguments for each Value.  Used to enforce load/store ordering.
+	// additional pretend arguments for each Value. Used to enforce load/store ordering.
 	additionalArgs := make([][]*Value, f.NumValues())
 
 	for _, b := range f.Blocks {
@@ -77,12 +77,12 @@ func schedule(f *Func) {
 				uses[v.ID]++
 			}
 		}
-		// Compute score.  Larger numbers are scheduled closer to the end of the block.
+		// Compute score. Larger numbers are scheduled closer to the end of the block.
 		for _, v := range b.Values {
 			switch {
 			case v.Op == OpAMD64LoweredGetClosurePtr:
 				// We also score GetLoweredClosurePtr as early as possible to ensure that the
-				// context register is not stomped.  GetLoweredClosurePtr should only appear
+				// context register is not stomped. GetLoweredClosurePtr should only appear
 				// in the entry block where there are no phi functions, so there is no
 				// conflict or ambiguity here.
 				if b != f.Entry {
@@ -96,8 +96,8 @@ func schedule(f *Func) {
 				// We want all the vardefs next.
 				score[v.ID] = ScoreVarDef
 			case v.Type.IsMemory():
-				// Schedule stores as early as possible.  This tends to
-				// reduce register pressure.  It also helps make sure
+				// Schedule stores as early as possible. This tends to
+				// reduce register pressure. It also helps make sure
 				// VARDEF ops are scheduled before the corresponding LEA.
 				score[v.ID] = ScoreMemory
 			case v.Type.IsFlags():
@@ -117,7 +117,7 @@ func schedule(f *Func) {
 			// Schedule values dependent on the control value at the end.
 			// This reduces the number of register spills. We don't find
 			// all values that depend on the control, just values with a
-			// direct dependency.  This is cheaper and in testing there
+			// direct dependency. This is cheaper and in testing there
 			// was no difference in the number of spills.
 			for _, v := range b.Values {
 				if v.Op != OpPhi {
diff --git a/src/cmd/compile/internal/ssa/sparsetree.go b/src/cmd/compile/internal/ssa/sparsetree.go
index 9a08f35d9d..cae91e7ddb 100644
--- a/src/cmd/compile/internal/ssa/sparsetree.go
+++ b/src/cmd/compile/internal/ssa/sparsetree.go
@@ -99,7 +99,7 @@ func (t sparseTree) numberBlock(b *Block, n int32) int32 {
 // Sibling returns a sibling of x in the dominator tree (i.e.,
 // a node with the same immediate dominator) or nil if there
 // are no remaining siblings in the arbitrary but repeatable
-// order chosen.  Because the Child-Sibling order is used
+// order chosen. Because the Child-Sibling order is used
 // to assign entry and exit numbers in the treewalk, those
 // numbers are also consistent with this order (i.e.,
 // Sibling(x) has entry number larger than x's exit number).
@@ -108,7 +108,7 @@ func (t sparseTree) Sibling(x *Block) *Block {
 }
 
 // Child returns a child of x in the dominator tree, or
-// nil if there are none.  The choice of first child is
+// nil if there are none. The choice of first child is
 // arbitrary but repeatable.
 func (t sparseTree) Child(x *Block) *Block {
 	return t[x.ID].child
diff --git a/src/cmd/compile/internal/ssa/stackalloc.go b/src/cmd/compile/internal/ssa/stackalloc.go
index 0e6cae0924..ef8a5846b0 100644
--- a/src/cmd/compile/internal/ssa/stackalloc.go
+++ b/src/cmd/compile/internal/ssa/stackalloc.go
@@ -91,8 +91,8 @@ func (s *stackAllocState) stackalloc() {
 
 	// For each type, we keep track of all the stack slots we
 	// have allocated for that type.
-	// TODO: share slots among equivalent types.  We would need to
-	// only share among types with the same GC signature.  See the
+	// TODO: share slots among equivalent types. We would need to
+	// only share among types with the same GC signature. See the
 	// type.Equal calls below for where this matters.
 	locations := map[Type][]LocalSlot{}
 
@@ -177,7 +177,7 @@ func (s *stackAllocState) stackalloc() {
 // computeLive computes a map from block ID to a list of
 // stack-slot-needing value IDs live at the end of that block.
 // TODO: this could be quadratic if lots of variables are live across lots of
-// basic blocks.  Figure out a way to make this function (or, more precisely, the user
+// basic blocks. Figure out a way to make this function (or, more precisely, the user
 // of this function) require only linear size & time.
 func (s *stackAllocState) computeLive(spillLive [][]ID) {
 	s.live = make([][]ID, s.f.NumBlocks())
@@ -206,7 +206,7 @@ func (s *stackAllocState) computeLive(spillLive [][]ID) {
 				if v.Op == OpPhi {
 					// Save phi for later.
 					// Note: its args might need a stack slot even though
-					// the phi itself doesn't.  So don't use needSlot.
+					// the phi itself doesn't. So don't use needSlot.
 					if !v.Type.IsMemory() && !v.Type.IsVoid() {
 						phis = append(phis, v)
 					}
@@ -299,7 +299,7 @@ func (s *stackAllocState) buildInterferenceGraph() {
 			if v.Op == OpArg && s.values[v.ID].needSlot {
 				// OpArg is an input argument which is pre-spilled.
 				// We add back v.ID here because we want this value
-				// to appear live even before this point.  Being live
+				// to appear live even before this point. Being live
 				// all the way to the start of the entry block prevents other
 				// values from being allocated to the same slot and clobbering
 				// the input value before we have a chance to load it.
diff --git a/src/cmd/compile/internal/ssa/value.go b/src/cmd/compile/internal/ssa/value.go
index cc8c9fe871..3ec788355d 100644
--- a/src/cmd/compile/internal/ssa/value.go
+++ b/src/cmd/compile/internal/ssa/value.go
@@ -10,21 +10,21 @@ import (
 )
 
 // A Value represents a value in the SSA representation of the program.
-// The ID and Type fields must not be modified.  The remainder may be modified
+// The ID and Type fields must not be modified. The remainder may be modified
 // if they preserve the value of the Value (e.g. changing a (mul 2 x) to an (add x x)).
 type Value struct {
-	// A unique identifier for the value.  For performance we allocate these IDs
+	// A unique identifier for the value. For performance we allocate these IDs
 	// densely starting at 1.  There is no guarantee that there won't be occasional holes, though.
 	ID ID
 
-	// The operation that computes this value.  See op.go.
+	// The operation that computes this value. See op.go.
 	Op Op
 
-	// The type of this value.  Normally this will be a Go type, but there
+	// The type of this value. Normally this will be a Go type, but there
 	// are a few other pseudo-types, see type.go.
 	Type Type
 
-	// Auxiliary info for this value.  The type of this information depends on the opcode and type.
+	// Auxiliary info for this value. The type of this information depends on the opcode and type.
 	// AuxInt is used for integer values, Aux is used for other values.
 	AuxInt int64
 	Aux    interface{}
@@ -49,7 +49,7 @@ type Value struct {
 //  OpConst      int64      0    int64 constant
 //  OpAddcq      int64      1    amd64 op: v = arg[0] + constant
 
-// short form print.  Just v#.
+// short form print. Just v#.
 func (v *Value) String() string {
 	if v == nil {
 		return "nil" // should never happen, but not panicking helps with debugging
diff --git a/src/cmd/compile/internal/x86/cgen64.go b/src/cmd/compile/internal/x86/cgen64.go
index 7e40a32db3..8bb7d371a3 100644
--- a/src/cmd/compile/internal/x86/cgen64.go
+++ b/src/cmd/compile/internal/x86/cgen64.go
@@ -95,7 +95,7 @@ func cgen64(n *gc.Node, res *gc.Node) {
 		split64(r, &lo2, &hi2)
 	}
 
-	// Do op.  Leave result in DX:AX.
+	// Do op. Leave result in DX:AX.
 	switch n.Op {
 	// TODO: Constants
 	case gc.OADD:
diff --git a/src/cmd/compile/internal/x86/gsubr.go b/src/cmd/compile/internal/x86/gsubr.go
index 98595716cf..4fd6680cb4 100644
--- a/src/cmd/compile/internal/x86/gsubr.go
+++ b/src/cmd/compile/internal/x86/gsubr.go
@@ -1511,7 +1511,7 @@ func floatmove_387(f *gc.Node, t *gc.Node) {
 		// The way the code generator uses floating-point
 	// registers, a move from F0 to F0 is intended as a no-op.
 	// On the x86, it's not: it pushes a second copy of F0
-	// on the floating point stack.  So toss it away here.
+	// on the floating point stack. So toss it away here.
 	// Also, F0 is the *only* register we ever evaluate
 	// into, so we should only see register/register as F0/F0.
 	/*
diff --git a/src/cmd/compile/internal/x86/peep.go b/src/cmd/compile/internal/x86/peep.go
index 239e9cc35f..b9f05d3b47 100644
--- a/src/cmd/compile/internal/x86/peep.go
+++ b/src/cmd/compile/internal/x86/peep.go
@@ -221,7 +221,7 @@ loop1:
 	// MOVSD removal.
 	// We never use packed registers, so a MOVSD between registers
 	// can be replaced by MOVAPD, which moves the pair of float64s
-	// instead of just the lower one.  We only use the lower one, but
+	// instead of just the lower one. We only use the lower one, but
 	// the processor can do better if we do moves using both.
 	for r := g.Start; r != nil; r = r.Link {
 		p = r.Prog
diff --git a/src/cmd/cover/cover.go b/src/cmd/cover/cover.go
index c5d1682651..46495950e9 100644
--- a/src/cmd/cover/cover.go
+++ b/src/cmd/cover/cover.go
@@ -311,8 +311,8 @@ func (f *File) addImport(path string) string {
 var slashslash = []byte("//")
 
 // initialComments returns the prefix of content containing only
-// whitespace and line comments.  Any +build directives must appear
-// within this region.  This approach is more reliable than using
+// whitespace and line comments. Any +build directives must appear
+// within this region. This approach is more reliable than using
 // go/printer to print a modified AST containing comments.
 //
 func initialComments(content []byte) []byte {
diff --git a/src/cmd/dist/build.go b/src/cmd/dist/build.go
index a8c43495c3..e0e2ba1e3b 100644
--- a/src/cmd/dist/build.go
+++ b/src/cmd/dist/build.go
@@ -284,7 +284,7 @@ func findgoversion() string {
 	}
 
 	// The $GOROOT/VERSION.cache file is a cache to avoid invoking
-	// git every time we run this command.  Unlike VERSION, it gets
+	// git every time we run this command. Unlike VERSION, it gets
 	// deleted by the clean command.
 	path = pathf("%s/VERSION.cache", goroot)
 	if isfile(path) {
@@ -399,8 +399,8 @@ func setup() {
 
 	// Create object directory.
 	// We keep it in pkg/ so that all the generated binaries
-	// are in one tree.  If pkg/obj/libgc.a exists, it is a dreg from
-	// before we used subdirectories of obj.  Delete all of obj
+	// are in one tree. If pkg/obj/libgc.a exists, it is a dreg from
+	// before we used subdirectories of obj. Delete all of obj
 	// to clean up.
 	if p := pathf("%s/pkg/obj/libgc.a", goroot); isfile(p) {
 		xremoveall(pathf("%s/pkg/obj", goroot))
diff --git a/src/cmd/dist/buildruntime.go b/src/cmd/dist/buildruntime.go
index 17dc015448..d696beb5b3 100644
--- a/src/cmd/dist/buildruntime.go
+++ b/src/cmd/dist/buildruntime.go
@@ -82,7 +82,7 @@ func mkzbootstrap(file string) {
 }
 
 // stackGuardMultiplier returns a multiplier to apply to the default
-// stack guard size.  Larger multipliers are used for non-optimized
+// stack guard size. Larger multipliers are used for non-optimized
 // builds that have larger stack frames.
 func stackGuardMultiplier() int {
 	for _, s := range strings.Split(os.Getenv("GO_GCFLAGS"), " ") {
diff --git a/src/cmd/dist/test.go b/src/cmd/dist/test.go
index 25ccfff015..5406745ffc 100644
--- a/src/cmd/dist/test.go
+++ b/src/cmd/dist/test.go
@@ -378,7 +378,7 @@ func (t *tester) registerTests() {
 	})
 
 	// Test that internal linking of standard packages does not
-	// require libgcc.  This ensures that we can install a Go
+	// require libgcc. This ensures that we can install a Go
 	// release on a system that does not have a C compiler
 	// installed and still build Go programs (that don't use cgo).
 	for _, pkg := range cgoPackages {
diff --git a/src/cmd/fix/main.go b/src/cmd/fix/main.go
index dc10d6beb5..8b62346595 100644
--- a/src/cmd/fix/main.go
+++ b/src/cmd/fix/main.go
@@ -168,7 +168,7 @@ func processFile(filename string, useStdin bool) error {
 
 	// Print AST.  We did that after each fix, so this appears
 	// redundant, but it is necessary to generate gofmt-compatible
-	// source code in a few cases.  The official gofmt style is the
+	// source code in a few cases. The official gofmt style is the
 	// output of the printer run on a standard AST generated by the parser,
 	// but the source we generated inside the loop above is the
 	// output of the printer run on a mangled AST generated by a fixer.
diff --git a/src/cmd/fix/typecheck.go b/src/cmd/fix/typecheck.go
index 391afbbc05..0352c49db0 100644
--- a/src/cmd/fix/typecheck.go
+++ b/src/cmd/fix/typecheck.go
@@ -18,9 +18,9 @@ import (
 // The fact that it is partial is very important: the input is
 // an AST and a description of some type information to
 // assume about one or more packages, but not all the
-// packages that the program imports.  The checker is
+// packages that the program imports. The checker is
 // expected to do as much as it can with what it has been
-// given.  There is not enough information supplied to do
+// given. There is not enough information supplied to do
 // a full type check, but the type checker is expected to
 // apply information that can be derived from variable
 // declarations, function and method returns, and type switches
@@ -30,14 +30,14 @@ import (
 // TODO(rsc,gri): Replace with go/typechecker.
 // Doing that could be an interesting test case for go/typechecker:
 // the constraints about working with partial information will
-// likely exercise it in interesting ways.  The ideal interface would
+// likely exercise it in interesting ways. The ideal interface would
 // be to pass typecheck a map from importpath to package API text
 // (Go source code), but for now we use data structures (TypeConfig, Type).
 //
 // The strings mostly use gofmt form.
 //
 // A Field or FieldList has as its type a comma-separated list
-// of the types of the fields.  For example, the field list
+// of the types of the fields. For example, the field list
 //	x, y, z int
 // has type "int, int, int".
 
@@ -242,7 +242,7 @@ func typecheck1(cfg *TypeConfig, f interface{}, typeof map[interface{}]string, a
 		// propagate the type to all the uses.
 		// The !isDecl case is a cheat here, but it makes
 		// up in some cases for not paying attention to
-		// struct fields.  The real type checker will be
+		// struct fields. The real type checker will be
 		// more accurate so we won't need the cheat.
 		if id, ok := n.(*ast.Ident); ok && id.Obj != nil && (isDecl || typeof[id.Obj] == "") {
 			typeof[id.Obj] = typ
@@ -367,7 +367,7 @@ func typecheck1(cfg *TypeConfig, f interface{}, typeof map[interface{}]string, a
 			typeof[n] = all
 
 		case *ast.ValueSpec:
-			// var declaration.  Use type if present.
+			// var declaration. Use type if present.
 			if n.Type != nil {
 				t := typeof[n.Type]
 				if !isType(t) {
@@ -586,7 +586,7 @@ func typecheck1(cfg *TypeConfig, f interface{}, typeof map[interface{}]string, a
 
 // Convert between function type strings and lists of types.
 // Using strings makes this a little harder, but it makes
-// a lot of the rest of the code easier.  This will all go away
+// a lot of the rest of the code easier. This will all go away
 // when we can use go/typechecker directly.
 
 // splitFunc splits "func(x,y,z) (a,b,c)" into ["x", "y", "z"] and ["a", "b", "c"].
diff --git a/src/cmd/go/build.go b/src/cmd/go/build.go
index 8bb73765da..5977828a3a 100644
--- a/src/cmd/go/build.go
+++ b/src/cmd/go/build.go
@@ -517,7 +517,7 @@ func isMetaPackage(name string) bool {
 }
 
 // libname returns the filename to use for the shared library when using
-// -buildmode=shared.  The rules we use are:
+// -buildmode=shared. The rules we use are:
 // Use arguments for special 'meta' packages:
 //	std --> libstd.so
 //	std cmd --> libstd,cmd.so
@@ -788,7 +788,7 @@ func goFilesPackage(gofiles []string) *Package {
 
 	// Synthesize fake "directory" that only shows the named files,
 	// to make it look like this is a standard package or
-	// command directory.  So that local imports resolve
+	// command directory. So that local imports resolve
 	// consistently, the files must all be in the same directory.
 	var dirent []os.FileInfo
 	var dir string
@@ -950,7 +950,7 @@ func (b *builder) action1(mode buildMode, depMode buildMode, p *Package, looksha
 	// If we are not doing a cross-build, then record the binary we'll
 	// generate for cgo as a dependency of the build of any package
 	// using cgo, to make sure we do not overwrite the binary while
-	// a package is using it.  If this is a cross-build, then the cgo we
+	// a package is using it. If this is a cross-build, then the cgo we
 	// are writing is not the cgo we need to use.
 	if goos == runtime.GOOS && goarch == runtime.GOARCH && !buildRace && !buildMSan {
 		if (len(p.CgoFiles) > 0 || p.Standard && p.ImportPath == "runtime/cgo") && !buildLinkshared && buildBuildmode != "shared" {
@@ -986,7 +986,7 @@ func (b *builder) action1(mode buildMode, depMode buildMode, p *Package, looksha
 	}
 
 	if p.local && p.target == "" {
-		// Imported via local path.  No permanent target.
+		// Imported via local path. No permanent target.
 		mode = modeBuild
 	}
 	work := p.pkgdir
@@ -1034,7 +1034,7 @@ func (b *builder) action1(mode buildMode, depMode buildMode, p *Package, looksha
 			// the name will show up in ps listings. If the caller has specified
 			// a name, use that instead of a.out. The binary is generated
 			// in an otherwise empty subdirectory named exe to avoid
-			// naming conflicts.  The only possible conflict is if we were
+			// naming conflicts. The only possible conflict is if we were
 			// to create a top-level package named exe.
 			name := "a.out"
 			if p.exeName != "" {
@@ -1224,10 +1224,10 @@ func (b *builder) do(root *action) {
 	// The original implementation here was a true queue
 	// (using a channel) but it had the effect of getting
 	// distracted by low-level leaf actions to the detriment
-	// of completing higher-level actions.  The order of
+	// of completing higher-level actions. The order of
 	// work does not matter much to overall execution time,
 	// but when running "go test std" it is nice to see each test
-	// results as soon as possible.  The priorities assigned
+	// results as soon as possible. The priorities assigned
 	// ensure that, all else being equal, the execution prefers
 	// to do what it would have done first in a simple depth-first
 	// dependency order traversal.
@@ -1547,7 +1547,7 @@ func (b *builder) build(a *action) (err error) {
 
 	// NOTE(rsc): On Windows, it is critically important that the
 	// gcc-compiled objects (cgoObjects) be listed after the ordinary
-	// objects in the archive.  I do not know why this is.
+	// objects in the archive. I do not know why this is.
 	// https://golang.org/issue/2601
 	objects = append(objects, cgoObjects...)
 
@@ -1653,7 +1653,7 @@ func (b *builder) install(a *action) (err error) {
 	}
 
 	// remove object dir to keep the amount of
-	// garbage down in a large build.  On an operating system
+	// garbage down in a large build. On an operating system
 	// with aggressive buffering, cleaning incrementally like
 	// this keeps the intermediate objects from hitting the disk.
 	if !buildWork {
@@ -1798,7 +1798,7 @@ func (b *builder) copyFile(a *action, dst, src string, perm os.FileMode, force b
 	df, err := os.OpenFile(dst, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, perm)
 	if err != nil && toolIsWindows {
 		// Windows does not allow deletion of a binary file
-		// while it is executing.  Try to move it out of the way.
+		// while it is executing. Try to move it out of the way.
 		// If the move fails, which is likely, we'll try again the
 		// next time we do an install of this binary.
 		if err := os.Rename(dst, dst+"~"); err == nil {
@@ -1928,7 +1928,7 @@ func (b *builder) showcmd(dir string, format string, args ...interface{}) {
 // The output is expected to contain references to 'dir', usually
 // the source directory for the package that has failed to build.
 // showOutput rewrites mentions of dir with a relative path to dir
-// when the relative path is shorter.  This is usually more pleasant.
+// when the relative path is shorter. This is usually more pleasant.
 // For example, if fmt doesn't compile and we are in src/html,
 // the output is
 //
@@ -1986,7 +1986,7 @@ func relPaths(paths []string) []string {
 // errPrintedOutput is a special error indicating that a command failed
 // but that it generated output as well, and that output has already
 // been printed, so there's no point showing 'exit status 1' or whatever
-// the wait status was.  The main executor, builder.do, knows not to
+// the wait status was. The main executor, builder.do, knows not to
 // print this error.
 var errPrintedOutput = errors.New("already printed output - no need to show error")
 
@@ -2055,7 +2055,7 @@ func (b *builder) runOut(dir string, desc string, env []string, cmdargs ...inter
 		err := cmd.Run()
 
 		// cmd.Run will fail on Unix if some other process has the binary
-		// we want to run open for writing.  This can happen here because
+		// we want to run open for writing. This can happen here because
 		// we build and install the cgo command and then run it.
 		// If another command was kicked off while we were writing the
 		// cgo binary, the child process for that command may be holding
@@ -2067,27 +2067,27 @@ func (b *builder) runOut(dir string, desc string, env []string, cmdargs ...inter
 		// The answer is that running a command is fork and exec.
 		// A child forked while the cgo fd is open inherits that fd.
 		// Until the child has called exec, it holds the fd open and the
-		// kernel will not let us run cgo.  Even if the child were to close
+		// kernel will not let us run cgo. Even if the child were to close
 		// the fd explicitly, it would still be open from the time of the fork
 		// until the time of the explicit close, and the race would remain.
 		//
 		// On Unix systems, this results in ETXTBSY, which formats
 		// as "text file busy".  Rather than hard-code specific error cases,
-		// we just look for that string.  If this happens, sleep a little
-		// and try again.  We let this happen three times, with increasing
+		// we just look for that string. If this happens, sleep a little
+		// and try again. We let this happen three times, with increasing
 		// sleep lengths: 100+200+400 ms = 0.7 seconds.
 		//
 		// An alternate solution might be to split the cmd.Run into
 		// separate cmd.Start and cmd.Wait, and then use an RWLock
 		// to make sure that copyFile only executes when no cmd.Start
-		// call is in progress.  However, cmd.Start (really syscall.forkExec)
+		// call is in progress. However, cmd.Start (really syscall.forkExec)
 		// only guarantees that when it returns, the exec is committed to
-		// happen and succeed.  It uses a close-on-exec file descriptor
+		// happen and succeed. It uses a close-on-exec file descriptor
 		// itself to determine this, so we know that when cmd.Start returns,
 		// at least one close-on-exec file descriptor has been closed.
 		// However, we cannot be sure that all of them have been closed,
 		// so the program might still encounter ETXTBSY even with such
-		// an RWLock.  The race window would be smaller, perhaps, but not
+		// an RWLock. The race window would be smaller, perhaps, but not
 		// guaranteed to be gone.
 		//
 		// Sleeping when we observe the race seems to be the most reliable
@@ -2137,7 +2137,7 @@ func (b *builder) mkdir(dir string) error {
 	b.exec.Lock()
 	defer b.exec.Unlock()
 	// We can be a little aggressive about being
-	// sure directories exist.  Skip repeated calls.
+	// sure directories exist. Skip repeated calls.
 	if b.mkdirCache[dir] {
 		return nil
 	}
@@ -2745,7 +2745,7 @@ func (tools gccgoToolchain) ld(b *builder, root *action, out string, allactions
 		// initialization code.
 		//
 		// The user remains responsible for linking against
-		// -lgo -lpthread -lm in the final link.  We can't use
+		// -lgo -lpthread -lm in the final link. We can't use
 		// -r to pick them up because we can't combine
 		// split-stack and non-split-stack code in a single -r
 		// link, and libgo picks up non-split-stack code from
@@ -3183,7 +3183,7 @@ func (b *builder) cgo(p *Package, cgoExe, obj string, pcCFLAGS, pcLDFLAGS, cgofi
 		case strings.HasPrefix(f, "-fsanitize="):
 			continue
 		// runpath flags not applicable unless building a shared
-		// object or executable; see issue 12115 for details.  This
+		// object or executable; see issue 12115 for details. This
 		// is necessary as Go currently does not offer a way to
 		// specify the set of LDFLAGS that only apply to shared
 		// objects.
@@ -3534,12 +3534,12 @@ func (b *builder) swigOne(p *Package, file, obj string, pcCFLAGS []string, cxx b
 
 // disableBuildID adjusts a linker command line to avoid creating a
 // build ID when creating an object file rather than an executable or
-// shared library.  Some systems, such as Ubuntu, always add
+// shared library. Some systems, such as Ubuntu, always add
 // --build-id to every link, but we don't want a build ID when we are
-// producing an object file.  On some of those system a plain -r (not
+// producing an object file. On some of those system a plain -r (not
 // -Wl,-r) will turn off --build-id, but clang 3.0 doesn't support a
-// plain -r.  I don't know how to turn off --build-id when using clang
-// other than passing a trailing --build-id=none.  So that is what we
+// plain -r. I don't know how to turn off --build-id when using clang
+// other than passing a trailing --build-id=none. So that is what we
 // do, but only on systems likely to support it, which is to say,
 // systems that normally use gold or the GNU linker.
 func (b *builder) disableBuildID(ldflags []string) []string {
diff --git a/src/cmd/go/get.go b/src/cmd/go/get.go
index 9bf45da78f..56a34c0b1b 100644
--- a/src/cmd/go/get.go
+++ b/src/cmd/go/get.go
@@ -112,7 +112,7 @@ func runGet(cmd *Command, args []string) {
 
 	// Code we downloaded and all code that depends on it
 	// needs to be evicted from the package cache so that
-	// the information will be recomputed.  Instead of keeping
+	// the information will be recomputed. Instead of keeping
 	// track of the reverse dependency information, evict
 	// everything.
 	for name := range packageCache {
@@ -142,7 +142,7 @@ func runGet(cmd *Command, args []string) {
 }
 
 // downloadPaths prepares the list of paths to pass to download.
-// It expands ... patterns that can be expanded.  If there is no match
+// It expands ... patterns that can be expanded. If there is no match
 // for a particular pattern, downloadPaths leaves it in the result list,
 // in the hope that we can figure out the repository from the
 // initial ...-free prefix.
@@ -153,7 +153,7 @@ func downloadPaths(args []string) []string {
 		if strings.Contains(a, "...") {
 			var expand []string
 			// Use matchPackagesInFS to avoid printing
-			// warnings.  They will be printed by the
+			// warnings. They will be printed by the
 			// eventual call to importPaths instead.
 			if build.IsLocalImport(a) {
 				expand = matchPackagesInFS(a)
@@ -237,7 +237,7 @@ func download(arg string, parent *Package, stk *importStack, mode int) {
 			return
 		}
 
-		// Warn that code.google.com is shutting down.  We
+		// Warn that code.google.com is shutting down. We
 		// issue the warning here because this is where we
 		// have the import stack.
 		if strings.HasPrefix(p.ImportPath, "code.google.com") {
@@ -355,7 +355,7 @@ func downloadPackage(p *Package) error {
 	}
 
 	if p.build.SrcRoot != "" {
-		// Directory exists.  Look for checkout along path to src.
+		// Directory exists. Look for checkout along path to src.
 		vcs, rootPath, err = vcsForDir(p)
 		if err != nil {
 			return err
@@ -399,7 +399,7 @@ func downloadPackage(p *Package) error {
 	}
 
 	if p.build.SrcRoot == "" {
-		// Package not found.  Put in first directory of $GOPATH.
+		// Package not found. Put in first directory of $GOPATH.
 		list := filepath.SplitList(buildContext.GOPATH)
 		if len(list) == 0 {
 			return fmt.Errorf("cannot download, $GOPATH not set. For more details see: go help gopath")
@@ -430,7 +430,7 @@ func downloadPackage(p *Package) error {
 		return fmt.Errorf("%s exists but is not a directory", meta)
 	}
 	if err != nil {
-		// Metadata directory does not exist.  Prepare to checkout new copy.
+		// Metadata directory does not exist. Prepare to checkout new copy.
 		// Some version control tools require the target directory not to exist.
 		// We require that too, just to avoid stepping on existing work.
 		if _, err := os.Stat(root); err == nil {
diff --git a/src/cmd/go/go_test.go b/src/cmd/go/go_test.go
index fab29503ef..aa0016ad1e 100644
--- a/src/cmd/go/go_test.go
+++ b/src/cmd/go/go_test.go
@@ -109,7 +109,7 @@ func TestMain(m *testing.M) {
 	os.Exit(r)
 }
 
-// The length of an mtime tick on this system.  This is an estimate of
+// The length of an mtime tick on this system. This is an estimate of
 // how long we need to sleep to ensure that the mtime of two files is
 // different.
 // We used to try to be clever but that didn't always work (see golang.org/issue/12205).
@@ -181,7 +181,7 @@ func (tg *testgoData) pwd() string {
 	return wd
 }
 
-// cd changes the current directory to the named directory.  Note that
+// cd changes the current directory to the named directory. Note that
 // using this means that the test must not be run in parallel with any
 // other tests.
 func (tg *testgoData) cd(dir string) {
@@ -325,7 +325,7 @@ func (tg *testgoData) getStderr() string {
 }
 
 // doGrepMatch looks for a regular expression in a buffer, and returns
-// whether it is found.  The regular expression is matched against
+// whether it is found. The regular expression is matched against
 // each line separately, as with the grep command.
 func (tg *testgoData) doGrepMatch(match string, b *bytes.Buffer) bool {
 	if !tg.ran {
@@ -341,7 +341,7 @@ func (tg *testgoData) doGrepMatch(match string, b *bytes.Buffer) bool {
 }
 
 // doGrep looks for a regular expression in a buffer and fails if it
-// is not found.  The name argument is the name of the output we are
+// is not found. The name argument is the name of the output we are
 // searching, "output" or "error".  The msg argument is logged on
 // failure.
 func (tg *testgoData) doGrep(match string, b *bytes.Buffer, name, msg string) {
@@ -375,7 +375,7 @@ func (tg *testgoData) grepBoth(match, msg string) {
 }
 
 // doGrepNot looks for a regular expression in a buffer and fails if
-// it is found.  The name and msg arguments are as for doGrep.
+// it is found. The name and msg arguments are as for doGrep.
 func (tg *testgoData) doGrepNot(match string, b *bytes.Buffer, name, msg string) {
 	if tg.doGrepMatch(match, b) {
 		tg.t.Log(msg)
@@ -440,8 +440,8 @@ func (tg *testgoData) grepCountBoth(match string) int {
 }
 
 // creatingTemp records that the test plans to create a temporary file
-// or directory.  If the file or directory exists already, it will be
-// removed.  When the test completes, the file or directory will be
+// or directory. If the file or directory exists already, it will be
+// removed. When the test completes, the file or directory will be
 // removed if it exists.
 func (tg *testgoData) creatingTemp(path string) {
 	if filepath.IsAbs(path) && !strings.HasPrefix(path, tg.tempdir) {
@@ -457,7 +457,7 @@ func (tg *testgoData) creatingTemp(path string) {
 	tg.temps = append(tg.temps, path)
 }
 
-// makeTempdir makes a temporary directory for a run of testgo.  If
+// makeTempdir makes a temporary directory for a run of testgo. If
 // the temporary directory was already created, this does nothing.
 func (tg *testgoData) makeTempdir() {
 	if tg.tempdir == "" {
@@ -1105,8 +1105,8 @@ func testMove(t *testing.T, vcs, url, base, config string) {
 	}
 	if vcs == "git" {
 		// git will ask for a username and password when we
-		// run go get -d -f -u.  An empty username and
-		// password will work.  Prevent asking by setting
+		// run go get -d -f -u. An empty username and
+		// password will work. Prevent asking by setting
 		// GIT_ASKPASS.
 		tg.creatingTemp("sink" + exeSuffix)
 		tg.tempFile("src/sink/sink.go", `package main; func main() {}`)
diff --git a/src/cmd/go/main.go b/src/cmd/go/main.go
index f36d9f39aa..65cbab2b0d 100644
--- a/src/cmd/go/main.go
+++ b/src/cmd/go/main.go
@@ -339,7 +339,7 @@ func importPathsNoDotExpansion(args []string) []string {
 	for _, a := range args {
 		// Arguments are supposed to be import paths, but
 		// as a courtesy to Windows developers, rewrite \ to /
-		// in command-line arguments.  Handles .\... and so on.
+		// in command-line arguments. Handles .\... and so on.
 		if filepath.Separator == '\\' {
 			a = strings.Replace(a, `\`, `/`, -1)
 		}
@@ -472,7 +472,7 @@ NextVar:
 }
 
 // matchPattern(pattern)(name) reports whether
-// name matches pattern.  Pattern is a limited glob
+// name matches pattern. Pattern is a limited glob
 // pattern in which '...' means 'any string' and there
 // is no other special syntax.
 func matchPattern(pattern string) func(name string) bool {
@@ -629,7 +629,7 @@ func matchPackages(pattern string) []string {
 
 // allPackagesInFS is like allPackages but is passed a pattern
 // beginning ./ or ../, meaning it should scan the tree rooted
-// at the given directory.  There are ... in the pattern too.
+// at the given directory. There are ... in the pattern too.
 func allPackagesInFS(pattern string) []string {
 	pkgs := matchPackagesInFS(pattern)
 	if len(pkgs) == 0 {
diff --git a/src/cmd/go/note.go b/src/cmd/go/note.go
index 2f9db143dc..ada8ddded4 100644
--- a/src/cmd/go/note.go
+++ b/src/cmd/go/note.go
@@ -71,7 +71,7 @@ func readELFNote(filename, name string, typ int32) ([]byte, error) {
 var elfGoNote = []byte("Go\x00\x00")
 
 // The Go build ID is stored in a note described by an ELF PT_NOTE prog
-// header.  The caller has already opened filename, to get f, and read
+// header. The caller has already opened filename, to get f, and read
 // at least 4 kB out, in data.
 func readELFGoBuildID(filename string, f *os.File, data []byte) (buildid string, err error) {
 	// Assume the note content is in the data, already read.
diff --git a/src/cmd/go/pkg.go b/src/cmd/go/pkg.go
index 9de33f3521..8b0508894f 100644
--- a/src/cmd/go/pkg.go
+++ b/src/cmd/go/pkg.go
@@ -27,8 +27,8 @@ import (
 // A Package describes a single package found in a directory.
 type Package struct {
 	// Note: These fields are part of the go command's public API.
-	// See list.go.  It is okay to add fields, but not to change or
-	// remove existing ones.  Keep in sync with list.go
+	// See list.go. It is okay to add fields, but not to change or
+	// remove existing ones. Keep in sync with list.go
 	Dir           string `json:",omitempty"` // directory containing package sources
 	ImportPath    string `json:",omitempty"` // import path of package in dir
 	ImportComment string `json:",omitempty"` // path in import comment on package statement
@@ -208,7 +208,7 @@ func (p *PackageError) Error() string {
 		return fmt.Sprintf("%s\npackage %s\n", p.Err, strings.Join(p.ImportStack, "\n\timports "))
 	}
 	if p.Pos != "" {
-		// Omit import stack.  The full path to the file where the error
+		// Omit import stack. The full path to the file where the error
 		// is the most important thing.
 		return p.Pos + ": " + p.Err
 	}
@@ -267,8 +267,8 @@ func reloadPackage(arg string, stk *importStack) *Package {
 }
 
 // dirToImportPath returns the pseudo-import path we use for a package
-// outside the Go path.  It begins with _/ and then contains the full path
-// to the directory.  If the package lives in c:\home\gopher\my\pkg then
+// outside the Go path. It begins with _/ and then contains the full path
+// to the directory. If the package lives in c:\home\gopher\my\pkg then
 // the pseudo-import path is _/c_/home/gopher/my/pkg.
 // Using a pseudo-import path like this makes the ./ imports no longer
 // a special case, so that all the code to deal with ordinary imports works
@@ -472,7 +472,7 @@ func hasGoFiles(dir string) bool {
 }
 
 // reusePackage reuses package p to satisfy the import at the top
-// of the import stack stk.  If this use causes an import loop,
+// of the import stack stk. If this use causes an import loop,
 // reusePackage updates p's error information to record the loop.
 func reusePackage(p *Package, stk *importStack) *Package {
 	// We use p.imports==nil to detect a package that
@@ -715,7 +715,7 @@ func expandScanner(err error) error {
 		// Prepare error with \n before each message.
 		// When printed in something like context: %v
 		// this will put the leading file positions each on
-		// its own line.  It will also show all the errors
+		// its own line. It will also show all the errors
 		// instead of just the first, as err.Error does.
 		var buf bytes.Buffer
 		for _, e := range err {
@@ -1356,8 +1356,8 @@ func isStale(p *Package) bool {
 	}
 
 	// A package without Go sources means we only found
-	// the installed .a file.  Since we don't know how to rebuild
-	// it, it can't be stale, even if -a is set.  This enables binary-only
+	// the installed .a file. Since we don't know how to rebuild
+	// it, it can't be stale, even if -a is set. This enables binary-only
 	// distributions of Go packages, although such binaries are
 	// only useful with the specific version of the toolchain that
 	// created them.
@@ -1442,7 +1442,7 @@ func isStale(p *Package) bool {
 	// As a courtesy to developers installing new versions of the compiler
 	// frequently, define that packages are stale if they are
 	// older than the compiler, and commands if they are older than
-	// the linker.  This heuristic will not work if the binaries are
+	// the linker. This heuristic will not work if the binaries are
 	// back-dated, as some binary distributions may do, but it does handle
 	// a very common case.
 	// See issue 3036.
@@ -1564,7 +1564,7 @@ var cwd, _ = os.Getwd()
 var cmdCache = map[string]*Package{}
 
 // loadPackage is like loadImport but is used for command-line arguments,
-// not for paths found in import statements.  In addition to ordinary import paths,
+// not for paths found in import statements. In addition to ordinary import paths,
 // loadPackage accepts pseudo-paths beginning with cmd/ to denote commands
 // in the Go command directory, as well as paths to those directories.
 func loadPackage(arg string, stk *importStack) *Package {
@@ -1628,7 +1628,7 @@ func loadPackage(arg string, stk *importStack) *Package {
 // command line arguments 'args'.  If a named package
 // cannot be loaded at all (for example, if the directory does not exist),
 // then packages prints an error and does not include that
-// package in the results.  However, if errors occur trying
+// package in the results. However, if errors occur trying
 // to load dependencies of a named package, the named
 // package is still returned, with p.Incomplete = true
 // and details in p.DepsErrors.
diff --git a/src/cmd/go/run.go b/src/cmd/go/run.go
index d9b0cac6a6..18387b5eaf 100644
--- a/src/cmd/go/run.go
+++ b/src/cmd/go/run.go
@@ -128,7 +128,7 @@ func runRun(cmd *Command, args []string) {
 }
 
 // runProgram is the action for running a binary that has already
-// been compiled.  We ignore exit status.
+// been compiled. We ignore exit status.
 func (b *builder) runProgram(a *action) error {
 	cmdline := stringList(findExecCmd(), a.deps[0].target, a.args)
 	if buildN || buildX {
diff --git a/src/cmd/go/test.go b/src/cmd/go/test.go
index 1996fc4183..ca1a7d2722 100644
--- a/src/cmd/go/test.go
+++ b/src/cmd/go/test.go
@@ -388,7 +388,7 @@ func runTest(cmd *Command, args []string) {
 	}
 
 	// If a test timeout was given and is parseable, set our kill timeout
-	// to that timeout plus one minute.  This is a backup alarm in case
+	// to that timeout plus one minute. This is a backup alarm in case
 	// the test wedges with a goroutine spinning and its background
 	// timer does not get a chance to fire.
 	if dt, err := time.ParseDuration(testTimeout); err == nil && dt > 0 {
@@ -691,7 +691,7 @@ func (b *builder) test(p *Package) (buildAction, runAction, printAction *action,
 	// the usual place in the temporary tree, because then
 	// other tests will see it as the real package.
 	// Instead we make a _test directory under the import path
-	// and then repeat the import path there.  We tell the
+	// and then repeat the import path there. We tell the
 	// compiler and linker to look in that _test directory first.
 	//
 	// That is, if the package under test is unicode/utf8,
diff --git a/src/cmd/go/vcs.go b/src/cmd/go/vcs.go
index bda72f44f7..8d480d74fb 100644
--- a/src/cmd/go/vcs.go
+++ b/src/cmd/go/vcs.go
@@ -93,7 +93,7 @@ var vcsHg = &vcsCmd{
 	downloadCmd: []string{"pull"},
 
 	// We allow both tag and branch names as 'tags'
-	// for selecting a version.  This lets people have
+	// for selecting a version. This lets people have
 	// a go.release.r60 branch and a go1 branch
 	// and make changes in both, without constantly
 	// editing .hgtags.
diff --git a/src/cmd/gofmt/internal.go b/src/cmd/gofmt/internal.go
index f764b10ebb..cbc6983b61 100644
--- a/src/cmd/gofmt/internal.go
+++ b/src/cmd/gofmt/internal.go
@@ -28,9 +28,9 @@ func parse(fset *token.FileSet, filename string, src []byte, fragmentOk bool) (
 ) {
 	// Try as whole source file.
 	file, err = parser.ParseFile(fset, filename, src, parserMode)
-	// If there's no error, return.  If the error is that the source file didn't begin with a
+	// If there's no error, return. If the error is that the source file didn't begin with a
 	// package line and source fragments are ok, fall through to
-	// try as a source fragment.  Stop and return on any other error.
+	// try as a source fragment. Stop and return on any other error.
 	if err == nil || !fragmentOk || !strings.Contains(err.Error(), "expected 'package'") {
 		return
 	}
@@ -59,7 +59,7 @@ func parse(fset *token.FileSet, filename string, src []byte, fragmentOk bool) (
 
 	// If this is a statement list, make it a source file
 	// by inserting a package clause and turning the list
-	// into a function body.  This handles expressions too.
+	// into a function body. This handles expressions too.
 	// Insert using a ;, not a newline, so that the line numbers
 	// in fsrc match the ones in src. Add an extra '\n' before the '}'
 	// to make sure comments are flushed before the '}'.
diff --git a/src/cmd/gofmt/rewrite.go b/src/cmd/gofmt/rewrite.go
index 1eaeca6f10..550492bf29 100644
--- a/src/cmd/gofmt/rewrite.go
+++ b/src/cmd/gofmt/rewrite.go
@@ -158,7 +158,7 @@ func isWildcard(s string) bool {
 // recording wildcard submatches in m.
 // If m == nil, match checks whether pattern == val.
 func match(m map[string]reflect.Value, pattern, val reflect.Value) bool {
-	// Wildcard matches any expression.  If it appears multiple
+	// Wildcard matches any expression. If it appears multiple
 	// times in the pattern, it must match the same expression
 	// each time.
 	if m != nil && pattern.IsValid() && pattern.Type() == identType {
diff --git a/src/cmd/internal/obj/arm/asm5.go b/src/cmd/internal/obj/arm/asm5.go
index d75a16354c..9da33bc854 100644
--- a/src/cmd/internal/obj/arm/asm5.go
+++ b/src/cmd/internal/obj/arm/asm5.go
@@ -2372,7 +2372,7 @@ func asmout(ctxt *obj.Link, p *obj.Prog, o *Optab, out []uint32) {
 
 		// This is supposed to be something that stops execution.
 	// It's not supposed to be reached, ever, but if it is, we'd
-	// like to be able to tell how we got there.  Assemble as
+	// like to be able to tell how we got there. Assemble as
 	// 0xf7fabcfd which is guaranteed to raise undefined instruction
 	// exception.
 	case 96: /* UNDEF */
diff --git a/src/cmd/internal/obj/arm64/a.out.go b/src/cmd/internal/obj/arm64/a.out.go
index f459483cce..ab05894950 100644
--- a/src/cmd/internal/obj/arm64/a.out.go
+++ b/src/cmd/internal/obj/arm64/a.out.go
@@ -1,14 +1,14 @@
 // cmd/7c/7.out.h  from Vita Nuova.
 // https://code.google.com/p/ken-cc/source/browse/src/cmd/7c/7.out.h
 //
-// 	Copyright © 1994-1999 Lucent Technologies Inc.  All rights reserved.
+// 	Copyright © 1994-1999 Lucent Technologies Inc. All rights reserved.
 // 	Portions Copyright © 1995-1997 C H Forsyth (forsyth@terzarima.net)
 // 	Portions Copyright © 1997-1999 Vita Nuova Limited
 // 	Portions Copyright © 2000-2007 Vita Nuova Holdings Limited (www.vitanuova.com)
 // 	Portions Copyright © 2004,2006 Bruce Ellis
 // 	Portions Copyright © 2005-2007 C H Forsyth (forsyth@terzarima.net)
 // 	Revisions Copyright © 2000-2007 Lucent Technologies Inc. and others
-// 	Portions Copyright © 2009 The Go Authors.  All rights reserved.
+// 	Portions Copyright © 2009 The Go Authors. All rights reserved.
 //
 // Permission is hereby granted, free of charge, to any person obtaining a copy
 // of this software and associated documentation files (the "Software"), to deal
@@ -167,7 +167,7 @@ const (
 )
 
 // Not registers, but flags that can be combined with regular register
-// constants to indicate extended register conversion.  When checking,
+// constants to indicate extended register conversion. When checking,
 // you should subtract obj.RBaseARM64 first. From this difference, bit 11
 // indicates extended register, bits 8-10 select the conversion mode.
 const REG_EXT = obj.RBaseARM64 + 1<<11
diff --git a/src/cmd/internal/obj/arm64/asm7.go b/src/cmd/internal/obj/arm64/asm7.go
index 162acd2555..2b0a9cc287 100644
--- a/src/cmd/internal/obj/arm64/asm7.go
+++ b/src/cmd/internal/obj/arm64/asm7.go
@@ -1,14 +1,14 @@
 // cmd/7l/asm.c, cmd/7l/asmout.c, cmd/7l/optab.c, cmd/7l/span.c, cmd/ld/sub.c, cmd/ld/mod.c, from Vita Nuova.
 // https://code.google.com/p/ken-cc/source/browse/
 //
-// 	Copyright © 1994-1999 Lucent Technologies Inc.  All rights reserved.
+// 	Copyright © 1994-1999 Lucent Technologies Inc. All rights reserved.
 // 	Portions Copyright © 1995-1997 C H Forsyth (forsyth@terzarima.net)
 // 	Portions Copyright © 1997-1999 Vita Nuova Limited
 // 	Portions Copyright © 2000-2007 Vita Nuova Holdings Limited (www.vitanuova.com)
 // 	Portions Copyright © 2004,2006 Bruce Ellis
 // 	Portions Copyright © 2005-2007 C H Forsyth (forsyth@terzarima.net)
 // 	Revisions Copyright © 2000-2007 Lucent Technologies Inc. and others
-// 	Portions Copyright © 2009 The Go Authors.  All rights reserved.
+// 	Portions Copyright © 2009 The Go Authors. All rights reserved.
 //
 // Permission is hereby granted, free of charge, to any person obtaining a copy
 // of this software and associated documentation files (the "Software"), to deal
@@ -2811,7 +2811,7 @@ func asmout(ctxt *obj.Link, p *obj.Prog, o *Optab, out []uint32) {
 
 	// This is supposed to be something that stops execution.
 	// It's not supposed to be reached, ever, but if it is, we'd
-	// like to be able to tell how we got there.  Assemble as
+	// like to be able to tell how we got there. Assemble as
 	// 0xbea71700 which is guaranteed to raise undefined instruction
 	// exception.
 	case 90:
diff --git a/src/cmd/internal/obj/arm64/list7.go b/src/cmd/internal/obj/arm64/list7.go
index 53d67c91bb..36f544b53a 100644
--- a/src/cmd/internal/obj/arm64/list7.go
+++ b/src/cmd/internal/obj/arm64/list7.go
@@ -1,14 +1,14 @@
 // cmd/7l/list.c and cmd/7l/sub.c from Vita Nuova.
 // https://code.google.com/p/ken-cc/source/browse/
 //
-// 	Copyright © 1994-1999 Lucent Technologies Inc.  All rights reserved.
+// 	Copyright © 1994-1999 Lucent Technologies Inc. All rights reserved.
 // 	Portions Copyright © 1995-1997 C H Forsyth (forsyth@terzarima.net)
 // 	Portions Copyright © 1997-1999 Vita Nuova Limited
 // 	Portions Copyright © 2000-2007 Vita Nuova Holdings Limited (www.vitanuova.com)
 // 	Portions Copyright © 2004,2006 Bruce Ellis
 // 	Portions Copyright © 2005-2007 C H Forsyth (forsyth@terzarima.net)
 // 	Revisions Copyright © 2000-2007 Lucent Technologies Inc. and others
-// 	Portions Copyright © 2009 The Go Authors.  All rights reserved.
+// 	Portions Copyright © 2009 The Go Authors. All rights reserved.
 //
 // Permission is hereby granted, free of charge, to any person obtaining a copy
 // of this software and associated documentation files (the "Software"), to deal
diff --git a/src/cmd/internal/obj/arm64/obj7.go b/src/cmd/internal/obj/arm64/obj7.go
index 93c4b1a6b8..a4487d0125 100644
--- a/src/cmd/internal/obj/arm64/obj7.go
+++ b/src/cmd/internal/obj/arm64/obj7.go
@@ -1,14 +1,14 @@
 // cmd/7l/noop.c, cmd/7l/obj.c, cmd/ld/pass.c from Vita Nuova.
 // https://code.google.com/p/ken-cc/source/browse/
 //
-// 	Copyright © 1994-1999 Lucent Technologies Inc.  All rights reserved.
+// 	Copyright © 1994-1999 Lucent Technologies Inc. All rights reserved.
 // 	Portions Copyright © 1995-1997 C H Forsyth (forsyth@terzarima.net)
 // 	Portions Copyright © 1997-1999 Vita Nuova Limited
 // 	Portions Copyright © 2000-2007 Vita Nuova Holdings Limited (www.vitanuova.com)
 // 	Portions Copyright © 2004,2006 Bruce Ellis
 // 	Portions Copyright © 2005-2007 C H Forsyth (forsyth@terzarima.net)
 // 	Revisions Copyright © 2000-2007 Lucent Technologies Inc. and others
-// 	Portions Copyright © 2009 The Go Authors.  All rights reserved.
+// 	Portions Copyright © 2009 The Go Authors. All rights reserved.
 //
 // Permission is hereby granted, free of charge, to any person obtaining a copy
 // of this software and associated documentation files (the "Software"), to deal
diff --git a/src/cmd/internal/obj/link.go b/src/cmd/internal/obj/link.go
index 4ae819178d..53a8fa3334 100644
--- a/src/cmd/internal/obj/link.go
+++ b/src/cmd/internal/obj/link.go
@@ -460,7 +460,7 @@ const (
 	// have the inherent issue that a 32-bit (or 64-bit!) displacement cannot be
 	// stuffed into a 32-bit instruction, so an address needs to be spread across
 	// several instructions, and in turn this requires a sequence of relocations, each
-	// updating a part of an instruction.  This leads to relocation codes that are
+	// updating a part of an instruction. This leads to relocation codes that are
 	// inherently processor specific.
 
 	// Arm64.
diff --git a/src/cmd/internal/obj/objfile.go b/src/cmd/internal/obj/objfile.go
index ced1e842e0..7ff9fcaa91 100644
--- a/src/cmd/internal/obj/objfile.go
+++ b/src/cmd/internal/obj/objfile.go
@@ -108,7 +108,7 @@ import (
 )
 
 // The Go and C compilers, and the assembler, call writeobj to write
-// out a Go object file.  The linker does not call this; the linker
+// out a Go object file. The linker does not call this; the linker
 // does not write out object files.
 func Writeobjdirect(ctxt *Link, b *Biobuf) {
 	Flushplist(ctxt)
diff --git a/src/cmd/internal/obj/ppc64/obj9.go b/src/cmd/internal/obj/ppc64/obj9.go
index 11be4d79f6..c747138ece 100644
--- a/src/cmd/internal/obj/ppc64/obj9.go
+++ b/src/cmd/internal/obj/ppc64/obj9.go
@@ -953,7 +953,7 @@ func stacksplit(ctxt *obj.Link, p *obj.Prog, framesize int32) *obj.Prog {
 	}
 
 	if ctxt.Flag_dynlink {
-		// Avoid calling morestack via a PLT when dynamically linking.  The
+		// Avoid calling morestack via a PLT when dynamically linking. The
 		// PLT stubs generated by the system linker on ppc64le when "std r2,
 		// 24(r1)" to save the TOC pointer in their callers stack
 		// frame. Unfortunately (and necessarily) morestack is called before
diff --git a/src/cmd/internal/obj/textflag.go b/src/cmd/internal/obj/textflag.go
index cf742a5218..57ecea334c 100644
--- a/src/cmd/internal/obj/textflag.go
+++ b/src/cmd/internal/obj/textflag.go
@@ -3,7 +3,7 @@
 // license that can be found in the LICENSE file.
 
 // This file defines flags attached to various functions
-// and data objects.  The compilers, assemblers, and linker must
+// and data objects. The compilers, assemblers, and linker must
 // all agree on these values.
 
 package obj
@@ -14,7 +14,7 @@ const (
 	// Deprecated: Not implemented, do not use.
 	NOPROF = 1
 
-	// It is ok for the linker to get multiple of these symbols.  It will
+	// It is ok for the linker to get multiple of these symbols. It will
 	// pick one of the duplicates to use.
 	DUPOK = 2
 
diff --git a/src/cmd/internal/obj/util.go b/src/cmd/internal/obj/util.go
index 29768e0dd1..a1c1cca895 100644
--- a/src/cmd/internal/obj/util.go
+++ b/src/cmd/internal/obj/util.go
@@ -553,7 +553,7 @@ const (
 )
 
 // RegisterRegister binds a pretty-printer (Rconv) for register
-// numbers to a given register number range.  Lo is inclusive,
+// numbers to a given register number range. Lo is inclusive,
 // hi exclusive (valid registers are lo through hi-1).
 func RegisterRegister(lo, hi int, Rconv func(int) string) {
 	regSpace = append(regSpace, regSet{lo, hi, Rconv})
diff --git a/src/cmd/internal/obj/x86/asm6.go b/src/cmd/internal/obj/x86/asm6.go
index 9ab6615e43..c4f2140e9c 100644
--- a/src/cmd/internal/obj/x86/asm6.go
+++ b/src/cmd/internal/obj/x86/asm6.go
@@ -2285,7 +2285,7 @@ func oclass(ctxt *obj.Link, p *obj.Prog, a *obj.Addr) int {
 				}
 			case obj.NAME_AUTO, obj.NAME_PARAM:
 				// These names must have a base of SP.  The old compiler
-				// uses 0 for the base register.  SSA uses REG_SP.
+				// uses 0 for the base register. SSA uses REG_SP.
 				if a.Reg != REG_SP && a.Reg != 0 {
 					return Yxxx
 				}
diff --git a/src/cmd/internal/obj/x86/obj6.go b/src/cmd/internal/obj/x86/obj6.go
index 3f8426ae38..a553c94b8b 100644
--- a/src/cmd/internal/obj/x86/obj6.go
+++ b/src/cmd/internal/obj/x86/obj6.go
@@ -610,7 +610,7 @@ func preprocess(ctxt *obj.Link, cursym *obj.LSym) {
 
 	var bpsize int
 	if p.Mode == 64 && obj.Framepointer_enabled != 0 && autoffset > 0 {
-		// Make room for to save a base pointer.  If autoffset == 0,
+		// Make room for to save a base pointer. If autoffset == 0,
 		// this might do something special like a tail jump to
 		// another function, so in that case we omit this.
 		bpsize = ctxt.Arch.Ptrsize
diff --git a/src/cmd/link/internal/amd64/asm.go b/src/cmd/link/internal/amd64/asm.go
index fa785c25f3..eff9c032be 100644
--- a/src/cmd/link/internal/amd64/asm.go
+++ b/src/cmd/link/internal/amd64/asm.go
@@ -259,7 +259,7 @@ func adddynrel(s *ld.LSym, r *ld.Reloc) {
 				return
 			}
 			// The code is asking for the address of an external
-			// function.  We provide it with the address of the
+			// function. We provide it with the address of the
 			// correspondent GOT symbol.
 			addgotsym(targ)
 
@@ -292,7 +292,7 @@ func adddynrel(s *ld.LSym, r *ld.Reloc) {
 			// Instead, interpret the C declaration
 			//	void *_Cvar_stderr = &stderr;
 			// as making _Cvar_stderr the name of a GOT entry
-			// for stderr.  This is separate from the usual GOT entry,
+			// for stderr. This is separate from the usual GOT entry,
 			// just in case the C code assigns to the variable,
 			// and of course it only works for single pointers,
 			// but we only need to support cgo and that's all it needs.
@@ -564,7 +564,7 @@ func addpltsym(s *ld.LSym) {
 		// To do lazy symbol lookup right, we're supposed
 		// to tell the dynamic loader which library each
 		// symbol comes from and format the link info
-		// section just so.  I'm too lazy (ha!) to do that
+		// section just so. I'm too lazy (ha!) to do that
 		// so for now we'll just use non-lazy pointers,
 		// which don't need to be told which library to use.
 		//
diff --git a/src/cmd/link/internal/ld/ar.go b/src/cmd/link/internal/ld/ar.go
index bd14a4326c..321dd243b2 100644
--- a/src/cmd/link/internal/ld/ar.go
+++ b/src/cmd/link/internal/ld/ar.go
@@ -57,9 +57,9 @@ type ArHdr struct {
 }
 
 // hostArchive reads an archive file holding host objects and links in
-// required objects.  The general format is the same as a Go archive
+// required objects. The general format is the same as a Go archive
 // file, but it has an armap listing symbols and the objects that
-// define them.  This is used for the compiler support library
+// define them. This is used for the compiler support library
 // libgcc.a.
 func hostArchive(name string) {
 	f, err := obj.Bopenr(name)
diff --git a/src/cmd/link/internal/ld/data.go b/src/cmd/link/internal/ld/data.go
index 67af9d5ba8..d5e591a045 100644
--- a/src/cmd/link/internal/ld/data.go
+++ b/src/cmd/link/internal/ld/data.go
@@ -222,7 +222,7 @@ func datcmp(s1 *LSym, s2 *LSym) int {
 	}
 
 	// For ppc64, we want to interleave the .got and .toc sections
-	// from input files.  Both are type SELFGOT, so in that case
+	// from input files. Both are type SELFGOT, so in that case
 	// fall through to the name comparison (conveniently, .got
 	// sorts before .toc).
 	if s1.Type != obj.SELFGOT && s1.Size != s2.Size {
diff --git a/src/cmd/link/internal/ld/dwarf.go b/src/cmd/link/internal/ld/dwarf.go
index fb3d8fb2cd..200f4ccd9e 100644
--- a/src/cmd/link/internal/ld/dwarf.go
+++ b/src/cmd/link/internal/ld/dwarf.go
@@ -1132,7 +1132,7 @@ func defptrto(dwtype *DWDie) *DWDie {
 }
 
 // Copies src's children into dst. Copies attributes by value.
-// DWAttr.data is copied as pointer only.  If except is one of
+// DWAttr.data is copied as pointer only. If except is one of
 // the top-level children, it will not be copied.
 func copychildrenexcept(dst *DWDie, src *DWDie, except *DWDie) {
 	for src = src.child; src != nil; src = src.link {
@@ -2263,7 +2263,7 @@ func dwarfaddshstrings(shstrtab *LSym) {
 	}
 }
 
-// Add section symbols for DWARF debug info.  This is called before
+// Add section symbols for DWARF debug info. This is called before
 // dwarfaddelfheaders.
 func dwarfaddelfsectionsyms() {
 	if infosym != nil {
diff --git a/src/cmd/link/internal/ld/ldmacho.go b/src/cmd/link/internal/ld/ldmacho.go
index 2abfa3336f..327a477085 100644
--- a/src/cmd/link/internal/ld/ldmacho.go
+++ b/src/cmd/link/internal/ld/ldmacho.go
@@ -845,7 +845,7 @@ func ldmacho(f *obj.Biobuf, pkg string, length int64, pn string) {
 			}
 
 			// For i386 Mach-O PC-relative, the addend is written such that
-			// it *is* the PC being subtracted.  Use that to make
+			// it *is* the PC being subtracted. Use that to make
 			// it match our version of PC-relative.
 			if rel.pcrel != 0 && Thearch.Thechar == '8' {
 				rp.Add += int64(rp.Off) + int64(rp.Siz)
diff --git a/src/cmd/link/internal/ld/ldpe.go b/src/cmd/link/internal/ld/ldpe.go
index 8439c06560..47b32f0099 100644
--- a/src/cmd/link/internal/ld/ldpe.go
+++ b/src/cmd/link/internal/ld/ldpe.go
@@ -234,7 +234,7 @@ func ldpe(f *obj.Biobuf, pkg string, length int64, pn string) {
 
 		if sect.sh.Characteristics&(IMAGE_SCN_CNT_CODE|IMAGE_SCN_CNT_INITIALIZED_DATA|IMAGE_SCN_CNT_UNINITIALIZED_DATA) == 0 {
 			// This has been seen for .idata sections, which we
-			// want to ignore.  See issues 5106 and 5273.
+			// want to ignore. See issues 5106 and 5273.
 			continue
 		}
 
@@ -283,7 +283,7 @@ func ldpe(f *obj.Biobuf, pkg string, length int64, pn string) {
 		}
 		if sect.sh.Characteristics&(IMAGE_SCN_CNT_CODE|IMAGE_SCN_CNT_INITIALIZED_DATA|IMAGE_SCN_CNT_UNINITIALIZED_DATA) == 0 {
 			// This has been seen for .idata sections, which we
-			// want to ignore.  See issues 5106 and 5273.
+			// want to ignore. See issues 5106 and 5273.
 			continue
 		}
 
diff --git a/src/cmd/link/internal/ld/lib.go b/src/cmd/link/internal/ld/lib.go
index 27fef60f18..d078069f4a 100644
--- a/src/cmd/link/internal/ld/lib.go
+++ b/src/cmd/link/internal/ld/lib.go
@@ -577,7 +577,7 @@ func loadlib() {
 	if Linkmode == LinkExternal && !iscgo {
 		// This indicates a user requested -linkmode=external.
 		// The startup code uses an import of runtime/cgo to decide
-		// whether to initialize the TLS.  So give it one.  This could
+		// whether to initialize the TLS.  So give it one. This could
 		// be handled differently but it's an unusual case.
 		loadinternal("runtime/cgo")
 
@@ -1112,8 +1112,8 @@ func hostlink() {
 
 	// On Windows, given -o foo, GCC will append ".exe" to produce
 	// "foo.exe".  We have decided that we want to honor the -o
-	// option.  To make this work, we append a '.' so that GCC
-	// will decide that the file already has an extension.  We
+	// option. To make this work, we append a '.' so that GCC
+	// will decide that the file already has an extension. We
 	// only want to do this when producing a Windows output file
 	// on a Windows host.
 	outopt := outfile
@@ -1179,8 +1179,8 @@ func hostlink() {
 
 		// clang, unlike GCC, passes -rdynamic to the linker
 		// even when linking with -static, causing a linker
-		// error when using GNU ld.  So take out -rdynamic if
-		// we added it.  We do it in this order, rather than
+		// error when using GNU ld. So take out -rdynamic if
+		// we added it. We do it in this order, rather than
 		// only adding -rdynamic later, so that -extldflags
 		// can override -rdynamic without using -static.
 		if Iself && p == "-static" {
@@ -1254,8 +1254,8 @@ func hostlinkArchArgs() []string {
 	return nil
 }
 
-// ldobj loads an input object.  If it is a host object (an object
-// compiled by a non-Go compiler) it returns the Hostobj pointer.  If
+// ldobj loads an input object. If it is a host object (an object
+// compiled by a non-Go compiler) it returns the Hostobj pointer. If
 // it is a Go object, it returns nil.
 func ldobj(f *obj.Biobuf, pkg string, length int64, pn string, file string, whence int) *Hostobj {
 	eof := obj.Boffset(f) + length
@@ -1772,7 +1772,7 @@ func stkcheck(up *Chain, depth int) int {
 					return -1
 				}
 
-			// Indirect call.  Assume it is a call to a splitting function,
+			// Indirect call. Assume it is a call to a splitting function,
 			// so we have to make sure it can call morestack.
 			// Arrange the data structures to report both calls, so that
 			// if there is an error, stkprint shows all the steps involved.
diff --git a/src/cmd/link/internal/ld/macho.go b/src/cmd/link/internal/ld/macho.go
index 010e7da0ee..d88a414dbf 100644
--- a/src/cmd/link/internal/ld/macho.go
+++ b/src/cmd/link/internal/ld/macho.go
@@ -123,9 +123,9 @@ var sortsym []*LSym
 var nsortsym int
 
 // Amount of space left for adding load commands
-// that refer to dynamic libraries.  Because these have
+// that refer to dynamic libraries. Because these have
 // to go in the Mach-O header, we can't just pick a
-// "big enough" header size.  The initial header is
+// "big enough" header size. The initial header is
 // one page, the non-dynamic library stuff takes
 // up about 1300 bytes; we overestimate that as 2k.
 var load_budget int = INITIAL_MACHO_HEADR - 2*1024
@@ -338,7 +338,7 @@ func domacho() {
 
 func Machoadddynlib(lib string) {
 	// Will need to store the library name rounded up
-	// and 24 bytes of header metadata.  If not enough
+	// and 24 bytes of header metadata. If not enough
 	// space, grab another page of initial space at the
 	// beginning of the output file.
 	load_budget -= (len(lib)+7)/8*8 + 24
@@ -785,12 +785,12 @@ func Domacholink() int64 {
 	s4 := Linklookup(Ctxt, ".machosymstr", 0)
 
 	// Force the linkedit section to end on a 16-byte
-	// boundary.  This allows pure (non-cgo) Go binaries
+	// boundary. This allows pure (non-cgo) Go binaries
 	// to be code signed correctly.
 	//
 	// Apple's codesign_allocate (a helper utility for
 	// the codesign utility) can do this fine itself if
-	// it is run on a dynamic Mach-O binary.  However,
+	// it is run on a dynamic Mach-O binary. However,
 	// when it is run on a pure (non-cgo) Go binary, where
 	// the linkedit section is mostly empty, it fails to
 	// account for the extra padding that it itself adds
diff --git a/src/cmd/link/internal/ld/pcln.go b/src/cmd/link/internal/ld/pcln.go
index 92c02f6992..8400468501 100644
--- a/src/cmd/link/internal/ld/pcln.go
+++ b/src/cmd/link/internal/ld/pcln.go
@@ -399,7 +399,7 @@ const (
 )
 
 // findfunctab generates a lookup table to quickly find the containing
-// function for a pc.  See src/runtime/symtab.go:findfunc for details.
+// function for a pc. See src/runtime/symtab.go:findfunc for details.
 func findfunctab() {
 	t := Linklookup(Ctxt, "runtime.findfunctab", 0)
 	t.Type = obj.SRODATA
diff --git a/src/cmd/link/internal/ld/symtab.go b/src/cmd/link/internal/ld/symtab.go
index b87ca81007..aea55299f5 100644
--- a/src/cmd/link/internal/ld/symtab.go
+++ b/src/cmd/link/internal/ld/symtab.go
@@ -47,7 +47,7 @@ func putelfstr(s string) int {
 
 	// When dynamically linking, we create LSym's by reading the names from
 	// the symbol tables of the shared libraries and so the names need to
-	// match exactly.  Tools like DTrace will have to wait for now.
+	// match exactly. Tools like DTrace will have to wait for now.
 	if !DynlinkingGo() {
 		// Rewrite · to . for ASCII-only tools like DTrace (sigh)
 		s = strings.Replace(s, "·", ".", -1)
diff --git a/src/cmd/link/internal/ppc64/asm.go b/src/cmd/link/internal/ppc64/asm.go
index 169accc594..6c731d4b1e 100644
--- a/src/cmd/link/internal/ppc64/asm.go
+++ b/src/cmd/link/internal/ppc64/asm.go
@@ -48,7 +48,7 @@ func genplt() {
 	var i int
 
 	// The ppc64 ABI PLT has similar concepts to other
-	// architectures, but is laid out quite differently.  When we
+	// architectures, but is laid out quite differently. When we
 	// see an R_PPC64_REL24 relocation to a dynamic symbol
 	// (indicating that the call needs to go through the PLT), we
 	// generate up to three stubs and reserve a PLT slot.
@@ -78,7 +78,7 @@ func genplt() {
 	// 5) We generate the glink resolver stub (only once).  This
 	//    computes which symbol resolver stub we came through and
 	//    invokes the dynamic resolver via a pointer provided by
-	//    the dynamic linker.  This will patch up the .plt slot to
+	//    the dynamic linker. This will patch up the .plt slot to
 	//    point directly at the function so future calls go
 	//    straight from the call stub to the real function, and
 	//    then call the function.
@@ -89,8 +89,8 @@ func genplt() {
 	// platforms.
 
 	// Find all R_PPC64_REL24 relocations that reference dynamic
-	// imports.  Reserve PLT entries for these symbols and
-	// generate call stubs.  The call stubs need to live in .text,
+	// imports. Reserve PLT entries for these symbols and
+	// generate call stubs. The call stubs need to live in .text,
 	// which is why we need to do this pass this early.
 	//
 	// This assumes "case 1" from the ABI, where the caller needs
@@ -131,7 +131,7 @@ func genplt() {
 			// Update the relocation to use the call stub
 			r.Sym = stub
 
-			// Restore TOC after bl.  The compiler put a
+			// Restore TOC after bl. The compiler put a
 			// nop here for us to overwrite.
 			o1 = 0xe8410018 // ld r2,24(r1)
 			ld.Ctxt.Arch.ByteOrder.PutUint32(s.P[r.Off+4:], o1)
@@ -284,7 +284,7 @@ func adddynrel(s *ld.LSym, r *ld.Reloc) {
 
 		// This is a local call, so the caller isn't setting
 		// up r12 and r2 is the same for the caller and
-		// callee.  Hence, we need to go to the local entry
+		// callee. Hence, we need to go to the local entry
 		// point.  (If we don't do this, the callee will try
 		// to use r12 to compute r2.)
 		r.Add += int64(r.Sym.Localentry) * 4
@@ -465,7 +465,7 @@ func elfsetupplt() {
 		// The dynamic linker stores the address of the
 		// dynamic resolver and the DSO identifier in the two
 		// doublewords at the beginning of the .plt section
-		// before the PLT array.  Reserve space for these.
+		// before the PLT array. Reserve space for these.
 		plt.Size = 16
 	}
 }
diff --git a/src/cmd/link/internal/x86/asm.go b/src/cmd/link/internal/x86/asm.go
index 830a7e6af9..ad423dce99 100644
--- a/src/cmd/link/internal/x86/asm.go
+++ b/src/cmd/link/internal/x86/asm.go
@@ -299,7 +299,7 @@ func adddynrel(s *ld.LSym, r *ld.Reloc) {
 			// Instead, interpret the C declaration
 			//	void *_Cvar_stderr = &stderr;
 			// as making _Cvar_stderr the name of a GOT entry
-			// for stderr.  This is separate from the usual GOT entry,
+			// for stderr. This is separate from the usual GOT entry,
 			// just in case the C code assigns to the variable,
 			// and of course it only works for single pointers,
 			// but we only need to support cgo and that's all it needs.
diff --git a/src/cmd/pprof/internal/profile/encode.go b/src/cmd/pprof/internal/profile/encode.go
index 9e669980a1..6b879a84ac 100644
--- a/src/cmd/pprof/internal/profile/encode.go
+++ b/src/cmd/pprof/internal/profile/encode.go
@@ -15,7 +15,7 @@ func (p *Profile) decoder() []decoder {
 }
 
 // preEncode populates the unexported fields to be used by encode
-// (with suffix X) from the corresponding exported fields.  The
+// (with suffix X) from the corresponding exported fields. The
 // exported fields are cleared up to facilitate testing.
 func (p *Profile) preEncode() {
 	strings := make(map[string]int)
diff --git a/src/cmd/pprof/internal/profile/legacy_profile.go b/src/cmd/pprof/internal/profile/legacy_profile.go
index c7c047a64b..e1f24c4c6d 100644
--- a/src/cmd/pprof/internal/profile/legacy_profile.go
+++ b/src/cmd/pprof/internal/profile/legacy_profile.go
@@ -291,7 +291,7 @@ func ParseTracebacks(b []byte) (*Profile, error) {
 		if s, addrs := extractHexAddresses(l); len(s) > 0 {
 			for _, addr := range addrs {
 				// Addresses from stack traces point to the next instruction after
-				// each call.  Adjust by -1 to land somewhere on the actual call
+				// each call. Adjust by -1 to land somewhere on the actual call
 				// (except for the leaf, which is not a call).
 				if len(sloc) > 0 {
 					addr--
@@ -427,7 +427,7 @@ func cpuProfile(b []byte, period int64, parse func(b []byte) (uint64, []byte)) (
 //   3rd word -- 0
 //
 // Addresses from stack traces may point to the next instruction after
-// each call.  Optionally adjust by -1 to land somewhere on the actual
+// each call. Optionally adjust by -1 to land somewhere on the actual
 // call (except for the leaf, which is not a call).
 func parseCPUSamples(b []byte, parse func(b []byte) (uint64, []byte), adjust bool, p *Profile) ([]byte, map[uint64]*Location, error) {
 	locs := make(map[uint64]*Location)
@@ -570,7 +570,7 @@ func parseHeap(b []byte) (p *Profile, err error) {
 		var sloc []*Location
 		for i, addr := range addrs {
 			// Addresses from stack traces point to the next instruction after
-			// each call.  Adjust by -1 to land somewhere on the actual call
+			// each call. Adjust by -1 to land somewhere on the actual call
 			// (except for the leaf, which is not a call).
 			if i > 0 {
 				addr--
@@ -778,7 +778,7 @@ func parseContention(b []byte) (p *Profile, err error) {
 		var sloc []*Location
 		for i, addr := range addrs {
 			// Addresses from stack traces point to the next instruction after
-			// each call.  Adjust by -1 to land somewhere on the actual call
+			// each call. Adjust by -1 to land somewhere on the actual call
 			// (except for the leaf, which is not a call).
 			if i > 0 {
 				addr--
@@ -921,7 +921,7 @@ func parseThread(b []byte) (*Profile, error) {
 		var sloc []*Location
 		for i, addr := range addrs {
 			// Addresses from stack traces point to the next instruction after
-			// each call.  Adjust by -1 to land somewhere on the actual call
+			// each call. Adjust by -1 to land somewhere on the actual call
 			// (except for the leaf, which is not a call).
 			if i > 0 {
 				addr--
diff --git a/src/cmd/pprof/internal/profile/profile.go b/src/cmd/pprof/internal/profile/profile.go
index 6d175bf32a..28e713d7be 100644
--- a/src/cmd/pprof/internal/profile/profile.go
+++ b/src/cmd/pprof/internal/profile/profile.go
@@ -114,7 +114,7 @@ type Function struct {
 	filenameX   int64
 }
 
-// Parse parses a profile and checks for its validity.  The input
+// Parse parses a profile and checks for its validity. The input
 // may be a gzip-compressed encoded protobuf or one of many legacy
 // profile formats which may be unsupported in the future.
 func Parse(r io.Reader) (*Profile, error) {
@@ -221,7 +221,7 @@ func (p *Profile) Write(w io.Writer) error {
 	return err
 }
 
-// CheckValid tests whether the profile is valid.  Checks include, but are
+// CheckValid tests whether the profile is valid. Checks include, but are
 // not limited to:
 //   - len(Profile.Sample[n].value) == len(Profile.value_unit)
 //   - Sample.id has a corresponding Profile.Location
diff --git a/src/cmd/pprof/internal/profile/prune.go b/src/cmd/pprof/internal/profile/prune.go
index abc898cb37..1924fada7a 100644
--- a/src/cmd/pprof/internal/profile/prune.go
+++ b/src/cmd/pprof/internal/profile/prune.go
@@ -12,7 +12,7 @@ import (
 )
 
 // Prune removes all nodes beneath a node matching dropRx, and not
-// matching keepRx.  If the root node of a Sample matches, the sample
+// matching keepRx. If the root node of a Sample matches, the sample
 // will have an empty stack.
 func (p *Profile) Prune(dropRx, keepRx *regexp.Regexp) {
 	prune := make(map[uint64]bool)
diff --git a/src/cmd/pprof/internal/report/report.go b/src/cmd/pprof/internal/report/report.go
index b6694f559f..b2b07b24f9 100644
--- a/src/cmd/pprof/internal/report/report.go
+++ b/src/cmd/pprof/internal/report/report.go
@@ -390,7 +390,7 @@ func printCallgrind(w io.Writer, rpt *Report) error {
 
 // callgrindName implements the callgrind naming compression scheme.
 // For names not previously seen returns "(N) name", where N is a
-// unique index.  For names previously seen returns "(N)" where N is
+// unique index. For names previously seen returns "(N)" where N is
 // the index returned the first time.
 func callgrindName(names map[string]int, name string) string {
 	if name == "" {
diff --git a/src/cmd/pprof/internal/symbolz/symbolz.go b/src/cmd/pprof/internal/symbolz/symbolz.go
index c81e522208..15b3b6df26 100644
--- a/src/cmd/pprof/internal/symbolz/symbolz.go
+++ b/src/cmd/pprof/internal/symbolz/symbolz.go
@@ -24,7 +24,7 @@ var (
 
 // Symbolize symbolizes profile p by parsing data returned by a
 // symbolz handler. syms receives the symbolz query (hex addresses
-// separated by '+') and returns the symbolz output in a string.  It
+// separated by '+') and returns the symbolz output in a string. It
 // symbolizes all locations based on their addresses, regardless of
 // mapping.
 func Symbolize(source string, syms func(string, string) ([]byte, error), p *profile.Profile) error {
diff --git a/src/cmd/vet/cgo.go b/src/cmd/vet/cgo.go
index f056f07f88..b896862c8f 100644
--- a/src/cmd/vet/cgo.go
+++ b/src/cmd/vet/cgo.go
@@ -56,7 +56,7 @@ func checkCgoCall(f *File, node ast.Node) {
 }
 
 // cgoBaseType tries to look through type conversions involving
-// unsafe.Pointer to find the real type.  It converts:
+// unsafe.Pointer to find the real type. It converts:
 //   unsafe.Pointer(x) => x
 //   *(*unsafe.Pointer)(unsafe.Pointer(&x)) => x
 func cgoBaseType(f *File, arg ast.Expr) types.Type {
@@ -106,7 +106,7 @@ func cgoBaseType(f *File, arg ast.Expr) types.Type {
 }
 
 // typeOKForCgoCall returns true if the type of arg is OK to pass to a
-// C function using cgo.  This is not true for Go types with embedded
+// C function using cgo. This is not true for Go types with embedded
 // pointers.
 func typeOKForCgoCall(t types.Type) bool {
 	if t == nil {
diff --git a/src/cmd/vet/main.go b/src/cmd/vet/main.go
index 23c041bef3..fc3873997b 100644
--- a/src/cmd/vet/main.go
+++ b/src/cmd/vet/main.go
@@ -122,7 +122,7 @@ func vet(name string) bool {
 	return report[name].isTrue()
 }
 
-// setExit sets the value for os.Exit when it is called, later.  It
+// setExit sets the value for os.Exit when it is called, later. It
 // remembers the highest value.
 func setExit(err int) {
 	if err > exitCode {
diff --git a/src/cmd/vet/method.go b/src/cmd/vet/method.go
index 00949df437..8a554e152a 100644
--- a/src/cmd/vet/method.go
+++ b/src/cmd/vet/method.go
@@ -26,10 +26,10 @@ type MethodSig struct {
 }
 
 // canonicalMethods lists the input and output types for Go methods
-// that are checked using dynamic interface checks.  Because the
+// that are checked using dynamic interface checks. Because the
 // checks are dynamic, such methods would not cause a compile error
 // if they have the wrong signature: instead the dynamic check would
-// fail, sometimes mysteriously.  If a method is found with a name listed
+// fail, sometimes mysteriously. If a method is found with a name listed
 // here but not the input/output types listed here, vet complains.
 //
 // A few of the canonical methods have very common names.
@@ -39,7 +39,7 @@ type MethodSig struct {
 // To do that, the arguments that have a = prefix are treated as
 // signals that the canonical meaning is intended: if a Scan
 // method doesn't have a fmt.ScanState as its first argument,
-// we let it go.  But if it does have a fmt.ScanState, then the
+// we let it go. But if it does have a fmt.ScanState, then the
 // rest has to match.
 var canonicalMethods = map[string]MethodSig{
 	// "Flush": {{}, {"error"}}, // http.Flusher and jpeg.writer conflict
diff --git a/src/cmd/vet/print.go b/src/cmd/vet/print.go
index a16e864cad..61139fdc11 100644
--- a/src/cmd/vet/print.go
+++ b/src/cmd/vet/print.go
@@ -67,7 +67,7 @@ var printfList = map[string]int{
 }
 
 // printList records the unformatted-print functions. The value is the location
-// of the first parameter to be printed.  Names are lower-cased so the lookup is
+// of the first parameter to be printed. Names are lower-cased so the lookup is
 // case insensitive.
 var printList = map[string]int{
 	"error":  0,
diff --git a/src/cmd/yacc/testdata/expr/expr.y b/src/cmd/yacc/testdata/expr/expr.y
index bb8e9bfd84..c39f9198cb 100644
--- a/src/cmd/yacc/testdata/expr/expr.y
+++ b/src/cmd/yacc/testdata/expr/expr.y
@@ -95,14 +95,14 @@ expr3:
 // for clarity.
 const eof = 0
 
-// The parser uses the type <prefix>Lex as a lexer.  It must provide
+// The parser uses the type <prefix>Lex as a lexer. It must provide
 // the methods Lex(*<prefix>SymType) int and Error(string).
 type exprLex struct {
 	line []byte
 	peek rune
 }
 
-// The parser calls this method to get each new token.  This
+// The parser calls this method to get each new token. This
 // implementation returns operators and NUM.
 func (x *exprLex) Lex(yylval *exprSymType) int {
 	for {
diff --git a/src/compress/flate/deflate.go b/src/compress/flate/deflate.go
index 169a0c7b2e..8bcd61ac2a 100644
--- a/src/compress/flate/deflate.go
+++ b/src/compress/flate/deflate.go
@@ -491,9 +491,9 @@ func NewWriter(w io.Writer, level int) (*Writer, error) {
 }
 
 // NewWriterDict is like NewWriter but initializes the new
-// Writer with a preset dictionary.  The returned Writer behaves
+// Writer with a preset dictionary. The returned Writer behaves
 // as if the dictionary had been written to it without producing
-// any compressed output.  The compressed data written to w
+// any compressed output. The compressed data written to w
 // can only be decompressed by a Reader initialized with the
 // same dictionary.
 func NewWriterDict(w io.Writer, level int, dict []byte) (*Writer, error) {
diff --git a/src/compress/flate/deflate_test.go b/src/compress/flate/deflate_test.go
index 72bc6652c8..c165ade734 100644
--- a/src/compress/flate/deflate_test.go
+++ b/src/compress/flate/deflate_test.go
@@ -247,7 +247,7 @@ func testSync(t *testing.T, level int, input []byte, name string) {
 		// not necessarily the case: the write Flush may emit
 		// some extra framing bits that are not necessary
 		// to process to obtain the first half of the uncompressed
-		// data.  The test ran correctly most of the time, because
+		// data. The test ran correctly most of the time, because
 		// the background goroutine had usually read even
 		// those extra bits by now, but it's not a useful thing to
 		// check.
diff --git a/src/compress/flate/huffman_bit_writer.go b/src/compress/flate/huffman_bit_writer.go
index 616440412e..abbb63464c 100644
--- a/src/compress/flate/huffman_bit_writer.go
+++ b/src/compress/flate/huffman_bit_writer.go
@@ -200,7 +200,7 @@ func (w *huffmanBitWriter) writeBytes(bytes []byte) {
 // The result is written into the codegen array, and the frequencies
 // of each code is written into the codegenFreq array.
 // Codes 0-15 are single byte codes. Codes 16-18 are followed by additional
-// information.  Code badCode is an end marker
+// information. Code badCode is an end marker
 //
 //  numLiterals      The number of literals in literalEncoding
 //  numOffsets       The number of offsets in offsetEncoding
@@ -213,7 +213,7 @@ func (w *huffmanBitWriter) generateCodegen(numLiterals int, numOffsets int) {
 	// This is fine because the output is always shorter than the input used
 	// so far.
 	codegen := w.codegen // cache
-	// Copy the concatenated code sizes to codegen.  Put a marker at the end.
+	// Copy the concatenated code sizes to codegen. Put a marker at the end.
 	copy(codegen[0:numLiterals], w.literalEncoding.codeBits)
 	copy(codegen[numLiterals:numLiterals+numOffsets], w.offsetEncoding.codeBits)
 	codegen[numLiterals+numOffsets] = badCode
diff --git a/src/compress/flate/huffman_code.go b/src/compress/flate/huffman_code.go
index 50ec79c940..1a4de12dd6 100644
--- a/src/compress/flate/huffman_code.go
+++ b/src/compress/flate/huffman_code.go
@@ -113,7 +113,7 @@ const maxBitsLimit = 16
 // The cases of 0, 1, and 2 literals are handled by special case code.
 //
 // list  An array of the literals with non-zero frequencies
-//             and their associated frequencies.  The array is in order of increasing
+//             and their associated frequencies. The array is in order of increasing
 //             frequency, and has as its last element a special element with frequency
 //             MaxInt32
 // maxBits     The maximum number of bits that should be used to encode any literal.
@@ -128,7 +128,7 @@ func (h *huffmanEncoder) bitCounts(list []literalNode, maxBits int32) []int32 {
 	list = list[0 : n+1]
 	list[n] = maxNode()
 
-	// The tree can't have greater depth than n - 1, no matter what.  This
+	// The tree can't have greater depth than n - 1, no matter what. This
 	// saves a little bit of work in some small cases
 	if maxBits > n-1 {
 		maxBits = n - 1
@@ -197,7 +197,7 @@ func (h *huffmanEncoder) bitCounts(list []literalNode, maxBits int32) []int32 {
 
 		if l.needed--; l.needed == 0 {
 			// We've done everything we need to do for this level.
-			// Continue calculating one level up.  Fill in nextPairFreq
+			// Continue calculating one level up. Fill in nextPairFreq
 			// of that level with the sum of the two nodes we've just calculated on
 			// this level.
 			if l.level == maxBits {
@@ -277,7 +277,7 @@ func (h *huffmanEncoder) generate(freq []int32, maxBits int32) {
 	h.codeBits = h.codeBits[0:len(freq)]
 	list = list[0:count]
 	if count <= 2 {
-		// Handle the small cases here, because they are awkward for the general case code.  With
+		// Handle the small cases here, because they are awkward for the general case code. With
 		// two or fewer literals, everything has bit length 1.
 		for i, node := range list {
 			// "list" is in order of increasing literal value.
diff --git a/src/compress/flate/inflate.go b/src/compress/flate/inflate.go
index dccfdf2288..501b45b72f 100644
--- a/src/compress/flate/inflate.go
+++ b/src/compress/flate/inflate.go
@@ -115,7 +115,7 @@ type huffmanDecoder struct {
 // trees are permitted.
 func (h *huffmanDecoder) init(bits []int) bool {
 	// Sanity enables additional runtime tests during Huffman
-	// table construction.  It's intended to be used during
+	// table construction. It's intended to be used during
 	// development to supplement the currently ad-hoc unit tests.
 	const sanity = false
 
@@ -162,7 +162,7 @@ func (h *huffmanDecoder) init(bits []int) bool {
 	// Check that the coding is complete (i.e., that we've
 	// assigned all 2-to-the-max possible bit sequences).
 	// Exception: To be compatible with zlib, we also need to
-	// accept degenerate single-code codings.  See also
+	// accept degenerate single-code codings. See also
 	// TestDegenerateHuffmanCoding.
 	if code != 1<<uint(max) && !(code == 1 && max == 1) {
 		return false
@@ -200,7 +200,7 @@ func (h *huffmanDecoder) init(bits []int) bool {
 		if n <= huffmanChunkBits {
 			for off := reverse; off < len(h.chunks); off += 1 << uint(n) {
 				// We should never need to overwrite
-				// an existing chunk.  Also, 0 is
+				// an existing chunk. Also, 0 is
 				// never a valid chunk, because the
 				// lower 4 "count" bits should be
 				// between 1 and 15.
@@ -230,7 +230,7 @@ func (h *huffmanDecoder) init(bits []int) bool {
 
 	if sanity {
 		// Above we've sanity checked that we never overwrote
-		// an existing entry.  Here we additionally check that
+		// an existing entry. Here we additionally check that
 		// we filled the tables completely.
 		for i, chunk := range h.chunks {
 			if chunk == 0 {
@@ -478,7 +478,7 @@ func (f *decompressor) readHuffman() error {
 
 // Decode a single Huffman block from f.
 // hl and hd are the Huffman states for the lit/length values
-// and the distance values, respectively.  If hd == nil, using the
+// and the distance values, respectively. If hd == nil, using the
 // fixed distance encoding associated with fixed Huffman blocks.
 func (f *decompressor) huffmanBlock() {
 	const (
@@ -791,9 +791,9 @@ func NewReader(r io.Reader) io.ReadCloser {
 }
 
 // NewReaderDict is like NewReader but initializes the reader
-// with a preset dictionary.  The returned Reader behaves as if
+// with a preset dictionary. The returned Reader behaves as if
 // the uncompressed data stream started with the given dictionary,
-// which has already been read.  NewReaderDict is typically used
+// which has already been read. NewReaderDict is typically used
 // to read data compressed by NewWriterDict.
 //
 // The ReadCloser returned by NewReader also implements Resetter.
diff --git a/src/compress/gzip/gunzip.go b/src/compress/gzip/gunzip.go
index 3d331454a6..4a4f19443d 100644
--- a/src/compress/gzip/gunzip.go
+++ b/src/compress/gzip/gunzip.go
@@ -58,14 +58,14 @@ type Header struct {
 // uncompressed data from a gzip-format compressed file.
 //
 // In general, a gzip file can be a concatenation of gzip files,
-// each with its own header.  Reads from the Reader
+// each with its own header. Reads from the Reader
 // return the concatenation of the uncompressed data of each.
 // Only the first header is recorded in the Reader fields.
 //
 // Gzip files store a length and checksum of the uncompressed data.
 // The Reader will return a ErrChecksum when Read
 // reaches the end of the uncompressed data if it does not
-// have the expected length or checksum.  Clients should treat data
+// have the expected length or checksum. Clients should treat data
 // returned by Read as tentative until they receive the io.EOF
 // marking the end of the data.
 type Reader struct {
@@ -299,7 +299,7 @@ func (z *Reader) Read(p []byte) (n int, err error) {
 		return
 	}
 
-	// Yes.  Reset and read from it.
+	// Yes. Reset and read from it.
 	z.digest.Reset()
 	z.size = 0
 	return z.Read(p)
diff --git a/src/container/heap/heap.go b/src/container/heap/heap.go
index c467a11910..5fe23b9537 100644
--- a/src/container/heap/heap.go
+++ b/src/container/heap/heap.go
@@ -25,7 +25,7 @@ import "sort"
 //	!h.Less(j, i) for 0 <= i < h.Len() and 2*i+1 <= j <= 2*i+2 and j < h.Len()
 //
 // Note that Push and Pop in this interface are for package heap's
-// implementation to call.  To add and remove things from the heap,
+// implementation to call. To add and remove things from the heap,
 // use heap.Push and heap.Pop.
 type Interface interface {
 	sort.Interface
diff --git a/src/crypto/aes/block.go b/src/crypto/aes/block.go
index 57a7e9e25f..41ea9cf95e 100644
--- a/src/crypto/aes/block.go
+++ b/src/crypto/aes/block.go
@@ -137,7 +137,7 @@ func subw(w uint32) uint32 {
 // Rotate
 func rotw(w uint32) uint32 { return w<<8 | w>>24 }
 
-// Key expansion algorithm.  See FIPS-197, Figure 11.
+// Key expansion algorithm. See FIPS-197, Figure 11.
 // Their rcon[i] is our powx[i-1] << 24.
 func expandKeyGo(key []byte, enc, dec []uint32) {
 	// Encryption key setup.
diff --git a/src/crypto/cipher/cipher.go b/src/crypto/cipher/cipher.go
index 7d27fde61d..531ecad9ac 100644
--- a/src/crypto/cipher/cipher.go
+++ b/src/crypto/cipher/cipher.go
@@ -9,8 +9,8 @@
 package cipher
 
 // A Block represents an implementation of block cipher
-// using a given key.  It provides the capability to encrypt
-// or decrypt individual blocks.  The mode implementations
+// using a given key. It provides the capability to encrypt
+// or decrypt individual blocks. The mode implementations
 // extend that capability to streams of blocks.
 type Block interface {
 	// BlockSize returns the cipher's block size.
diff --git a/src/crypto/md5/md5.go b/src/crypto/md5/md5.go
index a3550cb7dd..ce58d5e713 100644
--- a/src/crypto/md5/md5.go
+++ b/src/crypto/md5/md5.go
@@ -89,7 +89,7 @@ func (d0 *digest) Sum(in []byte) []byte {
 }
 
 func (d *digest) checkSum() [Size]byte {
-	// Padding.  Add a 1 bit and 0 bits until 56 bytes mod 64.
+	// Padding. Add a 1 bit and 0 bits until 56 bytes mod 64.
 	len := d.len
 	var tmp [64]byte
 	tmp[0] = 0x80
diff --git a/src/crypto/rand/rand_unix.go b/src/crypto/rand/rand_unix.go
index 37dd37eeb8..631972b92a 100644
--- a/src/crypto/rand/rand_unix.go
+++ b/src/crypto/rand/rand_unix.go
@@ -84,7 +84,7 @@ func (hr hideAgainReader) Read(p []byte) (n int, err error) {
 // systems without a reliable /dev/urandom.
 
 // newReader returns a new pseudorandom generator that
-// seeds itself by reading from entropy.  If entropy == nil,
+// seeds itself by reading from entropy. If entropy == nil,
 // the generator seeds itself by reading from the system's
 // random number generator, typically /dev/random.
 // The Read method on the returned reader always returns
diff --git a/src/crypto/rand/util.go b/src/crypto/rand/util.go
index 599cdc22cd..592c57e763 100644
--- a/src/crypto/rand/util.go
+++ b/src/crypto/rand/util.go
@@ -70,7 +70,7 @@ func Prime(rand io.Reader, bits int) (p *big.Int, err error) {
 
 		p.SetBytes(bytes)
 
-		// Calculate the value mod the product of smallPrimes.  If it's
+		// Calculate the value mod the product of smallPrimes. If it's
 		// a multiple of any of these primes we add two until it isn't.
 		// The probability of overflowing is minimal and can be ignored
 		// because we still perform Miller-Rabin tests on the result.
diff --git a/src/crypto/rc4/rc4.go b/src/crypto/rc4/rc4.go
index 9acb681bfb..bd04aee695 100644
--- a/src/crypto/rc4/rc4.go
+++ b/src/crypto/rc4/rc4.go
@@ -23,7 +23,7 @@ func (k KeySizeError) Error() string {
 	return "crypto/rc4: invalid key size " + strconv.Itoa(int(k))
 }
 
-// NewCipher creates and returns a new Cipher.  The key argument should be the
+// NewCipher creates and returns a new Cipher. The key argument should be the
 // RC4 key, at least 1 byte and at most 256 bytes.
 func NewCipher(key []byte) (*Cipher, error) {
 	k := len(key)
@@ -52,7 +52,7 @@ func (c *Cipher) Reset() {
 }
 
 // xorKeyStreamGeneric sets dst to the result of XORing src with the
-// key stream.  Dst and src may be the same slice but otherwise should
+// key stream. Dst and src may be the same slice but otherwise should
 // not overlap.
 //
 // This is the pure Go version. rc4_{amd64,386,arm}* contain assembly
diff --git a/src/crypto/rsa/pss.go b/src/crypto/rsa/pss.go
index 7c82f181cb..1ba194a4ad 100644
--- a/src/crypto/rsa/pss.go
+++ b/src/crypto/rsa/pss.go
@@ -64,7 +64,7 @@ func emsaPSSEncode(mHash []byte, emBits int, salt []byte, hash hash.Hash) ([]byt
 	hash.Reset()
 
 	// 7.  Generate an octet string PS consisting of emLen - sLen - hLen - 2
-	//     zero octets.  The length of PS may be 0.
+	//     zero octets. The length of PS may be 0.
 	//
 	// 8.  Let DB = PS || 0x01 || salt; DB is an octet string of length
 	//     emLen - hLen - 1.
diff --git a/src/crypto/sha1/sha1.go b/src/crypto/sha1/sha1.go
index 9f1a96e364..ac593b1bf0 100644
--- a/src/crypto/sha1/sha1.go
+++ b/src/crypto/sha1/sha1.go
@@ -90,7 +90,7 @@ func (d0 *digest) Sum(in []byte) []byte {
 
 func (d *digest) checkSum() [Size]byte {
 	len := d.len
-	// Padding.  Add a 1 bit and 0 bits until 56 bytes mod 64.
+	// Padding. Add a 1 bit and 0 bits until 56 bytes mod 64.
 	var tmp [64]byte
 	tmp[0] = 0x80
 	if len%64 < 56 {
diff --git a/src/crypto/sha1/sha1_test.go b/src/crypto/sha1/sha1_test.go
index 4a629518b7..80ac5e9f74 100644
--- a/src/crypto/sha1/sha1_test.go
+++ b/src/crypto/sha1/sha1_test.go
@@ -2,7 +2,7 @@
 // Use of this source code is governed by a BSD-style
 // license that can be found in the LICENSE file.
 
-// SHA1 hash algorithm.  See RFC 3174.
+// SHA1 hash algorithm. See RFC 3174.
 
 package sha1
 
diff --git a/src/crypto/sha256/sha256.go b/src/crypto/sha256/sha256.go
index d84cebf2ff..74b05b92d7 100644
--- a/src/crypto/sha256/sha256.go
+++ b/src/crypto/sha256/sha256.go
@@ -137,7 +137,7 @@ func (d0 *digest) Sum(in []byte) []byte {
 
 func (d *digest) checkSum() [Size]byte {
 	len := d.len
-	// Padding.  Add a 1 bit and 0 bits until 56 bytes mod 64.
+	// Padding. Add a 1 bit and 0 bits until 56 bytes mod 64.
 	var tmp [64]byte
 	tmp[0] = 0x80
 	if len%64 < 56 {
diff --git a/src/crypto/sha256/sha256_test.go b/src/crypto/sha256/sha256_test.go
index 1d883d3905..9ac8a96dfc 100644
--- a/src/crypto/sha256/sha256_test.go
+++ b/src/crypto/sha256/sha256_test.go
@@ -2,7 +2,7 @@
 // Use of this source code is governed by a BSD-style
 // license that can be found in the LICENSE file.
 
-// SHA256 hash algorithm.  See FIPS 180-2.
+// SHA256 hash algorithm. See FIPS 180-2.
 
 package sha256
 
diff --git a/src/crypto/sha512/sha512.go b/src/crypto/sha512/sha512.go
index e7781fd2f4..5603c90fb7 100644
--- a/src/crypto/sha512/sha512.go
+++ b/src/crypto/sha512/sha512.go
@@ -208,7 +208,7 @@ func (d0 *digest) Sum(in []byte) []byte {
 }
 
 func (d *digest) checkSum() [Size]byte {
-	// Padding.  Add a 1 bit and 0 bits until 112 bytes mod 128.
+	// Padding. Add a 1 bit and 0 bits until 112 bytes mod 128.
 	len := d.len
 	var tmp [128]byte
 	tmp[0] = 0x80
diff --git a/src/crypto/sha512/sha512_test.go b/src/crypto/sha512/sha512_test.go
index 04b3d4a3cc..6992d125de 100644
--- a/src/crypto/sha512/sha512_test.go
+++ b/src/crypto/sha512/sha512_test.go
@@ -2,7 +2,7 @@
 // Use of this source code is governed by a BSD-style
 // license that can be found in the LICENSE file.
 
-// SHA512 hash algorithm.  See FIPS 180-4.
+// SHA512 hash algorithm. See FIPS 180-4.
 
 package sha512
 
diff --git a/src/crypto/tls/conn.go b/src/crypto/tls/conn.go
index 03775685fb..65b1d4b2e3 100644
--- a/src/crypto/tls/conn.go
+++ b/src/crypto/tls/conn.go
@@ -1073,7 +1073,7 @@ func (c *Conn) OCSPResponse() []byte {
 }
 
 // VerifyHostname checks that the peer certificate chain is valid for
-// connecting to host.  If so, it returns nil; if not, it returns an error
+// connecting to host. If so, it returns nil; if not, it returns an error
 // describing the problem.
 func (c *Conn) VerifyHostname(host string) error {
 	c.handshakeMutex.Lock()
diff --git a/src/crypto/tls/handshake_server.go b/src/crypto/tls/handshake_server.go
index e16cddcbd8..dbab60b6bd 100644
--- a/src/crypto/tls/handshake_server.go
+++ b/src/crypto/tls/handshake_server.go
@@ -462,7 +462,7 @@ func (hs *serverHandshakeState) doFullHandshake() error {
 
 	// If we received a client cert in response to our certificate request message,
 	// the client will send us a certificateVerifyMsg immediately after the
-	// clientKeyExchangeMsg.  This message is a digest of all preceding
+	// clientKeyExchangeMsg. This message is a digest of all preceding
 	// handshake-layer messages that is signed using the private key corresponding
 	// to the client's certificate. This allows us to verify that the client is in
 	// possession of the private key of the certificate.
diff --git a/src/crypto/tls/handshake_server_test.go b/src/crypto/tls/handshake_server_test.go
index 74ad72a848..f8de4e4551 100644
--- a/src/crypto/tls/handshake_server_test.go
+++ b/src/crypto/tls/handshake_server_test.go
@@ -69,7 +69,7 @@ func testClientHello(t *testing.T, serverConfig *Config, m handshakeMessage) {
 
 func testClientHelloFailure(t *testing.T, serverConfig *Config, m handshakeMessage, expectedSubStr string) {
 	// Create in-memory network connection,
-	// send message to server.  Should return
+	// send message to server. Should return
 	// expected error.
 	c, s := net.Pipe()
 	go func() {
diff --git a/src/crypto/tls/key_agreement.go b/src/crypto/tls/key_agreement.go
index 0e6a7c2262..3326894a08 100644
--- a/src/crypto/tls/key_agreement.go
+++ b/src/crypto/tls/key_agreement.go
@@ -51,7 +51,7 @@ func (ka rsaKeyAgreement) processClientKeyExchange(config *Config, cert *Certifi
 	if err != nil {
 		return nil, err
 	}
-	// We don't check the version number in the premaster secret.  For one,
+	// We don't check the version number in the premaster secret. For one,
 	// by checking it, we would leak information about the validity of the
 	// encrypted pre-master secret. Secondly, it provides only a small
 	// benefit against a downgrade attack and some implementations send the
diff --git a/src/crypto/tls/tls_test.go b/src/crypto/tls/tls_test.go
index 5cc14278a0..27394e6d81 100644
--- a/src/crypto/tls/tls_test.go
+++ b/src/crypto/tls/tls_test.go
@@ -199,7 +199,7 @@ func TestDialTimeout(t *testing.T) {
 func TestConnReadNonzeroAndEOF(t *testing.T) {
 	// This test is racy: it assumes that after a write to a
 	// localhost TCP connection, the peer TCP connection can
-	// immediately read it.  Because it's racy, we skip this test
+	// immediately read it. Because it's racy, we skip this test
 	// in short mode, and then retry it several times with an
 	// increasing sleep in between our final write (via srv.Close
 	// below) and the following read.
diff --git a/src/crypto/x509/pem_decrypt.go b/src/crypto/x509/pem_decrypt.go
index 49ceadb436..0388d63e14 100644
--- a/src/crypto/x509/pem_decrypt.go
+++ b/src/crypto/x509/pem_decrypt.go
@@ -42,7 +42,7 @@ type rfc1423Algo struct {
 }
 
 // rfc1423Algos holds a slice of the possible ways to encrypt a PEM
-// block.  The ivSize numbers were taken from the OpenSSL source.
+// block. The ivSize numbers were taken from the OpenSSL source.
 var rfc1423Algos = []rfc1423Algo{{
 	cipher:     PEMCipherDES,
 	name:       "DES-CBC",
diff --git a/src/crypto/x509/root_windows.go b/src/crypto/x509/root_windows.go
index 81018b78fe..51c3be3fa4 100644
--- a/src/crypto/x509/root_windows.go
+++ b/src/crypto/x509/root_windows.go
@@ -179,7 +179,7 @@ func (c *Certificate) systemVerify(opts *VerifyOptions) (chains [][]*Certificate
 	}
 
 	// CertGetCertificateChain will traverse Windows's root stores
-	// in an attempt to build a verified certificate chain.  Once
+	// in an attempt to build a verified certificate chain. Once
 	// it has found a verified chain, it stops. MSDN docs on
 	// CERT_CHAIN_CONTEXT:
 	//
diff --git a/src/crypto/x509/verify.go b/src/crypto/x509/verify.go
index 27e9bbfbcc..d3b62d174c 100644
--- a/src/crypto/x509/verify.go
+++ b/src/crypto/x509/verify.go
@@ -179,7 +179,7 @@ func (c *Certificate) isValid(certType int, currentChain []*Certificate, opts *V
 	// being valid for encryption only, but no-one noticed. Another
 	// European CA marked its signature keys as not being valid for
 	// signatures. A different CA marked its own trusted root certificate
-	// as being invalid for certificate signing.  Another national CA
+	// as being invalid for certificate signing. Another national CA
 	// distributed a certificate to be used to encrypt data for the
 	// country’s tax authority that was marked as only being usable for
 	// digital signatures but not for encryption. Yet another CA reversed
diff --git a/src/database/sql/convert.go b/src/database/sql/convert.go
index 740fd9d6e7..92c3b689c1 100644
--- a/src/database/sql/convert.go
+++ b/src/database/sql/convert.go
@@ -44,7 +44,7 @@ func driverArgs(ds *driverStmt, args []interface{}) ([]driver.Value, error) {
 	// Let the Stmt convert its own arguments.
 	for n, arg := range args {
 		// First, see if the value itself knows how to convert
-		// itself to a driver type.  For example, a NullString
+		// itself to a driver type. For example, a NullString
 		// struct changing into a string or nil.
 		if svi, ok := arg.(driver.Valuer); ok {
 			sv, err := svi.Value()
diff --git a/src/database/sql/driver/driver.go b/src/database/sql/driver/driver.go
index eca25f29a0..70c44fb921 100644
--- a/src/database/sql/driver/driver.go
+++ b/src/database/sql/driver/driver.go
@@ -144,7 +144,7 @@ type Stmt interface {
 // any type to a driver Value.
 type ColumnConverter interface {
 	// ColumnConverter returns a ValueConverter for the provided
-	// column index.  If the type of a specific column isn't known
+	// column index. If the type of a specific column isn't known
 	// or shouldn't be handled specially, DefaultValueConverter
 	// can be returned.
 	ColumnConverter(idx int) ValueConverter
@@ -154,7 +154,7 @@ type ColumnConverter interface {
 type Rows interface {
 	// Columns returns the names of the columns. The number of
 	// columns of the result is inferred from the length of the
-	// slice.  If a particular column name isn't known, an empty
+	// slice. If a particular column name isn't known, an empty
 	// string should be returned for that entry.
 	Columns() []string
 
diff --git a/src/database/sql/driver/types.go b/src/database/sql/driver/types.go
index bc54784989..fbca1ea635 100644
--- a/src/database/sql/driver/types.go
+++ b/src/database/sql/driver/types.go
@@ -15,7 +15,7 @@ import (
 //
 // Various implementations of ValueConverter are provided by the
 // driver package to provide consistent implementations of conversions
-// between drivers.  The ValueConverters have several uses:
+// between drivers. The ValueConverters have several uses:
 //
 //  * converting from the Value types as provided by the sql package
 //    into a database table's specific column type and making sure it
diff --git a/src/database/sql/fakedb_test.go b/src/database/sql/fakedb_test.go
index b5ff121358..662c81d1e9 100644
--- a/src/database/sql/fakedb_test.go
+++ b/src/database/sql/fakedb_test.go
@@ -37,7 +37,7 @@ var _ = log.Printf
 // named method on fakeStmt to panic.
 //
 // When opening a fakeDriver's database, it starts empty with no
-// tables.  All tables and data are stored in memory only.
+// tables. All tables and data are stored in memory only.
 type fakeDriver struct {
 	mu         sync.Mutex // guards 3 following fields
 	openCount  int        // conn opens
@@ -705,7 +705,7 @@ func (s *fakeStmt) Query(args []driver.Value) (driver.Rows, error) {
 rows:
 	for _, trow := range t.rows {
 		// Process the where clause, skipping non-match rows. This is lazy
-		// and just uses fmt.Sprintf("%v") to test equality.  Good enough
+		// and just uses fmt.Sprintf("%v") to test equality. Good enough
 		// for test code.
 		for widx, wcol := range s.whereCol {
 			idx := t.columnIndex(wcol)
diff --git a/src/database/sql/sql.go b/src/database/sql/sql.go
index 28c36160b5..7ba7ce5c90 100644
--- a/src/database/sql/sql.go
+++ b/src/database/sql/sql.go
@@ -797,7 +797,7 @@ func (db *DB) conn(strategy connReuseStrategy) (*driverConn, error) {
 		return conn, nil
 	}
 
-	// Out of free connections or we were asked not to use one.  If we're not
+	// Out of free connections or we were asked not to use one. If we're not
 	// allowed to open any more connections, make a request and wait.
 	if db.maxOpen > 0 && db.numOpen >= db.maxOpen {
 		// Make the connRequest channel. It's buffered so that the
@@ -1207,7 +1207,7 @@ type Tx struct {
 	// ErrTxDone.
 	done bool
 
-	// All Stmts prepared for this transaction.  These will be closed after the
+	// All Stmts prepared for this transaction. These will be closed after the
 	// transaction has been committed or rolled back.
 	stmts struct {
 		sync.Mutex
@@ -1286,7 +1286,7 @@ func (tx *Tx) Prepare(query string) (*Stmt, error) {
 	// necessary. Or, better: keep a map in DB of query string to
 	// Stmts, and have Stmt.Execute do the right thing and
 	// re-prepare if the Conn in use doesn't have that prepared
-	// statement.  But we'll want to avoid caching the statement
+	// statement. But we'll want to avoid caching the statement
 	// in the case where we only call conn.Prepare implicitly
 	// (such as in db.Exec or tx.Exec), but the caller package
 	// can't be holding a reference to the returned statement.
@@ -1334,7 +1334,7 @@ func (tx *Tx) Prepare(query string) (*Stmt, error) {
 // be used once the transaction has been committed or rolled back.
 func (tx *Tx) Stmt(stmt *Stmt) *Stmt {
 	// TODO(bradfitz): optimize this. Currently this re-prepares
-	// each time.  This is fine for now to illustrate the API but
+	// each time. This is fine for now to illustrate the API but
 	// we should really cache already-prepared statements
 	// per-Conn. See also the big comment in Tx.Prepare.
 
@@ -1441,9 +1441,9 @@ type Stmt struct {
 	closed bool
 
 	// css is a list of underlying driver statement interfaces
-	// that are valid on particular connections.  This is only
+	// that are valid on particular connections. This is only
 	// used if tx == nil and one is found that has idle
-	// connections.  If tx != nil, txsi is always used.
+	// connections. If tx != nil, txsi is always used.
 	css []connStmt
 
 	// lastNumClosed is copied from db.numClosed when Stmt is created
@@ -1741,9 +1741,9 @@ type Rows struct {
 	closeStmt driver.Stmt // if non-nil, statement to Close on close
 }
 
-// Next prepares the next result row for reading with the Scan method.  It
+// Next prepares the next result row for reading with the Scan method. It
 // returns true on success, or false if there is no next result row or an error
-// happened while preparing it.  Err should be consulted to distinguish between
+// happened while preparing it. Err should be consulted to distinguish between
 // the two cases.
 //
 // Every call to Scan, even the first one, must be preceded by a call to Next.
@@ -1898,8 +1898,8 @@ func (r *Row) Scan(dest ...interface{}) error {
 	// the Rows in our defer, when we return from this function.
 	// the contract with the driver.Next(...) interface is that it
 	// can return slices into read-only temporary memory that's
-	// only valid until the next Scan/Close.  But the TODO is that
-	// for a lot of drivers, this copy will be unnecessary.  We
+	// only valid until the next Scan/Close. But the TODO is that
+	// for a lot of drivers, this copy will be unnecessary. We
 	// should provide an optional interface for drivers to
 	// implement to say, "don't worry, the []bytes that I return
 	// from Next will not be modified again." (for instance, if
diff --git a/src/database/sql/sql_test.go b/src/database/sql/sql_test.go
index 68f17fb6b0..6f11303c14 100644
--- a/src/database/sql/sql_test.go
+++ b/src/database/sql/sql_test.go
@@ -911,7 +911,7 @@ func nullTestRun(t *testing.T, spec nullTestSpec) {
 	if err == nil {
 		// TODO: this test fails, but it's just because
 		// fakeConn implements the optional Execer interface,
-		// so arguably this is the correct behavior.  But
+		// so arguably this is the correct behavior. But
 		// maybe I should flesh out the fakeConn.Exec
 		// implementation so this properly fails.
 		// t.Errorf("expected error inserting nil name with Exec")
diff --git a/src/debug/dwarf/buf.go b/src/debug/dwarf/buf.go
index 98fe7a6ec6..7443043c11 100644
--- a/src/debug/dwarf/buf.go
+++ b/src/debug/dwarf/buf.go
@@ -22,16 +22,16 @@ type buf struct {
 	err    error
 }
 
-// Data format, other than byte order.  This affects the handling of
+// Data format, other than byte order. This affects the handling of
 // certain field formats.
 type dataFormat interface {
-	// DWARF version number.  Zero means unknown.
+	// DWARF version number. Zero means unknown.
 	version() int
 
 	// 64-bit DWARF format?
 	dwarf64() (dwarf64 bool, isKnown bool)
 
-	// Size of an address, in bytes.  Zero means unknown.
+	// Size of an address, in bytes. Zero means unknown.
 	addrsize() int
 }
 
diff --git a/src/debug/dwarf/entry.go b/src/debug/dwarf/entry.go
index 5001bf85a2..6f72005e72 100644
--- a/src/debug/dwarf/entry.go
+++ b/src/debug/dwarf/entry.go
@@ -506,7 +506,7 @@ func (b *buf) entry(atab abbrevTable, ubase Offset) *Entry {
 }
 
 // A Reader allows reading Entry structures from a DWARF ``info'' section.
-// The Entry structures are arranged in a tree.  The Reader's Next function
+// The Entry structures are arranged in a tree. The Reader's Next function
 // return successive entries from a pre-order traversal of the tree.
 // If an entry has children, its Children field will be true, and the children
 // follow, terminated by an Entry with Tag 0.
@@ -598,7 +598,7 @@ func (r *Reader) Next() (*Entry, error) {
 }
 
 // SkipChildren skips over the child entries associated with
-// the last Entry returned by Next.  If that Entry did not have
+// the last Entry returned by Next. If that Entry did not have
 // children or Next has not been called, SkipChildren is a no-op.
 func (r *Reader) SkipChildren() {
 	if r.err != nil || !r.lastChildren {
@@ -625,13 +625,13 @@ func (r *Reader) SkipChildren() {
 	}
 }
 
-// clone returns a copy of the reader.  This is used by the typeReader
+// clone returns a copy of the reader. This is used by the typeReader
 // interface.
 func (r *Reader) clone() typeReader {
 	return r.d.Reader()
 }
 
-// offset returns the current buffer offset.  This is used by the
+// offset returns the current buffer offset. This is used by the
 // typeReader interface.
 func (r *Reader) offset() Offset {
 	return r.b.off
diff --git a/src/debug/dwarf/open.go b/src/debug/dwarf/open.go
index 7255195031..0e9c01c2e9 100644
--- a/src/debug/dwarf/open.go
+++ b/src/debug/dwarf/open.go
@@ -78,9 +78,9 @@ func New(abbrev, aranges, frame, info, line, pubnames, ranges, str []byte) (*Dat
 	return d, nil
 }
 
-// AddTypes will add one .debug_types section to the DWARF data.  A
+// AddTypes will add one .debug_types section to the DWARF data. A
 // typical object with DWARF version 4 debug info will have multiple
-// .debug_types sections.  The name is used for error reporting only,
+// .debug_types sections. The name is used for error reporting only,
 // and serves to distinguish one .debug_types section from another.
 func (d *Data) AddTypes(name string, types []byte) error {
 	return d.parseTypes(name, types)
diff --git a/src/debug/dwarf/type.go b/src/debug/dwarf/type.go
index e4dc6480d8..9b39078a6f 100644
--- a/src/debug/dwarf/type.go
+++ b/src/debug/dwarf/type.go
@@ -356,7 +356,7 @@ func (d *Data) readType(name string, r typeReader, off Offset, typeCache map[Off
 	}
 
 	// Get Type referred to by Entry's AttrType field.
-	// Set err if error happens.  Not having a type is an error.
+	// Set err if error happens. Not having a type is an error.
 	typeOf := func(e *Entry) Type {
 		tval := e.Val(AttrType)
 		var t Type
@@ -549,7 +549,7 @@ func (d *Data) readType(name string, r typeReader, off Offset, typeCache map[Off
 					bito = f.ByteOffset * 8
 				}
 				if bito == lastFieldBitOffset && t.Kind != "union" {
-					// Last field was zero width.  Fix array length.
+					// Last field was zero width. Fix array length.
 					// (DWARF writes out 0-length arrays as if they were 1-length arrays.)
 					zeroArray(lastFieldType)
 				}
@@ -560,7 +560,7 @@ func (d *Data) readType(name string, r typeReader, off Offset, typeCache map[Off
 		if t.Kind != "union" {
 			b, ok := e.Val(AttrByteSize).(int64)
 			if ok && b*8 == lastFieldBitOffset {
-				// Final field must be zero width.  Fix array length.
+				// Final field must be zero width. Fix array length.
 				zeroArray(lastFieldType)
 			}
 		}
diff --git a/src/debug/dwarf/type_test.go b/src/debug/dwarf/type_test.go
index 2bd7a48961..0283466f08 100644
--- a/src/debug/dwarf/type_test.go
+++ b/src/debug/dwarf/type_test.go
@@ -34,7 +34,7 @@ var typedefTests = map[string]string{
 }
 
 // As Apple converts gcc to a clang-based front end
-// they keep breaking the DWARF output.  This map lists the
+// they keep breaking the DWARF output. This map lists the
 // conversion from real answer to Apple answer.
 var machoBug = map[string]string{
 	"func(*char, ...) void":                                 "func(*char) void",
diff --git a/src/debug/dwarf/typeunit.go b/src/debug/dwarf/typeunit.go
index 4032cd4745..ed42547386 100644
--- a/src/debug/dwarf/typeunit.go
+++ b/src/debug/dwarf/typeunit.go
@@ -9,11 +9,11 @@ import (
 	"strconv"
 )
 
-// Parse the type units stored in a DWARF4 .debug_types section.  Each
+// Parse the type units stored in a DWARF4 .debug_types section. Each
 // type unit defines a single primary type and an 8-byte signature.
 // Other sections may then use formRefSig8 to refer to the type.
 
-// The typeUnit format is a single type with a signature.  It holds
+// The typeUnit format is a single type with a signature. It holds
 // the same data as a compilation unit.
 type typeUnit struct {
 	unit
diff --git a/src/debug/elf/elf.go b/src/debug/elf/elf.go
index f53ba0079a..613b8c501d 100644
--- a/src/debug/elf/elf.go
+++ b/src/debug/elf/elf.go
@@ -1896,7 +1896,7 @@ type Prog32 struct {
 	Align  uint32 /* Alignment in memory and file. */
 }
 
-// ELF32 Dynamic structure.  The ".dynamic" section contains an array of them.
+// ELF32 Dynamic structure. The ".dynamic" section contains an array of them.
 type Dyn32 struct {
 	Tag int32  /* Entry type. */
 	Val uint32 /* Integer/Address value. */
@@ -1997,7 +1997,7 @@ type Prog64 struct {
 	Align  uint64 /* Alignment in memory and file. */
 }
 
-// ELF64 Dynamic structure.  The ".dynamic" section contains an array of them.
+// ELF64 Dynamic structure. The ".dynamic" section contains an array of them.
 type Dyn64 struct {
 	Tag int64  /* Entry type. */
 	Val uint64 /* Integer/address value */
diff --git a/src/debug/gosym/pclntab.go b/src/debug/gosym/pclntab.go
index 3aad41fe06..01a9f11f05 100644
--- a/src/debug/gosym/pclntab.go
+++ b/src/debug/gosym/pclntab.go
@@ -53,7 +53,7 @@ const oldQuantum = 1
 func (t *LineTable) parse(targetPC uint64, targetLine int) (b []byte, pc uint64, line int) {
 	// The PC/line table can be thought of as a sequence of
 	//  <pc update>* <line update>
-	// batches.  Each update batch results in a (pc, line) pair,
+	// batches. Each update batch results in a (pc, line) pair,
 	// where line applies to every PC from pc up to but not
 	// including the pc of the next pair.
 	//
diff --git a/src/debug/gosym/symtab.go b/src/debug/gosym/symtab.go
index aab53752ea..bde4cc7ac5 100644
--- a/src/debug/gosym/symtab.go
+++ b/src/debug/gosym/symtab.go
@@ -103,7 +103,7 @@ type Obj struct {
  * Symbol tables
  */
 
-// Table represents a Go symbol table.  It stores all of the
+// Table represents a Go symbol table. It stores all of the
 // symbols decoded from the program and provides methods to translate
 // between symbols, names, and addresses.
 type Table struct {
@@ -353,7 +353,7 @@ func NewTable(symtab []byte, pcln *LineTable) (*Table, error) {
 	}
 
 	// Count text symbols and attach frame sizes, parameters, and
-	// locals to them.  Also, find object file boundaries.
+	// locals to them. Also, find object file boundaries.
 	lastf := 0
 	for i := 0; i < len(t.Syms); i++ {
 		sym := &t.Syms[i]
@@ -503,7 +503,7 @@ func (t *Table) PCToLine(pc uint64) (file string, line int, fn *Func) {
 }
 
 // LineToPC looks up the first program counter on the given line in
-// the named file.  It returns UnknownPathError or UnknownLineError if
+// the named file. It returns UnknownPathError or UnknownLineError if
 // there is an error looking up this line.
 func (t *Table) LineToPC(file string, line int) (pc uint64, fn *Func, err error) {
 	obj, ok := t.Files[file]
diff --git a/src/encoding/ascii85/ascii85.go b/src/encoding/ascii85/ascii85.go
index 4d7193873a..d42eb0ab00 100644
--- a/src/encoding/ascii85/ascii85.go
+++ b/src/encoding/ascii85/ascii85.go
@@ -20,7 +20,7 @@ import (
 //
 // The encoding handles 4-byte chunks, using a special encoding
 // for the last fragment, so Encode is not appropriate for use on
-// individual blocks of a large data stream.  Use NewEncoder() instead.
+// individual blocks of a large data stream. Use NewEncoder() instead.
 //
 // Often, ascii85-encoded data is wrapped in <~ and ~> symbols.
 // Encode does not add these.
@@ -85,7 +85,7 @@ func Encode(dst, src []byte) int {
 // MaxEncodedLen returns the maximum length of an encoding of n source bytes.
 func MaxEncodedLen(n int) int { return (n + 3) / 4 * 5 }
 
-// NewEncoder returns a new ascii85 stream encoder.  Data written to
+// NewEncoder returns a new ascii85 stream encoder. Data written to
 // the returned writer will be encoded and then written to w.
 // Ascii85 encodings operate in 32-bit blocks; when finished
 // writing, the caller must Close the returned encoder to flush any
@@ -294,7 +294,7 @@ func (d *decoder) Read(p []byte) (n int, err error) {
 			}
 		}
 
-		// Out of input, out of decoded output.  Check errors.
+		// Out of input, out of decoded output. Check errors.
 		if d.err != nil {
 			return 0, d.err
 		}
diff --git a/src/encoding/asn1/marshal.go b/src/encoding/asn1/marshal.go
index 6e858584a6..2b796c4e75 100644
--- a/src/encoding/asn1/marshal.go
+++ b/src/encoding/asn1/marshal.go
@@ -17,7 +17,7 @@ import (
 
 // A forkableWriter is an in-memory buffer that can be
 // 'forked' to create new forkableWriters that bracket the
-// original.  After
+// original. After
 //    pre, post := w.fork()
 // the overall sequence of bytes represented is logically w+pre+post.
 type forkableWriter struct {
diff --git a/src/encoding/base32/base32.go b/src/encoding/base32/base32.go
index 5a9e86919d..c193e65e1b 100644
--- a/src/encoding/base32/base32.go
+++ b/src/encoding/base32/base32.go
@@ -17,7 +17,7 @@ import (
  */
 
 // An Encoding is a radix 32 encoding/decoding scheme, defined by a
-// 32-character alphabet.  The most common is the "base32" encoding
+// 32-character alphabet. The most common is the "base32" encoding
 // introduced for SASL GSSAPI and standardized in RFC 4648.
 // The alternate "base32hex" encoding is used in DNSSEC.
 type Encoding struct {
@@ -66,7 +66,7 @@ var removeNewlinesMapper = func(r rune) rune {
 //
 // The encoding pads the output to a multiple of 8 bytes,
 // so Encode is not appropriate for use on individual blocks
-// of a large data stream.  Use NewEncoder() instead.
+// of a large data stream. Use NewEncoder() instead.
 func (enc *Encoding) Encode(dst, src []byte) {
 	if len(src) == 0 {
 		return
@@ -208,7 +208,7 @@ func (e *encoder) Close() error {
 	return e.err
 }
 
-// NewEncoder returns a new base32 stream encoder.  Data written to
+// NewEncoder returns a new base32 stream encoder. Data written to
 // the returned writer will be encoded using enc and then written to w.
 // Base32 encodings operate in 5-byte blocks; when finished
 // writing, the caller must Close the returned encoder to flush any
@@ -313,9 +313,9 @@ func (enc *Encoding) decode(dst, src []byte) (n int, end bool, err error) {
 	return n, end, nil
 }
 
-// Decode decodes src using the encoding enc.  It writes at most
+// Decode decodes src using the encoding enc. It writes at most
 // DecodedLen(len(src)) bytes to dst and returns the number of bytes
-// written.  If src contains invalid base32 data, it will return the
+// written. If src contains invalid base32 data, it will return the
 // number of bytes successfully written and CorruptInputError.
 // New line characters (\r and \n) are ignored.
 func (enc *Encoding) Decode(dst, src []byte) (n int, err error) {
diff --git a/src/encoding/base64/base64.go b/src/encoding/base64/base64.go
index 1bda804c38..0de9b40f85 100644
--- a/src/encoding/base64/base64.go
+++ b/src/encoding/base64/base64.go
@@ -15,7 +15,7 @@ import (
  */
 
 // An Encoding is a radix 64 encoding/decoding scheme, defined by a
-// 64-character alphabet.  The most common encoding is the "base64"
+// 64-character alphabet. The most common encoding is the "base64"
 // encoding defined in RFC 4648 and used in MIME (RFC 2045) and PEM
 // (RFC 1421).  RFC 4648 also defines an alternate encoding, which is
 // the standard encoding with - and _ substituted for + and /.
@@ -89,7 +89,7 @@ var RawURLEncoding = URLEncoding.WithPadding(NoPadding)
 //
 // The encoding pads the output to a multiple of 4 bytes,
 // so Encode is not appropriate for use on individual blocks
-// of a large data stream.  Use NewEncoder() instead.
+// of a large data stream. Use NewEncoder() instead.
 func (enc *Encoding) Encode(dst, src []byte) {
 	if len(src) == 0 {
 		return
@@ -213,7 +213,7 @@ func (e *encoder) Close() error {
 	return e.err
 }
 
-// NewEncoder returns a new base64 stream encoder.  Data written to
+// NewEncoder returns a new base64 stream encoder. Data written to
 // the returned writer will be encoded using enc and then written to w.
 // Base64 encodings operate in 4-byte blocks; when finished
 // writing, the caller must Close the returned encoder to flush any
@@ -328,9 +328,9 @@ func (enc *Encoding) decode(dst, src []byte) (n int, end bool, err error) {
 	return n, end, err
 }
 
-// Decode decodes src using the encoding enc.  It writes at most
+// Decode decodes src using the encoding enc. It writes at most
 // DecodedLen(len(src)) bytes to dst and returns the number of bytes
-// written.  If src contains invalid base64 data, it will return the
+// written. If src contains invalid base64 data, it will return the
 // number of bytes successfully written and CorruptInputError.
 // New line characters (\r and \n) are ignored.
 func (enc *Encoding) Decode(dst, src []byte) (n int, err error) {
diff --git a/src/encoding/binary/binary_test.go b/src/encoding/binary/binary_test.go
index efc425ec42..3511a996a1 100644
--- a/src/encoding/binary/binary_test.go
+++ b/src/encoding/binary/binary_test.go
@@ -266,7 +266,7 @@ func TestBlankFields(t *testing.T) {
 }
 
 // An attempt to read into a struct with an unexported field will
-// panic.  This is probably not the best choice, but at this point
+// panic. This is probably not the best choice, but at this point
 // anything else would be an API change.
 
 type Unexported struct {
diff --git a/src/encoding/csv/reader.go b/src/encoding/csv/reader.go
index 816ed26754..58f6eed1e6 100644
--- a/src/encoding/csv/reader.go
+++ b/src/encoding/csv/reader.go
@@ -14,11 +14,11 @@
 //
 // Carriage returns before newline characters are silently removed.
 //
-// Blank lines are ignored.  A line with only whitespace characters (excluding
+// Blank lines are ignored. A line with only whitespace characters (excluding
 // the ending newline character) is not considered a blank line.
 //
 // Fields which start and stop with the quote character " are called
-// quoted-fields.  The beginning and ending quote are not part of the
+// quoted-fields. The beginning and ending quote are not part of the
 // field.
 //
 // The source:
@@ -84,15 +84,15 @@ var (
 // The exported fields can be changed to customize the details before the
 // first call to Read or ReadAll.
 //
-// Comma is the field delimiter.  It defaults to ','.
+// Comma is the field delimiter. It defaults to ','.
 //
 // Comment, if not 0, is the comment character. Lines beginning with the
 // Comment character are ignored.
 //
 // If FieldsPerRecord is positive, Read requires each record to
-// have the given number of fields.  If FieldsPerRecord is 0, Read sets it to
+// have the given number of fields. If FieldsPerRecord is 0, Read sets it to
 // the number of fields in the first record, so that future records must
-// have the same field count.  If FieldsPerRecord is negative, no check is
+// have the same field count. If FieldsPerRecord is negative, no check is
 // made and records may have a variable number of fields.
 //
 // If LazyQuotes is true, a quote may appear in an unquoted field and a
@@ -131,7 +131,7 @@ func (r *Reader) error(err error) error {
 	}
 }
 
-// Read reads one record from r.  The record is a slice of strings with each
+// Read reads one record from r. The record is a slice of strings with each
 // string representing one field.
 func (r *Reader) Read() (record []string, err error) {
 	for {
@@ -179,7 +179,7 @@ func (r *Reader) ReadAll() (records [][]string, err error) {
 func (r *Reader) readRune() (rune, error) {
 	r1, _, err := r.r.ReadRune()
 
-	// Handle \r\n here.  We make the simplifying assumption that
+	// Handle \r\n here. We make the simplifying assumption that
 	// anytime \r is followed by \n that it can be folded to \n.
 	// We will not detect files which contain both \r\n and bare \n.
 	if r1 == '\r' {
@@ -210,13 +210,13 @@ func (r *Reader) skip(delim rune) error {
 
 // parseRecord reads and parses a single csv record from r.
 func (r *Reader) parseRecord() (fields []string, err error) {
-	// Each record starts on a new line.  We increment our line
+	// Each record starts on a new line. We increment our line
 	// number (lines start at 1, not 0) and set column to -1
 	// so as we increment in readRune it points to the character we read.
 	r.line++
 	r.column = -1
 
-	// Peek at the first rune.  If it is an error we are done.
+	// Peek at the first rune. If it is an error we are done.
 	// If we support comments and it is the comment character
 	// then skip to the end of line.
 
@@ -249,8 +249,8 @@ func (r *Reader) parseRecord() (fields []string, err error) {
 	}
 }
 
-// parseField parses the next field in the record.  The read field is
-// located in r.field.  Delim is the first character not part of the field
+// parseField parses the next field in the record. The read field is
+// located in r.field. Delim is the first character not part of the field
 // (r.Comma or '\n').
 func (r *Reader) parseField() (haveField bool, delim rune, err error) {
 	r.field.Reset()
diff --git a/src/encoding/csv/writer.go b/src/encoding/csv/writer.go
index e8739fb554..84b7aa1ed1 100644
--- a/src/encoding/csv/writer.go
+++ b/src/encoding/csv/writer.go
@@ -15,7 +15,7 @@ import (
 // A Writer writes records to a CSV encoded file.
 //
 // As returned by NewWriter, a Writer writes records terminated by a
-// newline and uses ',' as the field delimiter.  The exported fields can be
+// newline and uses ',' as the field delimiter. The exported fields can be
 // changed to customize the details before the first call to Write or WriteAll.
 //
 // Comma is the field delimiter.
diff --git a/src/encoding/gob/debug.go b/src/encoding/gob/debug.go
index 536bbdb5ac..d69d36f516 100644
--- a/src/encoding/gob/debug.go
+++ b/src/encoding/gob/debug.go
@@ -7,7 +7,7 @@
 
 package gob
 
-// This file is not normally included in the gob package.  Used only for debugging the package itself.
+// This file is not normally included in the gob package. Used only for debugging the package itself.
 // Except for reading uints, it is an implementation of a reader that is independent of
 // the one implemented by Decoder.
 // To enable the Debug function, delete the +build ignore line above and do
@@ -241,7 +241,7 @@ func (deb *debugger) delimitedMessage(indent tab) bool {
 // loadBlock preps us to read a message
 // of the length specified next in the input. It returns
 // the length of the block. The argument tells whether
-// an EOF is acceptable now.  If it is and one is found,
+// an EOF is acceptable now. If it is and one is found,
 // the return value is negative.
 func (deb *debugger) loadBlock(eofOK bool) int {
 	n64, w, err := decodeUintReader(deb.r, deb.tmp) // deb.uint64 will error at EOF
@@ -339,7 +339,7 @@ func (deb *debugger) string() string {
 	return string(b)
 }
 
-// delta returns the field delta at the input point.  The expect argument,
+// delta returns the field delta at the input point. The expect argument,
 // if non-negative, identifies what the value should be.
 func (deb *debugger) delta(expect int) int {
 	delta := int(deb.uint64())
diff --git a/src/encoding/gob/decode.go b/src/encoding/gob/decode.go
index 3b0dca86f3..3b2249f616 100644
--- a/src/encoding/gob/decode.go
+++ b/src/encoding/gob/decode.go
@@ -216,10 +216,10 @@ func ignoreTwoUints(i *decInstr, state *decoderState, v reflect.Value) {
 }
 
 // Since the encoder writes no zeros, if we arrive at a decoder we have
-// a value to extract and store.  The field number has already been read
+// a value to extract and store. The field number has already been read
 // (it's how we knew to call this decoder).
 // Each decoder is responsible for handling any indirections associated
-// with the data structure.  If any pointer so reached is nil, allocation must
+// with the data structure. If any pointer so reached is nil, allocation must
 // be done.
 
 // decAlloc takes a value and returns a settable value that can
@@ -308,9 +308,9 @@ func decUint64(i *decInstr, state *decoderState, value reflect.Value) {
 }
 
 // Floating-point numbers are transmitted as uint64s holding the bits
-// of the underlying representation.  They are sent byte-reversed, with
+// of the underlying representation. They are sent byte-reversed, with
 // the exponent end coming out first, so integer floating point numbers
-// (for example) transmit more compactly.  This routine does the
+// (for example) transmit more compactly. This routine does the
 // unswizzling.
 func float64FromBits(u uint64) float64 {
 	var v uint64
@@ -332,7 +332,7 @@ func float32FromBits(u uint64, ovfl error) float64 {
 	if av < 0 {
 		av = -av
 	}
-	// +Inf is OK in both 32- and 64-bit floats.  Underflow is always OK.
+	// +Inf is OK in both 32- and 64-bit floats. Underflow is always OK.
 	if math.MaxFloat32 < av && av <= math.MaxFloat64 {
 		error_(ovfl)
 	}
@@ -421,7 +421,7 @@ func ignoreUint8Array(i *decInstr, state *decoderState, value reflect.Value) {
 // Execution engine
 
 // The encoder engine is an array of instructions indexed by field number of the incoming
-// decoder.  It is executed with random access according to field number.
+// decoder. It is executed with random access according to field number.
 type decEngine struct {
 	instr    []decInstr
 	numInstr int // the number of active instructions
@@ -442,7 +442,7 @@ func (dec *Decoder) decodeSingle(engine *decEngine, ut *userTypeInfo, value refl
 }
 
 // decodeStruct decodes a top-level struct and stores it in value.
-// Indir is for the value, not the type.  At the time of the call it may
+// Indir is for the value, not the type. At the time of the call it may
 // differ from ut.indir, which was computed when the engine was built.
 // This state cannot arise for decodeSingle, which is called directly
 // from the user's value, not from the innards of an engine.
@@ -536,7 +536,7 @@ func (dec *Decoder) decodeArrayHelper(state *decoderState, value reflect.Value,
 }
 
 // decodeArray decodes an array and stores it in value.
-// The length is an unsigned integer preceding the elements.  Even though the length is redundant
+// The length is an unsigned integer preceding the elements. Even though the length is redundant
 // (it's part of the type), it's a useful check and is included in the encoding.
 func (dec *Decoder) decodeArray(atyp reflect.Type, state *decoderState, value reflect.Value, elemOp decOp, length int, ovfl error, helper decHelper) {
 	if n := state.decodeUint(); n != uint64(length) {
@@ -1075,7 +1075,7 @@ func (dec *Decoder) compileIgnoreSingle(remoteId typeId) (engine *decEngine, err
 	return
 }
 
-// compileDec compiles the decoder engine for a value.  If the value is not a struct,
+// compileDec compiles the decoder engine for a value. If the value is not a struct,
 // it calls out to compileSingle.
 func (dec *Decoder) compileDec(remoteId typeId, ut *userTypeInfo) (engine *decEngine, err error) {
 	defer catchError(&err)
diff --git a/src/encoding/gob/decoder.go b/src/encoding/gob/decoder.go
index c453e9ba39..c182941773 100644
--- a/src/encoding/gob/decoder.go
+++ b/src/encoding/gob/decoder.go
@@ -130,9 +130,9 @@ func (dec *Decoder) nextUint() uint64 {
 // decodeTypeSequence parses:
 // TypeSequence
 //	(TypeDefinition DelimitedTypeDefinition*)?
-// and returns the type id of the next value.  It returns -1 at
+// and returns the type id of the next value. It returns -1 at
 // EOF.  Upon return, the remainder of dec.buf is the value to be
-// decoded.  If this is an interface value, it can be ignored by
+// decoded. If this is an interface value, it can be ignored by
 // resetting that buffer.
 func (dec *Decoder) decodeTypeSequence(isInterface bool) typeId {
 	for dec.err == nil {
@@ -150,7 +150,7 @@ func (dec *Decoder) decodeTypeSequence(isInterface bool) typeId {
 		// Type definition for (-id) follows.
 		dec.recvType(-id)
 		// When decoding an interface, after a type there may be a
-		// DelimitedValue still in the buffer.  Skip its count.
+		// DelimitedValue still in the buffer. Skip its count.
 		// (Alternatively, the buffer is empty and the byte count
 		// will be absorbed by recvMessage.)
 		if dec.buf.Len() > 0 {
@@ -177,7 +177,7 @@ func (dec *Decoder) Decode(e interface{}) error {
 	}
 	value := reflect.ValueOf(e)
 	// If e represents a value as opposed to a pointer, the answer won't
-	// get back to the caller.  Make sure it's a pointer.
+	// get back to the caller. Make sure it's a pointer.
 	if value.Type().Kind() != reflect.Ptr {
 		dec.err = errors.New("gob: attempt to decode into a non-pointer")
 		return dec.err
@@ -187,7 +187,7 @@ func (dec *Decoder) Decode(e interface{}) error {
 
 // DecodeValue reads the next value from the input stream.
 // If v is the zero reflect.Value (v.Kind() == Invalid), DecodeValue discards the value.
-// Otherwise, it stores the value into v.  In that case, v must represent
+// Otherwise, it stores the value into v. In that case, v must represent
 // a non-nil pointer to data or be an assignable reflect.Value (v.CanSet())
 // If the input is at EOF, DecodeValue returns io.EOF and
 // does not modify v.
diff --git a/src/encoding/gob/encode.go b/src/encoding/gob/encode.go
index 96052ef33b..2b3a556eac 100644
--- a/src/encoding/gob/encode.go
+++ b/src/encoding/gob/encode.go
@@ -96,7 +96,7 @@ func (enc *Encoder) freeEncoderState(e *encoderState) {
 	enc.freeList = e
 }
 
-// Unsigned integers have a two-state encoding.  If the number is less
+// Unsigned integers have a two-state encoding. If the number is less
 // than 128 (0 through 0x7F), its value is written directly.
 // Otherwise the value is written in big-endian byte order preceded
 // by the byte length, negated.
@@ -152,8 +152,8 @@ func (state *encoderState) update(instr *encInstr) {
 
 // Each encoder for a composite is responsible for handling any
 // indirections associated with the elements of the data structure.
-// If any pointer so reached is nil, no bytes are written.  If the
-// data item is zero, no bytes are written.  Single values - ints,
+// If any pointer so reached is nil, no bytes are written. If the
+// data item is zero, no bytes are written. Single values - ints,
 // strings etc. - are indirected before calling their encoders.
 // Otherwise, the output (for a scalar) is the field number, as an
 // encoded integer, followed by the field data in its appropriate
@@ -203,9 +203,9 @@ func encUint(i *encInstr, state *encoderState, v reflect.Value) {
 
 // floatBits returns a uint64 holding the bits of a floating-point number.
 // Floating-point numbers are transmitted as uint64s holding the bits
-// of the underlying representation.  They are sent byte-reversed, with
+// of the underlying representation. They are sent byte-reversed, with
 // the exponent end coming out first, so integer floating point numbers
-// (for example) transmit more compactly.  This routine does the
+// (for example) transmit more compactly. This routine does the
 // swizzling.
 func floatBits(f float64) uint64 {
 	u := math.Float64bits(f)
@@ -272,7 +272,7 @@ func encStructTerminator(i *encInstr, state *encoderState, v reflect.Value) {
 // Execution engine
 
 // encEngine an array of instructions indexed by field number of the encoding
-// data, typically a struct.  It is executed top to bottom, walking the struct.
+// data, typically a struct. It is executed top to bottom, walking the struct.
 type encEngine struct {
 	instr []encInstr
 }
@@ -297,7 +297,7 @@ func (enc *Encoder) encodeSingle(b *encBuffer, engine *encEngine, value reflect.
 	defer enc.freeEncoderState(state)
 	state.fieldnum = singletonField
 	// There is no surrounding struct to frame the transmission, so we must
-	// generate data even if the item is zero.  To do this, set sendZero.
+	// generate data even if the item is zero. To do this, set sendZero.
 	state.sendZero = true
 	instr := &engine.instr[singletonField]
 	if instr.indir > 0 {
@@ -386,7 +386,7 @@ func (enc *Encoder) encodeMap(b *encBuffer, mv reflect.Value, keyOp, elemOp encO
 // encodeInterface encodes the interface value iv.
 // To send an interface, we send a string identifying the concrete type, followed
 // by the type identifier (which might require defining that type right now), followed
-// by the concrete value.  A nil value gets sent as the empty string for the name,
+// by the concrete value. A nil value gets sent as the empty string for the name,
 // followed by no value.
 func (enc *Encoder) encodeInterface(b *encBuffer, iv reflect.Value) {
 	// Gobs can encode nil interface values but not typed interface
@@ -417,7 +417,7 @@ func (enc *Encoder) encodeInterface(b *encBuffer, iv reflect.Value) {
 	enc.sendTypeDescriptor(enc.writer(), state, ut)
 	// Send the type id.
 	enc.sendTypeId(state, ut)
-	// Encode the value into a new buffer.  Any nested type definitions
+	// Encode the value into a new buffer. Any nested type definitions
 	// should be written to b, before the encoded value.
 	enc.pushWriter(b)
 	data := encBufferPool.Get().(*encBuffer)
diff --git a/src/encoding/gob/encoder.go b/src/encoding/gob/encoder.go
index 62d0f42e81..92b559ee11 100644
--- a/src/encoding/gob/encoder.go
+++ b/src/encoding/gob/encoder.go
@@ -191,7 +191,7 @@ func (enc *Encoder) sendTypeDescriptor(w io.Writer, state *encoderState, ut *use
 			return
 		}
 		// If the type info has still not been transmitted, it means we have
-		// a singleton basic type (int, []byte etc.) at top level.  We don't
+		// a singleton basic type (int, []byte etc.) at top level. We don't
 		// need to send the type info but we do need to update enc.sent.
 		if !sent {
 			info, err := getTypeInfo(ut)
diff --git a/src/encoding/gob/encoder_test.go b/src/encoding/gob/encoder_test.go
index 811dd2b18c..9fa01d7bfc 100644
--- a/src/encoding/gob/encoder_test.go
+++ b/src/encoding/gob/encoder_test.go
@@ -439,8 +439,8 @@ func (this *interfaceIndirectTestT) F() bool {
 	return true
 }
 
-// A version of a bug reported on golang-nuts.  Also tests top-level
-// slice of interfaces.  The issue was registering *T caused T to be
+// A version of a bug reported on golang-nuts. Also tests top-level
+// slice of interfaces. The issue was registering *T caused T to be
 // stored as the concrete type.
 func TestInterfaceIndirect(t *testing.T) {
 	Register(&interfaceIndirectTestT{})
@@ -463,7 +463,7 @@ func TestInterfaceIndirect(t *testing.T) {
 
 // Also, when the ignored object contains an interface value, it may define
 // types. Make sure that skipping the value still defines the types by using
-// the encoder/decoder pair to send a value afterwards.  If an interface
+// the encoder/decoder pair to send a value afterwards. If an interface
 // is sent, its type in the test is always NewType0, so this checks that the
 // encoder and decoder don't skew with respect to type definitions.
 
@@ -913,7 +913,7 @@ func TestMutipleEncodingsOfBadType(t *testing.T) {
 // There was an error check comparing the length of the input with the
 // length of the slice being decoded. It was wrong because the next
 // thing in the input might be a type definition, which would lead to
-// an incorrect length check.  This test reproduces the corner case.
+// an incorrect length check. This test reproduces the corner case.
 
 type Z struct {
 }
diff --git a/src/encoding/gob/error.go b/src/encoding/gob/error.go
index 92cc0c615e..8b5265c278 100644
--- a/src/encoding/gob/error.go
+++ b/src/encoding/gob/error.go
@@ -9,7 +9,7 @@ import "fmt"
 // Errors in decoding and encoding are handled using panic and recover.
 // Panics caused by user error (that is, everything except run-time panics
 // such as "index out of bounds" errors) do not leave the file that caused
-// them, but are instead turned into plain error returns.  Encoding and
+// them, but are instead turned into plain error returns. Encoding and
 // decoding functions and methods that do not return an error either use
 // panic to report an error or are guaranteed error-free.
 
@@ -30,7 +30,7 @@ func error_(err error) {
 }
 
 // catchError is meant to be used as a deferred function to turn a panic(gobError) into a
-// plain error.  It overwrites the error return of the function that deferred its call.
+// plain error. It overwrites the error return of the function that deferred its call.
 func catchError(err *error) {
 	if e := recover(); e != nil {
 		ge, ok := e.(gobError)
diff --git a/src/encoding/gob/example_interface_test.go b/src/encoding/gob/example_interface_test.go
index 4681e6307b..cf5ba38607 100644
--- a/src/encoding/gob/example_interface_test.go
+++ b/src/encoding/gob/example_interface_test.go
@@ -60,7 +60,7 @@ func interfaceEncode(enc *gob.Encoder, p Pythagoras) {
 	// registered. We registered it in the calling function.
 
 	// Pass pointer to interface so Encode sees (and hence sends) a value of
-	// interface type.  If we passed p directly it would see the concrete type instead.
+	// interface type. If we passed p directly it would see the concrete type instead.
 	// See the blog post, "The Laws of Reflection" for background.
 	err := enc.Encode(&p)
 	if err != nil {
diff --git a/src/encoding/gob/example_test.go b/src/encoding/gob/example_test.go
index 020352ceee..16b71236f0 100644
--- a/src/encoding/gob/example_test.go
+++ b/src/encoding/gob/example_test.go
@@ -24,7 +24,7 @@ type Q struct {
 // This example shows the basic usage of the package: Create an encoder,
 // transmit some values, receive them with a decoder.
 func Example_basic() {
-	// Initialize the encoder and decoder.  Normally enc and dec would be
+	// Initialize the encoder and decoder. Normally enc and dec would be
 	// bound to network connections and the encoder and decoder would
 	// run in different processes.
 	var network bytes.Buffer        // Stand-in for a network connection
diff --git a/src/encoding/gob/gobencdec_test.go b/src/encoding/gob/gobencdec_test.go
index d674f0c784..ecc91eef1f 100644
--- a/src/encoding/gob/gobencdec_test.go
+++ b/src/encoding/gob/gobencdec_test.go
@@ -376,7 +376,7 @@ func TestGobEncoderIndirectArrayField(t *testing.T) {
 }
 
 // As long as the fields have the same name and implement the
-// interface, we can cross-connect them.  Not sure it's useful
+// interface, we can cross-connect them. Not sure it's useful
 // and may even be bad but it works and it's hard to prevent
 // without exposing the contents of the object, which would
 // defeat the purpose.
@@ -434,7 +434,7 @@ func TestGobEncoderValueEncoder(t *testing.T) {
 }
 
 // Test that we can use a value then a pointer type of a GobEncoder
-// in the same encoded value.  Bug 4647.
+// in the same encoded value. Bug 4647.
 func TestGobEncoderValueThenPointer(t *testing.T) {
 	v := ValueGobber("forty-two")
 	w := ValueGobber("six-by-nine")
diff --git a/src/encoding/gob/type.go b/src/encoding/gob/type.go
index cf5cec0703..c27f7e9707 100644
--- a/src/encoding/gob/type.go
+++ b/src/encoding/gob/type.go
@@ -17,7 +17,7 @@ import (
 )
 
 // userTypeInfo stores the information associated with a type the user has handed
-// to the package.  It's computed once and stored in a map keyed by reflection
+// to the package. It's computed once and stored in a map keyed by reflection
 // type.
 type userTypeInfo struct {
 	user        reflect.Type // the type the user handed us
@@ -44,7 +44,7 @@ var (
 )
 
 // validType returns, and saves, the information associated with user-provided type rt.
-// If the user type is not valid, err will be non-nil.  To be used when the error handler
+// If the user type is not valid, err will be non-nil. To be used when the error handler
 // is not set up.
 func validUserType(rt reflect.Type) (ut *userTypeInfo, err error) {
 	userTypeLock.RLock()
@@ -64,7 +64,7 @@ func validUserType(rt reflect.Type) (ut *userTypeInfo, err error) {
 	ut.base = rt
 	ut.user = rt
 	// A type that is just a cycle of pointers (such as type T *T) cannot
-	// be represented in gobs, which need some concrete data.  We use a
+	// be represented in gobs, which need some concrete data. We use a
 	// cycle detection algorithm from Knuth, Vol 2, Section 3.1, Ex 6,
 	// pp 539-540.  As we step through indirections, run another type at
 	// half speed. If they meet up, there's a cycle.
@@ -493,7 +493,7 @@ func newTypeObject(name string, ut *userTypeInfo, rt reflect.Type) (gobType, err
 		// For arrays, maps, and slices, we set the type id after the elements
 		// are constructed. This is to retain the order of type id allocation after
 		// a fix made to handle recursive types, which changed the order in
-		// which types are built.  Delaying the setting in this way preserves
+		// which types are built. Delaying the setting in this way preserves
 		// type ids while allowing recursive types to be described. Structs,
 		// done below, were already handling recursion correctly so they
 		// assign the top-level id before those of the field.
@@ -597,7 +597,7 @@ func getBaseType(name string, rt reflect.Type) (gobType, error) {
 
 // getType returns the Gob type describing the given reflect.Type.
 // Should be called only when handling GobEncoders/Decoders,
-// which may be pointers.  All other types are handled through the
+// which may be pointers. All other types are handled through the
 // base type, never a pointer.
 // typeLock must be held.
 func getType(name string, ut *userTypeInfo, rt reflect.Type) (gobType, error) {
@@ -642,7 +642,7 @@ func bootstrapType(name string, e interface{}, expect typeId) typeId {
 // For bootstrapping purposes, we assume that the recipient knows how
 // to decode a wireType; it is exactly the wireType struct here, interpreted
 // using the gob rules for sending a structure, except that we assume the
-// ids for wireType and structType etc. are known.  The relevant pieces
+// ids for wireType and structType etc. are known. The relevant pieces
 // are built in encode.go's init() function.
 // To maintain binary compatibility, if you extend this type, always put
 // the new fields last.
@@ -789,7 +789,7 @@ func mustGetTypeInfo(rt reflect.Type) *typeInfo {
 //
 // Note: Since gobs can be stored permanently, it is good design
 // to guarantee the encoding used by a GobEncoder is stable as the
-// software evolves.  For instance, it might make sense for GobEncode
+// software evolves. For instance, it might make sense for GobEncode
 // to include a version number in the encoding.
 type GobEncoder interface {
 	// GobEncode returns a byte slice representing the encoding of the
@@ -838,8 +838,8 @@ func RegisterName(name string, value interface{}) {
 }
 
 // Register records a type, identified by a value for that type, under its
-// internal type name.  That name will identify the concrete type of a value
-// sent or received as an interface variable.  Only types that will be
+// internal type name. That name will identify the concrete type of a value
+// sent or received as an interface variable. Only types that will be
 // transferred as implementations of interface values need to be registered.
 // Expecting to be used only during initialization, it panics if the mapping
 // between types and names is not a bijection.
diff --git a/src/encoding/hex/hex.go b/src/encoding/hex/hex.go
index a51b1db61c..73a25034be 100644
--- a/src/encoding/hex/hex.go
+++ b/src/encoding/hex/hex.go
@@ -18,7 +18,7 @@ const hextable = "0123456789abcdef"
 func EncodedLen(n int) int { return n * 2 }
 
 // Encode encodes src into EncodedLen(len(src))
-// bytes of dst.  As a convenience, it returns the number
+// bytes of dst. As a convenience, it returns the number
 // of bytes written to dst, but this value is always EncodedLen(len(src)).
 // Encode implements hexadecimal encoding.
 func Encode(dst, src []byte) int {
diff --git a/src/encoding/json/decode.go b/src/encoding/json/decode.go
index 539d952ad6..3e4b16e410 100644
--- a/src/encoding/json/decode.go
+++ b/src/encoding/json/decode.go
@@ -29,9 +29,9 @@ import (
 // with the following additional rules:
 //
 // To unmarshal JSON into a pointer, Unmarshal first handles the case of
-// the JSON being the JSON literal null.  In that case, Unmarshal sets
-// the pointer to nil.  Otherwise, Unmarshal unmarshals the JSON into
-// the value pointed at by the pointer.  If the pointer is nil, Unmarshal
+// the JSON being the JSON literal null. In that case, Unmarshal sets
+// the pointer to nil. Otherwise, Unmarshal unmarshals the JSON into
+// the value pointed at by the pointer. If the pointer is nil, Unmarshal
 // allocates a new value for it to point to.
 //
 // To unmarshal JSON into a struct, Unmarshal matches incoming object
@@ -534,7 +534,7 @@ func (d *decodeState) array(v reflect.Value) {
 
 	if i < v.Len() {
 		if v.Kind() == reflect.Array {
-			// Array.  Zero the rest.
+			// Array. Zero the rest.
 			z := reflect.Zero(v.Type().Elem())
 			for ; i < v.Len(); i++ {
 				v.Index(i).Set(z)
@@ -902,7 +902,7 @@ func (d *decodeState) literalStore(item []byte, v reflect.Value, fromQuoted bool
 }
 
 // The xxxInterface routines build up a value to be stored
-// in an empty interface.  They are not strictly necessary,
+// in an empty interface. They are not strictly necessary,
 // but they avoid the weight of reflection in this common case.
 
 // valueInterface is like value but returns interface{}
diff --git a/src/encoding/json/encode.go b/src/encoding/json/encode.go
index e54f7e9469..982561d6ec 100644
--- a/src/encoding/json/encode.go
+++ b/src/encoding/json/encode.go
@@ -131,7 +131,7 @@ import (
 // an UnsupportedTypeError.
 //
 // JSON cannot represent cyclic data structures and Marshal does not
-// handle them.  Passing cyclic structures to Marshal will result in
+// handle them. Passing cyclic structures to Marshal will result in
 // an infinite recursion.
 //
 func Marshal(v interface{}) ([]byte, error) {
@@ -325,7 +325,7 @@ func typeEncoder(t reflect.Type) encoderFunc {
 
 	// To deal with recursive types, populate the map with an
 	// indirect func before we build it. This type waits on the
-	// real func (f) to be ready and then calls it.  This indirect
+	// real func (f) to be ready and then calls it. This indirect
 	// func is only used for recursive types.
 	encoderCache.Lock()
 	if encoderCache.m == nil {
diff --git a/src/encoding/json/scanner.go b/src/encoding/json/scanner.go
index e495a4e8f0..a6d8706c73 100644
--- a/src/encoding/json/scanner.go
+++ b/src/encoding/json/scanner.go
@@ -132,7 +132,7 @@ const (
 
 // These values are stored in the parseState stack.
 // They give the current state of a composite value
-// being scanned.  If the parser is inside a nested value
+// being scanned. If the parser is inside a nested value
 // the parseState describes the nested state, outermost at entry 0.
 const (
 	parseObjectKey   = iota // parsing object key (before colon)
diff --git a/src/encoding/json/stream.go b/src/encoding/json/stream.go
index c056f2b6a5..f5612692b8 100644
--- a/src/encoding/json/stream.go
+++ b/src/encoding/json/stream.go
@@ -148,7 +148,7 @@ func (dec *Decoder) refill() error {
 		dec.buf = newBuf
 	}
 
-	// Read.  Delay error for next iteration (after scan).
+	// Read. Delay error for next iteration (after scan).
 	n, err := dec.r.Read(dec.buf[len(dec.buf):cap(dec.buf)])
 	dec.buf = dec.buf[0 : len(dec.buf)+n]
 
diff --git a/src/encoding/pem/pem.go b/src/encoding/pem/pem.go
index 506196b1db..ff2bed161a 100644
--- a/src/encoding/pem/pem.go
+++ b/src/encoding/pem/pem.go
@@ -150,7 +150,7 @@ func Decode(data []byte) (p *Block, rest []byte) {
 func decodeError(data, rest []byte) (*Block, []byte) {
 	// If we get here then we have rejected a likely looking, but
 	// ultimately invalid PEM block. We need to start over from a new
-	// position.  We have consumed the preamble line and will have consumed
+	// position. We have consumed the preamble line and will have consumed
 	// any lines which could be header lines. However, a valid preamble
 	// line is not a valid header line, therefore we cannot have consumed
 	// the preamble line for the any subsequent block. Thus, we will always
diff --git a/src/encoding/xml/marshal.go b/src/encoding/xml/marshal.go
index 9fcd5d7695..b9f5a39fde 100644
--- a/src/encoding/xml/marshal.go
+++ b/src/encoding/xml/marshal.go
@@ -26,9 +26,9 @@ const (
 //
 // Marshal handles an array or slice by marshalling each of the elements.
 // Marshal handles a pointer by marshalling the value it points at or, if the
-// pointer is nil, by writing nothing.  Marshal handles an interface value by
+// pointer is nil, by writing nothing. Marshal handles an interface value by
 // marshalling the value it contains or, if the interface value is nil, by
-// writing nothing.  Marshal handles all other data by writing one or more XML
+// writing nothing. Marshal handles all other data by writing one or more XML
 // elements containing the data.
 //
 // The name for the XML elements is taken from, in order of preference:
@@ -63,7 +63,7 @@ const (
 //       value were part of the outer struct.
 //
 // If a field uses a tag "a>b>c", then the element c will be nested inside
-// parent elements a and b.  Fields that appear next to each other that name
+// parent elements a and b. Fields that appear next to each other that name
 // the same parent will be enclosed in one XML element.
 //
 // See MarshalIndent for an example.
@@ -217,7 +217,7 @@ func (enc *Encoder) EncodeToken(t Token) error {
 		return p.cachedWriteError()
 	case ProcInst:
 		// First token to be encoded which is also a ProcInst with target of xml
-		// is the xml declaration.  The only ProcInst where target of xml is allowed.
+		// is the xml declaration. The only ProcInst where target of xml is allowed.
 		if t.Target == "xml" && p.Buffered() != 0 {
 			return fmt.Errorf("xml: EncodeToken of ProcInst xml target only valid for xml declaration, first token encoded")
 		}
@@ -949,8 +949,8 @@ type parentStack struct {
 }
 
 // trim updates the XML context to match the longest common prefix of the stack
-// and the given parents.  A closing tag will be written for every parent
-// popped.  Passing a zero slice or nil will close all the elements.
+// and the given parents. A closing tag will be written for every parent
+// popped. Passing a zero slice or nil will close all the elements.
 func (s *parentStack) trim(parents []string) error {
 	split := 0
 	for ; split < len(parents) && split < len(s.stack); split++ {
diff --git a/src/encoding/xml/read.go b/src/encoding/xml/read.go
index 38d7cdfb15..ee725cb8bb 100644
--- a/src/encoding/xml/read.go
+++ b/src/encoding/xml/read.go
@@ -27,7 +27,7 @@ import (
 // discarded.
 //
 // Because Unmarshal uses the reflect package, it can only assign
-// to exported (upper case) fields.  Unmarshal uses a case-sensitive
+// to exported (upper case) fields. Unmarshal uses a case-sensitive
 // comparison to match XML element names to tag values and struct
 // field names.
 //
@@ -37,7 +37,7 @@ import (
 //
 //   * If the struct has a field of type []byte or string with tag
 //      ",innerxml", Unmarshal accumulates the raw XML nested inside the
-//      element in that field.  The rest of the rules still apply.
+//      element in that field. The rest of the rules still apply.
 //
 //   * If the struct has a field named XMLName of type xml.Name,
 //      Unmarshal records the element name in that field.
@@ -59,7 +59,7 @@ import (
 //
 //   * If the XML element contains comments, they are accumulated in
 //      the first struct field that has tag ",comment".  The struct
-//      field may have type []byte or string.  If there is no such
+//      field may have type []byte or string. If there is no such
 //      field, the comments are discarded.
 //
 //   * If the XML element contains a sub-element whose name matches
@@ -102,7 +102,7 @@ import (
 //
 // Unmarshal maps an XML element or attribute value to an integer or
 // floating-point field by setting the field to the result of
-// interpreting the string value in decimal.  There is no check for
+// interpreting the string value in decimal. There is no check for
 // overflow.
 //
 // Unmarshal maps an XML element to an xml.Name by recording the
diff --git a/src/encoding/xml/xml.go b/src/encoding/xml/xml.go
index 5c2fb6f90e..9a3b792955 100644
--- a/src/encoding/xml/xml.go
+++ b/src/encoding/xml/xml.go
@@ -219,7 +219,7 @@ func NewDecoder(r io.Reader) *Decoder {
 //
 // Slices of bytes in the returned token data refer to the
 // parser's internal buffer and remain valid only until the next
-// call to Token.  To acquire a copy of the bytes, call CopyToken
+// call to Token. To acquire a copy of the bytes, call CopyToken
 // or the token's Copy method.
 //
 // Token expands self-closing elements such as <br/>
@@ -332,7 +332,7 @@ func (d *Decoder) switchToReader(r io.Reader) {
 }
 
 // Parsing state - stack holds old name space translations
-// and the current set of open elements.  The translations to pop when
+// and the current set of open elements. The translations to pop when
 // ending a given tag are *below* it on the stack, which is
 // more work but forced on us by XML.
 type stack struct {
@@ -1230,7 +1230,7 @@ func isNameString(s string) bool {
 
 // These tables were generated by cut and paste from Appendix B of
 // the XML spec at http://www.xml.com/axml/testaxml.htm
-// and then reformatting.  First corresponds to (Letter | '_' | ':')
+// and then reformatting. First corresponds to (Letter | '_' | ':')
 // and second corresponds to NameChar.
 
 var first = &unicode.RangeTable{
diff --git a/src/expvar/expvar.go b/src/expvar/expvar.go
index 1d51bc97f9..d675a0230c 100644
--- a/src/expvar/expvar.go
+++ b/src/expvar/expvar.go
@@ -15,7 +15,7 @@
 //	memstats  runtime.Memstats
 //
 // The package is sometimes only imported for the side effect of
-// registering its HTTP handler and the above variables.  To use it
+// registering its HTTP handler and the above variables. To use it
 // this way, link this package into your program:
 //	import _ "expvar"
 //
diff --git a/src/flag/flag.go b/src/flag/flag.go
index 3abc80e9c6..6acbbcd321 100644
--- a/src/flag/flag.go
+++ b/src/flag/flag.go
@@ -261,7 +261,7 @@ const (
 	PanicOnError                         // Call panic with a descriptive error.
 )
 
-// A FlagSet represents a set of defined flags.  The zero value of a FlagSet
+// A FlagSet represents a set of defined flags. The zero value of a FlagSet
 // has no name and has ContinueOnError error handling.
 type FlagSet struct {
 	// Usage is the function called when an error occurs while parsing flags.
@@ -324,7 +324,7 @@ func (f *FlagSet) VisitAll(fn func(*Flag)) {
 }
 
 // VisitAll visits the command-line flags in lexicographical order, calling
-// fn for each.  It visits all flags, even those not set.
+// fn for each. It visits all flags, even those not set.
 func VisitAll(fn func(*Flag)) {
 	CommandLine.VisitAll(fn)
 }
@@ -338,7 +338,7 @@ func (f *FlagSet) Visit(fn func(*Flag)) {
 }
 
 // Visit visits the command-line flags in lexicographical order, calling fn
-// for each.  It visits only those flags that have been set.
+// for each. It visits only those flags that have been set.
 func Visit(fn func(*Flag)) {
 	CommandLine.Visit(fn)
 }
@@ -514,7 +514,7 @@ func (f *FlagSet) NFlag() int { return len(f.actual) }
 // NFlag returns the number of command-line flags that have been set.
 func NFlag() int { return len(CommandLine.actual) }
 
-// Arg returns the i'th argument.  Arg(0) is the first remaining argument
+// Arg returns the i'th argument. Arg(0) is the first remaining argument
 // after flags have been processed. Arg returns an empty string if the
 // requested element does not exist.
 func (f *FlagSet) Arg(i int) string {
@@ -524,7 +524,7 @@ func (f *FlagSet) Arg(i int) string {
 	return f.args[i]
 }
 
-// Arg returns the i'th command-line argument.  Arg(0) is the first remaining argument
+// Arg returns the i'th command-line argument. Arg(0) is the first remaining argument
 // after flags have been processed. Arg returns an empty string if the
 // requested element does not exist.
 func Arg(i int) string {
@@ -890,7 +890,7 @@ func (f *FlagSet) parseOne() (bool, error) {
 }
 
 // Parse parses flag definitions from the argument list, which should not
-// include the command name.  Must be called after all flags in the FlagSet
+// include the command name. Must be called after all flags in the FlagSet
 // are defined and before flags are accessed by the program.
 // The return value will be ErrHelp if -help or -h were set but not defined.
 func (f *FlagSet) Parse(arguments []string) error {
diff --git a/src/fmt/fmt_test.go b/src/fmt/fmt_test.go
index 3cbe93419e..0d0e313807 100644
--- a/src/fmt/fmt_test.go
+++ b/src/fmt/fmt_test.go
@@ -579,7 +579,7 @@ var fmtTests = []struct {
 
 	// The "<nil>" show up because maps are printed by
 	// first obtaining a list of keys and then looking up
-	// each key.  Since NaNs can be map keys but cannot
+	// each key. Since NaNs can be map keys but cannot
 	// be fetched directly, the lookup fails and returns a
 	// zero reflect.Value, which formats as <nil>.
 	// This test is just to check that it shows the two NaNs at all.
diff --git a/src/fmt/format.go b/src/fmt/format.go
index fc8d057be4..e49b8af967 100644
--- a/src/fmt/format.go
+++ b/src/fmt/format.go
@@ -133,7 +133,7 @@ func (f *fmt) fmt_boolean(v bool) {
 	}
 }
 
-// integer; interprets prec but not wid.  Once formatted, result is sent to pad()
+// integer; interprets prec but not wid. Once formatted, result is sent to pad()
 // and then flags are cleared.
 func (f *fmt) integer(a int64, base uint64, signedness bool, digits string) {
 	// precision of 0 and value of 0 means "print nothing"
diff --git a/src/fmt/scan.go b/src/fmt/scan.go
index fa63e4983a..bf7c9acb8e 100644
--- a/src/fmt/scan.go
+++ b/src/fmt/scan.go
@@ -33,7 +33,7 @@ type ScanState interface {
 	// Token skips space in the input if skipSpace is true, then returns the
 	// run of Unicode code points c satisfying f(c).  If f is nil,
 	// !unicode.IsSpace(c) is used; that is, the token will hold non-space
-	// characters.  Newlines are treated appropriately for the operation being
+	// characters. Newlines are treated appropriately for the operation being
 	// performed; see the package documentation for more information.
 	// The returned slice points to shared data that may be overwritten
 	// by the next call to Token, a call to a Scan function using the ScanState
@@ -50,15 +50,15 @@ type ScanState interface {
 
 // Scanner is implemented by any value that has a Scan method, which scans
 // the input for the representation of a value and stores the result in the
-// receiver, which must be a pointer to be useful.  The Scan method is called
+// receiver, which must be a pointer to be useful. The Scan method is called
 // for any argument to Scan, Scanf, or Scanln that implements it.
 type Scanner interface {
 	Scan(state ScanState, verb rune) error
 }
 
 // Scan scans text read from standard input, storing successive
-// space-separated values into successive arguments.  Newlines count
-// as space.  It returns the number of items successfully scanned.
+// space-separated values into successive arguments. Newlines count
+// as space. It returns the number of items successfully scanned.
 // If that is less than the number of arguments, err will report why.
 func Scan(a ...interface{}) (n int, err error) {
 	return Fscan(os.Stdin, a...)
@@ -72,7 +72,7 @@ func Scanln(a ...interface{}) (n int, err error) {
 
 // Scanf scans text read from standard input, storing successive
 // space-separated values into successive arguments as determined by
-// the format.  It returns the number of items successfully scanned.
+// the format. It returns the number of items successfully scanned.
 // If that is less than the number of arguments, err will report why.
 // Newlines in the input must match newlines in the format.
 // The one exception: the verb %c always scans the next rune in the
@@ -93,8 +93,8 @@ func (r *stringReader) Read(b []byte) (n int, err error) {
 }
 
 // Sscan scans the argument string, storing successive space-separated
-// values into successive arguments.  Newlines count as space.  It
-// returns the number of items successfully scanned.  If that is less
+// values into successive arguments. Newlines count as space. It
+// returns the number of items successfully scanned. If that is less
 // than the number of arguments, err will report why.
 func Sscan(str string, a ...interface{}) (n int, err error) {
 	return Fscan((*stringReader)(&str), a...)
@@ -107,7 +107,7 @@ func Sscanln(str string, a ...interface{}) (n int, err error) {
 }
 
 // Sscanf scans the argument string, storing successive space-separated
-// values into successive arguments as determined by the format.  It
+// values into successive arguments as determined by the format. It
 // returns the number of items successfully parsed.
 // Newlines in the input must match newlines in the format.
 func Sscanf(str string, format string, a ...interface{}) (n int, err error) {
@@ -115,8 +115,8 @@ func Sscanf(str string, format string, a ...interface{}) (n int, err error) {
 }
 
 // Fscan scans text read from r, storing successive space-separated
-// values into successive arguments.  Newlines count as space.  It
-// returns the number of items successfully scanned.  If that is less
+// values into successive arguments. Newlines count as space. It
+// returns the number of items successfully scanned. If that is less
 // than the number of arguments, err will report why.
 func Fscan(r io.Reader, a ...interface{}) (n int, err error) {
 	s, old := newScanState(r, true, false)
@@ -135,7 +135,7 @@ func Fscanln(r io.Reader, a ...interface{}) (n int, err error) {
 }
 
 // Fscanf scans text read from r, storing successive space-separated
-// values into successive arguments as determined by the format.  It
+// values into successive arguments as determined by the format. It
 // returns the number of items successfully parsed.
 // Newlines in the input must match newlines in the format.
 func Fscanf(r io.Reader, format string, a ...interface{}) (n int, err error) {
@@ -448,8 +448,8 @@ func (s *ss) skipSpace(stopAtNewline bool) {
 	}
 }
 
-// token returns the next space-delimited string from the input.  It
-// skips white space.  For Scanln, it stops at newlines.  For Scan,
+// token returns the next space-delimited string from the input. It
+// skips white space. For Scanln, it stops at newlines. For Scan,
 // newlines are treated as spaces.
 func (s *ss) token(skipSpace bool, f func(rune) bool) []byte {
 	if skipSpace {
@@ -518,7 +518,7 @@ func (s *ss) notEOF() {
 	s.UnreadRune()
 }
 
-// accept checks the next rune in the input.  If it's a byte (sic) in the string, it puts it in the
+// accept checks the next rune in the input. If it's a byte (sic) in the string, it puts it in the
 // buffer and returns true. Otherwise it return false.
 func (s *ss) accept(ok string) bool {
 	return s.consume(ok, true)
@@ -542,7 +542,7 @@ func (s *ss) scanBool(verb rune) bool {
 	if !s.okVerb(verb, "tv", "boolean") {
 		return false
 	}
-	// Syntax-checking a boolean is annoying.  We're not fastidious about case.
+	// Syntax-checking a boolean is annoying. We're not fastidious about case.
 	switch s.getRune() {
 	case '0':
 		return false
@@ -636,7 +636,7 @@ func (s *ss) scanBasePrefix() (base int, digits string, found bool) {
 }
 
 // scanInt returns the value of the integer represented by the next
-// token, checking for overflow.  Any error is stored in s.err.
+// token, checking for overflow. Any error is stored in s.err.
 func (s *ss) scanInt(verb rune, bitSize int) int64 {
 	if verb == 'c' {
 		return s.scanRune(bitSize)
@@ -669,7 +669,7 @@ func (s *ss) scanInt(verb rune, bitSize int) int64 {
 }
 
 // scanUint returns the value of the unsigned integer represented
-// by the next token, checking for overflow.  Any error is stored in s.err.
+// by the next token, checking for overflow. Any error is stored in s.err.
 func (s *ss) scanUint(verb rune, bitSize int) uint64 {
 	if verb == 'c' {
 		return uint64(s.scanRune(bitSize))
@@ -1148,7 +1148,7 @@ func (s *ss) doScanf(format string, a []interface{}) (numProcessed int, err erro
 		}
 		// Either we failed to advance, we have a percent character, or we ran out of input.
 		if format[i] != '%' {
-			// Can't advance format.  Why not?
+			// Can't advance format. Why not?
 			if w < 0 {
 				s.errorString("input does not match format")
 			}
diff --git a/src/fmt/scan_test.go b/src/fmt/scan_test.go
index 3302a7ca2d..c9a731b10c 100644
--- a/src/fmt/scan_test.go
+++ b/src/fmt/scan_test.go
@@ -767,7 +767,7 @@ func TestUnreadRuneWithBufio(t *testing.T) {
 
 type TwoLines string
 
-// Scan attempts to read two lines into the object.  Scanln should prevent this
+// Scan attempts to read two lines into the object. Scanln should prevent this
 // because it stops at newline; Scan and Scanf should be fine.
 func (t *TwoLines) Scan(state ScanState, verb rune) error {
 	chars := make([]rune, 0, 100)
diff --git a/src/go/ast/import.go b/src/go/ast/import.go
index 5c794c3e79..6b27fe822e 100644
--- a/src/go/ast/import.go
+++ b/src/go/ast/import.go
@@ -31,7 +31,7 @@ func SortImports(fset *token.FileSet, f *File) {
 		specs := d.Specs[:0]
 		for j, s := range d.Specs {
 			if j > i && fset.Position(s.Pos()).Line > 1+fset.Position(d.Specs[j-1].End()).Line {
-				// j begins a new run.  End this one.
+				// j begins a new run. End this one.
 				specs = append(specs, sortSpecs(fset, f, d.Specs[i:j])...)
 				i = j
 			}
diff --git a/src/go/ast/resolve.go b/src/go/ast/resolve.go
index 0406bfc584..c1830b5e4d 100644
--- a/src/go/ast/resolve.go
+++ b/src/go/ast/resolve.go
@@ -56,7 +56,7 @@ func resolve(scope *Scope, ident *Ident) bool {
 // indexed by package id (canonical import path).
 // An Importer must determine the canonical import path and
 // check the map to see if it is already present in the imports map.
-// If so, the Importer can return the map entry.  Otherwise, the
+// If so, the Importer can return the map entry. Otherwise, the
 // Importer should load the package data for the given path into
 // a new *Object (pkg), record pkg in the imports map, and then
 // return pkg.
diff --git a/src/go/build/build.go b/src/go/build/build.go
index b723269fda..1bd44cb3e5 100644
--- a/src/go/build/build.go
+++ b/src/go/build/build.go
@@ -55,8 +55,8 @@ type Context struct {
 	InstallSuffix string
 
 	// By default, Import uses the operating system's file system calls
-	// to read directories and files.  To read from other sources,
-	// callers can set the following functions.  They all have default
+	// to read directories and files. To read from other sources,
+	// callers can set the following functions. They all have default
 	// behaviors that use the local file system, so clients need only set
 	// the functions whose behaviors they wish to change.
 
@@ -302,7 +302,7 @@ type ImportMode uint
 
 const (
 	// If FindOnly is set, Import stops after locating the directory
-	// that should contain the sources for a package.  It does not
+	// that should contain the sources for a package. It does not
 	// read any files in the directory.
 	FindOnly ImportMode = 1 << iota
 
@@ -691,7 +691,7 @@ Found:
 			continue
 		}
 
-		// Going to save the file.  For non-Go files, can stop here.
+		// Going to save the file. For non-Go files, can stop here.
 		switch ext {
 		case ".c":
 			p.CFiles = append(p.CFiles, name)
@@ -1087,7 +1087,7 @@ var slashslash = []byte("//")
 // lines beginning with '// +build' are taken as build directives.
 //
 // The file is accepted only if each such line lists something
-// matching the file.  For example:
+// matching the file. For example:
 //
 //	// +build windows linux
 //
@@ -1279,7 +1279,7 @@ func safeCgoName(s string, spaces bool) bool {
 // Single quotes and double quotes are recognized to prevent splitting within the
 // quoted region, and are removed from the resulting substrings. If a quote in s
 // isn't closed err will be set and r will have the unclosed argument as the
-// last element.  The backslash is used for escaping.
+// last element. The backslash is used for escaping.
 //
 // For example, the following string:
 //
diff --git a/src/go/build/deps_test.go b/src/go/build/deps_test.go
index 77fd701665..9bd3ec82bb 100644
--- a/src/go/build/deps_test.go
+++ b/src/go/build/deps_test.go
@@ -21,7 +21,7 @@ import (
 )
 
 // pkgDeps defines the expected dependencies between packages in
-// the Go source tree.  It is a statement of policy.
+// the Go source tree. It is a statement of policy.
 // Changes should not be made to this map without prior discussion.
 //
 // The map contains two kinds of entries:
diff --git a/src/go/build/doc.go b/src/go/build/doc.go
index 236277e247..c926467059 100644
--- a/src/go/build/doc.go
+++ b/src/go/build/doc.go
@@ -8,7 +8,7 @@
 //
 // The Go path is a list of directory trees containing Go source code.
 // It is consulted to resolve imports that cannot be found in the standard
-// Go tree.  The default path is the value of the GOPATH environment
+// Go tree. The default path is the value of the GOPATH environment
 // variable, interpreted as a path list appropriate to the operating system
 // (on Unix, the variable is a colon-separated string;
 // on Windows, a semicolon-separated string;
@@ -16,7 +16,7 @@
 //
 // Each directory listed in the Go path must have a prescribed structure:
 //
-// The src/ directory holds source code.  The path below 'src' determines
+// The src/ directory holds source code. The path below 'src' determines
 // the import path or executable name.
 //
 // The pkg/ directory holds installed package objects.
@@ -31,9 +31,9 @@
 //
 // The bin/ directory holds compiled commands.
 // Each command is named for its source directory, but only
-// using the final element, not the entire path.  That is, the
+// using the final element, not the entire path. That is, the
 // command with source in DIR/src/foo/quux is installed into
-// DIR/bin/quux, not DIR/bin/foo/quux.  The foo/ is stripped
+// DIR/bin/quux, not DIR/bin/foo/quux. The foo/ is stripped
 // so that you can add DIR/bin to your PATH to get at the
 // installed commands.
 //
diff --git a/src/go/doc/comment.go b/src/go/doc/comment.go
index 5631539abc..ed8eef4c61 100644
--- a/src/go/doc/comment.go
+++ b/src/go/doc/comment.go
@@ -398,7 +398,7 @@ func blocks(text string) []block {
 
 // ToText prepares comment text for presentation in textual output.
 // It wraps paragraphs of text to width or fewer Unicode code points
-// and then prefixes each line with the indent.  In preformatted sections
+// and then prefixes each line with the indent. In preformatted sections
 // (such as program text), it prefixes each non-blank line with preIndent.
 func ToText(w io.Writer, text string, indent, preIndent string, width int) {
 	l := lineWrapper{
diff --git a/src/go/doc/testdata/benchmark.go b/src/go/doc/testdata/benchmark.go
index 905e49644a..1d581f057e 100644
--- a/src/go/doc/testdata/benchmark.go
+++ b/src/go/doc/testdata/benchmark.go
@@ -33,7 +33,7 @@ type B struct {
 	result    BenchmarkResult
 }
 
-// StartTimer starts timing a test.  This function is called automatically
+// StartTimer starts timing a test. This function is called automatically
 // before a benchmark starts, but it can also used to resume timing after
 // a call to StopTimer.
 func (b *B) StartTimer() {
@@ -43,7 +43,7 @@ func (b *B) StartTimer() {
 	}
 }
 
-// StopTimer stops timing a test.  This can be used to pause the timer
+// StopTimer stops timing a test. This can be used to pause the timer
 // while performing complex initialization that you don't
 // want to measure.
 func (b *B) StopTimer() {
@@ -134,9 +134,9 @@ func (b *B) run() BenchmarkResult {
 	return b.result
 }
 
-// launch launches the benchmark function.  It gradually increases the number
+// launch launches the benchmark function. It gradually increases the number
 // of benchmark iterations until the benchmark runs for a second in order
-// to get a reasonable measurement.  It prints timing information in this form
+// to get a reasonable measurement. It prints timing information in this form
 //		testing.BenchmarkHello	100000		19 ns/op
 // launch is run by the fun function as a separate goroutine.
 func (b *B) launch() {
diff --git a/src/go/doc/testdata/testing.0.golden b/src/go/doc/testdata/testing.0.golden
index f8348f1ac3..83cf37cd3a 100644
--- a/src/go/doc/testdata/testing.0.golden
+++ b/src/go/doc/testdata/testing.0.golden
@@ -78,10 +78,10 @@ TYPES
 	// SetBytes records the number of bytes processed in a single ...
 	func (b *B) SetBytes(n int64)
 
-	// StartTimer starts timing a test.  This function is called ...
+	// StartTimer starts timing a test. This function is called ...
 	func (b *B) StartTimer()
 
-	// StopTimer stops timing a test.  This can be used to pause the ...
+	// StopTimer stops timing a test. This can be used to pause the ...
 	func (b *B) StopTimer()
 
 	// The results of a benchmark run. 
diff --git a/src/go/doc/testdata/testing.1.golden b/src/go/doc/testdata/testing.1.golden
index 282bb1015a..b9d14517a9 100644
--- a/src/go/doc/testdata/testing.1.golden
+++ b/src/go/doc/testdata/testing.1.golden
@@ -25,8 +25,8 @@ VARIABLES
 	// 
 	var (
 		// The short flag requests that tests run more quickly, but its functionality
-		// is provided by test writers themselves.  The testing package is just its
-		// home.  The all.bash installation script sets it to make installation more
+		// is provided by test writers themselves. The testing package is just its
+		// home. The all.bash installation script sets it to make installation more
 		// efficient, but by default the flag is off so a plain "go test" will do a
 		// full test of the package.
 		short	= flag.Bool("test.short", false, "run smaller test suite to save time")
@@ -151,13 +151,13 @@ TYPES
 	// SetBytes records the number of bytes processed in a single ...
 	func (b *B) SetBytes(n int64)
 
-	// StartTimer starts timing a test.  This function is called ...
+	// StartTimer starts timing a test. This function is called ...
 	func (b *B) StartTimer()
 
-	// StopTimer stops timing a test.  This can be used to pause the ...
+	// StopTimer stops timing a test. This can be used to pause the ...
 	func (b *B) StopTimer()
 
-	// launch launches the benchmark function.  It gradually increases ...
+	// launch launches the benchmark function. It gradually increases ...
 	func (b *B) launch()
 
 	// log generates the output. It's always at the same stack depth. 
diff --git a/src/go/doc/testdata/testing.2.golden b/src/go/doc/testdata/testing.2.golden
index f8348f1ac3..83cf37cd3a 100644
--- a/src/go/doc/testdata/testing.2.golden
+++ b/src/go/doc/testdata/testing.2.golden
@@ -78,10 +78,10 @@ TYPES
 	// SetBytes records the number of bytes processed in a single ...
 	func (b *B) SetBytes(n int64)
 
-	// StartTimer starts timing a test.  This function is called ...
+	// StartTimer starts timing a test. This function is called ...
 	func (b *B) StartTimer()
 
-	// StopTimer stops timing a test.  This can be used to pause the ...
+	// StopTimer stops timing a test. This can be used to pause the ...
 	func (b *B) StopTimer()
 
 	// The results of a benchmark run. 
diff --git a/src/go/doc/testdata/testing.go b/src/go/doc/testdata/testing.go
index 93ed494c32..52810f7a56 100644
--- a/src/go/doc/testdata/testing.go
+++ b/src/go/doc/testdata/testing.go
@@ -22,7 +22,7 @@
 //         }
 //     }
 // The benchmark package will vary b.N until the benchmark function lasts
-// long enough to be timed reliably.  The output
+// long enough to be timed reliably. The output
 //     testing.BenchmarkHello    10000000    282 ns/op
 // means that the loop ran 10000000 times at a speed of 282 ns per loop.
 //
@@ -51,8 +51,8 @@ import (
 
 var (
 	// The short flag requests that tests run more quickly, but its functionality
-	// is provided by test writers themselves.  The testing package is just its
-	// home.  The all.bash installation script sets it to make installation more
+	// is provided by test writers themselves. The testing package is just its
+	// home. The all.bash installation script sets it to make installation more
 	// efficient, but by default the flag is off so a plain "go test" will do a
 	// full test of the package.
 	short = flag.Bool("test.short", false, "run smaller test suite to save time")
@@ -152,9 +152,9 @@ func (c *common) FailNow() {
 	// This previous version duplicated code (those lines are in
 	// tRunner no matter what), but worse the goroutine teardown
 	// implicit in runtime.Goexit was not guaranteed to complete
-	// before the test exited.  If a test deferred an important cleanup
+	// before the test exited. If a test deferred an important cleanup
 	// function (like removing temporary files), there was no guarantee
-	// it would run on a test failure.  Because we send on c.signal during
+	// it would run on a test failure. Because we send on c.signal during
 	// a top-of-stack deferred function now, we know that the send
 	// only happens after any other stacked defers have completed.
 	runtime.Goexit()
diff --git a/src/go/format/internal.go b/src/go/format/internal.go
index 9d04878f86..b8b470da8b 100644
--- a/src/go/format/internal.go
+++ b/src/go/format/internal.go
@@ -28,9 +28,9 @@ func parse(fset *token.FileSet, filename string, src []byte, fragmentOk bool) (
 ) {
 	// Try as whole source file.
 	file, err = parser.ParseFile(fset, filename, src, parserMode)
-	// If there's no error, return.  If the error is that the source file didn't begin with a
+	// If there's no error, return. If the error is that the source file didn't begin with a
 	// package line and source fragments are ok, fall through to
-	// try as a source fragment.  Stop and return on any other error.
+	// try as a source fragment. Stop and return on any other error.
 	if err == nil || !fragmentOk || !strings.Contains(err.Error(), "expected 'package'") {
 		return
 	}
@@ -59,7 +59,7 @@ func parse(fset *token.FileSet, filename string, src []byte, fragmentOk bool) (
 
 	// If this is a statement list, make it a source file
 	// by inserting a package clause and turning the list
-	// into a function body.  This handles expressions too.
+	// into a function body. This handles expressions too.
 	// Insert using a ;, not a newline, so that the line numbers
 	// in fsrc match the ones in src. Add an extra '\n' before the '}'
 	// to make sure comments are flushed before the '}'.
diff --git a/src/go/scanner/scanner.go b/src/go/scanner/scanner.go
index e9476c4dee..4041d9aa47 100644
--- a/src/go/scanner/scanner.go
+++ b/src/go/scanner/scanner.go
@@ -26,7 +26,7 @@ import (
 type ErrorHandler func(pos token.Position, msg string)
 
 // A Scanner holds the scanner's internal state while processing
-// a given text.  It can be allocated as part of another data
+// a given text. It can be allocated as part of another data
 // structure but must be initialized via Init before use.
 //
 type Scanner struct {
diff --git a/src/go/types/initorder.go b/src/go/types/initorder.go
index 0fd567b269..ac9016b46e 100644
--- a/src/go/types/initorder.go
+++ b/src/go/types/initorder.go
@@ -12,7 +12,7 @@ import (
 // initOrder computes the Info.InitOrder for package variables.
 func (check *Checker) initOrder() {
 	// An InitOrder may already have been computed if a package is
-	// built from several calls to (*Checker).Files.  Clear it.
+	// built from several calls to (*Checker).Files. Clear it.
 	check.Info.InitOrder = check.Info.InitOrder[:0]
 
 	// compute the object dependency graph and
diff --git a/src/go/types/object.go b/src/go/types/object.go
index b835c6e53e..707b806d3f 100644
--- a/src/go/types/object.go
+++ b/src/go/types/object.go
@@ -188,7 +188,7 @@ func (obj *Var) Anonymous() bool { return obj.anonymous }
 func (obj *Var) IsField() bool { return obj.isField }
 
 // A Func represents a declared function, concrete method, or abstract
-// (interface) method.  Its Type() is always a *Signature.
+// (interface) method. Its Type() is always a *Signature.
 // An abstract method may belong to many interfaces due to embedding.
 type Func struct {
 	object
diff --git a/src/go/types/package.go b/src/go/types/package.go
index 4a432b5496..a588ee73dc 100644
--- a/src/go/types/package.go
+++ b/src/go/types/package.go
@@ -55,7 +55,7 @@ func (pkg *Package) MarkComplete() { pkg.complete = true }
 // pkg; the list is in source order. Package unsafe is excluded.
 //
 // If pkg was loaded from export data, Imports includes packages that
-// provide package-level objects referenced by pkg.  This may be more or
+// provide package-level objects referenced by pkg. This may be more or
 // less than the set of packages directly imported by pkg's source code.
 func (pkg *Package) Imports() []*Package { return pkg.imports }
 
diff --git a/src/go/types/scope.go b/src/go/types/scope.go
index 3502840225..b5d34d6e65 100644
--- a/src/go/types/scope.go
+++ b/src/go/types/scope.go
@@ -31,7 +31,7 @@ type Scope struct {
 }
 
 // NewScope returns a new, empty scope contained in the given parent
-// scope, if any.  The comment is for debugging only.
+// scope, if any. The comment is for debugging only.
 func NewScope(parent *Scope, pos, end token.Pos, comment string) *Scope {
 	s := &Scope{parent, nil, nil, pos, end, comment}
 	// don't add children to Universe scope!
diff --git a/src/go/types/type.go b/src/go/types/type.go
index d8415f1fdf..4e00da3212 100644
--- a/src/go/types/type.go
+++ b/src/go/types/type.go
@@ -229,7 +229,7 @@ func NewSignature(recv *Var, params, results *Tuple, variadic bool) *Signature {
 // function.
 //
 // For an abstract method, Recv returns the enclosing interface either
-// as a *Named or an *Interface.  Due to embedding, an interface may
+// as a *Named or an *Interface. Due to embedding, an interface may
 // contain methods whose receiver type is a different interface.
 func (s *Signature) Recv() *Var { return s.recv }
 
diff --git a/src/html/template/error.go b/src/html/template/error.go
index 8f99e1b962..5637384bd8 100644
--- a/src/html/template/error.go
+++ b/src/html/template/error.go
@@ -164,7 +164,7 @@ const (
 	//   different context than an earlier pass, there is no single context.
 	//   In the example, there is missing a quote, so it is not clear
 	//   whether {{.}} is meant to be inside a JS string or in a JS value
-	//   context.  The second iteration would produce something like
+	//   context. The second iteration would produce something like
 	//
 	//     <script>var x = ['firstValue,'secondValue]</script>
 	ErrRangeLoopReentry
diff --git a/src/html/template/escape.go b/src/html/template/escape.go
index 3c18340547..595bf0011e 100644
--- a/src/html/template/escape.go
+++ b/src/html/template/escape.go
@@ -15,8 +15,8 @@ import (
 
 // escapeTemplate rewrites the named template, which must be
 // associated with t, to guarantee that the output of any of the named
-// templates is properly escaped.  If no error is returned, then the named templates have
-// been modified.  Otherwise the named templates have been rendered
+// templates is properly escaped. If no error is returned, then the named templates have
+// been modified. Otherwise the named templates have been rendered
 // unusable.
 func escapeTemplate(tmpl *Template, node parse.Node, name string) error {
 	e := newEscaper(tmpl)
diff --git a/src/image/color/color.go b/src/image/color/color.go
index cae059b6da..104433974e 100644
--- a/src/image/color/color.go
+++ b/src/image/color/color.go
@@ -147,7 +147,7 @@ type Model interface {
 func ModelFunc(f func(Color) Color) Model {
 	// Note: using *modelFunc as the implementation
 	// means that callers can still use comparisons
-	// like m == RGBAModel.  This is not possible if
+	// like m == RGBAModel. This is not possible if
 	// we use the func value directly, because funcs
 	// are no longer comparable.
 	return &modelFunc{f}
diff --git a/src/image/gif/reader.go b/src/image/gif/reader.go
index 72b52e36e5..6bfc72e974 100644
--- a/src/image/gif/reader.go
+++ b/src/image/gif/reader.go
@@ -96,7 +96,7 @@ type decoder struct {
 // blockReader parses the block structure of GIF image data, which
 // comprises (n, (n bytes)) blocks, with 1 <= n <= 255.  It is the
 // reader given to the LZW decoder, which is thus immune to the
-// blocking.  After the LZW decoder completes, there will be a 0-byte
+// blocking. After the LZW decoder completes, there will be a 0-byte
 // block remaining (0, ()), which is consumed when checking that the
 // blockReader is exhausted.
 type blockReader struct {
diff --git a/src/io/io.go b/src/io/io.go
index 016e9247eb..f7f059ff45 100644
--- a/src/io/io.go
+++ b/src/io/io.go
@@ -41,23 +41,23 @@ var ErrNoProgress = errors.New("multiple Read calls return no data or error")
 
 // Reader is the interface that wraps the basic Read method.
 //
-// Read reads up to len(p) bytes into p.  It returns the number of bytes
-// read (0 <= n <= len(p)) and any error encountered.  Even if Read
+// Read reads up to len(p) bytes into p. It returns the number of bytes
+// read (0 <= n <= len(p)) and any error encountered. Even if Read
 // returns n < len(p), it may use all of p as scratch space during the call.
 // If some data is available but not len(p) bytes, Read conventionally
 // returns what is available instead of waiting for more.
 //
 // When Read encounters an error or end-of-file condition after
 // successfully reading n > 0 bytes, it returns the number of
-// bytes read.  It may return the (non-nil) error from the same call
+// bytes read. It may return the (non-nil) error from the same call
 // or return the error (and n == 0) from a subsequent call.
 // An instance of this general case is that a Reader returning
 // a non-zero number of bytes at the end of the input stream may
-// return either err == EOF or err == nil.  The next Read should
+// return either err == EOF or err == nil. The next Read should
 // return 0, EOF.
 //
 // Callers should always process the n > 0 bytes returned before
-// considering the error err.  Doing so correctly handles I/O errors
+// considering the error err. Doing so correctly handles I/O errors
 // that happen after reading some bytes and also both of the
 // allowed EOF behaviors.
 //
@@ -176,15 +176,15 @@ type WriterTo interface {
 // ReaderAt is the interface that wraps the basic ReadAt method.
 //
 // ReadAt reads len(p) bytes into p starting at offset off in the
-// underlying input source.  It returns the number of bytes
+// underlying input source. It returns the number of bytes
 // read (0 <= n <= len(p)) and any error encountered.
 //
 // When ReadAt returns n < len(p), it returns a non-nil error
-// explaining why more bytes were not returned.  In this respect,
+// explaining why more bytes were not returned. In this respect,
 // ReadAt is stricter than Read.
 //
 // Even if ReadAt returns n < len(p), it may use all of p as scratch
-// space during the call.  If some data is available but not len(p) bytes,
+// space during the call. If some data is available but not len(p) bytes,
 // ReadAt blocks until either all the data is available or an error occurs.
 // In this respect ReadAt is different from Read.
 //
@@ -206,7 +206,7 @@ type ReaderAt interface {
 // WriterAt is the interface that wraps the basic WriteAt method.
 //
 // WriteAt writes len(p) bytes from p to the underlying data stream
-// at offset off.  It returns the number of bytes written from p (0 <= n <= len(p))
+// at offset off. It returns the number of bytes written from p (0 <= n <= len(p))
 // and any error encountered that caused the write to stop early.
 // WriteAt must return a non-nil error if it returns n < len(p).
 //
@@ -335,7 +335,7 @@ func CopyN(dst Writer, src Reader, n int64) (written int64, err error) {
 }
 
 // Copy copies from src to dst until either EOF is reached
-// on src or an error occurs.  It returns the number of bytes
+// on src or an error occurs. It returns the number of bytes
 // copied and the first error encountered while copying, if any.
 //
 // A successful Copy returns err == nil, not err == EOF.
@@ -497,7 +497,7 @@ func (s *SectionReader) Size() int64 { return s.limit - s.base }
 
 // TeeReader returns a Reader that writes to w what it reads from r.
 // All reads from r performed through it are matched with
-// corresponding writes to w.  There is no internal buffering -
+// corresponding writes to w. There is no internal buffering -
 // the write must complete before the read completes.
 // Any error encountered while writing is reported as a read error.
 func TeeReader(r Reader, w Writer) Reader {
diff --git a/src/io/ioutil/ioutil.go b/src/io/ioutil/ioutil.go
index e90a33f99b..8ecbb2de76 100644
--- a/src/io/ioutil/ioutil.go
+++ b/src/io/ioutil/ioutil.go
@@ -63,8 +63,8 @@ func ReadFile(filename string) ([]byte, error) {
 		}
 	}
 	// As initial capacity for readAll, use n + a little extra in case Size is zero,
-	// and to avoid another allocation after Read has filled the buffer.  The readAll
-	// call will read into its allocated internal buffer cheaply.  If the size was
+	// and to avoid another allocation after Read has filled the buffer. The readAll
+	// call will read into its allocated internal buffer cheaply. If the size was
 	// wrong, we'll either waste some space off the end or reallocate as needed, but
 	// in the overwhelmingly common case we'll get it just right.
 	return readAll(f, n+bytes.MinRead)
diff --git a/src/io/ioutil/tempfile.go b/src/io/ioutil/tempfile.go
index a85982ef25..42718cc73d 100644
--- a/src/io/ioutil/tempfile.go
+++ b/src/io/ioutil/tempfile.go
@@ -41,8 +41,8 @@ func nextSuffix() string {
 // If dir is the empty string, TempFile uses the default directory
 // for temporary files (see os.TempDir).
 // Multiple programs calling TempFile simultaneously
-// will not choose the same file.  The caller can use f.Name()
-// to find the pathname of the file.  It is the caller's responsibility
+// will not choose the same file. The caller can use f.Name()
+// to find the pathname of the file. It is the caller's responsibility
 // to remove the file when no longer needed.
 func TempFile(dir, prefix string) (f *os.File, err error) {
 	if dir == "" {
@@ -68,10 +68,10 @@ func TempFile(dir, prefix string) (f *os.File, err error) {
 
 // TempDir creates a new temporary directory in the directory dir
 // with a name beginning with prefix and returns the path of the
-// new directory.  If dir is the empty string, TempDir uses the
+// new directory. If dir is the empty string, TempDir uses the
 // default directory for temporary files (see os.TempDir).
 // Multiple programs calling TempDir simultaneously
-// will not choose the same directory.  It is the caller's responsibility
+// will not choose the same directory. It is the caller's responsibility
 // to remove the directory when no longer needed.
 func TempDir(dir, prefix string) (name string, err error) {
 	if dir == "" {
diff --git a/src/io/multi.go b/src/io/multi.go
index 16860aa361..c23c12b151 100644
--- a/src/io/multi.go
+++ b/src/io/multi.go
@@ -25,7 +25,7 @@ func (mr *multiReader) Read(p []byte) (n int, err error) {
 }
 
 // MultiReader returns a Reader that's the logical concatenation of
-// the provided input readers.  They're read sequentially.  Once all
+// the provided input readers. They're read sequentially. Once all
 // inputs have returned EOF, Read will return EOF.  If any of the readers
 // return a non-nil, non-EOF error, Read will return that error.
 func MultiReader(readers ...Reader) Reader {
diff --git a/src/log/log.go b/src/log/log.go
index 4cfe550300..26cdb532df 100644
--- a/src/log/log.go
+++ b/src/log/log.go
@@ -42,8 +42,8 @@ const (
 )
 
 // A Logger represents an active logging object that generates lines of
-// output to an io.Writer.  Each logging operation makes a single call to
-// the Writer's Write method.  A Logger can be used simultaneously from
+// output to an io.Writer. Each logging operation makes a single call to
+// the Writer's Write method. A Logger can be used simultaneously from
 // multiple goroutines; it guarantees to serialize access to the Writer.
 type Logger struct {
 	mu     sync.Mutex // ensures atomic writes; protects the following fields
@@ -53,7 +53,7 @@ type Logger struct {
 	buf    []byte     // for accumulating text to write
 }
 
-// New creates a new Logger.   The out variable sets the
+// New creates a new Logger. The out variable sets the
 // destination to which log data will be written.
 // The prefix appears at the beginning of each generated log line.
 // The flag argument defines the logging properties.
@@ -134,10 +134,10 @@ func (l *Logger) formatHeader(buf *[]byte, t time.Time, file string, line int) {
 	}
 }
 
-// Output writes the output for a logging event.  The string s contains
+// Output writes the output for a logging event. The string s contains
 // the text to print after the prefix specified by the flags of the
-// Logger.  A newline is appended if the last character of s is not
-// already a newline.  Calldepth is used to recover the PC and is
+// Logger. A newline is appended if the last character of s is not
+// already a newline. Calldepth is used to recover the PC and is
 // provided for generality, although at the moment on all pre-defined
 // paths it will be 2.
 func (l *Logger) Output(calldepth int, s string) error {
@@ -334,10 +334,10 @@ func Panicln(v ...interface{}) {
 	panic(s)
 }
 
-// Output writes the output for a logging event.  The string s contains
+// Output writes the output for a logging event. The string s contains
 // the text to print after the prefix specified by the flags of the
-// Logger.  A newline is appended if the last character of s is not
-// already a newline.  Calldepth is the count of the number of
+// Logger. A newline is appended if the last character of s is not
+// already a newline. Calldepth is the count of the number of
 // frames to skip when computing the file name and line number
 // if Llongfile or Lshortfile is set; a value of 1 will print the details
 // for the caller of Output.
diff --git a/src/log/syslog/syslog.go b/src/log/syslog/syslog.go
index f489059d5a..9e888dd1d9 100644
--- a/src/log/syslog/syslog.go
+++ b/src/log/syslog/syslog.go
@@ -85,8 +85,8 @@ type Writer struct {
 }
 
 // This interface and the separate syslog_unix.go file exist for
-// Solaris support as implemented by gccgo.  On Solaris you cannot
-// simply open a TCP connection to the syslog daemon.  The gccgo
+// Solaris support as implemented by gccgo. On Solaris you cannot
+// simply open a TCP connection to the syslog daemon. The gccgo
 // sources have a syslog_solaris.go file that implements unixSyslog to
 // return a type that satisfies this interface and simply calls the C
 // library syslog function.
@@ -100,7 +100,7 @@ type netConn struct {
 	conn  net.Conn
 }
 
-// New establishes a new connection to the system log daemon.  Each
+// New establishes a new connection to the system log daemon. Each
 // write to the returned writer sends a log message with the given
 // priority and prefix.
 func New(priority Priority, tag string) (*Writer, error) {
@@ -108,7 +108,7 @@ func New(priority Priority, tag string) (*Writer, error) {
 }
 
 // Dial establishes a connection to a log daemon by connecting to
-// address raddr on the specified network.  Each write to the returned
+// address raddr on the specified network. Each write to the returned
 // writer sends a log message with the given facility, severity and
 // tag.
 // If network is empty, Dial will connect to the local syslog server.
diff --git a/src/math/acosh.go b/src/math/acosh.go
index e394008b07..dce21b2350 100644
--- a/src/math/acosh.go
+++ b/src/math/acosh.go
@@ -6,7 +6,7 @@ package math
 
 // The original C code, the long comment, and the constants
 // below are from FreeBSD's /usr/src/lib/msun/src/e_acosh.c
-// and came with this notice.  The go code is a simplified
+// and came with this notice. The go code is a simplified
 // version of the original C.
 //
 // ====================================================
diff --git a/src/math/asinh.go b/src/math/asinh.go
index ff2de0215f..3b793b0cea 100644
--- a/src/math/asinh.go
+++ b/src/math/asinh.go
@@ -6,7 +6,7 @@ package math
 
 // The original C code, the long comment, and the constants
 // below are from FreeBSD's /usr/src/lib/msun/src/s_asinh.c
-// and came with this notice.  The go code is a simplified
+// and came with this notice. The go code is a simplified
 // version of the original C.
 //
 // ====================================================
diff --git a/src/math/atanh.go b/src/math/atanh.go
index 113d5c103c..d59a8474fc 100644
--- a/src/math/atanh.go
+++ b/src/math/atanh.go
@@ -6,7 +6,7 @@ package math
 
 // The original C code, the long comment, and the constants
 // below are from FreeBSD's /usr/src/lib/msun/src/e_atanh.c
-// and came with this notice.  The go code is a simplified
+// and came with this notice. The go code is a simplified
 // version of the original C.
 //
 // ====================================================
diff --git a/src/math/big/arith_test.go b/src/math/big/arith_test.go
index f46a494f17..ea8e82d0b6 100644
--- a/src/math/big/arith_test.go
+++ b/src/math/big/arith_test.go
@@ -442,7 +442,7 @@ func benchmarkBitLenN(b *testing.B, nbits uint) {
 	}
 }
 
-// Individual bitLen tests.  Numbers chosen to examine both sides
+// Individual bitLen tests. Numbers chosen to examine both sides
 // of powers-of-two boundaries.
 func BenchmarkBitLen0(b *testing.B)  { benchmarkBitLenN(b, 0) }
 func BenchmarkBitLen1(b *testing.B)  { benchmarkBitLenN(b, 1) }
diff --git a/src/math/big/nat.go b/src/math/big/nat.go
index 79cf6e07f7..7668b6481b 100644
--- a/src/math/big/nat.go
+++ b/src/math/big/nat.go
@@ -647,7 +647,7 @@ func trailingZeroBits(x Word) uint {
 	// x & -x leaves only the right-most bit set in the word. Let k be the
 	// index of that bit. Since only a single bit is set, the value is two
 	// to the power of k. Multiplying by a power of two is equivalent to
-	// left shifting, in this case by k bits.  The de Bruijn constant is
+	// left shifting, in this case by k bits. The de Bruijn constant is
 	// such that all six bit, consecutive substrings are distinct.
 	// Therefore, if we have a left shifted version of this constant we can
 	// find by how many bits it was shifted by looking at which six bit
@@ -1018,7 +1018,7 @@ func (z nat) expNNWindowed(x, y, m nat) nat {
 		for j := 0; j < _W; j += n {
 			if i != len(y)-1 || j != 0 {
 				// Unrolled loop for significant performance
-				// gain.  Use go test -bench=".*" in crypto/rsa
+				// gain. Use go test -bench=".*" in crypto/rsa
 				// to check performance before making changes.
 				zz = zz.mul(z, z)
 				zz, z = z, zz
diff --git a/src/math/big/rat.go b/src/math/big/rat.go
index 2cd9ed0938..56ce33d882 100644
--- a/src/math/big/rat.go
+++ b/src/math/big/rat.go
@@ -63,7 +63,7 @@ func (z *Rat) SetFloat64(f float64) *Rat {
 
 // quotToFloat32 returns the non-negative float32 value
 // nearest to the quotient a/b, using round-to-even in
-// halfway cases.  It does not mutate its arguments.
+// halfway cases. It does not mutate its arguments.
 // Preconditions: b is non-zero; a and b have no common factors.
 func quotToFloat32(a, b nat) (f float32, exact bool) {
 	const (
@@ -161,7 +161,7 @@ func quotToFloat32(a, b nat) (f float32, exact bool) {
 
 // quotToFloat64 returns the non-negative float64 value
 // nearest to the quotient a/b, using round-to-even in
-// halfway cases.  It does not mutate its arguments.
+// halfway cases. It does not mutate its arguments.
 // Preconditions: b is non-zero; a and b have no common factors.
 func quotToFloat64(a, b nat) (f float64, exact bool) {
 	const (
diff --git a/src/math/big/ratconv_test.go b/src/math/big/ratconv_test.go
index da2fdab4ca..17bda47637 100644
--- a/src/math/big/ratconv_test.go
+++ b/src/math/big/ratconv_test.go
@@ -137,7 +137,7 @@ func TestFloatString(t *testing.T) {
 	}
 }
 
-// Test inputs to Rat.SetString.  The prefix "long:" causes the test
+// Test inputs to Rat.SetString. The prefix "long:" causes the test
 // to be skipped in --test.short mode.  (The threshold is about 500us.)
 var float64inputs = []string{
 	// Constants plundered from strconv/testfp.txt.
diff --git a/src/math/cmplx/sqrt.go b/src/math/cmplx/sqrt.go
index 276be07ae9..72f81e907c 100644
--- a/src/math/cmplx/sqrt.go
+++ b/src/math/cmplx/sqrt.go
@@ -43,7 +43,7 @@ import "math"
 // Cancelation error in r-x or r+x is avoided by using the
 // identity  2 Re w Im w  =  y.
 //
-// Note that -w is also a square root of z.  The root chosen
+// Note that -w is also a square root of z. The root chosen
 // is always in the right half plane and Im w has the same sign as y.
 //
 // ACCURACY:
diff --git a/src/math/erf.go b/src/math/erf.go
index 4cd80f80c3..8ddd5f9809 100644
--- a/src/math/erf.go
+++ b/src/math/erf.go
@@ -10,7 +10,7 @@ package math
 
 // The original C code and the long comment below are
 // from FreeBSD's /usr/src/lib/msun/src/s_erf.c and
-// came with this notice.  The go code is a simplified
+// came with this notice. The go code is a simplified
 // version of the original C.
 //
 // ====================================================
diff --git a/src/math/exp.go b/src/math/exp.go
index f31585fa77..3268c9888c 100644
--- a/src/math/exp.go
+++ b/src/math/exp.go
@@ -15,7 +15,7 @@ func Exp(x float64) float64
 
 // The original C code, the long comment, and the constants
 // below are from FreeBSD's /usr/src/lib/msun/src/e_exp.c
-// and came with this notice.  The go code is a simplified
+// and came with this notice. The go code is a simplified
 // version of the original C.
 //
 // ====================================================
diff --git a/src/math/expm1.go b/src/math/expm1.go
index 670b96de5e..8ce67e5e61 100644
--- a/src/math/expm1.go
+++ b/src/math/expm1.go
@@ -6,7 +6,7 @@ package math
 
 // The original C code, the long comment, and the constants
 // below are from FreeBSD's /usr/src/lib/msun/src/s_expm1.c
-// and came with this notice.  The go code is a simplified
+// and came with this notice. The go code is a simplified
 // version of the original C.
 //
 // ====================================================
diff --git a/src/math/gamma.go b/src/math/gamma.go
index 164f54f332..841ec114a0 100644
--- a/src/math/gamma.go
+++ b/src/math/gamma.go
@@ -21,7 +21,7 @@ package math
 //
 // DESCRIPTION:
 //
-// Returns gamma function of the argument.  The result is
+// Returns gamma function of the argument. The result is
 // correctly signed, and the sign (+1 or -1) is also
 // returned in a global (extern) variable named signgam.
 // This variable is also filled in by the logarithmic gamma
diff --git a/src/math/j0.go b/src/math/j0.go
index de7738880e..cbef7aa7d6 100644
--- a/src/math/j0.go
+++ b/src/math/j0.go
@@ -10,7 +10,7 @@ package math
 
 // The original C code and the long comment below are
 // from FreeBSD's /usr/src/lib/msun/src/e_j0.c and
-// came with this notice.  The go code is a simplified
+// came with this notice. The go code is a simplified
 // version of the original C.
 //
 // ====================================================
diff --git a/src/math/j1.go b/src/math/j1.go
index c537a72eb2..d359d9072e 100644
--- a/src/math/j1.go
+++ b/src/math/j1.go
@@ -10,7 +10,7 @@ package math
 
 // The original C code and the long comment below are
 // from FreeBSD's /usr/src/lib/msun/src/e_j1.c and
-// came with this notice.  The go code is a simplified
+// came with this notice. The go code is a simplified
 // version of the original C.
 //
 // ====================================================
diff --git a/src/math/jn.go b/src/math/jn.go
index ffb8a00f50..721112f77c 100644
--- a/src/math/jn.go
+++ b/src/math/jn.go
@@ -10,7 +10,7 @@ package math
 
 // The original C code and the long comment below are
 // from FreeBSD's /usr/src/lib/msun/src/e_jn.c and
-// came with this notice.  The go code is a simplified
+// came with this notice. The go code is a simplified
 // version of the original C.
 //
 // ====================================================
diff --git a/src/math/lgamma.go b/src/math/lgamma.go
index 6a02c412d9..19ac3ffafc 100644
--- a/src/math/lgamma.go
+++ b/src/math/lgamma.go
@@ -10,7 +10,7 @@ package math
 
 // The original C code and the long comment below are
 // from FreeBSD's /usr/src/lib/msun/src/e_lgamma_r.c and
-// came with this notice.  The go code is a simplified
+// came with this notice. The go code is a simplified
 // version of the original C.
 //
 // ====================================================
diff --git a/src/math/log.go b/src/math/log.go
index 818f00a73f..e328348328 100644
--- a/src/math/log.go
+++ b/src/math/log.go
@@ -10,7 +10,7 @@ package math
 
 // The original C code, the long comment, and the constants
 // below are from FreeBSD's /usr/src/lib/msun/src/e_log.c
-// and came with this notice.  The go code is a simpler
+// and came with this notice. The go code is a simpler
 // version of the original C.
 //
 // ====================================================
diff --git a/src/math/log1p.go b/src/math/log1p.go
index 12b98684c3..d1bddfb100 100644
--- a/src/math/log1p.go
+++ b/src/math/log1p.go
@@ -6,7 +6,7 @@ package math
 
 // The original C code, the long comment, and the constants
 // below are from FreeBSD's /usr/src/lib/msun/src/s_log1p.c
-// and came with this notice.  The go code is a simplified
+// and came with this notice. The go code is a simplified
 // version of the original C.
 //
 // ====================================================
diff --git a/src/math/modf.go b/src/math/modf.go
index 81cb8b5a9c..c5bb89455f 100644
--- a/src/math/modf.go
+++ b/src/math/modf.go
@@ -5,7 +5,7 @@
 package math
 
 // Modf returns integer and fractional floating-point numbers
-// that sum to f.  Both values have the same sign as f.
+// that sum to f. Both values have the same sign as f.
 //
 // Special cases are:
 //	Modf(±Inf) = ±Inf, NaN
diff --git a/src/math/remainder.go b/src/math/remainder.go
index 9a4e4154c4..504fdda7df 100644
--- a/src/math/remainder.go
+++ b/src/math/remainder.go
@@ -6,7 +6,7 @@ package math
 
 // The original C code and the comment below are from
 // FreeBSD's /usr/src/lib/msun/src/e_remainder.c and came
-// with this notice.  The go code is a simplified version of
+// with this notice. The go code is a simplified version of
 // the original C.
 //
 // ====================================================
diff --git a/src/math/sqrt.go b/src/math/sqrt.go
index 96af6e2687..b633a4a6ad 100644
--- a/src/math/sqrt.go
+++ b/src/math/sqrt.go
@@ -6,7 +6,7 @@ package math
 
 // The original C code and the long comment below are
 // from FreeBSD's /usr/src/lib/msun/src/e_sqrt.c and
-// came with this notice.  The go code is a simplified
+// came with this notice. The go code is a simplified
 // version of the original C.
 //
 // ====================================================
@@ -79,7 +79,7 @@ package math
 //      equal to huge for some floating point number "huge" and "tiny".
 //
 //
-// Notes:  Rounding mode detection omitted.  The constants "mask", "shift",
+// Notes:  Rounding mode detection omitted. The constants "mask", "shift",
 // and "bias" are found in src/math/bits.go
 
 // Sqrt returns the square root of x.
diff --git a/src/mime/mediatype.go b/src/mime/mediatype.go
index efee65bb00..1845401127 100644
--- a/src/mime/mediatype.go
+++ b/src/mime/mediatype.go
@@ -221,7 +221,7 @@ func isNotTokenChar(r rune) bool {
 
 // consumeToken consumes a token from the beginning of provided
 // string, per RFC 2045 section 5.1 (referenced from 2183), and return
-// the token consumed and the rest of the string.  Returns ("", v) on
+// the token consumed and the rest of the string. Returns ("", v) on
 // failure to consume at least one character.
 func consumeToken(v string) (token, rest string) {
 	notPos := strings.IndexFunc(v, isNotTokenChar)
@@ -237,7 +237,7 @@ func consumeToken(v string) (token, rest string) {
 // consumeValue consumes a "value" per RFC 2045, where a value is
 // either a 'token' or a 'quoted-string'.  On success, consumeValue
 // returns the value consumed (and de-quoted/escaped, if a
-// quoted-string) and the rest of the string.  On failure, returns
+// quoted-string) and the rest of the string. On failure, returns
 // ("", v).
 func consumeValue(v string) (value, rest string) {
 	if v == "" {
diff --git a/src/mime/multipart/multipart.go b/src/mime/multipart/multipart.go
index 3b746a5e15..5b5168c826 100644
--- a/src/mime/multipart/multipart.go
+++ b/src/mime/multipart/multipart.go
@@ -150,13 +150,13 @@ func (pr partReader) Read(d []byte) (n int, err error) {
 	}()
 	if p.buffer.Len() >= len(d) {
 		// Internal buffer of unconsumed data is large enough for
-		// the read request.  No need to parse more at the moment.
+		// the read request. No need to parse more at the moment.
 		return p.buffer.Read(d)
 	}
 	peek, err := p.mr.bufReader.Peek(peekBufferSize) // TODO(bradfitz): add buffer size accessor
 
 	// Look for an immediate empty part without a leading \r\n
-	// before the boundary separator.  Some MIME code makes empty
+	// before the boundary separator. Some MIME code makes empty
 	// parts like this. Most browsers, however, write the \r\n
 	// before the subsequent boundary even for empty parts and
 	// won't hit this path.
@@ -210,7 +210,7 @@ func (p *Part) Close() error {
 }
 
 // Reader is an iterator over parts in a MIME multipart body.
-// Reader's underlying parser consumes its input as needed.  Seeking
+// Reader's underlying parser consumes its input as needed. Seeking
 // isn't supported.
 type Reader struct {
 	bufReader *bufio.Reader
@@ -310,7 +310,7 @@ func (mr *Reader) isBoundaryDelimiterLine(line []byte) (ret bool) {
 	rest = skipLWSPChar(rest)
 
 	// On the first part, see our lines are ending in \n instead of \r\n
-	// and switch into that mode if so.  This is a violation of the spec,
+	// and switch into that mode if so. This is a violation of the spec,
 	// but occurs in practice.
 	if mr.partsRead == 0 && len(rest) == 1 && rest[0] == '\n' {
 		mr.nl = mr.nl[1:]
diff --git a/src/mime/multipart/multipart_test.go b/src/mime/multipart/multipart_test.go
index d06bb4159a..82a7f86e67 100644
--- a/src/mime/multipart/multipart_test.go
+++ b/src/mime/multipart/multipart_test.go
@@ -446,8 +446,8 @@ type parseTest struct {
 var parseTests = []parseTest{
 	// Actual body from App Engine on a blob upload. The final part (the
 	// Content-Type: message/external-body) is what App Engine replaces
-	// the uploaded file with.  The other form fields (prefixed with
-	// "other" in their form-data name) are unchanged.  A bug was
+	// the uploaded file with. The other form fields (prefixed with
+	// "other" in their form-data name) are unchanged. A bug was
 	// reported with blob uploads failing when the other fields were
 	// empty. This was the MIME POST body that previously failed.
 	{
diff --git a/src/net/addrselect.go b/src/net/addrselect.go
index 58ab7d706c..0b9d160fd4 100644
--- a/src/net/addrselect.go
+++ b/src/net/addrselect.go
@@ -203,7 +203,7 @@ func (s *byRFC6724) Less(i, j int) bool {
 		// (e.g., https://golang.org/issue/13283).  Glibc instead only
 		// uses CommonPrefixLen for IPv4 when the source and destination
 		// addresses are on the same subnet, but that requires extra
-		// work to find the netmask for our source addresses.  As a
+		// work to find the netmask for our source addresses. As a
 		// simpler heuristic, we limit its use to when the source and
 		// destination belong to the same special purpose block.
 		if da4 {
diff --git a/src/net/conf.go b/src/net/conf.go
index ddaa978f4f..36566a49e2 100644
--- a/src/net/conf.go
+++ b/src/net/conf.go
@@ -185,7 +185,7 @@ func (c *conf) hostLookupOrder(hostname string) (ret hostLookupOrder) {
 		hostname = hostname[:len(hostname)-1]
 	}
 	if stringsHasSuffixFold(hostname, ".local") {
-		// Per RFC 6762, the ".local" TLD is special.  And
+		// Per RFC 6762, the ".local" TLD is special. And
 		// because Go's native resolver doesn't do mDNS or
 		// similar local resolution mechanisms, assume that
 		// libc might (via Avahi, etc) and use cgo.
diff --git a/src/net/dial_test.go b/src/net/dial_test.go
index 1df923f14b..0bcdbfc925 100644
--- a/src/net/dial_test.go
+++ b/src/net/dial_test.go
@@ -298,7 +298,7 @@ func TestDialParallel(t *testing.T) {
 	const fallbackDelay = 200 * time.Millisecond
 
 	// Some cases will run quickly when "connection refused" is fast,
-	// or trigger the fallbackDelay on Windows.  This value holds the
+	// or trigger the fallbackDelay on Windows. This value holds the
 	// lesser of the two delays.
 	var closedPortOrFallbackDelay time.Duration
 	if closedPortDelay < fallbackDelay {
diff --git a/src/net/dnsclient.go b/src/net/dnsclient.go
index 5094ac4f1b..f1835b8c06 100644
--- a/src/net/dnsclient.go
+++ b/src/net/dnsclient.go
@@ -45,7 +45,7 @@ func answer(name, server string, dns *dnsMsg, qtype uint16) (cname string, addrs
 	}
 	if dns.rcode != dnsRcodeSuccess {
 		// None of the error codes make sense
-		// for the query we sent.  If we didn't get
+		// for the query we sent. If we didn't get
 		// a name error and we didn't get success,
 		// the server is behaving incorrectly or
 		// having temporary trouble.
diff --git a/src/net/dnsconfig_unix.go b/src/net/dnsconfig_unix.go
index 0515ca90de..181d47b36d 100644
--- a/src/net/dnsconfig_unix.go
+++ b/src/net/dnsconfig_unix.go
@@ -61,7 +61,7 @@ func dnsReadConfig(filename string) *dnsConfig {
 		case "nameserver": // add one name server
 			if len(f) > 1 && len(conf.servers) < 3 { // small, but the standard limit
 				// One more check: make sure server name is
-				// just an IP address.  Otherwise we need DNS
+				// just an IP address. Otherwise we need DNS
 				// to look it up.
 				if parseIPv4(f[1]) != nil {
 					conf.servers = append(conf.servers, f[1])
diff --git a/src/net/dnsmsg.go b/src/net/dnsmsg.go
index 5747fd232b..c01381f190 100644
--- a/src/net/dnsmsg.go
+++ b/src/net/dnsmsg.go
@@ -2,7 +2,7 @@
 // Use of this source code is governed by a BSD-style
 // license that can be found in the LICENSE file.
 
-// DNS packet assembly.  See RFC 1035.
+// DNS packet assembly. See RFC 1035.
 //
 // This is intended to support name resolution during Dial.
 // It doesn't have to be blazing fast.
@@ -18,7 +18,7 @@
 // generic pack/unpack routines.
 //
 // TODO(rsc):  There are enough names defined in this file that they're all
-// prefixed with dns.  Perhaps put this in its own package later.
+// prefixed with dns. Perhaps put this in its own package later.
 
 package net
 
@@ -376,7 +376,7 @@ func (rr *dnsRR_AAAA) Walk(f func(v interface{}, name, tag string) bool) bool {
 // All the packers and unpackers take a (msg []byte, off int)
 // and return (off1 int, ok bool).  If they return ok==false, they
 // also return off1==len(msg), so that the next unpacker will
-// also fail.  This lets us avoid checks of ok until the end of a
+// also fail. This lets us avoid checks of ok until the end of a
 // packing sequence.
 
 // Map of constructors for each RR wire type.
@@ -399,7 +399,7 @@ var rr_mk = map[int]func() dnsRR{
 
 // Pack a domain name s into msg[off:].
 // Domain names are a sequence of counted strings
-// split at the dots.  They end with a zero-length string.
+// split at the dots. They end with a zero-length string.
 func packDomainName(s string, msg []byte, off int) (off1 int, ok bool) {
 	// Add trailing dot to canonicalize name.
 	if n := len(s); n == 0 || s[n-1] != '.' {
@@ -452,8 +452,8 @@ func packDomainName(s string, msg []byte, off int) (off1 int, ok bool) {
 // In addition to the simple sequences of counted strings above,
 // domain names are allowed to refer to strings elsewhere in the
 // packet, to avoid repeating common suffixes when returning
-// many entries in a single domain.  The pointers are marked
-// by a length byte with the top two bits set.  Ignoring those
+// many entries in a single domain. The pointers are marked
+// by a length byte with the top two bits set. Ignoring those
 // two bits, that byte and the next give a 14 bit offset from msg[0]
 // where we should pick up the trail.
 // Note that if we jump elsewhere in the packet,
diff --git a/src/net/fd_unix.go b/src/net/fd_unix.go
index 2639eab1c4..6c385dbef2 100644
--- a/src/net/fd_unix.go
+++ b/src/net/fd_unix.go
@@ -210,7 +210,7 @@ func (fd *netFD) Close() error {
 	}
 	// Unblock any I/O.  Once it all unblocks and returns,
 	// so that it cannot be referring to fd.sysfd anymore,
-	// the final decref will close fd.sysfd.  This should happen
+	// the final decref will close fd.sysfd. This should happen
 	// fairly quickly, since all the I/O is non-blocking, and any
 	// attempts to block in the pollDesc will return errClosing.
 	fd.pd.Evict()
@@ -464,7 +464,7 @@ func dupCloseOnExec(fd int) (newfd int, err error) {
 			// and fcntl there falls back (undocumented)
 			// to doing an ioctl instead, returning EBADF
 			// in this case because fd is not of the
-			// expected device fd type.  Treat it as
+			// expected device fd type. Treat it as
 			// EINVAL instead, so we fall back to the
 			// normal dup path.
 			// TODO: only do this on 10.6 if we can detect 10.6
diff --git a/src/net/http/cgi/host.go b/src/net/http/cgi/host.go
index 9b4d875418..b2657b13a8 100644
--- a/src/net/http/cgi/host.go
+++ b/src/net/http/cgi/host.go
@@ -10,7 +10,7 @@
 //
 // Note that using CGI means starting a new process to handle each
 // request, which is typically less efficient than using a
-// long-running server.  This package is intended primarily for
+// long-running server. This package is intended primarily for
 // compatibility with existing systems.
 package cgi
 
diff --git a/src/net/http/client.go b/src/net/http/client.go
index 3106d229da..68676a5dc9 100644
--- a/src/net/http/client.go
+++ b/src/net/http/client.go
@@ -237,7 +237,7 @@ func send(ireq *Request, rt RoundTripper, deadline time.Time) (*Response, error)
 	}
 
 	// Most the callers of send (Get, Post, et al) don't need
-	// Headers, leaving it uninitialized.  We guarantee to the
+	// Headers, leaving it uninitialized. We guarantee to the
 	// Transport that this has been initialized, though.
 	if req.Header == nil {
 		forkReq()
diff --git a/src/net/http/clientserver_test.go b/src/net/http/clientserver_test.go
index fbaa805712..171060b541 100644
--- a/src/net/http/clientserver_test.go
+++ b/src/net/http/clientserver_test.go
@@ -356,7 +356,7 @@ func TestH12_HandlerWritesTooLittle(t *testing.T) {
 }
 
 // Tests that the HTTP/1 and HTTP/2 servers prevent handlers from
-// writing more than they declared.  This test does not test whether
+// writing more than they declared. This test does not test whether
 // the transport deals with too much data, though, since the server
 // doesn't make it possible to send bogus data. For those tests, see
 // transport_test.go (for HTTP/1) or x/net/http2/transport_test.go
diff --git a/src/net/http/filetransport.go b/src/net/http/filetransport.go
index 821787e0c4..32126d7ec0 100644
--- a/src/net/http/filetransport.go
+++ b/src/net/http/filetransport.go
@@ -33,7 +33,7 @@ func NewFileTransport(fs FileSystem) RoundTripper {
 
 func (t fileTransport) RoundTrip(req *Request) (resp *Response, err error) {
 	// We start ServeHTTP in a goroutine, which may take a long
-	// time if the file is large.  The newPopulateResponseWriter
+	// time if the file is large. The newPopulateResponseWriter
 	// call returns a channel which either ServeHTTP or finish()
 	// sends our *Response on, once the *Response itself has been
 	// populated (even if the body itself is still being
diff --git a/src/net/http/fs.go b/src/net/http/fs.go
index 520a5477a7..7e672a0910 100644
--- a/src/net/http/fs.go
+++ b/src/net/http/fs.go
@@ -96,7 +96,7 @@ func dirList(w ResponseWriter, f File) {
 }
 
 // ServeContent replies to the request using the content in the
-// provided ReadSeeker.  The main benefit of ServeContent over io.Copy
+// provided ReadSeeker. The main benefit of ServeContent over io.Copy
 // is that it handles Range requests properly, sets the MIME type, and
 // handles If-Modified-Since requests.
 //
@@ -108,7 +108,7 @@ func dirList(w ResponseWriter, f File) {
 // never sent in the response.
 //
 // If modtime is not the zero time or Unix epoch, ServeContent
-// includes it in a Last-Modified header in the response.  If the
+// includes it in a Last-Modified header in the response. If the
 // request includes an If-Modified-Since header, ServeContent uses
 // modtime to decide whether the content needs to be sent at all.
 //
@@ -196,7 +196,7 @@ func serveContent(w ResponseWriter, r *Request, name string, modtime time.Time,
 			// The total number of bytes in all the ranges
 			// is larger than the size of the file by
 			// itself, so this is probably an attack, or a
-			// dumb client.  Ignore the range request.
+			// dumb client. Ignore the range request.
 			ranges = nil
 		}
 		switch {
@@ -291,7 +291,7 @@ func checkLastModified(w ResponseWriter, r *Request, modtime time.Time) bool {
 // checkETag implements If-None-Match and If-Range checks.
 //
 // The ETag or modtime must have been previously set in the
-// ResponseWriter's headers.  The modtime is only compared at second
+// ResponseWriter's headers. The modtime is only compared at second
 // granularity and may be the zero value to mean unknown.
 //
 // The return value is the effective request "Range" header to use and
@@ -336,7 +336,7 @@ func checkETag(w ResponseWriter, r *Request, modtime time.Time) (rangeReq string
 		}
 
 		// TODO(bradfitz): deal with comma-separated or multiple-valued
-		// list of If-None-match values.  For now just handle the common
+		// list of If-None-match values. For now just handle the common
 		// case of a single item.
 		if inm == etag || inm == "*" {
 			h := w.Header()
diff --git a/src/net/http/h2_bundle.go b/src/net/http/h2_bundle.go
index f778acb2b5..1e9088c9c3 100644
--- a/src/net/http/h2_bundle.go
+++ b/src/net/http/h2_bundle.go
@@ -300,7 +300,7 @@ func http2registerHTTPSProtocol(t *Transport, rt RoundTripper) (err error) {
 }
 
 // noDialClientConnPool is an implementation of http2.ClientConnPool
-// which never dials.  We let the HTTP/1.1 client dial and use its TLS
+// which never dials. We let the HTTP/1.1 client dial and use its TLS
 // connection instead.
 type http2noDialClientConnPool struct{ *http2clientConnPool }
 
@@ -1421,7 +1421,7 @@ type http2PriorityParam struct {
 	Exclusive bool
 
 	// Weight is the stream's zero-indexed weight. It should be
-	// set together with StreamDep, or neither should be set.  Per
+	// set together with StreamDep, or neither should be set. Per
 	// the spec, "Add one to the value to obtain a weight between
 	// 1 and 256."
 	Weight uint8
@@ -2335,7 +2335,7 @@ type http2connectionStater interface {
 	ConnectionState() tls.ConnectionState
 }
 
-// pipe is a goroutine-safe io.Reader/io.Writer pair.  It's like
+// pipe is a goroutine-safe io.Reader/io.Writer pair. It's like
 // io.Pipe except there are no PipeReader/PipeWriter halves, and the
 // underlying buffer is an interface. (io.Pipe is always unbuffered)
 type http2pipe struct {
@@ -4211,8 +4211,8 @@ func (b *http2requestBody) Read(p []byte) (n int, err error) {
 	return
 }
 
-// responseWriter is the http.ResponseWriter implementation.  It's
-// intentionally small (1 pointer wide) to minimize garbage.  The
+// responseWriter is the http.ResponseWriter implementation. It's
+// intentionally small (1 pointer wide) to minimize garbage. The
 // responseWriterState pointer inside is zeroed at the end of a
 // request (in handlerDone) and calls on the responseWriter thereafter
 // simply crash (caller's mistake), but the much larger responseWriterState
@@ -4386,7 +4386,7 @@ const http2TrailerPrefix = "Trailer:"
 // says you SHOULD (but not must) predeclare any trailers in the
 // header, the official ResponseWriter rules said trailers in Go must
 // be predeclared, and then we reuse the same ResponseWriter.Header()
-// map to mean both Headers and Trailers.  When it's time to write the
+// map to mean both Headers and Trailers. When it's time to write the
 // Trailers, we pick out the fields of Headers that were declared as
 // trailers. That worked for a while, until we found the first major
 // user of Trailers in the wild: gRPC (using them only over http2),
diff --git a/src/net/http/header.go b/src/net/http/header.go
index 57f311fedc..6343165a84 100644
--- a/src/net/http/header.go
+++ b/src/net/http/header.go
@@ -25,7 +25,7 @@ func (h Header) Add(key, value string) {
 }
 
 // Set sets the header entries associated with key to
-// the single element value.  It replaces any existing
+// the single element value. It replaces any existing
 // values associated with key.
 func (h Header) Set(key, value string) {
 	textproto.MIMEHeader(h).Set(key, value)
@@ -164,9 +164,9 @@ func (h Header) WriteSubset(w io.Writer, exclude map[string]bool) error {
 }
 
 // CanonicalHeaderKey returns the canonical format of the
-// header key s.  The canonicalization converts the first
+// header key s. The canonicalization converts the first
 // letter and any letter following a hyphen to upper case;
-// the rest are converted to lowercase.  For example, the
+// the rest are converted to lowercase. For example, the
 // canonical key for "accept-encoding" is "Accept-Encoding".
 // If s contains a space or invalid header field bytes, it is
 // returned without modifications.
@@ -186,7 +186,7 @@ func hasToken(v, token string) bool {
 	for sp := 0; sp <= len(v)-len(token); sp++ {
 		// Check that first character is good.
 		// The token is ASCII, so checking only a single byte
-		// is sufficient.  We skip this potential starting
+		// is sufficient. We skip this potential starting
 		// position if both the first byte and its potential
 		// ASCII uppercase equivalent (b|0x20) don't match.
 		// False positives ('^' => '~') are caught by EqualFold.
diff --git a/src/net/http/httptest/server.go b/src/net/http/httptest/server.go
index 7e52adb607..8655426eaf 100644
--- a/src/net/http/httptest/server.go
+++ b/src/net/http/httptest/server.go
@@ -158,7 +158,7 @@ func (s *Server) Close() {
 			// previously-flaky tests) in the case of
 			// socket-late-binding races from the http Client
 			// dialing this server and then getting an idle
-			// connection before the dial completed.  There is thus
+			// connection before the dial completed. There is thus
 			// a connected connection in StateNew with no
 			// associated Request. We only close StateIdle and
 			// StateNew because they're not doing anything. It's
@@ -297,7 +297,7 @@ func (s *Server) closeConn(c net.Conn) { s.closeConnChan(c, nil) }
 func (s *Server) closeConnChan(c net.Conn, done chan<- bool) {
 	if runtime.GOOS == "plan9" {
 		// Go's Plan 9 net package isn't great at unblocking reads when
-		// their underlying TCP connections are closed.  Don't trust
+		// their underlying TCP connections are closed. Don't trust
 		// that that the ConnState state machine will get to
 		// StateClosed. Instead, just go there directly. Plan 9 may leak
 		// resources if the syscall doesn't end up returning. Oh well.
diff --git a/src/net/http/httputil/dump.go b/src/net/http/httputil/dump.go
index 245eed0b21..3af5395898 100644
--- a/src/net/http/httputil/dump.go
+++ b/src/net/http/httputil/dump.go
@@ -128,7 +128,7 @@ func DumpRequestOut(req *http.Request, body bool) ([]byte, error) {
 
 	// If we used a dummy body above, remove it now.
 	// TODO: if the req.ContentLength is large, we allocate memory
-	// unnecessarily just to slice it off here.  But this is just
+	// unnecessarily just to slice it off here. But this is just
 	// a debug function, so this is acceptable for now. We could
 	// discard the body earlier if this matters.
 	if dummyBody {
@@ -269,7 +269,7 @@ func DumpRequest(req *http.Request, body bool) (dump []byte, err error) {
 var errNoBody = errors.New("sentinel error value")
 
 // failureToReadBody is a io.ReadCloser that just returns errNoBody on
-// Read.  It's swapped in when we don't actually want to consume
+// Read. It's swapped in when we don't actually want to consume
 // the body, but need a non-nil one, and want to distinguish the
 // error from reading the dummy body.
 type failureToReadBody struct{}
diff --git a/src/net/http/httputil/persist.go b/src/net/http/httputil/persist.go
index 987bcc96ba..4cb110b716 100644
--- a/src/net/http/httputil/persist.go
+++ b/src/net/http/httputil/persist.go
@@ -239,7 +239,7 @@ type ClientConn struct {
 	writeReq func(*http.Request, io.Writer) error
 }
 
-// NewClientConn returns a new ClientConn reading and writing c.  If r is not
+// NewClientConn returns a new ClientConn reading and writing c. If r is not
 // nil, it is the buffer to use when reading c.
 //
 // ClientConn is low-level and old. Applications should use Client or
diff --git a/src/net/http/httputil/reverseproxy.go b/src/net/http/httputil/reverseproxy.go
index 54411caeca..26a668b6df 100644
--- a/src/net/http/httputil/reverseproxy.go
+++ b/src/net/http/httputil/reverseproxy.go
@@ -180,9 +180,9 @@ func (p *ReverseProxy) ServeHTTP(rw http.ResponseWriter, req *http.Request) {
 	outreq.ProtoMinor = 1
 	outreq.Close = false
 
-	// Remove hop-by-hop headers to the backend.  Especially
+	// Remove hop-by-hop headers to the backend. Especially
 	// important is "Connection" because we want a persistent
-	// connection, regardless of what the client sent to us.  This
+	// connection, regardless of what the client sent to us. This
 	// is modifying the same underlying map from req (shallow
 	// copied above) so we only copy it if necessary.
 	copiedHeaders := false
diff --git a/src/net/http/pprof/pprof.go b/src/net/http/pprof/pprof.go
index 3400dbbdc6..2357d8ed1e 100644
--- a/src/net/http/pprof/pprof.go
+++ b/src/net/http/pprof/pprof.go
@@ -15,7 +15,7 @@
 //	import _ "net/http/pprof"
 //
 // If your application is not already running an http server, you
-// need to start one.  Add "net/http" and "log" to your imports and
+// need to start one. Add "net/http" and "log" to your imports and
 // the following code to your main function:
 //
 // 	go func() {
@@ -146,11 +146,11 @@ func Symbol(w http.ResponseWriter, r *http.Request) {
 	w.Header().Set("Content-Type", "text/plain; charset=utf-8")
 
 	// We have to read the whole POST body before
-	// writing any output.  Buffer the output here.
+	// writing any output. Buffer the output here.
 	var buf bytes.Buffer
 
 	// We don't know how many symbols we have, but we
-	// do have symbol information.  Pprof only cares whether
+	// do have symbol information. Pprof only cares whether
 	// this number is 0 (no symbols available) or > 0.
 	fmt.Fprintf(&buf, "num_symbols: 1\n")
 
diff --git a/src/net/http/request.go b/src/net/http/request.go
index 4037f40a3e..76fb8fe6d1 100644
--- a/src/net/http/request.go
+++ b/src/net/http/request.go
@@ -279,8 +279,8 @@ func (r *Request) Cookie(name string) (*Cookie, error) {
 	return nil, ErrNoCookie
 }
 
-// AddCookie adds a cookie to the request.  Per RFC 6265 section 5.4,
-// AddCookie does not attach more than one Cookie header field.  That
+// AddCookie adds a cookie to the request. Per RFC 6265 section 5.4,
+// AddCookie does not attach more than one Cookie header field. That
 // means all cookies, if any, are written into the same line,
 // separated by semicolon.
 func (r *Request) AddCookie(c *Cookie) {
@@ -375,7 +375,7 @@ func (r *Request) Write(w io.Writer) error {
 }
 
 // WriteProxy is like Write but writes the request in the form
-// expected by an HTTP proxy.  In particular, WriteProxy writes the
+// expected by an HTTP proxy. In particular, WriteProxy writes the
 // initial Request-URI line of the request with an absolute URI, per
 // section 5.1.2 of RFC 2616, including the scheme and host.
 // In either case, WriteProxy also writes a Host header, using
@@ -776,7 +776,7 @@ func readRequest(b *bufio.Reader, deleteHostHeader bool) (req *Request, err erro
 	// and
 	//	GET http://www.google.com/index.html HTTP/1.1
 	//	Host: doesntmatter
-	// the same.  In the second case, any Host line is ignored.
+	// the same. In the second case, any Host line is ignored.
 	req.Host = req.URL.Host
 	if req.Host == "" {
 		req.Host = req.Header.get("Host")
diff --git a/src/net/http/requestwrite_test.go b/src/net/http/requestwrite_test.go
index 671cca91a6..2545f6f4c2 100644
--- a/src/net/http/requestwrite_test.go
+++ b/src/net/http/requestwrite_test.go
@@ -604,7 +604,7 @@ func TestRequestWriteError(t *testing.T) {
 	failAfter, writeCount := 0, 0
 	errFail := errors.New("fake write failure")
 
-	// w is the buffered io.Writer to write the request to.  It
+	// w is the buffered io.Writer to write the request to. It
 	// fails exactly once on its Nth Write call, as controlled by
 	// failAfter. It also tracks the number of calls in
 	// writeCount.
diff --git a/src/net/http/response.go b/src/net/http/response.go
index c424f61cd0..a596d1d342 100644
--- a/src/net/http/response.go
+++ b/src/net/http/response.go
@@ -33,7 +33,7 @@ type Response struct {
 	ProtoMajor int    // e.g. 1
 	ProtoMinor int    // e.g. 0
 
-	// Header maps header keys to values.  If the response had multiple
+	// Header maps header keys to values. If the response had multiple
 	// headers with the same key, they may be concatenated, with comma
 	// delimiters.  (Section 4.2 of RFC 2616 requires that multiple headers
 	// be semantically equivalent to a comma-delimited sequence.) Values
@@ -57,8 +57,8 @@ type Response struct {
 	// with a "chunked" Transfer-Encoding.
 	Body io.ReadCloser
 
-	// ContentLength records the length of the associated content.  The
-	// value -1 indicates that the length is unknown.  Unless Request.Method
+	// ContentLength records the length of the associated content. The
+	// value -1 indicates that the length is unknown. Unless Request.Method
 	// is "HEAD", values >= 0 indicate that the given number of bytes may
 	// be read from Body.
 	ContentLength int64
@@ -68,7 +68,7 @@ type Response struct {
 	TransferEncoding []string
 
 	// Close records whether the header directed that the connection be
-	// closed after reading Body.  The value is advice for clients: neither
+	// closed after reading Body. The value is advice for clients: neither
 	// ReadResponse nor Response.Write ever closes a connection.
 	Close bool
 
@@ -108,8 +108,8 @@ func (r *Response) Cookies() []*Cookie {
 var ErrNoLocation = errors.New("http: no Location header in response")
 
 // Location returns the URL of the response's "Location" header,
-// if present.  Relative redirects are resolved relative to
-// the Response's Request.  ErrNoLocation is returned if no
+// if present. Relative redirects are resolved relative to
+// the Response's Request. ErrNoLocation is returned if no
 // Location header is present.
 func (r *Response) Location() (*url.URL, error) {
 	lv := r.Header.Get("Location")
diff --git a/src/net/http/serve_test.go b/src/net/http/serve_test.go
index 384b453ce0..250e18644c 100644
--- a/src/net/http/serve_test.go
+++ b/src/net/http/serve_test.go
@@ -617,7 +617,7 @@ func TestIdentityResponse(t *testing.T) {
 	defer ts.Close()
 
 	// Note: this relies on the assumption (which is true) that
-	// Get sends HTTP/1.1 or greater requests.  Otherwise the
+	// Get sends HTTP/1.1 or greater requests. Otherwise the
 	// server wouldn't have the choice to send back chunked
 	// responses.
 	for _, te := range []string{"", "identity"} {
@@ -984,7 +984,7 @@ func TestTLSServer(t *testing.T) {
 	defer ts.Close()
 
 	// Connect an idle TCP connection to this server before we run
-	// our real tests.  This idle connection used to block forever
+	// our real tests. This idle connection used to block forever
 	// in the TLS handshake, preventing future connections from
 	// being accepted. It may prevent future accidental blocking
 	// in newConn.
@@ -2027,7 +2027,7 @@ func TestHandlerPanicWithHijack(t *testing.T) {
 func testHandlerPanic(t *testing.T, withHijack, h2 bool, panicValue interface{}) {
 	defer afterTest(t)
 	// Unlike the other tests that set the log output to ioutil.Discard
-	// to quiet the output, this test uses a pipe.  The pipe serves three
+	// to quiet the output, this test uses a pipe. The pipe serves three
 	// purposes:
 	//
 	//   1) The log.Print from the http server (generated by the caught
@@ -2060,7 +2060,7 @@ func testHandlerPanic(t *testing.T, withHijack, h2 bool, panicValue interface{})
 	defer cst.close()
 
 	// Do a blocking read on the log output pipe so its logging
-	// doesn't bleed into the next test.  But wait only 5 seconds
+	// doesn't bleed into the next test. But wait only 5 seconds
 	// for it.
 	done := make(chan bool, 1)
 	go func() {
@@ -2205,10 +2205,10 @@ func testRequestBodyLimit(t *testing.T, h2 bool) {
 	nWritten := new(int64)
 	req, _ := NewRequest("POST", cst.ts.URL, io.LimitReader(countReader{neverEnding('a'), nWritten}, limit*200))
 
-	// Send the POST, but don't care it succeeds or not.  The
+	// Send the POST, but don't care it succeeds or not. The
 	// remote side is going to reply and then close the TCP
 	// connection, and HTTP doesn't really define if that's
-	// allowed or not.  Some HTTP clients will get the response
+	// allowed or not. Some HTTP clients will get the response
 	// and some (like ours, currently) will complain that the
 	// request write failed, without reading the response.
 	//
@@ -2650,7 +2650,7 @@ func TestOptions(t *testing.T) {
 }
 
 // Tests regarding the ordering of Write, WriteHeader, Header, and
-// Flush calls.  In Go 1.0, rw.WriteHeader immediately flushed the
+// Flush calls. In Go 1.0, rw.WriteHeader immediately flushed the
 // (*response).header to the wire. In Go 1.1, the actual wire flush is
 // delayed, so we could maybe tack on a Content-Length and better
 // Content-Type after we see more (or all) of the output. To preserve
@@ -3107,7 +3107,7 @@ func testTransportAndServerSharedBodyRace(t *testing.T, h2 bool) {
 
 	const bodySize = 1 << 20
 
-	// errorf is like t.Errorf, but also writes to println.  When
+	// errorf is like t.Errorf, but also writes to println. When
 	// this test fails, it hangs. This helps debugging and I've
 	// added this enough times "temporarily".  It now gets added
 	// full time.
diff --git a/src/net/http/server.go b/src/net/http/server.go
index 773dd59c6b..7a27a4157c 100644
--- a/src/net/http/server.go
+++ b/src/net/http/server.go
@@ -2,7 +2,7 @@
 // Use of this source code is governed by a BSD-style
 // license that can be found in the LICENSE file.
 
-// HTTP server.  See RFC 2616.
+// HTTP server. See RFC 2616.
 
 package http
 
@@ -74,7 +74,7 @@ type ResponseWriter interface {
 
 	// Write writes the data to the connection as part of an HTTP reply.
 	// If WriteHeader has not yet been called, Write calls WriteHeader(http.StatusOK)
-	// before writing the data.  If the Header does not contain a
+	// before writing the data. If the Header does not contain a
 	// Content-Type line, Write adds a Content-Type set to the result of passing
 	// the initial 512 bytes of written data to DetectContentType.
 	Write([]byte) (int, error)
@@ -342,7 +342,7 @@ type response struct {
 	requestBodyLimitHit bool
 
 	// trailers are the headers to be sent after the handler
-	// finishes writing the body.  This field is initialized from
+	// finishes writing the body. This field is initialized from
 	// the Trailer response header when the response header is
 	// written.
 	trailers []string
@@ -766,7 +766,7 @@ func (w *response) Header() Header {
 
 // maxPostHandlerReadBytes is the max number of Request.Body bytes not
 // consumed by a handler that the server will read from the client
-// in order to keep a connection alive.  If there are more bytes than
+// in order to keep a connection alive. If there are more bytes than
 // this then the server to be paranoid instead sends a "Connection:
 // close" response.
 //
@@ -855,8 +855,8 @@ func (h extraHeader) Write(w *bufio.Writer) {
 // to cw.res.conn.bufw.
 //
 // p is not written by writeHeader, but is the first chunk of the body
-// that will be written.  It is sniffed for a Content-Type if none is
-// set explicitly.  It's also used to set the Content-Length, if the
+// that will be written. It is sniffed for a Content-Type if none is
+// set explicitly. It's also used to set the Content-Length, if the
 // total body size was small and the handler has already finished
 // running.
 func (cw *chunkWriter) writeHeader(p []byte) {
@@ -911,9 +911,9 @@ func (cw *chunkWriter) writeHeader(p []byte) {
 	// Exceptions: 304/204/1xx responses never get Content-Length, and if
 	// it was a HEAD request, we don't know the difference between
 	// 0 actual bytes and 0 bytes because the handler noticed it
-	// was a HEAD request and chose not to write anything.  So for
+	// was a HEAD request and chose not to write anything. So for
 	// HEAD, the handler should either write the Content-Length or
-	// write non-zero bytes.  If it's actually 0 bytes and the
+	// write non-zero bytes. If it's actually 0 bytes and the
 	// handler never looked at the Request.Method, we just don't
 	// send a Content-Length header.
 	// Further, we don't send an automatic Content-Length if they
@@ -965,7 +965,7 @@ func (cw *chunkWriter) writeHeader(p []byte) {
 	}
 
 	// Per RFC 2616, we should consume the request body before
-	// replying, if the handler hasn't already done so.  But we
+	// replying, if the handler hasn't already done so. But we
 	// don't want to do an unbounded amount of reading here for
 	// DoS reasons, so we only try up to a threshold.
 	if w.req.ContentLength != 0 && !w.closeAfterReply {
@@ -1174,7 +1174,7 @@ func (w *response) bodyAllowed() bool {
 // The Life Of A Write is like this:
 //
 // Handler starts. No header has been sent. The handler can either
-// write a header, or just start writing.  Writing before sending a header
+// write a header, or just start writing. Writing before sending a header
 // sends an implicitly empty 200 OK header.
 //
 // If the handler didn't declare a Content-Length up front, we either
@@ -1200,7 +1200,7 @@ func (w *response) bodyAllowed() bool {
 // initial header contains both a Content-Type and Content-Length.
 // Also short-circuit in (1) when the header's been sent and not in
 // chunking mode, writing directly to (4) instead, if (2) has no
-// buffered data.  More generally, we could short-circuit from (1) to
+// buffered data. More generally, we could short-circuit from (1) to
 // (3) even in chunking mode if the write size from (1) is over some
 // threshold and nothing is in (2).  The answer might be mostly making
 // bufferBeforeChunkingSize smaller and having bufio's fast-paths deal
@@ -1341,7 +1341,7 @@ type closeWriter interface {
 var _ closeWriter = (*net.TCPConn)(nil)
 
 // closeWrite flushes any outstanding data and sends a FIN packet (if
-// client is connected via TCP), signalling that we're done.  We then
+// client is connected via TCP), signalling that we're done. We then
 // pause for a bit, hoping the client processes it before any
 // subsequent RST.
 //
@@ -1355,7 +1355,7 @@ func (c *conn) closeWriteAndWait() {
 }
 
 // validNPN reports whether the proto is not a blacklisted Next
-// Protocol Negotiation protocol.  Empty and built-in protocol types
+// Protocol Negotiation protocol. Empty and built-in protocol types
 // are blacklisted and can't be overridden with alternate
 // implementations.
 func validNPN(proto string) bool {
@@ -1433,7 +1433,7 @@ func (c *conn) serve() {
 				// able to read this if we're
 				// responding to them and hanging up
 				// while they're still writing their
-				// request.  Undefined behavior.
+				// request. Undefined behavior.
 				io.WriteString(c.rwc, "HTTP/1.1 431 Request Header Fields Too Large\r\nContent-Type: text/plain\r\nConnection: close\r\n\r\n431 Request Header Fields Too Large")
 				c.closeWriteAndWait()
 				return
@@ -1467,7 +1467,7 @@ func (c *conn) serve() {
 		// HTTP cannot have multiple simultaneous active requests.[*]
 		// Until the server replies to this request, it can't read another,
 		// so we might as well run the handler in this goroutine.
-		// [*] Not strictly true: HTTP pipelining.  We could let them all process
+		// [*] Not strictly true: HTTP pipelining. We could let them all process
 		// in parallel even if their responses need to be serialized.
 		serverHandler{c.server}.ServeHTTP(w, w.req)
 		if c.hijacked() {
@@ -1488,7 +1488,7 @@ func (w *response) sendExpectationFailed() {
 	// TODO(bradfitz): let ServeHTTP handlers handle
 	// requests with non-standard expectation[s]? Seems
 	// theoretical at best, and doesn't fit into the
-	// current ServeHTTP model anyway.  We'd need to
+	// current ServeHTTP model anyway. We'd need to
 	// make the ResponseWriter an optional
 	// "ExpectReplier" interface or something.
 	//
@@ -1608,7 +1608,7 @@ func requestBodyRemains(rc io.ReadCloser) bool {
 }
 
 // The HandlerFunc type is an adapter to allow the use of
-// ordinary functions as HTTP handlers.  If f is a function
+// ordinary functions as HTTP handlers. If f is a function
 // with the appropriate signature, HandlerFunc(f) is a
 // Handler that calls f.
 type HandlerFunc func(ResponseWriter, *Request)
@@ -1779,7 +1779,7 @@ func RedirectHandler(url string, code int) Handler {
 // been registered separately.
 //
 // Patterns may optionally begin with a host name, restricting matches to
-// URLs on that host only.  Host-specific patterns take precedence over
+// URLs on that host only. Host-specific patterns take precedence over
 // general patterns, so that a handler might register for the two patterns
 // "/codesearch" and "codesearch.google.com/" without also taking over
 // requests for "http://www.google.com/".
@@ -1968,7 +1968,7 @@ func HandleFunc(pattern string, handler func(ResponseWriter, *Request)) {
 }
 
 // Serve accepts incoming HTTP connections on the listener l,
-// creating a new service goroutine for each.  The service goroutines
+// creating a new service goroutine for each. The service goroutines
 // read requests and then call handler to reply to them.
 // Handler is typically nil, in which case the DefaultServeMux is used.
 func Serve(l net.Listener, handler Handler) error {
@@ -1988,10 +1988,10 @@ type Server struct {
 
 	// TLSNextProto optionally specifies a function to take over
 	// ownership of the provided TLS connection when an NPN
-	// protocol upgrade has occurred.  The map key is the protocol
+	// protocol upgrade has occurred. The map key is the protocol
 	// name negotiated. The Handler argument should be used to
 	// handle HTTP requests and will initialize the Request's TLS
-	// and RemoteAddr if not already set.  The connection is
+	// and RemoteAddr if not already set. The connection is
 	// automatically closed when the function returns.
 	// If TLSNextProto is nil, HTTP/2 support is enabled automatically.
 	TLSNextProto map[string]func(*Server, *tls.Conn, Handler)
@@ -2330,7 +2330,7 @@ type timeoutHandler struct {
 	body    string
 
 	// timeout returns the channel of a *time.Timer and
-	// cancelTimer cancels it.  They're stored separately for
+	// cancelTimer cancels it. They're stored separately for
 	// testing purposes.
 	timeout     func() <-chan time.Time // returns channel producing a timeout
 	cancelTimer func() bool             // optional
diff --git a/src/net/http/sniff.go b/src/net/http/sniff.go
index 44f83db020..54986b9956 100644
--- a/src/net/http/sniff.go
+++ b/src/net/http/sniff.go
@@ -14,8 +14,8 @@ const sniffLen = 512
 
 // DetectContentType implements the algorithm described
 // at http://mimesniff.spec.whatwg.org/ to determine the
-// Content-Type of the given data.  It considers at most the
-// first 512 bytes of data.  DetectContentType always returns
+// Content-Type of the given data. It considers at most the
+// first 512 bytes of data. DetectContentType always returns
 // a valid MIME type: if it cannot determine a more specific one, it
 // returns "application/octet-stream".
 func DetectContentType(data []byte) string {
diff --git a/src/net/http/transfer.go b/src/net/http/transfer.go
index 7ff4953a14..4c130f0cc4 100644
--- a/src/net/http/transfer.go
+++ b/src/net/http/transfer.go
@@ -276,7 +276,7 @@ func (t *transferReader) protoAtLeast(m, n int) bool {
 }
 
 // bodyAllowedForStatus reports whether a given response status code
-// permits a body.  See RFC2616, section 4.4.
+// permits a body. See RFC2616, section 4.4.
 func bodyAllowedForStatus(status int) bool {
 	switch {
 	case status >= 100 && status <= 199:
@@ -379,7 +379,7 @@ func readTransfer(msg interface{}, r *bufio.Reader) (err error) {
 		}
 	}
 
-	// Prepare body reader.  ContentLength < 0 means chunked encoding
+	// Prepare body reader. ContentLength < 0 means chunked encoding
 	// or close connection when finished, since multipart is not supported yet
 	switch {
 	case chunked(t.TransferEncoding):
@@ -727,11 +727,11 @@ func (b *body) readTrailer() error {
 	}
 
 	// Make sure there's a header terminator coming up, to prevent
-	// a DoS with an unbounded size Trailer.  It's not easy to
+	// a DoS with an unbounded size Trailer. It's not easy to
 	// slip in a LimitReader here, as textproto.NewReader requires
-	// a concrete *bufio.Reader.  Also, we can't get all the way
+	// a concrete *bufio.Reader. Also, we can't get all the way
 	// back up to our conn's LimitedReader that *might* be backing
-	// this bufio.Reader.  Instead, a hack: we iteratively Peek up
+	// this bufio.Reader. Instead, a hack: we iteratively Peek up
 	// to the bufio.Reader's max size, looking for a double CRLF.
 	// This limits the trailer to the underlying buffer size, typically 4kB.
 	if !seeUpcomingDoubleCRLF(b.r) {
diff --git a/src/net/http/transport.go b/src/net/http/transport.go
index f622f6f983..163e1bd2b9 100644
--- a/src/net/http/transport.go
+++ b/src/net/http/transport.go
@@ -118,7 +118,7 @@ type Transport struct {
 	DisableCompression bool
 
 	// MaxIdleConnsPerHost, if non-zero, controls the maximum idle
-	// (keep-alive) to keep per-host.  If zero,
+	// (keep-alive) to keep per-host. If zero,
 	// DefaultMaxIdleConnsPerHost is used.
 	MaxIdleConnsPerHost int
 
@@ -137,7 +137,7 @@ type Transport struct {
 
 	// TLSNextProto specifies how the Transport switches to an
 	// alternate protocol (such as HTTP/2) after a TLS NPN/ALPN
-	// protocol negotiation.  If Transport dials an TLS connection
+	// protocol negotiation. If Transport dials an TLS connection
 	// with a non-empty protocol name and TLSNextProto contains a
 	// map entry for that key (such as "h2"), then the func is
 	// called with the request's authority (such as "example.com"
@@ -306,7 +306,7 @@ func (t *Transport) RoundTrip(req *Request) (*Response, error) {
 
 		// Get the cached or newly-created connection to either the
 		// host (for http or https), the http proxy, or the http proxy
-		// pre-CONNECTed to https server.  In any case, we'll be ready
+		// pre-CONNECTed to https server. In any case, we'll be ready
 		// to send it requests.
 		pconn, err := t.getConn(req, cm)
 		if err != nil {
@@ -541,7 +541,7 @@ func (t *Transport) tryPutIdleConn(pconn *persistConn) error {
 		// We're done with this pconn and somebody else is
 		// currently waiting for a conn of this type (they're
 		// actively dialing, but this conn is ready
-		// first). Chrome calls this socket late binding.  See
+		// first). Chrome calls this socket late binding. See
 		// https://insouciant.org/tech/connection-management-in-chromium/
 		t.idleMu.Unlock()
 		return nil
@@ -666,7 +666,7 @@ func (t *Transport) dial(network, addr string) (net.Conn, error) {
 }
 
 // getConn dials and creates a new persistConn to the target as
-// specified in the connectMethod.  This includes doing a proxy CONNECT
+// specified in the connectMethod. This includes doing a proxy CONNECT
 // and/or setting up TLS.  If this doesn't return an error, the persistConn
 // is ready to write requests to.
 func (t *Transport) getConn(req *Request, cm connectMethod) (*persistConn, error) {
@@ -1558,7 +1558,7 @@ func (pc *persistConn) closeLocked(err error) {
 			// handlePendingDial's putOrCloseIdleConn when
 			// it turns out the abandoned connection in
 			// flight ended up negotiating an alternate
-			// protocol.  We don't use the connection
+			// protocol. We don't use the connection
 			// freelist for http2. That's done by the
 			// alternate protocol's RoundTripper.
 		} else {
diff --git a/src/net/http/transport_test.go b/src/net/http/transport_test.go
index e8a4623556..9f17017651 100644
--- a/src/net/http/transport_test.go
+++ b/src/net/http/transport_test.go
@@ -478,7 +478,7 @@ func TestTransportServerClosingUnexpectedly(t *testing.T) {
 
 	// This test has an expected race. Sleeping for 25 ms prevents
 	// it on most fast machines, causing the next fetch() call to
-	// succeed quickly.  But if we do get errors, fetch() will retry 5
+	// succeed quickly. But if we do get errors, fetch() will retry 5
 	// times with some delays between.
 	time.Sleep(25 * time.Millisecond)
 
@@ -518,7 +518,7 @@ func TestStressSurpriseServerCloses(t *testing.T) {
 	// after each request completes, regardless of whether it failed.
 	// If these are too high, OS X exhausts its ephemeral ports
 	// and hangs waiting for them to transition TCP states. That's
-	// not what we want to test.  TODO(bradfitz): use an io.Pipe
+	// not what we want to test. TODO(bradfitz): use an io.Pipe
 	// dialer for this test instead?
 	const (
 		numClients    = 20
@@ -1026,7 +1026,7 @@ func TestTransportPersistConnLeak(t *testing.T) {
 
 	growth := nfinal - n0
 
-	// We expect 0 or 1 extra goroutine, empirically.  Allow up to 5.
+	// We expect 0 or 1 extra goroutine, empirically. Allow up to 5.
 	// Previously we were leaking one per numReq.
 	if int(growth) > 5 {
 		t.Logf("goroutine growth: %d -> %d -> %d (delta: %d)", n0, nhigh, nfinal, growth)
@@ -1067,7 +1067,7 @@ func TestTransportPersistConnLeakShortBody(t *testing.T) {
 
 	growth := nfinal - n0
 
-	// We expect 0 or 1 extra goroutine, empirically.  Allow up to 5.
+	// We expect 0 or 1 extra goroutine, empirically. Allow up to 5.
 	// Previously we were leaking one per numReq.
 	t.Logf("goroutine growth: %d -> %d -> %d (delta: %d)", n0, nhigh, nfinal, growth)
 	if int(growth) > 5 {
@@ -1103,8 +1103,8 @@ func TestTransportIdleConnCrash(t *testing.T) {
 }
 
 // Test that the transport doesn't close the TCP connection early,
-// before the response body has been read.  This was a regression
-// which sadly lacked a triggering test.  The large response body made
+// before the response body has been read. This was a regression
+// which sadly lacked a triggering test. The large response body made
 // the old race easier to trigger.
 func TestIssue3644(t *testing.T) {
 	defer afterTest(t)
@@ -1199,7 +1199,7 @@ func TestTransportConcurrency(t *testing.T) {
 
 	// Due to the Transport's "socket late binding" (see
 	// idleConnCh in transport.go), the numReqs HTTP requests
-	// below can finish with a dial still outstanding.  To keep
+	// below can finish with a dial still outstanding. To keep
 	// the leak checker happy, keep track of pending dials and
 	// wait for them to finish (and be closed or returned to the
 	// idle pool) before we close idle connections.
@@ -2273,7 +2273,7 @@ func TestTLSServerClosesConnection(t *testing.T) {
 }
 
 // byteFromChanReader is an io.Reader that reads a single byte at a
-// time from the channel.  When the channel is closed, the reader
+// time from the channel. When the channel is closed, the reader
 // returns io.EOF.
 type byteFromChanReader chan byte
 
@@ -2405,7 +2405,7 @@ func (plan9SleepReader) Read(p []byte) (int, error) {
 		// After the fix to unblock TCP Reads in
 		// https://golang.org/cl/15941, this sleep is required
 		// on plan9 to make sure TCP Writes before an
-		// immediate TCP close go out on the wire.  On Plan 9,
+		// immediate TCP close go out on the wire. On Plan 9,
 		// it seems that a hangup of a TCP connection with
 		// queued data doesn't send the queued data first.
 		// https://golang.org/issue/9554
@@ -2424,7 +2424,7 @@ func (f closerFunc) Close() error { return f() }
 // from (or finish writing to) the socket.
 //
 // NOTE: we resend a request only if the request is idempotent, we reused a
-// keep-alive connection, and we haven't yet received any header data.  This
+// keep-alive connection, and we haven't yet received any header data. This
 // automatically prevents an infinite resend loop because we'll run out of the
 // cached keep-alive connections eventually.
 func TestRetryIdempotentRequestsOnError(t *testing.T) {
diff --git a/src/net/interface.go b/src/net/interface.go
index 64a284c157..c99f8fd216 100644
--- a/src/net/interface.go
+++ b/src/net/interface.go
@@ -15,7 +15,7 @@ var (
 )
 
 // Interface represents a mapping between network interface name
-// and index.  It also represents network interface facility
+// and index. It also represents network interface facility
 // information.
 type Interface struct {
 	Index        int          // positive integer that starts at one, zero is never used
diff --git a/src/net/interface_bsd.go b/src/net/interface_bsd.go
index 4525388c95..b173fbcefc 100644
--- a/src/net/interface_bsd.go
+++ b/src/net/interface_bsd.go
@@ -13,7 +13,7 @@ import (
 )
 
 // If the ifindex is zero, interfaceTable returns mappings of all
-// network interfaces.  Otherwise it returns a mapping of a specific
+// network interfaces. Otherwise it returns a mapping of a specific
 // interface.
 func interfaceTable(ifindex int) ([]Interface, error) {
 	tab, err := syscall.RouteRIB(syscall.NET_RT_IFLIST, ifindex)
@@ -95,7 +95,7 @@ func linkFlags(rawFlags int32) Flags {
 }
 
 // If the ifi is nil, interfaceAddrTable returns addresses for all
-// network interfaces.  Otherwise it returns addresses for a specific
+// network interfaces. Otherwise it returns addresses for a specific
 // interface.
 func interfaceAddrTable(ifi *Interface) ([]Addr, error) {
 	index := 0
diff --git a/src/net/interface_linux.go b/src/net/interface_linux.go
index 55beca5895..5e391b28b0 100644
--- a/src/net/interface_linux.go
+++ b/src/net/interface_linux.go
@@ -11,7 +11,7 @@ import (
 )
 
 // If the ifindex is zero, interfaceTable returns mappings of all
-// network interfaces.  Otherwise it returns a mapping of a specific
+// network interfaces. Otherwise it returns a mapping of a specific
 // interface.
 func interfaceTable(ifindex int) ([]Interface, error) {
 	tab, err := syscall.NetlinkRIB(syscall.RTM_GETLINK, syscall.AF_UNSPEC)
@@ -115,7 +115,7 @@ func linkFlags(rawFlags uint32) Flags {
 }
 
 // If the ifi is nil, interfaceAddrTable returns addresses for all
-// network interfaces.  Otherwise it returns addresses for a specific
+// network interfaces. Otherwise it returns addresses for a specific
 // interface.
 func interfaceAddrTable(ifi *Interface) ([]Addr, error) {
 	tab, err := syscall.NetlinkRIB(syscall.RTM_GETADDR, syscall.AF_UNSPEC)
diff --git a/src/net/interface_stub.go b/src/net/interface_stub.go
index d1e30f7e95..f64174c62e 100644
--- a/src/net/interface_stub.go
+++ b/src/net/interface_stub.go
@@ -7,14 +7,14 @@
 package net
 
 // If the ifindex is zero, interfaceTable returns mappings of all
-// network interfaces.  Otherwise it returns a mapping of a specific
+// network interfaces. Otherwise it returns a mapping of a specific
 // interface.
 func interfaceTable(ifindex int) ([]Interface, error) {
 	return nil, nil
 }
 
 // If the ifi is nil, interfaceAddrTable returns addresses for all
-// network interfaces.  Otherwise it returns addresses for a specific
+// network interfaces. Otherwise it returns addresses for a specific
 // interface.
 func interfaceAddrTable(ifi *Interface) ([]Addr, error) {
 	return nil, nil
diff --git a/src/net/interface_test.go b/src/net/interface_test.go
index 56c3e919a8..1487acf601 100644
--- a/src/net/interface_test.go
+++ b/src/net/interface_test.go
@@ -11,7 +11,7 @@ import (
 )
 
 // loopbackInterface returns an available logical network interface
-// for loopback tests.  It returns nil if no suitable interface is
+// for loopback tests. It returns nil if no suitable interface is
 // found.
 func loopbackInterface() *Interface {
 	ift, err := Interfaces()
diff --git a/src/net/interface_windows.go b/src/net/interface_windows.go
index 78bf375b6d..8b976e585f 100644
--- a/src/net/interface_windows.go
+++ b/src/net/interface_windows.go
@@ -61,7 +61,7 @@ func adapterAddresses() ([]*windows.IpAdapterAddresses, error) {
 }
 
 // If the ifindex is zero, interfaceTable returns mappings of all
-// network interfaces.  Otherwise it returns a mapping of a specific
+// network interfaces. Otherwise it returns a mapping of a specific
 // interface.
 func interfaceTable(ifindex int) ([]Interface, error) {
 	aas, err := adapterAddresses()
@@ -116,7 +116,7 @@ func interfaceTable(ifindex int) ([]Interface, error) {
 }
 
 // If the ifi is nil, interfaceAddrTable returns addresses for all
-// network interfaces.  Otherwise it returns addresses for a specific
+// network interfaces. Otherwise it returns addresses for a specific
 // interface.
 func interfaceAddrTable(ifi *Interface) ([]Addr, error) {
 	aas, err := adapterAddresses()
diff --git a/src/net/ip.go b/src/net/ip.go
index cc004d6072..a25729cfc9 100644
--- a/src/net/ip.go
+++ b/src/net/ip.go
@@ -653,7 +653,7 @@ func ParseIP(s string) IP {
 // RFC 4632 and RFC 4291.
 //
 // It returns the IP address and the network implied by the IP
-// and mask.  For example, ParseCIDR("192.168.100.1/16") returns
+// and mask. For example, ParseCIDR("192.168.100.1/16") returns
 // the IP address 192.168.100.1 and the network 192.168.0.0/16.
 func ParseCIDR(s string) (IP, *IPNet, error) {
 	i := byteIndex(s, '/')
diff --git a/src/net/iprawsock_plan9.go b/src/net/iprawsock_plan9.go
index e872eafe6b..6fb3893529 100644
--- a/src/net/iprawsock_plan9.go
+++ b/src/net/iprawsock_plan9.go
@@ -32,7 +32,7 @@ func (c *IPConn) ReadFrom(b []byte) (int, Addr, error) {
 }
 
 // ReadMsgIP reads a packet from c, copying the payload into b and the
-// associated out-of-band data into oob.  It returns the number of
+// associated out-of-band data into oob. It returns the number of
 // bytes copied into b, the number of bytes copied into oob, the flags
 // that were set on the packet and the source address of the packet.
 func (c *IPConn) ReadMsgIP(b, oob []byte) (n, oobn, flags int, addr *IPAddr, err error) {
@@ -44,7 +44,7 @@ func (c *IPConn) ReadMsgIP(b, oob []byte) (n, oobn, flags int, addr *IPAddr, err
 //
 // WriteToIP can be made to time out and return an error with
 // Timeout() == true after a fixed time limit; see SetDeadline and
-// SetWriteDeadline.  On packet-oriented connections, write timeouts
+// SetWriteDeadline. On packet-oriented connections, write timeouts
 // are rare.
 func (c *IPConn) WriteToIP(b []byte, addr *IPAddr) (int, error) {
 	return 0, &OpError{Op: "write", Net: c.fd.dir, Source: c.fd.laddr, Addr: addr.opAddr(), Err: syscall.EPLAN9}
@@ -56,7 +56,7 @@ func (c *IPConn) WriteTo(b []byte, addr Addr) (int, error) {
 }
 
 // WriteMsgIP writes a packet to addr via c, copying the payload from
-// b and the associated out-of-band data from oob.  It returns the
+// b and the associated out-of-band data from oob. It returns the
 // number of payload and out-of-band bytes written.
 func (c *IPConn) WriteMsgIP(b, oob []byte, addr *IPAddr) (n, oobn int, err error) {
 	return 0, 0, &OpError{Op: "write", Net: c.fd.dir, Source: c.fd.laddr, Addr: addr.opAddr(), Err: syscall.EPLAN9}
@@ -74,7 +74,7 @@ func dialIP(netProto string, laddr, raddr *IPAddr, deadline time.Time) (*IPConn,
 }
 
 // ListenIP listens for incoming IP packets addressed to the local
-// address laddr.  The returned connection's ReadFrom and WriteTo
+// address laddr. The returned connection's ReadFrom and WriteTo
 // methods can be used to receive and send IP packets with per-packet
 // addressing.
 func ListenIP(netProto string, laddr *IPAddr) (*IPConn, error) {
diff --git a/src/net/iprawsock_posix.go b/src/net/iprawsock_posix.go
index 449660db4e..7364bfe455 100644
--- a/src/net/iprawsock_posix.go
+++ b/src/net/iprawsock_posix.go
@@ -114,7 +114,7 @@ func (c *IPConn) ReadFrom(b []byte) (int, Addr, error) {
 }
 
 // ReadMsgIP reads a packet from c, copying the payload into b and the
-// associated out-of-band data into oob.  It returns the number of
+// associated out-of-band data into oob. It returns the number of
 // bytes copied into b, the number of bytes copied into oob, the flags
 // that were set on the packet and the source address of the packet.
 func (c *IPConn) ReadMsgIP(b, oob []byte) (n, oobn, flags int, addr *IPAddr, err error) {
@@ -140,7 +140,7 @@ func (c *IPConn) ReadMsgIP(b, oob []byte) (n, oobn, flags int, addr *IPAddr, err
 //
 // WriteToIP can be made to time out and return an error with
 // Timeout() == true after a fixed time limit; see SetDeadline and
-// SetWriteDeadline.  On packet-oriented connections, write timeouts
+// SetWriteDeadline. On packet-oriented connections, write timeouts
 // are rare.
 func (c *IPConn) WriteToIP(b []byte, addr *IPAddr) (int, error) {
 	if !c.ok() {
@@ -176,7 +176,7 @@ func (c *IPConn) WriteTo(b []byte, addr Addr) (int, error) {
 }
 
 // WriteMsgIP writes a packet to addr via c, copying the payload from
-// b and the associated out-of-band data from oob.  It returns the
+// b and the associated out-of-band data from oob. It returns the
 // number of payload and out-of-band bytes written.
 func (c *IPConn) WriteMsgIP(b, oob []byte, addr *IPAddr) (n, oobn int, err error) {
 	if !c.ok() {
@@ -228,7 +228,7 @@ func dialIP(netProto string, laddr, raddr *IPAddr, deadline time.Time) (*IPConn,
 }
 
 // ListenIP listens for incoming IP packets addressed to the local
-// address laddr.  The returned connection's ReadFrom and WriteTo
+// address laddr. The returned connection's ReadFrom and WriteTo
 // methods can be used to receive and send IP packets with per-packet
 // addressing.
 func ListenIP(netProto string, laddr *IPAddr) (*IPConn, error) {
diff --git a/src/net/ipsock.go b/src/net/ipsock.go
index cfa9e88464..d6a6785e06 100644
--- a/src/net/ipsock.go
+++ b/src/net/ipsock.go
@@ -22,7 +22,7 @@ var (
 
 	// supportsIPv4map reports whether the platform supports
 	// mapping an IPv4 address inside an IPv6 address at transport
-	// layer protocols.  See RFC 4291, RFC 4038 and RFC 3493.
+	// layer protocols. See RFC 4291, RFC 4038 and RFC 3493.
 	supportsIPv4map bool
 )
 
@@ -106,7 +106,7 @@ func ipv6only(addr IPAddr) bool {
 
 // SplitHostPort splits a network address of the form "host:port",
 // "[host]:port" or "[ipv6-host%zone]:port" into host or
-// ipv6-host%zone and port.  A literal address or host name for IPv6
+// ipv6-host%zone and port. A literal address or host name for IPv6
 // must be enclosed in square brackets, as in "[::1]:80",
 // "[ipv6-host]:http" or "[ipv6-host%zone]:80".
 func SplitHostPort(hostport string) (host, port string, err error) {
diff --git a/src/net/ipsock_plan9.go b/src/net/ipsock_plan9.go
index 4812146c5c..53a122ac8c 100644
--- a/src/net/ipsock_plan9.go
+++ b/src/net/ipsock_plan9.go
@@ -39,8 +39,8 @@ func probeIPv4Stack() bool {
 	return probe(netdir+"/iproute", "4i")
 }
 
-// probeIPv6Stack returns two boolean values.  If the first boolean
-// value is true, kernel supports basic IPv6 functionality.  If the
+// probeIPv6Stack returns two boolean values. If the first boolean
+// value is true, kernel supports basic IPv6 functionality. If the
 // second boolean value is true, kernel supports IPv6 IPv4-mapping.
 func probeIPv6Stack() (supportsIPv6, supportsIPv4map bool) {
 	// Plan 9 uses IPv6 natively, see ip(3).
diff --git a/src/net/ipsock_posix.go b/src/net/ipsock_posix.go
index 331985f33f..a42ca9c3e8 100644
--- a/src/net/ipsock_posix.go
+++ b/src/net/ipsock_posix.go
@@ -35,15 +35,15 @@ func probeIPv4Stack() bool {
 // Should we try to use the IPv4 socket interface if we're
 // only dealing with IPv4 sockets?  As long as the host system
 // understands IPv6, it's okay to pass IPv4 addresses to the IPv6
-// interface.  That simplifies our code and is most general.
+// interface. That simplifies our code and is most general.
 // Unfortunately, we need to run on kernels built without IPv6
-// support too.  So probe the kernel to figure it out.
+// support too. So probe the kernel to figure it out.
 //
 // probeIPv6Stack probes both basic IPv6 capability and IPv6 IPv4-
 // mapping capability which is controlled by IPV6_V6ONLY socket
 // option and/or kernel state "net.inet6.ip6.v6only".
-// It returns two boolean values.  If the first boolean value is
-// true, kernel supports basic IPv6 functionality.  If the second
+// It returns two boolean values. If the first boolean value is
+// true, kernel supports basic IPv6 functionality. If the second
 // boolean value is true, kernel supports IPv6 IPv4-mapping.
 func probeIPv6Stack() (supportsIPv6, supportsIPv4map bool) {
 	var probes = []struct {
@@ -93,8 +93,8 @@ func probeIPv6Stack() (supportsIPv6, supportsIPv4map bool) {
 }
 
 // favoriteAddrFamily returns the appropriate address family to
-// the given net, laddr, raddr and mode.  At first it figures
-// address family out from the net.  If mode indicates "listen"
+// the given net, laddr, raddr and mode. At first it figures
+// address family out from the net. If mode indicates "listen"
 // and laddr is a wildcard, it assumes that the user wants to
 // make a passive connection with a wildcard address family, both
 // AF_INET and AF_INET6, and a wildcard address like following:
@@ -182,7 +182,7 @@ func ipToSockaddr(family int, ip IP, port int, zone string) (syscall.Sockaddr, e
 		}
 		// IPv4 callers use 0.0.0.0 to mean "announce on any available address".
 		// In IPv6 mode, Linux treats that as meaning "announce on 0.0.0.0",
-		// which it refuses to do.  Rewrite to the IPv6 unspecified address.
+		// which it refuses to do. Rewrite to the IPv6 unspecified address.
 		if ip.Equal(IPv4zero) {
 			ip = IPv6zero
 		}
diff --git a/src/net/lookup.go b/src/net/lookup.go
index 0770b6e31d..ab6886ddff 100644
--- a/src/net/lookup.go
+++ b/src/net/lookup.go
@@ -92,7 +92,7 @@ func lookupIPDeadline(host string, deadline time.Time) (addrs []IPAddr, err erro
 	}
 
 	// We could push the deadline down into the name resolution
-	// functions.  However, the most commonly used implementation
+	// functions. However, the most commonly used implementation
 	// calls getaddrinfo, which has no timeout.
 
 	timeout := deadline.Sub(time.Now())
@@ -108,10 +108,10 @@ func lookupIPDeadline(host string, deadline time.Time) (addrs []IPAddr, err erro
 
 	select {
 	case <-t.C:
-		// The DNS lookup timed out for some reason.  Force
+		// The DNS lookup timed out for some reason. Force
 		// future requests to start the DNS lookup again
 		// rather than waiting for the current lookup to
-		// complete.  See issue 8602.
+		// complete. See issue 8602.
 		lookupGroup.Forget(host)
 
 		return nil, errTimeout
@@ -150,12 +150,12 @@ func LookupCNAME(name string) (cname string, err error) {
 }
 
 // LookupSRV tries to resolve an SRV query of the given service,
-// protocol, and domain name.  The proto is "tcp" or "udp".
+// protocol, and domain name. The proto is "tcp" or "udp".
 // The returned records are sorted by priority and randomized
 // by weight within a priority.
 //
 // LookupSRV constructs the DNS name to look up following RFC 2782.
-// That is, it looks up _service._proto.name.  To accommodate services
+// That is, it looks up _service._proto.name. To accommodate services
 // publishing SRV records under non-standard names, if both service
 // and proto are empty strings, LookupSRV looks up name directly.
 func LookupSRV(service, proto, name string) (cname string, addrs []*SRV, err error) {
diff --git a/src/net/net.go b/src/net/net.go
index d9d23fae8f..2ff1a34981 100644
--- a/src/net/net.go
+++ b/src/net/net.go
@@ -297,7 +297,7 @@ func (c *conn) File() (f *os.File, err error) {
 // Multiple goroutines may invoke methods on a PacketConn simultaneously.
 type PacketConn interface {
 	// ReadFrom reads a packet from the connection,
-	// copying the payload into b.  It returns the number of
+	// copying the payload into b. It returns the number of
 	// bytes copied into b and the return address that
 	// was on the packet.
 	// ReadFrom can be made to time out and return
diff --git a/src/net/rpc/client.go b/src/net/rpc/client.go
index d0c4a69214..862fb1ae0c 100644
--- a/src/net/rpc/client.go
+++ b/src/net/rpc/client.go
@@ -55,7 +55,7 @@ type Client struct {
 // reading of RPC responses for the client side of an RPC session.
 // The client calls WriteRequest to write a request to the connection
 // and calls ReadResponseHeader and ReadResponseBody in pairs
-// to read responses.  The client calls Close when finished with the
+// to read responses. The client calls Close when finished with the
 // connection. ReadResponseBody may be called with a nil
 // argument to force the body of the response to be read and then
 // discarded.
@@ -173,7 +173,7 @@ func (call *Call) done() {
 	case call.Done <- call:
 		// ok
 	default:
-		// We don't want to block here.  It is the caller's responsibility to make
+		// We don't want to block here. It is the caller's responsibility to make
 		// sure the channel has enough buffer space. See comment in Go().
 		if debugLog {
 			log.Println("rpc: discarding Call reply due to insufficient Done chan capacity")
@@ -285,9 +285,9 @@ func (client *Client) Close() error {
 	return client.codec.Close()
 }
 
-// Go invokes the function asynchronously.  It returns the Call structure representing
-// the invocation.  The done channel will signal when the call is complete by returning
-// the same Call object.  If done is nil, Go will allocate a new channel.
+// Go invokes the function asynchronously. It returns the Call structure representing
+// the invocation. The done channel will signal when the call is complete by returning
+// the same Call object. If done is nil, Go will allocate a new channel.
 // If non-nil, done must be buffered or Go will deliberately crash.
 func (client *Client) Go(serviceMethod string, args interface{}, reply interface{}, done chan *Call) *Call {
 	call := new(Call)
@@ -299,7 +299,7 @@ func (client *Client) Go(serviceMethod string, args interface{}, reply interface
 	} else {
 		// If caller passes done != nil, it must arrange that
 		// done has enough buffer for the number of simultaneous
-		// RPCs that will be using that channel.  If the channel
+		// RPCs that will be using that channel. If the channel
 		// is totally unbuffered, it's best not to run at all.
 		if cap(done) == 0 {
 			log.Panic("rpc: done channel is unbuffered")
diff --git a/src/net/rpc/jsonrpc/server.go b/src/net/rpc/jsonrpc/server.go
index 820b4ab9f5..40e4e6f2aa 100644
--- a/src/net/rpc/jsonrpc/server.go
+++ b/src/net/rpc/jsonrpc/server.go
@@ -110,7 +110,7 @@ func (c *serverCodec) WriteResponse(r *rpc.Response, x interface{}) error {
 	c.mutex.Unlock()
 
 	if b == nil {
-		// Invalid request so no id.  Use JSON null.
+		// Invalid request so no id. Use JSON null.
 		b = &null
 	}
 	resp := serverResponse{Id: b}
diff --git a/src/net/rpc/server.go b/src/net/rpc/server.go
index c4d4479958..cff32413a3 100644
--- a/src/net/rpc/server.go
+++ b/src/net/rpc/server.go
@@ -143,8 +143,8 @@ const (
 	DefaultDebugPath = "/debug/rpc"
 )
 
-// Precompute the reflect type for error.  Can't use error directly
-// because Typeof takes an empty interface value.  This is annoying.
+// Precompute the reflect type for error. Can't use error directly
+// because Typeof takes an empty interface value. This is annoying.
 var typeOfError = reflect.TypeOf((*error)(nil)).Elem()
 
 type methodType struct {
@@ -162,7 +162,7 @@ type service struct {
 	method map[string]*methodType // registered methods
 }
 
-// Request is a header written before every RPC call.  It is used internally
+// Request is a header written before every RPC call. It is used internally
 // but documented here as an aid to debugging, such as when analyzing
 // network traffic.
 type Request struct {
@@ -171,7 +171,7 @@ type Request struct {
 	next          *Request // for free list in Server
 }
 
-// Response is a header written before every RPC return.  It is used internally
+// Response is a header written before every RPC return. It is used internally
 // but documented here as an aid to debugging, such as when analyzing
 // network traffic.
 type Response struct {
@@ -442,7 +442,7 @@ func (c *gobServerCodec) Close() error {
 // ServeConn blocks, serving the connection until the client hangs up.
 // The caller typically invokes ServeConn in a go statement.
 // ServeConn uses the gob wire format (see package gob) on the
-// connection.  To use an alternate codec, use ServeCodec.
+// connection. To use an alternate codec, use ServeCodec.
 func (server *Server) ServeConn(conn io.ReadWriteCloser) {
 	buf := bufio.NewWriter(conn)
 	srv := &gobServerCodec{
@@ -583,7 +583,7 @@ func (server *Server) readRequestHeader(codec ServerCodec) (service *service, mt
 		return
 	}
 
-	// We read the header successfully.  If we see an error now,
+	// We read the header successfully. If we see an error now,
 	// we can still recover and move on to the next request.
 	keepReading = true
 
@@ -638,7 +638,7 @@ func RegisterName(name string, rcvr interface{}) error {
 // RPC responses for the server side of an RPC session.
 // The server calls ReadRequestHeader and ReadRequestBody in pairs
 // to read requests from the connection, and it calls WriteResponse to
-// write a response back.  The server calls Close when finished with the
+// write a response back. The server calls Close when finished with the
 // connection. ReadRequestBody may be called with a nil
 // argument to force the body of the request to be read and discarded.
 type ServerCodec interface {
@@ -654,7 +654,7 @@ type ServerCodec interface {
 // ServeConn blocks, serving the connection until the client hangs up.
 // The caller typically invokes ServeConn in a go statement.
 // ServeConn uses the gob wire format (see package gob) on the
-// connection.  To use an alternate codec, use ServeCodec.
+// connection. To use an alternate codec, use ServeCodec.
 func ServeConn(conn io.ReadWriteCloser) {
 	DefaultServer.ServeConn(conn)
 }
diff --git a/src/net/smtp/smtp.go b/src/net/smtp/smtp.go
index 0988350322..b4e4867a9e 100644
--- a/src/net/smtp/smtp.go
+++ b/src/net/smtp/smtp.go
@@ -83,8 +83,8 @@ func (c *Client) hello() error {
 
 // Hello sends a HELO or EHLO to the server as the given host name.
 // Calling this method is only necessary if the client needs control
-// over the host name used.  The client will introduce itself as "localhost"
-// automatically otherwise.  If Hello is called, it must be called before
+// over the host name used. The client will introduce itself as "localhost"
+// automatically otherwise. If Hello is called, it must be called before
 // any of the other methods.
 func (c *Client) Hello(localName string) error {
 	if c.didHello {
@@ -265,7 +265,7 @@ func (d *dataCloser) Close() error {
 
 // Data issues a DATA command to the server and returns a writer that
 // can be used to write the mail headers and body. The caller should
-// close the writer before calling any more methods on c.  A call to
+// close the writer before calling any more methods on c. A call to
 // Data must be preceded by one or more calls to Rcpt.
 func (c *Client) Data() (io.WriteCloser, error) {
 	_, _, err := c.cmd(354, "DATA")
@@ -287,7 +287,7 @@ var testHookStartTLS func(*tls.Config) // nil, except for tests
 //
 // The msg parameter should be an RFC 822-style email with headers
 // first, a blank line, and then the message body. The lines of msg
-// should be CRLF terminated.  The msg headers should usually include
+// should be CRLF terminated. The msg headers should usually include
 // fields such as "From", "To", "Subject", and "Cc".  Sending "Bcc"
 // messages is accomplished by including an email address in the to
 // parameter but not including it in the msg headers.
diff --git a/src/net/sockopt_bsd.go b/src/net/sockopt_bsd.go
index 2eae146ae2..567e4e1b7c 100644
--- a/src/net/sockopt_bsd.go
+++ b/src/net/sockopt_bsd.go
@@ -27,7 +27,7 @@ func setDefaultSockopts(s, family, sotype int, ipv6only bool) error {
 	}
 	if supportsIPv4map && family == syscall.AF_INET6 && sotype != syscall.SOCK_RAW {
 		// Allow both IP versions even if the OS default
-		// is otherwise.  Note that some operating systems
+		// is otherwise. Note that some operating systems
 		// never admit this option.
 		syscall.SetsockoptInt(s, syscall.IPPROTO_IPV6, syscall.IPV6_V6ONLY, boolint(ipv6only))
 	}
diff --git a/src/net/sockopt_linux.go b/src/net/sockopt_linux.go
index 147c263bcf..0f70b12407 100644
--- a/src/net/sockopt_linux.go
+++ b/src/net/sockopt_linux.go
@@ -12,7 +12,7 @@ import (
 func setDefaultSockopts(s, family, sotype int, ipv6only bool) error {
 	if family == syscall.AF_INET6 && sotype != syscall.SOCK_RAW {
 		// Allow both IP versions even if the OS default
-		// is otherwise.  Note that some operating systems
+		// is otherwise. Note that some operating systems
 		// never admit this option.
 		syscall.SetsockoptInt(s, syscall.IPPROTO_IPV6, syscall.IPV6_V6ONLY, boolint(ipv6only))
 	}
diff --git a/src/net/sockopt_solaris.go b/src/net/sockopt_solaris.go
index 147c263bcf..0f70b12407 100644
--- a/src/net/sockopt_solaris.go
+++ b/src/net/sockopt_solaris.go
@@ -12,7 +12,7 @@ import (
 func setDefaultSockopts(s, family, sotype int, ipv6only bool) error {
 	if family == syscall.AF_INET6 && sotype != syscall.SOCK_RAW {
 		// Allow both IP versions even if the OS default
-		// is otherwise.  Note that some operating systems
+		// is otherwise. Note that some operating systems
 		// never admit this option.
 		syscall.SetsockoptInt(s, syscall.IPPROTO_IPV6, syscall.IPV6_V6ONLY, boolint(ipv6only))
 	}
diff --git a/src/net/sockopt_windows.go b/src/net/sockopt_windows.go
index ff51626ac1..8017426521 100644
--- a/src/net/sockopt_windows.go
+++ b/src/net/sockopt_windows.go
@@ -12,7 +12,7 @@ import (
 func setDefaultSockopts(s syscall.Handle, family, sotype int, ipv6only bool) error {
 	if family == syscall.AF_INET6 && sotype != syscall.SOCK_RAW {
 		// Allow both IP versions even if the OS default
-		// is otherwise.  Note that some operating systems
+		// is otherwise. Note that some operating systems
 		// never admit this option.
 		syscall.SetsockoptInt(s, syscall.IPPROTO_IPV6, syscall.IPV6_V6ONLY, boolint(ipv6only))
 	}
diff --git a/src/net/tcpsock_plan9.go b/src/net/tcpsock_plan9.go
index 0eb40699fa..c25c05150e 100644
--- a/src/net/tcpsock_plan9.go
+++ b/src/net/tcpsock_plan9.go
@@ -130,7 +130,7 @@ func dialTCP(net string, laddr, raddr *TCPAddr, deadline time.Time, cancel <-cha
 	return newTCPConn(fd), nil
 }
 
-// TCPListener is a TCP network listener.  Clients should typically
+// TCPListener is a TCP network listener. Clients should typically
 // use variables of type Listener instead of assuming TCP.
 type TCPListener struct {
 	fd *netFD
@@ -197,11 +197,11 @@ func (l *TCPListener) SetDeadline(t time.Time) error {
 }
 
 // File returns a copy of the underlying os.File, set to blocking
-// mode.  It is the caller's responsibility to close f when finished.
+// mode. It is the caller's responsibility to close f when finished.
 // Closing l does not affect f, and closing f does not affect l.
 //
 // The returned os.File's file descriptor is different from the
-// connection's.  Attempting to change properties of the original
+// connection's. Attempting to change properties of the original
 // using this duplicate may or may not have the desired effect.
 func (l *TCPListener) File() (f *os.File, err error) {
 	f, err = l.dup()
@@ -212,8 +212,8 @@ func (l *TCPListener) File() (f *os.File, err error) {
 }
 
 // ListenTCP announces on the TCP address laddr and returns a TCP
-// listener.  Net must be "tcp", "tcp4", or "tcp6".  If laddr has a
-// port of 0, ListenTCP will choose an available port.  The caller can
+// listener. Net must be "tcp", "tcp4", or "tcp6".  If laddr has a
+// port of 0, ListenTCP will choose an available port. The caller can
 // use the Addr method of TCPListener to retrieve the chosen address.
 func ListenTCP(net string, laddr *TCPAddr) (*TCPListener, error) {
 	switch net {
diff --git a/src/net/tcpsock_posix.go b/src/net/tcpsock_posix.go
index 261c0be030..ecbe00fb34 100644
--- a/src/net/tcpsock_posix.go
+++ b/src/net/tcpsock_posix.go
@@ -173,18 +173,18 @@ func dialTCP(net string, laddr, raddr *TCPAddr, deadline time.Time, cancel <-cha
 	// TCP has a rarely used mechanism called a 'simultaneous connection' in
 	// which Dial("tcp", addr1, addr2) run on the machine at addr1 can
 	// connect to a simultaneous Dial("tcp", addr2, addr1) run on the machine
-	// at addr2, without either machine executing Listen.  If laddr == nil,
+	// at addr2, without either machine executing Listen. If laddr == nil,
 	// it means we want the kernel to pick an appropriate originating local
-	// address.  Some Linux kernels cycle blindly through a fixed range of
-	// local ports, regardless of destination port.  If a kernel happens to
+	// address. Some Linux kernels cycle blindly through a fixed range of
+	// local ports, regardless of destination port. If a kernel happens to
 	// pick local port 50001 as the source for a Dial("tcp", "", "localhost:50001"),
 	// then the Dial will succeed, having simultaneously connected to itself.
 	// This can only happen when we are letting the kernel pick a port (laddr == nil)
 	// and when there is no listener for the destination address.
-	// It's hard to argue this is anything other than a kernel bug.  If we
+	// It's hard to argue this is anything other than a kernel bug. If we
 	// see this happen, rather than expose the buggy effect to users, we
-	// close the fd and try again.  If it happens twice more, we relent and
-	// use the result.  See also:
+	// close the fd and try again. If it happens twice more, we relent and
+	// use the result. See also:
 	//	https://golang.org/issue/2690
 	//	http://stackoverflow.com/questions/4949858/
 	//
@@ -239,7 +239,7 @@ func spuriousENOTAVAIL(err error) bool {
 	return err == syscall.EADDRNOTAVAIL
 }
 
-// TCPListener is a TCP network listener.  Clients should typically
+// TCPListener is a TCP network listener. Clients should typically
 // use variables of type Listener instead of assuming TCP.
 type TCPListener struct {
 	fd *netFD
@@ -299,11 +299,11 @@ func (l *TCPListener) SetDeadline(t time.Time) error {
 }
 
 // File returns a copy of the underlying os.File, set to blocking
-// mode.  It is the caller's responsibility to close f when finished.
+// mode. It is the caller's responsibility to close f when finished.
 // Closing l does not affect f, and closing f does not affect l.
 //
 // The returned os.File's file descriptor is different from the
-// connection's.  Attempting to change properties of the original
+// connection's. Attempting to change properties of the original
 // using this duplicate may or may not have the desired effect.
 func (l *TCPListener) File() (f *os.File, err error) {
 	f, err = l.fd.dup()
@@ -314,8 +314,8 @@ func (l *TCPListener) File() (f *os.File, err error) {
 }
 
 // ListenTCP announces on the TCP address laddr and returns a TCP
-// listener.  Net must be "tcp", "tcp4", or "tcp6".  If laddr has a
-// port of 0, ListenTCP will choose an available port.  The caller can
+// listener. Net must be "tcp", "tcp4", or "tcp6".  If laddr has a
+// port of 0, ListenTCP will choose an available port. The caller can
 // use the Addr method of TCPListener to retrieve the chosen address.
 func ListenTCP(net string, laddr *TCPAddr) (*TCPListener, error) {
 	switch net {
diff --git a/src/net/textproto/header.go b/src/net/textproto/header.go
index d482eea8e5..2e2752a755 100644
--- a/src/net/textproto/header.go
+++ b/src/net/textproto/header.go
@@ -16,7 +16,7 @@ func (h MIMEHeader) Add(key, value string) {
 }
 
 // Set sets the header entries associated with key to
-// the single element value.  It replaces any existing
+// the single element value. It replaces any existing
 // values associated with key.
 func (h MIMEHeader) Set(key, value string) {
 	h[CanonicalMIMEHeaderKey(key)] = []string{value}
@@ -24,7 +24,7 @@ func (h MIMEHeader) Set(key, value string) {
 
 // Get gets the first value associated with the given key.
 // If there are no values associated with the key, Get returns "".
-// Get is a convenience method.  For more complex queries,
+// Get is a convenience method. For more complex queries,
 // access the map directly.
 func (h MIMEHeader) Get(key string) string {
 	if h == nil {
diff --git a/src/net/textproto/pipeline.go b/src/net/textproto/pipeline.go
index af0e3d8369..2e283218b5 100644
--- a/src/net/textproto/pipeline.go
+++ b/src/net/textproto/pipeline.go
@@ -66,8 +66,8 @@ func (p *Pipeline) EndResponse(id uint) {
 }
 
 // A sequencer schedules a sequence of numbered events that must
-// happen in order, one after the other.  The event numbering must start
-// at 0 and increment without skipping.  The event number wraps around
+// happen in order, one after the other. The event numbering must start
+// at 0 and increment without skipping. The event number wraps around
 // safely as long as there are not 2^32 simultaneous events pending.
 type sequencer struct {
 	mu   sync.Mutex
diff --git a/src/net/textproto/reader.go b/src/net/textproto/reader.go
index 37221cf3ad..e07d1d62e0 100644
--- a/src/net/textproto/reader.go
+++ b/src/net/textproto/reader.go
@@ -71,7 +71,7 @@ func (r *Reader) readLineSlice() ([]byte, error) {
 // ReadContinuedLine reads a possibly continued line from r,
 // eliding the final trailing ASCII white space.
 // Lines after the first are considered continuations if they
-// begin with a space or tab character.  In the returned data,
+// begin with a space or tab character. In the returned data,
 // continuation lines are separated from the previous line
 // only by a single space: the newline and leading white space
 // are removed.
@@ -204,7 +204,7 @@ func parseCodeLine(line string, expectCode int) (code int, continued bool, messa
 // ReadCodeLine reads a response code line of the form
 //	code message
 // where code is a three-digit status code and the message
-// extends to the rest of the line.  An example of such a line is:
+// extends to the rest of the line. An example of such a line is:
 //	220 plan9.bell-labs.com ESMTP
 //
 // If the prefix of the status does not match the digits in expectCode,
@@ -366,7 +366,7 @@ func (d *dotReader) Read(b []byte) (n int, err error) {
 				d.state = stateBeginLine
 				break
 			}
-			// Not part of \r\n.  Emit saved \r
+			// Not part of \r\n. Emit saved \r
 			br.UnreadByte()
 			c = '\r'
 			d.state = stateData
@@ -552,9 +552,9 @@ func (r *Reader) upcomingHeaderNewlines() (n int) {
 }
 
 // CanonicalMIMEHeaderKey returns the canonical format of the
-// MIME header key s.  The canonicalization converts the first
+// MIME header key s. The canonicalization converts the first
 // letter and any letter following a hyphen to upper case;
-// the rest are converted to lowercase.  For example, the
+// the rest are converted to lowercase. For example, the
 // canonical key for "accept-encoding" is "Accept-Encoding".
 // MIME header keys are assumed to be ASCII only.
 // If s contains a space or invalid header field bytes, it is
diff --git a/src/net/textproto/textproto.go b/src/net/textproto/textproto.go
index ed8a955375..8fd781e777 100644
--- a/src/net/textproto/textproto.go
+++ b/src/net/textproto/textproto.go
@@ -87,7 +87,7 @@ func Dial(network, addr string) (*Conn, error) {
 }
 
 // Cmd is a convenience method that sends a command after
-// waiting its turn in the pipeline.  The command text is the
+// waiting its turn in the pipeline. The command text is the
 // result of formatting format with args and appending \r\n.
 // Cmd returns the id of the command, for use with StartResponse and EndResponse.
 //
diff --git a/src/net/textproto/writer.go b/src/net/textproto/writer.go
index 56c490c283..1bc5974c6c 100644
--- a/src/net/textproto/writer.go
+++ b/src/net/textproto/writer.go
@@ -36,7 +36,7 @@ func (w *Writer) PrintfLine(format string, args ...interface{}) error {
 // DotWriter returns a writer that can be used to write a dot-encoding to w.
 // It takes care of inserting leading dots when necessary,
 // translating line-ending \n into \r\n, and adding the final .\r\n line
-// when the DotWriter is closed.  The caller should close the
+// when the DotWriter is closed. The caller should close the
 // DotWriter before the next call to a method on w.
 //
 // See the documentation for Reader's DotReader method for details about dot-encoding.
diff --git a/src/net/udpsock_plan9.go b/src/net/udpsock_plan9.go
index 88a80ad148..4bc3be7656 100644
--- a/src/net/udpsock_plan9.go
+++ b/src/net/udpsock_plan9.go
@@ -54,7 +54,7 @@ func (c *UDPConn) ReadFrom(b []byte) (int, Addr, error) {
 }
 
 // ReadMsgUDP reads a packet from c, copying the payload into b and
-// the associated out-of-band data into oob.  It returns the number
+// the associated out-of-band data into oob. It returns the number
 // of bytes copied into b, the number of bytes copied into oob, the
 // flags that were set on the packet and the source address of the
 // packet.
@@ -67,7 +67,7 @@ func (c *UDPConn) ReadMsgUDP(b, oob []byte) (n, oobn, flags int, addr *UDPAddr,
 //
 // WriteToUDP can be made to time out and return an error with
 // Timeout() == true after a fixed time limit; see SetDeadline and
-// SetWriteDeadline.  On packet-oriented connections, write timeouts
+// SetWriteDeadline. On packet-oriented connections, write timeouts
 // are rare.
 func (c *UDPConn) WriteToUDP(b []byte, addr *UDPAddr) (int, error) {
 	if !c.ok() || c.fd.data == nil {
@@ -107,7 +107,7 @@ func (c *UDPConn) WriteTo(b []byte, addr Addr) (int, error) {
 // WriteMsgUDP writes a packet to addr via c if c isn't connected, or
 // to c's remote destination address if c is connected (in which case
 // addr must be nil).  The payload is copied from b and the associated
-// out-of-band data is copied from oob.  It returns the number of
+// out-of-band data is copied from oob. It returns the number of
 // payload and out-of-band bytes written.
 func (c *UDPConn) WriteMsgUDP(b, oob []byte, addr *UDPAddr) (n, oobn int, err error) {
 	return 0, 0, &OpError{Op: "write", Net: c.fd.dir, Source: c.fd.laddr, Addr: addr.opAddr(), Err: syscall.EPLAN9}
@@ -168,10 +168,10 @@ func unmarshalUDPHeader(b []byte) (*udpHeader, []byte) {
 }
 
 // ListenUDP listens for incoming UDP packets addressed to the local
-// address laddr.  Net must be "udp", "udp4", or "udp6".  If laddr has
+// address laddr. Net must be "udp", "udp4", or "udp6".  If laddr has
 // a port of 0, ListenUDP will choose an available port.
 // The LocalAddr method of the returned UDPConn can be used to
-// discover the port.  The returned connection's ReadFrom and WriteTo
+// discover the port. The returned connection's ReadFrom and WriteTo
 // methods can be used to receive and send UDP packets with per-packet
 // addressing.
 func ListenUDP(net string, laddr *UDPAddr) (*UDPConn, error) {
diff --git a/src/net/udpsock_posix.go b/src/net/udpsock_posix.go
index 028151f9ed..3b9b129890 100644
--- a/src/net/udpsock_posix.go
+++ b/src/net/udpsock_posix.go
@@ -84,7 +84,7 @@ func (c *UDPConn) ReadFrom(b []byte) (int, Addr, error) {
 }
 
 // ReadMsgUDP reads a packet from c, copying the payload into b and
-// the associated out-of-band data into oob.  It returns the number
+// the associated out-of-band data into oob. It returns the number
 // of bytes copied into b, the number of bytes copied into oob, the
 // flags that were set on the packet and the source address of the
 // packet.
@@ -111,7 +111,7 @@ func (c *UDPConn) ReadMsgUDP(b, oob []byte) (n, oobn, flags int, addr *UDPAddr,
 //
 // WriteToUDP can be made to time out and return an error with
 // Timeout() == true after a fixed time limit; see SetDeadline and
-// SetWriteDeadline.  On packet-oriented connections, write timeouts
+// SetWriteDeadline. On packet-oriented connections, write timeouts
 // are rare.
 func (c *UDPConn) WriteToUDP(b []byte, addr *UDPAddr) (int, error) {
 	if !c.ok() {
@@ -149,7 +149,7 @@ func (c *UDPConn) WriteTo(b []byte, addr Addr) (int, error) {
 // WriteMsgUDP writes a packet to addr via c if c isn't connected, or
 // to c's remote destination address if c is connected (in which case
 // addr must be nil).  The payload is copied from b and the associated
-// out-of-band data is copied from oob.  It returns the number of
+// out-of-band data is copied from oob. It returns the number of
 // payload and out-of-band bytes written.
 func (c *UDPConn) WriteMsgUDP(b, oob []byte, addr *UDPAddr) (n, oobn int, err error) {
 	if !c.ok() {
@@ -197,10 +197,10 @@ func dialUDP(net string, laddr, raddr *UDPAddr, deadline time.Time) (*UDPConn, e
 }
 
 // ListenUDP listens for incoming UDP packets addressed to the local
-// address laddr.  Net must be "udp", "udp4", or "udp6".  If laddr has
+// address laddr. Net must be "udp", "udp4", or "udp6".  If laddr has
 // a port of 0, ListenUDP will choose an available port.
 // The LocalAddr method of the returned UDPConn can be used to
-// discover the port.  The returned connection's ReadFrom and WriteTo
+// discover the port. The returned connection's ReadFrom and WriteTo
 // methods can be used to receive and send UDP packets with per-packet
 // addressing.
 func ListenUDP(net string, laddr *UDPAddr) (*UDPConn, error) {
diff --git a/src/net/unixsock_plan9.go b/src/net/unixsock_plan9.go
index 4bd3962ccb..d0e3ca72e8 100644
--- a/src/net/unixsock_plan9.go
+++ b/src/net/unixsock_plan9.go
@@ -16,7 +16,7 @@ type UnixConn struct {
 	conn
 }
 
-// ReadFromUnix reads a packet from c, copying the payload into b.  It
+// ReadFromUnix reads a packet from c, copying the payload into b. It
 // returns the number of bytes copied into b and the source address of
 // the packet.
 //
@@ -33,7 +33,7 @@ func (c *UnixConn) ReadFrom(b []byte) (int, Addr, error) {
 }
 
 // ReadMsgUnix reads a packet from c, copying the payload into b and
-// the associated out-of-band data into oob.  It returns the number of
+// the associated out-of-band data into oob. It returns the number of
 // bytes copied into b, the number of bytes copied into oob, the flags
 // that were set on the packet, and the source address of the packet.
 func (c *UnixConn) ReadMsgUnix(b, oob []byte) (n, oobn, flags int, addr *UnixAddr, err error) {
@@ -44,7 +44,7 @@ func (c *UnixConn) ReadMsgUnix(b, oob []byte) (n, oobn, flags int, addr *UnixAdd
 //
 // WriteToUnix can be made to time out and return an error with
 // Timeout() == true after a fixed time limit; see SetDeadline and
-// SetWriteDeadline.  On packet-oriented connections, write timeouts
+// SetWriteDeadline. On packet-oriented connections, write timeouts
 // are rare.
 func (c *UnixConn) WriteToUnix(b []byte, addr *UnixAddr) (int, error) {
 	return 0, &OpError{Op: "write", Net: c.fd.dir, Source: c.fd.laddr, Addr: addr.opAddr(), Err: syscall.EPLAN9}
@@ -56,7 +56,7 @@ func (c *UnixConn) WriteTo(b []byte, addr Addr) (int, error) {
 }
 
 // WriteMsgUnix writes a packet to addr via c, copying the payload
-// from b and the associated out-of-band data from oob.  It returns
+// from b and the associated out-of-band data from oob. It returns
 // the number of payload and out-of-band bytes written.
 func (c *UnixConn) WriteMsgUnix(b, oob []byte, addr *UnixAddr) (n, oobn int, err error) {
 	return 0, 0, &OpError{Op: "write", Net: c.fd.dir, Source: c.fd.laddr, Addr: addr.opAddr(), Err: syscall.EPLAN9}
@@ -85,7 +85,7 @@ func dialUnix(net string, laddr, raddr *UnixAddr, deadline time.Time) (*UnixConn
 	return nil, &OpError{Op: "dial", Net: net, Source: laddr.opAddr(), Addr: raddr.opAddr(), Err: syscall.EPLAN9}
 }
 
-// UnixListener is a Unix domain socket listener.  Clients should
+// UnixListener is a Unix domain socket listener. Clients should
 // typically use variables of type Listener instead of assuming Unix
 // domain sockets.
 type UnixListener struct {
@@ -93,7 +93,7 @@ type UnixListener struct {
 }
 
 // ListenUnix announces on the Unix domain socket laddr and returns a
-// Unix listener.  The network net must be "unix" or "unixpacket".
+// Unix listener. The network net must be "unix" or "unixpacket".
 func ListenUnix(net string, laddr *UnixAddr) (*UnixListener, error) {
 	return nil, &OpError{Op: "listen", Net: net, Source: nil, Addr: laddr.opAddr(), Err: syscall.EPLAN9}
 }
@@ -110,7 +110,7 @@ func (l *UnixListener) Accept() (Conn, error) {
 	return nil, &OpError{Op: "accept", Net: l.fd.dir, Source: nil, Addr: l.fd.laddr, Err: syscall.EPLAN9}
 }
 
-// Close stops listening on the Unix address.  Already accepted
+// Close stops listening on the Unix address. Already accepted
 // connections are not closed.
 func (l *UnixListener) Close() error {
 	return &OpError{Op: "close", Net: l.fd.dir, Source: nil, Addr: l.fd.laddr, Err: syscall.EPLAN9}
@@ -128,18 +128,18 @@ func (l *UnixListener) SetDeadline(t time.Time) error {
 }
 
 // File returns a copy of the underlying os.File, set to blocking
-// mode.  It is the caller's responsibility to close f when finished.
+// mode. It is the caller's responsibility to close f when finished.
 // Closing l does not affect f, and closing f does not affect l.
 //
 // The returned os.File's file descriptor is different from the
-// connection's.  Attempting to change properties of the original
+// connection's. Attempting to change properties of the original
 // using this duplicate may or may not have the desired effect.
 func (l *UnixListener) File() (*os.File, error) {
 	return nil, &OpError{Op: "file", Net: l.fd.dir, Source: nil, Addr: l.fd.laddr, Err: syscall.EPLAN9}
 }
 
 // ListenUnixgram listens for incoming Unix datagram packets addressed
-// to the local address laddr.  The network net must be "unixgram".
+// to the local address laddr. The network net must be "unixgram".
 // The returned connection's ReadFrom and WriteTo methods can be used
 // to receive and send packets with per-packet addressing.
 func ListenUnixgram(net string, laddr *UnixAddr) (*UnixConn, error) {
diff --git a/src/net/unixsock_posix.go b/src/net/unixsock_posix.go
index 0e72e90344..83d3e8cb01 100644
--- a/src/net/unixsock_posix.go
+++ b/src/net/unixsock_posix.go
@@ -102,7 +102,7 @@ type UnixConn struct {
 
 func newUnixConn(fd *netFD) *UnixConn { return &UnixConn{conn{fd}} }
 
-// ReadFromUnix reads a packet from c, copying the payload into b.  It
+// ReadFromUnix reads a packet from c, copying the payload into b. It
 // returns the number of bytes copied into b and the source address of
 // the packet.
 //
@@ -140,7 +140,7 @@ func (c *UnixConn) ReadFrom(b []byte) (int, Addr, error) {
 }
 
 // ReadMsgUnix reads a packet from c, copying the payload into b and
-// the associated out-of-band data into oob.  It returns the number of
+// the associated out-of-band data into oob. It returns the number of
 // bytes copied into b, the number of bytes copied into oob, the flags
 // that were set on the packet, and the source address of the packet.
 func (c *UnixConn) ReadMsgUnix(b, oob []byte) (n, oobn, flags int, addr *UnixAddr, err error) {
@@ -164,7 +164,7 @@ func (c *UnixConn) ReadMsgUnix(b, oob []byte) (n, oobn, flags int, addr *UnixAdd
 //
 // WriteToUnix can be made to time out and return an error with
 // Timeout() == true after a fixed time limit; see SetDeadline and
-// SetWriteDeadline.  On packet-oriented connections, write timeouts
+// SetWriteDeadline. On packet-oriented connections, write timeouts
 // are rare.
 func (c *UnixConn) WriteToUnix(b []byte, addr *UnixAddr) (int, error) {
 	if !c.ok() {
@@ -200,7 +200,7 @@ func (c *UnixConn) WriteTo(b []byte, addr Addr) (n int, err error) {
 }
 
 // WriteMsgUnix writes a packet to addr via c, copying the payload
-// from b and the associated out-of-band data from oob.  It returns
+// from b and the associated out-of-band data from oob. It returns
 // the number of payload and out-of-band bytes written.
 func (c *UnixConn) WriteMsgUnix(b, oob []byte, addr *UnixAddr) (n, oobn int, err error) {
 	if !c.ok() {
@@ -269,7 +269,7 @@ func dialUnix(net string, laddr, raddr *UnixAddr, deadline time.Time) (*UnixConn
 	return newUnixConn(fd), nil
 }
 
-// UnixListener is a Unix domain socket listener.  Clients should
+// UnixListener is a Unix domain socket listener. Clients should
 // typically use variables of type Listener instead of assuming Unix
 // domain sockets.
 type UnixListener struct {
@@ -279,7 +279,7 @@ type UnixListener struct {
 }
 
 // ListenUnix announces on the Unix domain socket laddr and returns a
-// Unix listener.  The network net must be "unix" or "unixpacket".
+// Unix listener. The network net must be "unix" or "unixpacket".
 func ListenUnix(net string, laddr *UnixAddr) (*UnixListener, error) {
 	switch net {
 	case "unix", "unixpacket":
@@ -319,7 +319,7 @@ func (l *UnixListener) Accept() (Conn, error) {
 	return c, nil
 }
 
-// Close stops listening on the Unix address.  Already accepted
+// Close stops listening on the Unix address. Already accepted
 // connections are not closed.
 func (l *UnixListener) Close() error {
 	if l == nil || l.fd == nil {
@@ -334,7 +334,7 @@ func (l *UnixListener) Close() error {
 	// and replaced our socket name already--
 	// but this sequence (remove then close)
 	// is at least compatible with the auto-remove
-	// sequence in ListenUnix.  It's only non-Go
+	// sequence in ListenUnix. It's only non-Go
 	// programs that can mess us up.
 	if l.path[0] != '@' && l.unlink {
 		syscall.Unlink(l.path)
@@ -364,11 +364,11 @@ func (l *UnixListener) SetDeadline(t time.Time) error {
 }
 
 // File returns a copy of the underlying os.File, set to blocking
-// mode.  It is the caller's responsibility to close f when finished.
+// mode. It is the caller's responsibility to close f when finished.
 // Closing l does not affect f, and closing f does not affect l.
 //
 // The returned os.File's file descriptor is different from the
-// connection's.  Attempting to change properties of the original
+// connection's. Attempting to change properties of the original
 // using this duplicate may or may not have the desired effect.
 func (l *UnixListener) File() (f *os.File, err error) {
 	f, err = l.fd.dup()
@@ -379,7 +379,7 @@ func (l *UnixListener) File() (f *os.File, err error) {
 }
 
 // ListenUnixgram listens for incoming Unix datagram packets addressed
-// to the local address laddr.  The network net must be "unixgram".
+// to the local address laddr. The network net must be "unixgram".
 // The returned connection's ReadFrom and WriteTo methods can be used
 // to receive and send packets with per-packet addressing.
 func ListenUnixgram(net string, laddr *UnixAddr) (*UnixConn, error) {
diff --git a/src/net/url/url.go b/src/net/url/url.go
index 86ed887931..d2ec333310 100644
--- a/src/net/url/url.go
+++ b/src/net/url/url.go
@@ -427,7 +427,7 @@ func Parse(rawurl string) (*URL, error) {
 	return url, nil
 }
 
-// ParseRequestURI parses rawurl into a URL structure.  It assumes that
+// ParseRequestURI parses rawurl into a URL structure. It assumes that
 // rawurl was received in an HTTP request, so the rawurl is interpreted
 // only as an absolute URI or an absolute path.
 // The string rawurl is assumed not to have a #fragment suffix.
@@ -436,7 +436,7 @@ func ParseRequestURI(rawurl string) (*URL, error) {
 	return parse(rawurl, true)
 }
 
-// parse parses a URL from a string in one of two contexts.  If
+// parse parses a URL from a string in one of two contexts. If
 // viaRequest is true, the URL is assumed to have arrived via an HTTP request,
 // in which case only absolute URLs or path-absolute relative URLs are allowed.
 // If viaRequest is false, all forms of relative URLs are allowed.
@@ -852,8 +852,8 @@ func (u *URL) IsAbs() bool {
 	return u.Scheme != ""
 }
 
-// Parse parses a URL in the context of the receiver.  The provided URL
-// may be relative or absolute.  Parse returns nil, err on parse
+// Parse parses a URL in the context of the receiver. The provided URL
+// may be relative or absolute. Parse returns nil, err on parse
 // failure, otherwise its return value is the same as ResolveReference.
 func (u *URL) Parse(ref string) (*URL, error) {
 	refurl, err := Parse(ref)
@@ -865,7 +865,7 @@ func (u *URL) Parse(ref string) (*URL, error) {
 
 // ResolveReference resolves a URI reference to an absolute URI from
 // an absolute base URI, per RFC 3986 Section 5.2.  The URI reference
-// may be relative or absolute.  ResolveReference always returns a new
+// may be relative or absolute. ResolveReference always returns a new
 // URL instance, even if the returned URL is identical to either the
 // base or reference. If ref is an absolute URL, then ResolveReference
 // ignores base and returns a copy of ref.
diff --git a/src/os/doc.go b/src/os/doc.go
index b52aba3958..0313eac234 100644
--- a/src/os/doc.go
+++ b/src/os/doc.go
@@ -77,14 +77,14 @@ func (p *ProcessState) Success() bool {
 }
 
 // Sys returns system-dependent exit information about
-// the process.  Convert it to the appropriate underlying
+// the process. Convert it to the appropriate underlying
 // type, such as syscall.WaitStatus on Unix, to access its contents.
 func (p *ProcessState) Sys() interface{} {
 	return p.sys()
 }
 
 // SysUsage returns system-dependent resource usage information about
-// the exited process.  Convert it to the appropriate underlying
+// the exited process. Convert it to the appropriate underlying
 // type, such as *syscall.Rusage on Unix, to access its contents.
 // (On Unix, *syscall.Rusage matches struct rusage as defined in the
 // getrusage(2) manual page.)
diff --git a/src/os/env.go b/src/os/env.go
index 63ad7fd399..4a147144c3 100644
--- a/src/os/env.go
+++ b/src/os/env.go
@@ -27,7 +27,7 @@ func Expand(s string, mapping func(string) string) string {
 }
 
 // ExpandEnv replaces ${var} or $var in the string according to the values
-// of the current environment variables.  References to undefined
+// of the current environment variables. References to undefined
 // variables are replaced by the empty string.
 func ExpandEnv(s string) string {
 	return Expand(s, Getenv)
@@ -49,7 +49,7 @@ func isAlphaNum(c uint8) bool {
 }
 
 // getShellName returns the name that begins the string and the number of bytes
-// consumed to extract it.  If the name is enclosed in {}, it's part of a ${}
+// consumed to extract it. If the name is enclosed in {}, it's part of a ${}
 // expansion and two more bytes are needed than the length of the name.
 func getShellName(s string) (string, int) {
 	switch {
diff --git a/src/os/exec.go b/src/os/exec.go
index 15e95b9172..239fd92888 100644
--- a/src/os/exec.go
+++ b/src/os/exec.go
@@ -41,10 +41,10 @@ type ProcAttr struct {
 	// new process in the form returned by Environ.
 	// If it is nil, the result of Environ will be used.
 	Env []string
-	// Files specifies the open files inherited by the new process.  The
+	// Files specifies the open files inherited by the new process. The
 	// first three entries correspond to standard input, standard output, and
-	// standard error.  An implementation may support additional entries,
-	// depending on the underlying operating system.  A nil entry corresponds
+	// standard error. An implementation may support additional entries,
+	// depending on the underlying operating system. A nil entry corresponds
 	// to that file being closed when the process starts.
 	Files []*File
 
diff --git a/src/os/exec/exec_test.go b/src/os/exec/exec_test.go
index a69b5176d5..1f2fd12add 100644
--- a/src/os/exec/exec_test.go
+++ b/src/os/exec/exec_test.go
@@ -697,7 +697,7 @@ func TestHelperProcess(*testing.T) {
 		}
 		// Referring to fd3 here ensures that it is not
 		// garbage collected, and therefore closed, while
-		// executing the wantfd loop above.  It doesn't matter
+		// executing the wantfd loop above. It doesn't matter
 		// what we do with fd3 as long as we refer to it;
 		// closing it is the easy choice.
 		fd3.Close()
diff --git a/src/os/exec_posix.go b/src/os/exec_posix.go
index 94dd04beb2..3cf38b68ad 100644
--- a/src/os/exec_posix.go
+++ b/src/os/exec_posix.go
@@ -21,7 +21,7 @@ var (
 func startProcess(name string, argv []string, attr *ProcAttr) (p *Process, err error) {
 	// If there is no SysProcAttr (ie. no Chroot or changed
 	// UID/GID), double-check existence of the directory we want
-	// to chdir into.  We can make the error clearer this way.
+	// to chdir into. We can make the error clearer this way.
 	if attr != nil && attr.Sys == nil && attr.Dir != "" {
 		if _, err := Stat(attr.Dir); err != nil {
 			pe := err.(*PathError)
diff --git a/src/os/file.go b/src/os/file.go
index 4f8e3f3450..6b1ecbc34e 100644
--- a/src/os/file.go
+++ b/src/os/file.go
@@ -236,7 +236,7 @@ func (f *File) Chdir() error {
 	return nil
 }
 
-// Open opens the named file for reading.  If successful, methods on
+// Open opens the named file for reading. If successful, methods on
 // the returned file can be used for reading; the associated file
 // descriptor has mode O_RDONLY.
 // If there is an error, it will be of type *PathError.
diff --git a/src/os/file_plan9.go b/src/os/file_plan9.go
index c83fa028b9..0fe1b8213d 100644
--- a/src/os/file_plan9.go
+++ b/src/os/file_plan9.go
@@ -75,8 +75,8 @@ func syscallMode(i FileMode) (o uint32) {
 }
 
 // OpenFile is the generalized open call; most users will use Open
-// or Create instead.  It opens the named file with specified flag
-// (O_RDONLY etc.) and perm, (0666 etc.) if applicable.  If successful,
+// or Create instead. It opens the named file with specified flag
+// (O_RDONLY etc.) and perm, (0666 etc.) if applicable. If successful,
 // methods on the returned File can be used for I/O.
 // If there is an error, it will be of type *PathError.
 func OpenFile(name string, flag int, perm FileMode) (*File, error) {
diff --git a/src/os/file_unix.go b/src/os/file_unix.go
index 05d94f6edb..9b64f21650 100644
--- a/src/os/file_unix.go
+++ b/src/os/file_unix.go
@@ -79,8 +79,8 @@ func epipecheck(file *File, e error) {
 const DevNull = "/dev/null"
 
 // OpenFile is the generalized open call; most users will use Open
-// or Create instead.  It opens the named file with specified flag
-// (O_RDONLY etc.) and perm, (0666 etc.) if applicable.  If successful,
+// or Create instead. It opens the named file with specified flag
+// (O_RDONLY etc.) and perm, (0666 etc.) if applicable. If successful,
 // methods on the returned File can be used for I/O.
 // If there is an error, it will be of type *PathError.
 func OpenFile(name string, flag int, perm FileMode) (*File, error) {
@@ -115,7 +115,7 @@ func OpenFile(name string, flag int, perm FileMode) (*File, error) {
 	}
 
 	// There's a race here with fork/exec, which we are
-	// content to live with.  See ../syscall/exec_unix.go.
+	// content to live with. See ../syscall/exec_unix.go.
 	if !supportsCloseOnExec {
 		syscall.CloseOnExec(r)
 	}
@@ -176,7 +176,7 @@ func Stat(name string) (FileInfo, error) {
 
 // Lstat returns a FileInfo describing the named file.
 // If the file is a symbolic link, the returned FileInfo
-// describes the symbolic link.  Lstat makes no attempt to follow the link.
+// describes the symbolic link. Lstat makes no attempt to follow the link.
 // If there is an error, it will be of type *PathError.
 func Lstat(name string) (FileInfo, error) {
 	var fs fileStat
@@ -311,7 +311,7 @@ func Remove(name string) error {
 
 	// Both failed: figure out which error to return.
 	// OS X and Linux differ on whether unlink(dir)
-	// returns EISDIR, so can't use that.  However,
+	// returns EISDIR, so can't use that. However,
 	// both agree that rmdir(file) returns ENOTDIR,
 	// so we can use that to decide which error is real.
 	// Rmdir might also return ENOTDIR if given a bad
diff --git a/src/os/file_windows.go b/src/os/file_windows.go
index aa8c05c4ff..7d04477d42 100644
--- a/src/os/file_windows.go
+++ b/src/os/file_windows.go
@@ -136,8 +136,8 @@ func openDir(name string) (file *File, err error) {
 }
 
 // OpenFile is the generalized open call; most users will use Open
-// or Create instead.  It opens the named file with specified flag
-// (O_RDONLY etc.) and perm, (0666 etc.) if applicable.  If successful,
+// or Create instead. It opens the named file with specified flag
+// (O_RDONLY etc.) and perm, (0666 etc.) if applicable. If successful,
 // methods on the returned File can be used for I/O.
 // If there is an error, it will be of type *PathError.
 func OpenFile(name string, flag int, perm FileMode) (*File, error) {
diff --git a/src/os/getwd.go b/src/os/getwd.go
index d5da53b34b..4c3c0d94cb 100644
--- a/src/os/getwd.go
+++ b/src/os/getwd.go
@@ -20,7 +20,7 @@ var getwdCache struct {
 var useSyscallwd = func(error) bool { return true }
 
 // Getwd returns a rooted path name corresponding to the
-// current directory.  If the current directory can be
+// current directory. If the current directory can be
 // reached via multiple paths (due to symbolic links),
 // Getwd may return any one of them.
 func Getwd() (dir string, err error) {
@@ -74,7 +74,7 @@ func Getwd() (dir string, err error) {
 	}
 
 	// General algorithm: find name in parent
-	// and then find name of parent.  Each iteration
+	// and then find name of parent. Each iteration
 	// adds /name to the beginning of dir.
 	dir = ""
 	for parent := ".."; ; parent = "../" + parent {
diff --git a/src/os/os_unix_test.go b/src/os/os_unix_test.go
index d02e07b478..c47f5462ab 100644
--- a/src/os/os_unix_test.go
+++ b/src/os/os_unix_test.go
@@ -39,7 +39,7 @@ func TestChown(t *testing.T) {
 	}
 	// Use TempDir() to make sure we're on a local file system,
 	// so that the group ids returned by Getgroups will be allowed
-	// on the file.  On NFS, the Getgroups groups are
+	// on the file. On NFS, the Getgroups groups are
 	// basically useless.
 	f := newFile("TestChown", t)
 	defer Remove(f.Name())
@@ -50,7 +50,7 @@ func TestChown(t *testing.T) {
 	}
 
 	// Can't change uid unless root, but can try
-	// changing the group id.  First try our current group.
+	// changing the group id. First try our current group.
 	gid := Getgid()
 	t.Log("gid:", gid)
 	if err = Chown(f.Name(), -1, gid); err != nil {
@@ -86,7 +86,7 @@ func TestFileChown(t *testing.T) {
 	}
 	// Use TempDir() to make sure we're on a local file system,
 	// so that the group ids returned by Getgroups will be allowed
-	// on the file.  On NFS, the Getgroups groups are
+	// on the file. On NFS, the Getgroups groups are
 	// basically useless.
 	f := newFile("TestFileChown", t)
 	defer Remove(f.Name())
@@ -97,7 +97,7 @@ func TestFileChown(t *testing.T) {
 	}
 
 	// Can't change uid unless root, but can try
-	// changing the group id.  First try our current group.
+	// changing the group id. First try our current group.
 	gid := Getgid()
 	t.Log("gid:", gid)
 	if err = f.Chown(-1, gid); err != nil {
@@ -133,7 +133,7 @@ func TestLchown(t *testing.T) {
 	}
 	// Use TempDir() to make sure we're on a local file system,
 	// so that the group ids returned by Getgroups will be allowed
-	// on the file.  On NFS, the Getgroups groups are
+	// on the file. On NFS, the Getgroups groups are
 	// basically useless.
 	f := newFile("TestLchown", t)
 	defer Remove(f.Name())
@@ -150,7 +150,7 @@ func TestLchown(t *testing.T) {
 	defer Remove(linkname)
 
 	// Can't change uid unless root, but can try
-	// changing the group id.  First try our current group.
+	// changing the group id. First try our current group.
 	gid := Getgid()
 	t.Log("gid:", gid)
 	if err = Lchown(linkname, -1, gid); err != nil {
diff --git a/src/os/path.go b/src/os/path.go
index 84a3be3348..146d7b6954 100644
--- a/src/os/path.go
+++ b/src/os/path.go
@@ -61,7 +61,7 @@ func MkdirAll(path string, perm FileMode) error {
 
 // RemoveAll removes path and any children it contains.
 // It removes everything it can but returns the first error
-// it encounters.  If the path does not exist, RemoveAll
+// it encounters. If the path does not exist, RemoveAll
 // returns nil (no error).
 func RemoveAll(path string) error {
 	// Simple case: if Remove works, we're done.
diff --git a/src/os/path_test.go b/src/os/path_test.go
index b4531314d0..51dc25bb23 100644
--- a/src/os/path_test.go
+++ b/src/os/path_test.go
@@ -147,7 +147,7 @@ func TestRemoveAll(t *testing.T) {
 		// No error checking here: either RemoveAll
 		// will or won't be able to remove dpath;
 		// either way we want to see if it removes fpath
-		// and path/zzz.  Reasons why RemoveAll might
+		// and path/zzz. Reasons why RemoveAll might
 		// succeed in removing dpath as well include:
 		//	* running as root
 		//	* running on a file system without permissions (FAT)
diff --git a/src/os/pipe_test.go b/src/os/pipe_test.go
index 82b792eac4..74cce80ee4 100644
--- a/src/os/pipe_test.go
+++ b/src/os/pipe_test.go
@@ -88,7 +88,7 @@ func TestStdPipe(t *testing.T) {
 	}
 }
 
-// This is a helper for TestStdPipe.  It's not a test in itself.
+// This is a helper for TestStdPipe. It's not a test in itself.
 func TestStdPipeHelper(t *testing.T) {
 	if os.Getenv("GO_TEST_STD_PIPE_HELPER_SIGNAL") != "" {
 		signal.Notify(make(chan os.Signal, 1), syscall.SIGPIPE)
diff --git a/src/os/signal/signal.go b/src/os/signal/signal.go
index 2e6f186658..c1376daaea 100644
--- a/src/os/signal/signal.go
+++ b/src/os/signal/signal.go
@@ -79,7 +79,7 @@ func Ignore(sig ...os.Signal) {
 //
 // Package signal will not block sending to c: the caller must ensure
 // that c has sufficient buffer space to keep up with the expected
-// signal rate.  For a channel used for notification of just one signal value,
+// signal rate. For a channel used for notification of just one signal value,
 // a buffer of size 1 is sufficient.
 //
 // It is allowed to call Notify multiple times with the same channel:
diff --git a/src/os/stat_plan9.go b/src/os/stat_plan9.go
index fa4bd83aef..a2df5fe139 100644
--- a/src/os/stat_plan9.go
+++ b/src/os/stat_plan9.go
@@ -100,7 +100,7 @@ func Stat(name string) (FileInfo, error) {
 
 // Lstat returns a FileInfo describing the named file.
 // If the file is a symbolic link, the returned FileInfo
-// describes the symbolic link.  Lstat makes no attempt to follow the link.
+// describes the symbolic link. Lstat makes no attempt to follow the link.
 // If there is an error, it will be of type *PathError.
 func Lstat(name string) (FileInfo, error) {
 	return Stat(name)
diff --git a/src/os/stat_windows.go b/src/os/stat_windows.go
index 0b6c22c8e8..d65c58200f 100644
--- a/src/os/stat_windows.go
+++ b/src/os/stat_windows.go
@@ -68,7 +68,7 @@ func Stat(name string) (FileInfo, error) {
 
 // Lstat returns the FileInfo structure describing the named file.
 // If the file is a symbolic link, the returned FileInfo
-// describes the symbolic link.  Lstat makes no attempt to follow the link.
+// describes the symbolic link. Lstat makes no attempt to follow the link.
 // If there is an error, it will be of type *PathError.
 func Lstat(name string) (FileInfo, error) {
 	if len(name) == 0 {
diff --git a/src/os/types.go b/src/os/types.go
index 9d6f8e13d6..12b593fa1e 100644
--- a/src/os/types.go
+++ b/src/os/types.go
@@ -25,7 +25,7 @@ type FileInfo interface {
 // A FileMode represents a file's mode and permission bits.
 // The bits have the same definition on all systems, so that
 // information about files can be moved from one system
-// to another portably.  Not all bits apply to all systems.
+// to another portably. Not all bits apply to all systems.
 // The only required bit is ModeDir for directories.
 type FileMode uint32
 
diff --git a/src/os/user/lookup_unix.go b/src/os/user/lookup_unix.go
index e8a1eb1bbf..87ad1e7427 100644
--- a/src/os/user/lookup_unix.go
+++ b/src/os/user/lookup_unix.go
@@ -108,7 +108,7 @@ func lookupUnix(uid int, username string, lookupByName bool) (*User, error) {
 		Name:     C.GoString(pwd.pw_gecos),
 		HomeDir:  C.GoString(pwd.pw_dir),
 	}
-	// The pw_gecos field isn't quite standardized.  Some docs
+	// The pw_gecos field isn't quite standardized. Some docs
 	// say: "It is expected to be a comma separated list of
 	// personal data where the first item is the full name of the
 	// user."
diff --git a/src/path/filepath/path.go b/src/path/filepath/path.go
index dd6f3e7a99..4b70bf8824 100644
--- a/src/path/filepath/path.go
+++ b/src/path/filepath/path.go
@@ -61,7 +61,7 @@ const (
 )
 
 // Clean returns the shortest path name equivalent to path
-// by purely lexical processing.  It applies the following rules
+// by purely lexical processing. It applies the following rules
 // iteratively until no further processing can be done:
 //
 //	1. Replace multiple Separator elements with a single one.
@@ -229,7 +229,7 @@ func EvalSymlinks(path string) (string, error) {
 
 // Abs returns an absolute representation of path.
 // If the path is not absolute it will be joined with the current
-// working directory to turn it into an absolute path.  The absolute
+// working directory to turn it into an absolute path. The absolute
 // path name for a given file is not guaranteed to be unique.
 func Abs(path string) (string, error) {
 	return abs(path)
diff --git a/src/path/filepath/path_test.go b/src/path/filepath/path_test.go
index baeee97165..3622f9178e 100644
--- a/src/path/filepath/path_test.go
+++ b/src/path/filepath/path_test.go
@@ -449,7 +449,7 @@ func TestWalk(t *testing.T) {
 	checkMarks(t, true)
 	errors = errors[0:0]
 
-	// Test permission errors.  Only possible if we're not root
+	// Test permission errors. Only possible if we're not root
 	// and only on some file systems (AFS, FAT).  To avoid errors during
 	// all.bash on those file systems, skip during go test -short.
 	if os.Getuid() > 0 && !testing.Short() {
diff --git a/src/path/path.go b/src/path/path.go
index 01071a9a82..990fa3fcc5 100644
--- a/src/path/path.go
+++ b/src/path/path.go
@@ -48,7 +48,7 @@ func (b *lazybuf) string() string {
 }
 
 // Clean returns the shortest path name equivalent to path
-// by purely lexical processing.  It applies the following rules
+// by purely lexical processing. It applies the following rules
 // iteratively until no further processing can be done:
 //
 //	1. Replace multiple slashes with a single slash.
diff --git a/src/reflect/all_test.go b/src/reflect/all_test.go
index 2eb4f343f9..5df228db1a 100644
--- a/src/reflect/all_test.go
+++ b/src/reflect/all_test.go
@@ -4702,7 +4702,7 @@ func init() {
 			2 * PtrSize,
 			[]byte{1},
 			[]byte{1},
-			// Note: this one is tricky, as the receiver is not a pointer.  But we
+			// Note: this one is tricky, as the receiver is not a pointer. But we
 			// pass the receiver by reference to the autogenerated pointer-receiver
 			// version of the function.
 		})
@@ -5004,7 +5004,7 @@ func TestChanAlloc(t *testing.T) {
 		t.Errorf("allocs per chan send/recv: want 1 got %f", allocs)
 	}
 	// Note: there is one allocation in reflect.recv which seems to be
-	// a limitation of escape analysis.  If that is ever fixed the
+	// a limitation of escape analysis. If that is ever fixed the
 	// allocs < 0.5 condition will trigger and this test should be fixed.
 }
 
diff --git a/src/reflect/deepequal.go b/src/reflect/deepequal.go
index 3743e8042d..9770358ae7 100644
--- a/src/reflect/deepequal.go
+++ b/src/reflect/deepequal.go
@@ -9,7 +9,7 @@ package reflect
 import "unsafe"
 
 // During deepValueEqual, must keep track of checks that are
-// in progress.  The comparison algorithm assumes that all
+// in progress. The comparison algorithm assumes that all
 // checks in progress are true when it reencounters them.
 // Visited comparisons are stored in a map indexed by visit.
 type visit struct {
diff --git a/src/reflect/type.go b/src/reflect/type.go
index 1367ba34e7..dd8084ed0f 100644
--- a/src/reflect/type.go
+++ b/src/reflect/type.go
@@ -3,7 +3,7 @@
 // license that can be found in the LICENSE file.
 
 // Package reflect implements run-time reflection, allowing a program to
-// manipulate objects with arbitrary types.  The typical use is to take a value
+// manipulate objects with arbitrary types. The typical use is to take a value
 // with static type interface{} and extract its dynamic type information by
 // calling TypeOf, which returns a Type.
 //
@@ -24,10 +24,10 @@ import (
 
 // Type is the representation of a Go type.
 //
-// Not all methods apply to all kinds of types.  Restrictions,
+// Not all methods apply to all kinds of types. Restrictions,
 // if any, are noted in the documentation for each method.
 // Use the Kind method to find out the kind of type before
-// calling kind-specific methods.  Calling a method
+// calling kind-specific methods. Calling a method
 // inappropriate to the kind of type causes a run-time panic.
 type Type interface {
 	// Methods applicable to all types.
@@ -80,7 +80,7 @@ type Type interface {
 	// String returns a string representation of the type.
 	// The string representation may use shortened package names
 	// (e.g., base64 instead of "encoding/base64") and is not
-	// guaranteed to be unique among types.  To test for equality,
+	// guaranteed to be unique among types. To test for equality,
 	// compare the Types directly.
 	String() string
 
@@ -121,7 +121,7 @@ type Type interface {
 	ChanDir() ChanDir
 
 	// IsVariadic reports whether a function type's final input parameter
-	// is a "..." parameter.  If so, t.In(t.NumIn() - 1) returns the parameter's
+	// is a "..." parameter. If so, t.In(t.NumIn() - 1) returns the parameter's
 	// implicit actual type []T.
 	//
 	// For concreteness, if t represents func(x int, y ... float64), then
@@ -144,7 +144,7 @@ type Type interface {
 	Field(i int) StructField
 
 	// FieldByIndex returns the nested field corresponding
-	// to the index sequence.  It is equivalent to calling Field
+	// to the index sequence. It is equivalent to calling Field
 	// successively for each index i.
 	// It panics if the type's Kind is not Struct.
 	FieldByIndex(index []int) StructField
@@ -384,7 +384,7 @@ type structType struct {
 type Method struct {
 	// Name is the method name.
 	// PkgPath is the package path that qualifies a lower case (unexported)
-	// method name.  It is empty for upper case (exported) method names.
+	// method name. It is empty for upper case (exported) method names.
 	// The combination of PkgPath and Name uniquely identifies a method
 	// in a method set.
 	// See https://golang.org/ref/spec#Uniqueness_of_identifiers
@@ -754,7 +754,7 @@ type StructField struct {
 	// Name is the field name.
 	Name string
 	// PkgPath is the package path that qualifies a lower case (unexported)
-	// field name.  It is empty for upper case (exported) field names.
+	// field name. It is empty for upper case (exported) field names.
 	// See https://golang.org/ref/spec#Uniqueness_of_identifiers
 	PkgPath string
 
@@ -859,12 +859,12 @@ func (t *structType) Field(i int) (f StructField) {
 	f.Offset = p.offset
 
 	// NOTE(rsc): This is the only allocation in the interface
-	// presented by a reflect.Type.  It would be nice to avoid,
+	// presented by a reflect.Type. It would be nice to avoid,
 	// at least in the common cases, but we need to make sure
 	// that misbehaving clients of reflect cannot affect other
-	// uses of reflect.  One possibility is CL 5371098, but we
+	// uses of reflect. One possibility is CL 5371098, but we
 	// postponed that ugliness until there is a demonstrated
-	// need for the performance.  This is issue 2320.
+	// need for the performance. This is issue 2320.
 	f.Index = []int{i}
 	return
 }
@@ -1706,7 +1706,7 @@ func needKeyUpdate(t *rtype) bool {
 
 // Make sure these routines stay in sync with ../../runtime/hashmap.go!
 // These types exist only for GC, so we only fill out GC relevant info.
-// Currently, that's just size and the GC program.  We also fill in string
+// Currently, that's just size and the GC program. We also fill in string
 // for possible debugging use.
 const (
 	bucketSize uintptr = 8
@@ -2065,7 +2065,7 @@ var layoutCache struct {
 // function arguments and return values for the function type t.
 // If rcvr != nil, rcvr specifies the type of the receiver.
 // The returned type exists only for GC, so we only fill out GC relevant info.
-// Currently, that's just size and the GC program.  We also fill in
+// Currently, that's just size and the GC program. We also fill in
 // the name for possible debugging use.
 func funcLayout(t *rtype, rcvr *rtype) (frametype *rtype, argSize, retOffset uintptr, stk *bitVector, framePool *sync.Pool) {
 	if t.Kind() != Func {
diff --git a/src/reflect/value.go b/src/reflect/value.go
index 182c45a1ce..8af39b12ac 100644
--- a/src/reflect/value.go
+++ b/src/reflect/value.go
@@ -15,10 +15,10 @@ const cannotSet = "cannot set value obtained from unexported struct field"
 
 // Value is the reflection interface to a Go value.
 //
-// Not all methods apply to all kinds of values.  Restrictions,
+// Not all methods apply to all kinds of values. Restrictions,
 // if any, are noted in the documentation for each method.
 // Use the Kind method to find out the kind of value before
-// calling kind-specific methods.  Calling a method
+// calling kind-specific methods. Calling a method
 // inappropriate to the kind of type causes a run time panic.
 //
 // The zero Value represents no value.
@@ -57,7 +57,7 @@ type Value struct {
 	flag
 
 	// A method value represents a curried method invocation
-	// like r.Read for some receiver r.  The typ+val+flag bits describe
+	// like r.Read for some receiver r. The typ+val+flag bits describe
 	// the receiver r, but the flag's Kind bits say Func (methods are
 	// functions), and the top bits of the flag give the method number
 	// in r's type's method table.
@@ -115,14 +115,14 @@ func packEface(v Value) interface{} {
 		}
 		e.word = ptr
 	case v.flag&flagIndir != 0:
-		// Value is indirect, but interface is direct.  We need
+		// Value is indirect, but interface is direct. We need
 		// to load the data at v.ptr into the interface data word.
 		e.word = *(*unsafe.Pointer)(v.ptr)
 	default:
 		// Value is direct, and so is the interface.
 		e.word = v.ptr
 	}
-	// Now, fill in the type portion.  We're very careful here not
+	// Now, fill in the type portion. We're very careful here not
 	// to have any operation between the e.word and e.typ assignments
 	// that would let the garbage collector observe the partially-built
 	// interface value.
@@ -146,7 +146,7 @@ func unpackEface(i interface{}) Value {
 }
 
 // A ValueError occurs when a Value method is invoked on
-// a Value that does not support it.  Such cases are documented
+// a Value that does not support it. Such cases are documented
 // in the description of each method.
 type ValueError struct {
 	Method string
@@ -272,7 +272,7 @@ func (v Value) runes() []rune {
 }
 
 // CanAddr reports whether the value's address can be obtained with Addr.
-// Such values are called addressable.  A value is addressable if it is
+// Such values are called addressable. A value is addressable if it is
 // an element of a slice, an element of an addressable array,
 // a field of an addressable struct, or the result of dereferencing a pointer.
 // If CanAddr returns false, calling Addr will panic.
@@ -581,7 +581,7 @@ func methodReceiver(op string, v Value, methodIndex int) (rcvrtype, t *rtype, fn
 	return
 }
 
-// v is a method receiver.  Store at p the word which is used to
+// v is a method receiver. Store at p the word which is used to
 // encode that receiver at the start of the argument list.
 // Reflect uses the "interface" calling convention for
 // methods, which always uses one word to record the receiver.
@@ -1025,9 +1025,9 @@ func (v Value) MapIndex(key Value) Value {
 
 	// Do not require key to be exported, so that DeepEqual
 	// and other programs can use all the keys returned by
-	// MapKeys as arguments to MapIndex.  If either the map
+	// MapKeys as arguments to MapIndex. If either the map
 	// or the key is unexported, though, the result will be
-	// considered unexported.  This is consistent with the
+	// considered unexported. This is consistent with the
 	// behavior for structs, which allow read but not write
 	// of unexported fields.
 	key = key.assignTo("reflect.Value.MapIndex", tt.key, nil)
@@ -1079,7 +1079,7 @@ func (v Value) MapKeys() []Value {
 		key := mapiterkey(it)
 		if key == nil {
 			// Someone deleted an entry from the map since we
-			// called maplen above.  It's a data race, but nothing
+			// called maplen above. It's a data race, but nothing
 			// we can do about it.
 			break
 		}
@@ -1226,7 +1226,7 @@ func (v Value) OverflowUint(x uint64) bool {
 // result is zero if and only if v is a nil func Value.
 //
 // If v's Kind is Slice, the returned pointer is to the first
-// element of the slice.  If the slice is nil the returned value
+// element of the slice. If the slice is nil the returned value
 // is 0.  If the slice is empty but non-nil the return value is non-zero.
 func (v Value) Pointer() uintptr {
 	// TODO: deprecate
@@ -1883,7 +1883,7 @@ type runtimeSelect struct {
 	val unsafe.Pointer // ptr to data (SendDir) or ptr to receive buffer (RecvDir)
 }
 
-// rselect runs a select.  It returns the index of the chosen case.
+// rselect runs a select. It returns the index of the chosen case.
 // If the case was a receive, val is filled in with the received value.
 // The conventional OK bool indicates whether the receive corresponds
 // to a sent value.
@@ -2080,14 +2080,14 @@ func Indirect(v Value) Value {
 }
 
 // ValueOf returns a new Value initialized to the concrete value
-// stored in the interface i.  ValueOf(nil) returns the zero Value.
+// stored in the interface i. ValueOf(nil) returns the zero Value.
 func ValueOf(i interface{}) Value {
 	if i == nil {
 		return Value{}
 	}
 
 	// TODO: Maybe allow contents of a Value to live on the stack.
-	// For now we make the contents always escape to the heap.  It
+	// For now we make the contents always escape to the heap. It
 	// makes life easier in a few places (see chanrecv/mapassign
 	// comment below).
 	escapes(i)
@@ -2113,7 +2113,7 @@ func Zero(typ Type) Value {
 }
 
 // New returns a Value representing a pointer to a new zero value
-// for the specified type.  That is, the returned Value's Type is PtrTo(typ).
+// for the specified type. That is, the returned Value's Type is PtrTo(typ).
 func New(typ Type) Value {
 	if typ == nil {
 		panic("reflect: New(nil)")
@@ -2446,7 +2446,7 @@ func chanclose(ch unsafe.Pointer)
 func chanlen(ch unsafe.Pointer) int
 
 // Note: some of the noescape annotations below are technically a lie,
-// but safe in the context of this package.  Functions like chansend
+// but safe in the context of this package. Functions like chansend
 // and mapassign don't escape the referent, but may escape anything
 // the referent points to (they do shallow copies of the referent).
 // It is safe in this package because the referent may only point
diff --git a/src/regexp/backtrack.go b/src/regexp/backtrack.go
index 3a1100dde8..93334c3aff 100644
--- a/src/regexp/backtrack.go
+++ b/src/regexp/backtrack.go
@@ -146,7 +146,7 @@ func (m *machine) tryBacktrack(b *bitState, i input, pc uint32, pos int) bool {
 		// Optimization: rather than push and pop,
 		// code that is going to Push and continue
 		// the loop simply updates ip, p, and arg
-		// and jumps to CheckAndLoop.  We have to
+		// and jumps to CheckAndLoop. We have to
 		// do the ShouldVisit check that Push
 		// would have, but we avoid the stack
 		// manipulation.
diff --git a/src/regexp/exec.go b/src/regexp/exec.go
index 518272092a..6c6329e0b0 100644
--- a/src/regexp/exec.go
+++ b/src/regexp/exec.go
@@ -19,7 +19,7 @@ type queue struct {
 // A entry is an entry on a queue.
 // It holds both the instruction pc and the actual thread.
 // Some queue entries are just place holders so that the machine
-// knows it has considered that pc.  Such entries have t == nil.
+// knows it has considered that pc. Such entries have t == nil.
 type entry struct {
 	pc uint32
 	t  *thread
diff --git a/src/regexp/exec_test.go b/src/regexp/exec_test.go
index 0f95b95972..6ccf24e7e9 100644
--- a/src/regexp/exec_test.go
+++ b/src/regexp/exec_test.go
@@ -22,7 +22,7 @@ import (
 // considered during RE2's exhaustive tests, which run all possible
 // regexps over a given set of atoms and operators, up to a given
 // complexity, over all possible strings over a given alphabet,
-// up to a given size.  Rather than try to link with RE2, we read a
+// up to a given size. Rather than try to link with RE2, we read a
 // log file containing the test cases and the expected matches.
 // The log file, re2-exhaustive.txt, is generated by running 'make log'
 // in the open source RE2 distribution https://github.com/google/re2/.
@@ -41,21 +41,21 @@ import (
 //	-;0-3 0-1 1-2 2-3
 //
 // The stanza begins by defining a set of strings, quoted
-// using Go double-quote syntax, one per line.  Then the
+// using Go double-quote syntax, one per line. Then the
 // regexps section gives a sequence of regexps to run on
-// the strings.  In the block that follows a regexp, each line
+// the strings. In the block that follows a regexp, each line
 // gives the semicolon-separated match results of running
 // the regexp on the corresponding string.
 // Each match result is either a single -, meaning no match, or a
 // space-separated sequence of pairs giving the match and
-// submatch indices.  An unmatched subexpression formats
+// submatch indices. An unmatched subexpression formats
 // its pair as a single - (not illustrated above).  For now
 // each regexp run produces two match results, one for a
 // ``full match'' that restricts the regexp to matching the entire
 // string or nothing, and one for a ``partial match'' that gives
 // the leftmost first match found in the string.
 //
-// Lines beginning with # are comments.  Lines beginning with
+// Lines beginning with # are comments. Lines beginning with
 // a capital letter are test names printed during RE2's test suite
 // and are echoed into t but otherwise ignored.
 //
@@ -155,9 +155,9 @@ func testRE2(t *testing.T, file string) {
 			if !isSingleBytes(text) && strings.Contains(re.String(), `\B`) {
 				// RE2's \B considers every byte position,
 				// so it sees 'not word boundary' in the
-				// middle of UTF-8 sequences.  This package
+				// middle of UTF-8 sequences. This package
 				// only considers the positions between runes,
-				// so it disagrees.  Skip those cases.
+				// so it disagrees. Skip those cases.
 				continue
 			}
 			res := strings.Split(line, ";")
diff --git a/src/regexp/onepass.go b/src/regexp/onepass.go
index 628b57dc89..5b82f9666e 100644
--- a/src/regexp/onepass.go
+++ b/src/regexp/onepass.go
@@ -33,7 +33,7 @@ type onePassInst struct {
 }
 
 // OnePassPrefix returns a literal string that all matches for the
-// regexp must start with.  Complete is true if the prefix
+// regexp must start with. Complete is true if the prefix
 // is the entire match. Pc is the index of the last rune instruction
 // in the string. The OnePassPrefix skips over the mandatory
 // EmptyBeginText
diff --git a/src/regexp/regexp.go b/src/regexp/regexp.go
index 42ae6e1d7a..e1da9ed421 100644
--- a/src/regexp/regexp.go
+++ b/src/regexp/regexp.go
@@ -22,14 +22,14 @@
 // All characters are UTF-8-encoded code points.
 //
 // There are 16 methods of Regexp that match a regular expression and identify
-// the matched text.  Their names are matched by this regular expression:
+// the matched text. Their names are matched by this regular expression:
 //
 //	Find(All)?(String)?(Submatch)?(Index)?
 //
 // If 'All' is present, the routine matches successive non-overlapping
-// matches of the entire expression.  Empty matches abutting a preceding
-// match are ignored.  The return value is a slice containing the successive
-// return values of the corresponding non-'All' routine.  These routines take
+// matches of the entire expression. Empty matches abutting a preceding
+// match are ignored. The return value is a slice containing the successive
+// return values of the corresponding non-'All' routine. These routines take
 // an extra integer argument, n; if n >= 0, the function returns at most n
 // matches/submatches.
 //
@@ -45,9 +45,9 @@
 //
 // If 'Index' is present, matches and submatches are identified by byte index
 // pairs within the input string: result[2*n:2*n+1] identifies the indexes of
-// the nth submatch.  The pair for n==0 identifies the match of the entire
-// expression.  If 'Index' is not present, the match is identified by the
-// text of the match/submatch.  If an index is negative, it means that
+// the nth submatch. The pair for n==0 identifies the match of the entire
+// expression. If 'Index' is not present, the match is identified by the
+// text of the match/submatch. If an index is negative, it means that
 // subexpression did not match any string in the input.
 //
 // There is also a subset of the methods that can be applied to text read
@@ -55,7 +55,7 @@
 //
 //	MatchReader, FindReaderIndex, FindReaderSubmatchIndex
 //
-// This set may grow.  Note that regular expression matches may need to
+// This set may grow. Note that regular expression matches may need to
 // examine text beyond the text returned by a match, so the methods that
 // match text from a RuneReader may read arbitrarily far into the input
 // before returning.
@@ -258,10 +258,10 @@ func (re *Regexp) NumSubexp() int {
 }
 
 // SubexpNames returns the names of the parenthesized subexpressions
-// in this Regexp.  The name for the first sub-expression is names[1],
+// in this Regexp. The name for the first sub-expression is names[1],
 // so that if m is a match slice, the name for m[i] is SubexpNames()[i].
 // Since the Regexp as a whole cannot be named, names[0] is always
-// the empty string.  The slice should not be modified.
+// the empty string. The slice should not be modified.
 func (re *Regexp) SubexpNames() []string {
 	return re.subexpNames
 }
@@ -394,7 +394,7 @@ func (i *inputReader) context(pos int) syntax.EmptyOp {
 }
 
 // LiteralPrefix returns a literal string that must begin any match
-// of the regular expression re.  It returns the boolean true if the
+// of the regular expression re. It returns the boolean true if the
 // literal string comprises the entire regular expression.
 func (re *Regexp) LiteralPrefix() (prefix string, complete bool) {
 	return re.prefix, re.prefixComplete
@@ -417,7 +417,7 @@ func (re *Regexp) Match(b []byte) bool {
 }
 
 // MatchReader checks whether a textual regular expression matches the text
-// read by the RuneReader.  More complicated queries need to use Compile and
+// read by the RuneReader. More complicated queries need to use Compile and
 // the full Regexp interface.
 func MatchReader(pattern string, r io.RuneReader) (matched bool, err error) {
 	re, err := Compile(pattern)
@@ -428,7 +428,7 @@ func MatchReader(pattern string, r io.RuneReader) (matched bool, err error) {
 }
 
 // MatchString checks whether a textual regular expression
-// matches a string.  More complicated queries need
+// matches a string. More complicated queries need
 // to use Compile and the full Regexp interface.
 func MatchString(pattern string, s string) (matched bool, err error) {
 	re, err := Compile(pattern)
@@ -439,7 +439,7 @@ func MatchString(pattern string, s string) (matched bool, err error) {
 }
 
 // Match checks whether a textual regular expression
-// matches a byte slice.  More complicated queries need
+// matches a byte slice. More complicated queries need
 // to use Compile and the full Regexp interface.
 func Match(pattern string, b []byte) (matched bool, err error) {
 	re, err := Compile(pattern)
@@ -450,7 +450,7 @@ func Match(pattern string, b []byte) (matched bool, err error) {
 }
 
 // ReplaceAllString returns a copy of src, replacing matches of the Regexp
-// with the replacement string repl.  Inside repl, $ signs are interpreted as
+// with the replacement string repl. Inside repl, $ signs are interpreted as
 // in Expand, so for instance $1 represents the text of the first submatch.
 func (re *Regexp) ReplaceAllString(src, repl string) string {
 	n := 2
@@ -464,7 +464,7 @@ func (re *Regexp) ReplaceAllString(src, repl string) string {
 }
 
 // ReplaceAllLiteralString returns a copy of src, replacing matches of the Regexp
-// with the replacement string repl.  The replacement repl is substituted directly,
+// with the replacement string repl. The replacement repl is substituted directly,
 // without using Expand.
 func (re *Regexp) ReplaceAllLiteralString(src, repl string) string {
 	return string(re.replaceAll(nil, src, 2, func(dst []byte, match []int) []byte {
@@ -474,7 +474,7 @@ func (re *Regexp) ReplaceAllLiteralString(src, repl string) string {
 
 // ReplaceAllStringFunc returns a copy of src in which all matches of the
 // Regexp have been replaced by the return value of function repl applied
-// to the matched substring.  The replacement returned by repl is substituted
+// to the matched substring. The replacement returned by repl is substituted
 // directly, without using Expand.
 func (re *Regexp) ReplaceAllStringFunc(src string, repl func(string) string) string {
 	b := re.replaceAll(nil, src, 2, func(dst []byte, match []int) []byte {
@@ -530,7 +530,7 @@ func (re *Regexp) replaceAll(bsrc []byte, src string, nmatch int, repl func(dst
 			searchPos += width
 		} else if searchPos+1 > a[1] {
 			// This clause is only needed at the end of the input
-			// string.  In that case, DecodeRuneInString returns width=0.
+			// string. In that case, DecodeRuneInString returns width=0.
 			searchPos++
 		} else {
 			searchPos = a[1]
@@ -548,7 +548,7 @@ func (re *Regexp) replaceAll(bsrc []byte, src string, nmatch int, repl func(dst
 }
 
 // ReplaceAll returns a copy of src, replacing matches of the Regexp
-// with the replacement text repl.  Inside repl, $ signs are interpreted as
+// with the replacement text repl. Inside repl, $ signs are interpreted as
 // in Expand, so for instance $1 represents the text of the first submatch.
 func (re *Regexp) ReplaceAll(src, repl []byte) []byte {
 	n := 2
@@ -566,7 +566,7 @@ func (re *Regexp) ReplaceAll(src, repl []byte) []byte {
 }
 
 // ReplaceAllLiteral returns a copy of src, replacing matches of the Regexp
-// with the replacement bytes repl.  The replacement repl is substituted directly,
+// with the replacement bytes repl. The replacement repl is substituted directly,
 // without using Expand.
 func (re *Regexp) ReplaceAllLiteral(src, repl []byte) []byte {
 	return re.replaceAll(src, "", 2, func(dst []byte, match []int) []byte {
@@ -576,7 +576,7 @@ func (re *Regexp) ReplaceAllLiteral(src, repl []byte) []byte {
 
 // ReplaceAllFunc returns a copy of src in which all matches of the
 // Regexp have been replaced by the return value of function repl applied
-// to the matched byte slice.  The replacement returned by repl is substituted
+// to the matched byte slice. The replacement returned by repl is substituted
 // directly, without using Expand.
 func (re *Regexp) ReplaceAllFunc(src []byte, repl func([]byte) []byte) []byte {
 	return re.replaceAll(src, "", 2, func(dst []byte, match []int) []byte {
@@ -592,7 +592,7 @@ func special(b byte) bool {
 
 // QuoteMeta returns a string that quotes all regular expression metacharacters
 // inside the argument text; the returned string is a regular expression matching
-// the literal text.  For example, QuoteMeta(`[foo]`) returns `\[foo\]`.
+// the literal text. For example, QuoteMeta(`[foo]`) returns `\[foo\]`.
 func QuoteMeta(s string) string {
 	b := make([]byte, 2*len(s))
 
@@ -684,7 +684,7 @@ func (re *Regexp) Find(b []byte) []byte {
 }
 
 // FindIndex returns a two-element slice of integers defining the location of
-// the leftmost match in b of the regular expression.  The match itself is at
+// the leftmost match in b of the regular expression. The match itself is at
 // b[loc[0]:loc[1]].
 // A return value of nil indicates no match.
 func (re *Regexp) FindIndex(b []byte) (loc []int) {
@@ -696,9 +696,9 @@ func (re *Regexp) FindIndex(b []byte) (loc []int) {
 }
 
 // FindString returns a string holding the text of the leftmost match in s of the regular
-// expression.  If there is no match, the return value is an empty string,
+// expression. If there is no match, the return value is an empty string,
 // but it will also be empty if the regular expression successfully matches
-// an empty string.  Use FindStringIndex or FindStringSubmatch if it is
+// an empty string. Use FindStringIndex or FindStringSubmatch if it is
 // necessary to distinguish these cases.
 func (re *Regexp) FindString(s string) string {
 	a := re.doExecute(nil, nil, s, 0, 2)
@@ -709,7 +709,7 @@ func (re *Regexp) FindString(s string) string {
 }
 
 // FindStringIndex returns a two-element slice of integers defining the
-// location of the leftmost match in s of the regular expression.  The match
+// location of the leftmost match in s of the regular expression. The match
 // itself is at s[loc[0]:loc[1]].
 // A return value of nil indicates no match.
 func (re *Regexp) FindStringIndex(s string) (loc []int) {
@@ -722,7 +722,7 @@ func (re *Regexp) FindStringIndex(s string) (loc []int) {
 
 // FindReaderIndex returns a two-element slice of integers defining the
 // location of the leftmost match of the regular expression in text read from
-// the RuneReader.  The match text was found in the input stream at
+// the RuneReader. The match text was found in the input stream at
 // byte offset loc[0] through loc[1]-1.
 // A return value of nil indicates no match.
 func (re *Regexp) FindReaderIndex(r io.RuneReader) (loc []int) {
@@ -754,14 +754,14 @@ func (re *Regexp) FindSubmatch(b []byte) [][]byte {
 
 // Expand appends template to dst and returns the result; during the
 // append, Expand replaces variables in the template with corresponding
-// matches drawn from src.  The match slice should have been returned by
+// matches drawn from src. The match slice should have been returned by
 // FindSubmatchIndex.
 //
 // In the template, a variable is denoted by a substring of the form
 // $name or ${name}, where name is a non-empty sequence of letters,
-// digits, and underscores.  A purely numeric name like $1 refers to
+// digits, and underscores. A purely numeric name like $1 refers to
 // the submatch with the corresponding index; other names refer to
-// capturing parentheses named with the (?P<name>...) syntax.  A
+// capturing parentheses named with the (?P<name>...) syntax. A
 // reference to an out of range or unmatched index or a name that is not
 // present in the regular expression is replaced with an empty slice.
 //
@@ -920,7 +920,7 @@ func (re *Regexp) FindStringSubmatchIndex(s string) []int {
 // FindReaderSubmatchIndex returns a slice holding the index pairs
 // identifying the leftmost match of the regular expression of text read by
 // the RuneReader, and the matches, if any, of its subexpressions, as defined
-// by the 'Submatch' and 'Index' descriptions in the package comment.  A
+// by the 'Submatch' and 'Index' descriptions in the package comment. A
 // return value of nil indicates no match.
 func (re *Regexp) FindReaderSubmatchIndex(r io.RuneReader) []int {
 	return re.pad(re.doExecute(r, nil, "", 0, re.prog.NumCap))
diff --git a/src/regexp/syntax/compile.go b/src/regexp/syntax/compile.go
index 95f6f15698..83e53ba6ca 100644
--- a/src/regexp/syntax/compile.go
+++ b/src/regexp/syntax/compile.go
@@ -8,11 +8,11 @@ import "unicode"
 
 // A patchList is a list of instruction pointers that need to be filled in (patched).
 // Because the pointers haven't been filled in yet, we can reuse their storage
-// to hold the list.  It's kind of sleazy, but works well in practice.
+// to hold the list. It's kind of sleazy, but works well in practice.
 // See http://swtch.com/~rsc/regexp/regexp1.html for inspiration.
 //
 // These aren't really pointers: they're integers, so we can reinterpret them
-// this way without using package unsafe.  A value l denotes
+// this way without using package unsafe. A value l denotes
 // p.inst[l>>1].Out (l&1==0) or .Arg (l&1==1).
 // l == 0 denotes the empty list, okay because we start every program
 // with a fail instruction, so we'll never want to point at its output link.
diff --git a/src/regexp/syntax/parse.go b/src/regexp/syntax/parse.go
index 7505593a64..7278bba5ac 100644
--- a/src/regexp/syntax/parse.go
+++ b/src/regexp/syntax/parse.go
@@ -141,9 +141,9 @@ func (p *parser) push(re *Regexp) *Regexp {
 }
 
 // maybeConcat implements incremental concatenation
-// of literal runes into string nodes.  The parser calls this
+// of literal runes into string nodes. The parser calls this
 // before each push, so only the top fragment of the stack
-// might need processing.  Since this is called before a push,
+// might need processing. Since this is called before a push,
 // the topmost literal is no longer subject to operators like *
 // (Otherwise ab* would turn into (ab)*.)
 // If r >= 0 and there's a node left over, maybeConcat uses it
@@ -600,7 +600,7 @@ func (p *parser) leadingString(re *Regexp) ([]rune, Flags) {
 }
 
 // removeLeadingString removes the first n leading runes
-// from the beginning of re.  It returns the replacement for re.
+// from the beginning of re. It returns the replacement for re.
 func (p *parser) removeLeadingString(re *Regexp, n int) *Regexp {
 	if re.Op == OpConcat && len(re.Sub) > 0 {
 		// Removing a leading string in a concatenation
@@ -957,11 +957,11 @@ func (p *parser) parsePerlFlags(s string) (rest string, err error) {
 	// Perl 5.10 gave in and implemented the Python version too,
 	// but they claim that the last two are the preferred forms.
 	// PCRE and languages based on it (specifically, PHP and Ruby)
-	// support all three as well.  EcmaScript 4 uses only the Python form.
+	// support all three as well. EcmaScript 4 uses only the Python form.
 	//
 	// In both the open source world (via Code Search) and the
 	// Google source tree, (?P<expr>name) is the dominant form,
-	// so that's the one we implement.  One is enough.
+	// so that's the one we implement. One is enough.
 	if len(t) > 4 && t[2] == 'P' && t[3] == '<' {
 		// Pull out name.
 		end := strings.IndexRune(t, '>')
@@ -989,7 +989,7 @@ func (p *parser) parsePerlFlags(s string) (rest string, err error) {
 		return t[end+1:], nil
 	}
 
-	// Non-capturing group.  Might also twiddle Perl flags.
+	// Non-capturing group. Might also twiddle Perl flags.
 	var c rune
 	t = t[2:] // skip (?
 	flags := p.flags
@@ -1257,7 +1257,7 @@ Switch:
 		if c < utf8.RuneSelf && !isalnum(c) {
 			// Escaped non-word characters are always themselves.
 			// PCRE is not quite so rigorous: it accepts things like
-			// \q, but we don't.  We once rejected \_, but too many
+			// \q, but we don't. We once rejected \_, but too many
 			// programs and people insist on using it, so allow \_.
 			return c, t, nil
 		}
@@ -1292,7 +1292,7 @@ Switch:
 		if c == '{' {
 			// Any number of digits in braces.
 			// Perl accepts any text at all; it ignores all text
-			// after the first non-hex digit.  We require only hex digits,
+			// after the first non-hex digit. We require only hex digits,
 			// and at least one.
 			nhex := 0
 			r = 0
@@ -1333,10 +1333,10 @@ Switch:
 		}
 		return x*16 + y, t, nil
 
-	// C escapes.  There is no case 'b', to avoid misparsing
+	// C escapes. There is no case 'b', to avoid misparsing
 	// the Perl word-boundary \b as the C backspace \b
-	// when in POSIX mode.  In Perl, /\b/ means word-boundary
-	// but /[\b]/ means backspace.  We don't support that.
+	// when in POSIX mode. In Perl, /\b/ means word-boundary
+	// but /[\b]/ means backspace. We don't support that.
 	// If you want a backspace, embed a literal backspace
 	// character or use \x08.
 	case 'a':
@@ -1377,7 +1377,7 @@ type charGroup struct {
 }
 
 // parsePerlClassEscape parses a leading Perl character class escape like \d
-// from the beginning of s.  If one is present, it appends the characters to r
+// from the beginning of s. If one is present, it appends the characters to r
 // and returns the new slice r and the remainder of the string.
 func (p *parser) parsePerlClassEscape(s string, r []rune) (out []rune, rest string) {
 	if p.flags&PerlX == 0 || len(s) < 2 || s[0] != '\\' {
@@ -1391,7 +1391,7 @@ func (p *parser) parsePerlClassEscape(s string, r []rune) (out []rune, rest stri
 }
 
 // parseNamedClass parses a leading POSIX named character class like [:alnum:]
-// from the beginning of s.  If one is present, it appends the characters to r
+// from the beginning of s. If one is present, it appends the characters to r
 // and returns the new slice r and the remainder of the string.
 func (p *parser) parseNamedClass(s string, r []rune) (out []rune, rest string, err error) {
 	if len(s) < 2 || s[0] != '[' || s[1] != ':' {
@@ -1454,7 +1454,7 @@ func unicodeTable(name string) (*unicode.RangeTable, *unicode.RangeTable) {
 }
 
 // parseUnicodeClass parses a leading Unicode character class like \p{Han}
-// from the beginning of s.  If one is present, it appends the characters to r
+// from the beginning of s. If one is present, it appends the characters to r
 // and returns the new slice r and the remainder of the string.
 func (p *parser) parseUnicodeClass(s string, r []rune) (out []rune, rest string, err error) {
 	if p.flags&UnicodeGroups == 0 || len(s) < 2 || s[0] != '\\' || s[1] != 'p' && s[1] != 'P' {
@@ -1718,7 +1718,7 @@ func appendFoldedRange(r []rune, lo, hi rune) []rune {
 		hi = maxFold
 	}
 
-	// Brute force.  Depend on appendRange to coalesce ranges on the fly.
+	// Brute force. Depend on appendRange to coalesce ranges on the fly.
 	for c := lo; c <= hi; c++ {
 		r = appendRange(r, c, c)
 		f := unicode.SimpleFold(c)
diff --git a/src/regexp/syntax/prog.go b/src/regexp/syntax/prog.go
index ae6db31a44..c32ae8d9fa 100644
--- a/src/regexp/syntax/prog.go
+++ b/src/regexp/syntax/prog.go
@@ -144,7 +144,7 @@ func (i *Inst) op() InstOp {
 }
 
 // Prefix returns a literal string that all matches for the
-// regexp must start with.  Complete is true if the prefix
+// regexp must start with. Complete is true if the prefix
 // is the entire match.
 func (p *Prog) Prefix() (prefix string, complete bool) {
 	i, _ := p.skipNop(uint32(p.Start))
@@ -164,7 +164,7 @@ func (p *Prog) Prefix() (prefix string, complete bool) {
 }
 
 // StartCond returns the leading empty-width conditions that must
-// be true in any match.  It returns ^EmptyOp(0) if no matches are possible.
+// be true in any match. It returns ^EmptyOp(0) if no matches are possible.
 func (p *Prog) StartCond() EmptyOp {
 	var flag EmptyOp
 	pc := uint32(p.Start)
diff --git a/src/regexp/syntax/regexp.go b/src/regexp/syntax/regexp.go
index 329ca804c0..0fe9269f25 100644
--- a/src/regexp/syntax/regexp.go
+++ b/src/regexp/syntax/regexp.go
@@ -139,7 +139,7 @@ func writeRegexp(b *bytes.Buffer, re *Regexp) {
 		if len(re.Rune) == 0 {
 			b.WriteString(`^\x00-\x{10FFFF}`)
 		} else if re.Rune[0] == 0 && re.Rune[len(re.Rune)-1] == unicode.MaxRune {
-			// Contains 0 and MaxRune.  Probably a negated class.
+			// Contains 0 and MaxRune. Probably a negated class.
 			// Print the gaps.
 			b.WriteRune('^')
 			for i := 1; i < len(re.Rune)-1; i += 2 {
diff --git a/src/regexp/syntax/simplify.go b/src/regexp/syntax/simplify.go
index 6e5a226ed8..e439325139 100644
--- a/src/regexp/syntax/simplify.go
+++ b/src/regexp/syntax/simplify.go
@@ -8,7 +8,7 @@ package syntax
 // and with various other simplifications, such as rewriting /(?:a+)+/ to /a+/.
 // The resulting regexp will execute correctly but its string representation
 // will not produce the same parse tree, because capturing parentheses
-// may have been duplicated or removed.  For example, the simplified form
+// may have been duplicated or removed. For example, the simplified form
 // for /(x){1,2}/ is /(x)(x)?/ but both parentheses capture as $1.
 // The returned regexp may share structure with or be the original.
 func (re *Regexp) Simplify() *Regexp {
@@ -117,13 +117,13 @@ func (re *Regexp) Simplify() *Regexp {
 }
 
 // simplify1 implements Simplify for the unary OpStar,
-// OpPlus, and OpQuest operators.  It returns the simple regexp
+// OpPlus, and OpQuest operators. It returns the simple regexp
 // equivalent to
 //
 //	Regexp{Op: op, Flags: flags, Sub: {sub}}
 //
 // under the assumption that sub is already simple, and
-// without first allocating that structure.  If the regexp
+// without first allocating that structure. If the regexp
 // to be returned turns out to be equivalent to re, simplify1
 // returns re instead.
 //
diff --git a/src/regexp/syntax/simplify_test.go b/src/regexp/syntax/simplify_test.go
index b9d79686a4..9877db3d0a 100644
--- a/src/regexp/syntax/simplify_test.go
+++ b/src/regexp/syntax/simplify_test.go
@@ -59,7 +59,7 @@ var simplifyTests = []struct {
 	{`a{0,1}`, `a?`},
 	// The next three are illegible because Simplify inserts (?:)
 	// parens instead of () parens to avoid creating extra
-	// captured subexpressions.  The comments show a version with fewer parens.
+	// captured subexpressions. The comments show a version with fewer parens.
 	{`(a){0,2}`, `(?:(a)(a)?)?`},                       //       (aa?)?
 	{`(a){0,4}`, `(?:(a)(?:(a)(?:(a)(a)?)?)?)?`},       //   (a(a(aa?)?)?)?
 	{`(a){2,6}`, `(a)(a)(?:(a)(?:(a)(?:(a)(a)?)?)?)?`}, // aa(a(a(aa?)?)?)?
@@ -117,7 +117,7 @@ var simplifyTests = []struct {
 	// Empty string as a regular expression.
 	// The empty string must be preserved inside parens in order
 	// to make submatches work right, so these tests are less
-	// interesting than they might otherwise be.  String inserts
+	// interesting than they might otherwise be. String inserts
 	// explicit (?:) in place of non-parenthesized empty strings,
 	// to make them easier to spot for other parsers.
 	{`(a|b|)`, `([a-b]|(?:))`},
diff --git a/src/runtime/alg.go b/src/runtime/alg.go
index e507e71715..7aacc8cf9b 100644
--- a/src/runtime/alg.go
+++ b/src/runtime/alg.go
@@ -64,7 +64,7 @@ func memhash128(p unsafe.Pointer, h uintptr) uintptr {
 }
 
 // memhash_varlen is defined in assembly because it needs access
-// to the closure.  It appears here to provide an argument
+// to the closure. It appears here to provide an argument
 // signature for the assembly routine.
 func memhash_varlen(p unsafe.Pointer, h uintptr) uintptr
 
diff --git a/src/runtime/asm_386.s b/src/runtime/asm_386.s
index 9237d57f24..2d16f4940a 100644
--- a/src/runtime/asm_386.s
+++ b/src/runtime/asm_386.s
@@ -226,7 +226,7 @@ TEXT runtime·gogo(SB), NOSPLIT, $0-4
 
 // func mcall(fn func(*g))
 // Switch to m->g0's stack, call fn(g).
-// Fn must never return.  It should gogo(&g->sched)
+// Fn must never return. It should gogo(&g->sched)
 // to keep running g.
 TEXT runtime·mcall(SB), NOSPLIT, $0-4
 	MOVL	fn+0(FP), DI
@@ -259,7 +259,7 @@ TEXT runtime·mcall(SB), NOSPLIT, $0-4
 	RET
 
 // systemstack_switch is a dummy routine that systemstack leaves at the bottom
-// of the G stack.  We need to distinguish the routine that
+// of the G stack. We need to distinguish the routine that
 // lives at the bottom of the G stack from the one that lives
 // at the top of the system stack because the one at the top of
 // the system stack terminates the stack walk (see topofstack()).
@@ -291,7 +291,7 @@ TEXT runtime·systemstack(SB), NOSPLIT, $0-4
 	CALL	AX
 
 switch:
-	// save our state in g->sched.  Pretend to
+	// save our state in g->sched. Pretend to
 	// be systemstack_switch if the G stack is scanned.
 	MOVL	$runtime·systemstack_switch(SB), (g_sched+gobuf_pc)(AX)
 	MOVL	SP, (g_sched+gobuf_sp)(AX)
@@ -900,7 +900,7 @@ final1:
 	RET
 
 endofpage:
-	// address ends in 1111xxxx.  Might be up against
+	// address ends in 1111xxxx. Might be up against
 	// a page boundary, so load ending at last byte.
 	// Then shift bytes down using pshufb.
 	MOVOU	-32(AX)(BX*1), X1
@@ -1145,7 +1145,7 @@ DATA masks<>+0xfc(SB)/4, $0x00ffffff
 
 GLOBL masks<>(SB),RODATA,$256
 
-// these are arguments to pshufb.  They move data down from
+// these are arguments to pshufb. They move data down from
 // the high bytes of the register to the low bytes of the register.
 // index is how many bytes to move.
 DATA shifts<>+0x00(SB)/4, $0x00000000
@@ -1370,7 +1370,7 @@ small:
 	MOVL	(SI), SI
 	JMP	si_finish
 si_high:
-	// address ends in 111111xx.  Load up to bytes we want, move to correct position.
+	// address ends in 111111xx. Load up to bytes we want, move to correct position.
 	MOVL	-4(SI)(BX*1), SI
 	SHRL	CX, SI
 si_finish:
@@ -1606,7 +1606,7 @@ TEXT runtime·prefetcht2(SB),NOSPLIT,$0-4
 TEXT runtime·prefetchnta(SB),NOSPLIT,$0-4
 	RET
 
-// Add a module's moduledata to the linked list of moduledata objects.  This
+// Add a module's moduledata to the linked list of moduledata objects. This
 // is called from .init_array by a function generated in the linker and so
 // follows the platform ABI wrt register preservation -- it only touches AX,
 // CX (implicitly) and DX, but it does not follow the ABI wrt arguments:
diff --git a/src/runtime/asm_amd64.s b/src/runtime/asm_amd64.s
index ac4630c833..b4df1d80d7 100644
--- a/src/runtime/asm_amd64.s
+++ b/src/runtime/asm_amd64.s
@@ -203,7 +203,7 @@ TEXT runtime·gogo(SB), NOSPLIT, $0-8
 
 // func mcall(fn func(*g))
 // Switch to m->g0's stack, call fn(g).
-// Fn must never return.  It should gogo(&g->sched)
+// Fn must never return. It should gogo(&g->sched)
 // to keep running g.
 TEXT runtime·mcall(SB), NOSPLIT, $0-8
 	MOVQ	fn+0(FP), DI
@@ -237,7 +237,7 @@ TEXT runtime·mcall(SB), NOSPLIT, $0-8
 	RET
 
 // systemstack_switch is a dummy routine that systemstack leaves at the bottom
-// of the G stack.  We need to distinguish the routine that
+// of the G stack. We need to distinguish the routine that
 // lives at the bottom of the G stack from the one that lives
 // at the top of the system stack because the one at the top of
 // the system stack terminates the stack walk (see topofstack()).
@@ -268,7 +268,7 @@ TEXT runtime·systemstack(SB), NOSPLIT, $0-8
 	CALL	AX
 
 switch:
-	// save our state in g->sched.  Pretend to
+	// save our state in g->sched. Pretend to
 	// be systemstack_switch if the G stack is scanned.
 	MOVQ	$runtime·systemstack_switch(SB), SI
 	MOVQ	SI, (g_sched+gobuf_pc)(AX)
@@ -716,7 +716,7 @@ havem:
 	CALL	runtime·cgocallbackg(SB)
 	MOVQ	0(SP), R8
 
-	// Compute the size of the frame again.  FP and SP have
+	// Compute the size of the frame again. FP and SP have
 	// completely different values here than they did above,
 	// but only their difference matters.
 	LEAQ	fv+0(FP), AX
@@ -909,7 +909,7 @@ final1:
 	RET
 
 endofpage:
-	// address ends in 1111xxxx.  Might be up against
+	// address ends in 1111xxxx. Might be up against
 	// a page boundary, so load ending at last byte.
 	// Then shift bytes down using pshufb.
 	MOVOU	-32(AX)(CX*1), X1
@@ -1232,7 +1232,7 @@ TEXT ·checkASM(SB),NOSPLIT,$0-1
 	SETEQ	ret+0(FP)
 	RET
 
-// these are arguments to pshufb.  They move data down from
+// these are arguments to pshufb. They move data down from
 // the high bytes of the register to the low bytes of the register.
 // index is how many bytes to move.
 DATA shifts<>+0x00(SB)/8, $0x0000000000000000
@@ -1412,7 +1412,7 @@ small:
 	MOVQ	(SI), SI
 	JMP	si_finish
 si_high:
-	// address ends in 11111xxx.  Load up to bytes we want, move to correct position.
+	// address ends in 11111xxx. Load up to bytes we want, move to correct position.
 	MOVQ	-8(SI)(BX*1), SI
 	SHRQ	CX, SI
 si_finish:
@@ -1872,7 +1872,7 @@ sseloopentry:
 	CMPQ	DI, AX
 	JB	sseloop
 
-	// Search the last 16-byte chunk.  This chunk may overlap with the
+	// Search the last 16-byte chunk. This chunk may overlap with the
 	// chunks we've already searched, but that's ok.
 	MOVQ	AX, DI
 	MOVOU	(AX), X1
diff --git a/src/runtime/asm_amd64p32.s b/src/runtime/asm_amd64p32.s
index ae7a53821b..452ce04143 100644
--- a/src/runtime/asm_amd64p32.s
+++ b/src/runtime/asm_amd64p32.s
@@ -133,7 +133,7 @@ TEXT runtime·gogo(SB), NOSPLIT, $0-4
 
 // func mcall(fn func(*g))
 // Switch to m->g0's stack, call fn(g).
-// Fn must never return.  It should gogo(&g->sched)
+// Fn must never return. It should gogo(&g->sched)
 // to keep running g.
 TEXT runtime·mcall(SB), NOSPLIT, $0-4
 	MOVL	fn+0(FP), DI
@@ -166,7 +166,7 @@ TEXT runtime·mcall(SB), NOSPLIT, $0-4
 	RET
 
 // systemstack_switch is a dummy routine that systemstack leaves at the bottom
-// of the G stack.  We need to distinguish the routine that
+// of the G stack. We need to distinguish the routine that
 // lives at the bottom of the G stack from the one that lives
 // at the top of the system stack because the one at the top of
 // the system stack terminates the stack walk (see topofstack()).
@@ -198,7 +198,7 @@ TEXT runtime·systemstack(SB), NOSPLIT, $0-4
 	CALL	AX
 
 switch:
-	// save our state in g->sched.  Pretend to
+	// save our state in g->sched. Pretend to
 	// be systemstack_switch if the G stack is scanned.
 	MOVL	$runtime·systemstack_switch(SB), SI
 	MOVL	SI, (g_sched+gobuf_pc)(AX)
@@ -491,7 +491,7 @@ TEXT runtime·memclr(SB),NOSPLIT,$0-8
 	REP
 	STOSB
 	// Note: we zero only 4 bytes at a time so that the tail is at most
-	// 3 bytes.  That guarantees that we aren't zeroing pointers with STOSB.
+	// 3 bytes. That guarantees that we aren't zeroing pointers with STOSB.
 	// See issue 13160.
 	RET
 
@@ -692,7 +692,7 @@ small:
 	MOVQ	(SI), SI
 	JMP	si_finish
 si_high:
-	// address ends in 11111xxx.  Load up to bytes we want, move to correct position.
+	// address ends in 11111xxx. Load up to bytes we want, move to correct position.
 	MOVQ	BX, DX
 	ADDQ	SI, DX
 	MOVQ	-8(DX), SI
diff --git a/src/runtime/asm_arm.s b/src/runtime/asm_arm.s
index 2fdfbea0e1..46f8474f54 100644
--- a/src/runtime/asm_arm.s
+++ b/src/runtime/asm_arm.s
@@ -153,7 +153,7 @@ TEXT runtime·gogo(SB),NOSPLIT,$-4-4
 
 // func mcall(fn func(*g))
 // Switch to m->g0's stack, call fn(g).
-// Fn must never return.  It should gogo(&g->sched)
+// Fn must never return. It should gogo(&g->sched)
 // to keep running g.
 TEXT runtime·mcall(SB),NOSPLIT,$-4-4
 	// Save caller state in g->sched.
@@ -185,7 +185,7 @@ TEXT runtime·mcall(SB),NOSPLIT,$-4-4
 	RET
 
 // systemstack_switch is a dummy routine that systemstack leaves at the bottom
-// of the G stack.  We need to distinguish the routine that
+// of the G stack. We need to distinguish the routine that
 // lives at the bottom of the G stack from the one that lives
 // at the top of the system stack because the one at the top of
 // the system stack terminates the stack walk (see topofstack()).
@@ -217,7 +217,7 @@ TEXT runtime·systemstack(SB),NOSPLIT,$0-4
 	BL	(R0)
 
 switch:
-	// save our state in g->sched.  Pretend to
+	// save our state in g->sched. Pretend to
 	// be systemstack_switch if the G stack is scanned.
 	MOVW	$runtime·systemstack_switch(SB), R3
 #ifdef GOOS_nacl
@@ -973,7 +973,7 @@ yieldloop:
 // Called from cgo wrappers, this function returns g->m->curg.stack.hi.
 // Must obey the gcc calling convention.
 TEXT _cgo_topofstack(SB),NOSPLIT,$8
-	// R11 and g register are clobbered by load_g.  They are
+	// R11 and g register are clobbered by load_g. They are
 	// callee-save in the gcc calling convention, so save them here.
 	MOVW	R11, saveR11-4(SP)
 	MOVW	g, saveG-8(SP)
diff --git a/src/runtime/asm_arm64.s b/src/runtime/asm_arm64.s
index 5a5c64c270..e06aa11a5d 100644
--- a/src/runtime/asm_arm64.s
+++ b/src/runtime/asm_arm64.s
@@ -149,7 +149,7 @@ TEXT runtime·gogo(SB), NOSPLIT, $-8-8
 
 // void mcall(fn func(*g))
 // Switch to m->g0's stack, call fn(g).
-// Fn must never return.  It should gogo(&g->sched)
+// Fn must never return. It should gogo(&g->sched)
 // to keep running g.
 TEXT runtime·mcall(SB), NOSPLIT, $-8-8
 	// Save caller state in g->sched
@@ -178,7 +178,7 @@ TEXT runtime·mcall(SB), NOSPLIT, $-8-8
 	B	runtime·badmcall2(SB)
 
 // systemstack_switch is a dummy routine that systemstack leaves at the bottom
-// of the G stack.  We need to distinguish the routine that
+// of the G stack. We need to distinguish the routine that
 // lives at the bottom of the G stack from the one that lives
 // at the top of the system stack because the one at the top of
 // the system stack terminates the stack walk (see topofstack()).
@@ -211,7 +211,7 @@ TEXT runtime·systemstack(SB), NOSPLIT, $0-8
 	BL	(R3)
 
 switch:
-	// save our state in g->sched.  Pretend to
+	// save our state in g->sched. Pretend to
 	// be systemstack_switch if the G stack is scanned.
 	MOVD	$runtime·systemstack_switch(SB), R6
 	ADD	$8, R6	// get past prologue
@@ -542,7 +542,7 @@ g0:
 	BL	(R1)
 	MOVD	R0, R9
 
-	// Restore g, stack pointer.  R0 is errno, so don't touch it
+	// Restore g, stack pointer. R0 is errno, so don't touch it
 	MOVD	0(RSP), g
 	BL	runtime·save_g(SB)
 	MOVD	(g_stack+stack_hi)(g), R5
diff --git a/src/runtime/asm_mips64x.s b/src/runtime/asm_mips64x.s
index 80cea8587a..1ffa3ae348 100644
--- a/src/runtime/asm_mips64x.s
+++ b/src/runtime/asm_mips64x.s
@@ -130,7 +130,7 @@ TEXT runtime·gogo(SB), NOSPLIT, $-8-8
 
 // void mcall(fn func(*g))
 // Switch to m->g0's stack, call fn(g).
-// Fn must never return.  It should gogo(&g->sched)
+// Fn must never return. It should gogo(&g->sched)
 // to keep running g.
 TEXT runtime·mcall(SB), NOSPLIT, $-8-8
 	// Save caller state in g->sched
@@ -156,7 +156,7 @@ TEXT runtime·mcall(SB), NOSPLIT, $-8-8
 	JMP	runtime·badmcall2(SB)
 
 // systemstack_switch is a dummy routine that systemstack leaves at the bottom
-// of the G stack.  We need to distinguish the routine that
+// of the G stack. We need to distinguish the routine that
 // lives at the bottom of the G stack from the one that lives
 // at the top of the system stack because the one at the top of
 // the system stack terminates the stack walk (see topofstack()).
@@ -186,7 +186,7 @@ TEXT runtime·systemstack(SB), NOSPLIT, $0-8
 	JAL	(R4)
 
 switch:
-	// save our state in g->sched.  Pretend to
+	// save our state in g->sched. Pretend to
 	// be systemstack_switch if the G stack is scanned.
 	MOVV	$runtime·systemstack_switch(SB), R4
 	ADDV	$8, R4	// get past prologue
diff --git a/src/runtime/asm_ppc64x.h b/src/runtime/asm_ppc64x.h
index d6ae67fab9..5e55055fdb 100644
--- a/src/runtime/asm_ppc64x.h
+++ b/src/runtime/asm_ppc64x.h
@@ -14,7 +14,7 @@
 // +---------------------+ <- R1
 //
 // So a function that sets up a stack frame at all uses as least FIXED_FRAME
-// bytes of stack.  This mostly affects assembly that calls other functions
+// bytes of stack. This mostly affects assembly that calls other functions
 // with arguments (the arguments should be stored at FIXED_FRAME+0(R1),
 // FIXED_FRAME+8(R1) etc) and some other low-level places.
 //
diff --git a/src/runtime/asm_ppc64x.s b/src/runtime/asm_ppc64x.s
index f067b4a9b9..59bc8a22dd 100644
--- a/src/runtime/asm_ppc64x.s
+++ b/src/runtime/asm_ppc64x.s
@@ -155,7 +155,7 @@ TEXT runtime·gogo(SB), NOSPLIT|NOFRAME, $0-8
 
 // void mcall(fn func(*g))
 // Switch to m->g0's stack, call fn(g).
-// Fn must never return.  It should gogo(&g->sched)
+// Fn must never return. It should gogo(&g->sched)
 // to keep running g.
 TEXT runtime·mcall(SB), NOSPLIT|NOFRAME, $0-8
 	// Save caller state in g->sched
@@ -187,7 +187,7 @@ TEXT runtime·mcall(SB), NOSPLIT|NOFRAME, $0-8
 	BR	runtime·badmcall2(SB)
 
 // systemstack_switch is a dummy routine that systemstack leaves at the bottom
-// of the G stack.  We need to distinguish the routine that
+// of the G stack. We need to distinguish the routine that
 // lives at the bottom of the G stack from the one that lives
 // at the top of the system stack because the one at the top of
 // the system stack terminates the stack walk (see topofstack()).
@@ -226,7 +226,7 @@ TEXT runtime·systemstack(SB), NOSPLIT, $0-8
 	BL	(CTR)
 
 switch:
-	// save our state in g->sched.  Pretend to
+	// save our state in g->sched. Pretend to
 	// be systemstack_switch if the G stack is scanned.
 	MOVD	$runtime·systemstack_switch(SB), R6
 	ADD     $16, R6 // get past prologue (including r2-setting instructions when they're there)
diff --git a/src/runtime/cgo/callbacks.go b/src/runtime/cgo/callbacks.go
index eea0371c87..47bd2b0edc 100644
--- a/src/runtime/cgo/callbacks.go
+++ b/src/runtime/cgo/callbacks.go
@@ -22,7 +22,7 @@ func _runtime_cgocallback(unsafe.Pointer, unsafe.Pointer, uintptr)
 //go:cgo_export_static crosscall2
 //go:cgo_export_dynamic crosscall2
 
-// Panic.  The argument is converted into a Go string.
+// Panic. The argument is converted into a Go string.
 
 // Call like this in code compiled with gcc:
 //   struct { const char *p; } a;
@@ -69,7 +69,7 @@ var _cgo_thread_start = &x_cgo_thread_start
 // Creates a new system thread without updating any Go state.
 //
 // This method is invoked during shared library loading to create a new OS
-// thread to perform the runtime initialization.  This method is similar to
+// thread to perform the runtime initialization. This method is similar to
 // _cgo_sys_thread_start except that it doesn't update any Go state.
 
 //go:cgo_import_static x_cgo_sys_thread_create
@@ -82,7 +82,7 @@ var _cgo_sys_thread_create = &x_cgo_sys_thread_create
 //
 // We currently block at every CGO entry point (via _cgo_wait_runtime_init_done)
 // to ensure that the runtime has been initialized before the CGO call is
-// executed.  This is necessary for shared libraries where we kickoff runtime
+// executed. This is necessary for shared libraries where we kickoff runtime
 // initialization in a separate thread and return without waiting for this
 // thread to complete the init.
 
diff --git a/src/runtime/cgo/gcc_dragonfly_amd64.c b/src/runtime/cgo/gcc_dragonfly_amd64.c
index 5f26136916..85c53ca707 100644
--- a/src/runtime/cgo/gcc_dragonfly_amd64.c
+++ b/src/runtime/cgo/gcc_dragonfly_amd64.c
@@ -69,11 +69,11 @@ threadentry(void *v)
 	setg_gcc((void*)ts.g);
 
 	// On DragonFly, a new thread inherits the signal stack of the
-	// creating thread.  That confuses minit, so we remove that
-	// signal stack here before calling the regular mstart.  It's
+	// creating thread. That confuses minit, so we remove that
+	// signal stack here before calling the regular mstart. It's
 	// a bit baroque to remove a signal stack here only to add one
 	// in minit, but it's a simple change that keeps DragonFly
-	// working like other OS's.  At this point all signals are
+	// working like other OS's. At this point all signals are
 	// blocked, so there is no race.
 	memset(&ss, 0, sizeof ss);
 	ss.ss_flags = SS_DISABLE;
diff --git a/src/runtime/cgo/gcc_freebsd_arm.c b/src/runtime/cgo/gcc_freebsd_arm.c
index 8c294aa6d7..73f32792c5 100644
--- a/src/runtime/cgo/gcc_freebsd_arm.c
+++ b/src/runtime/cgo/gcc_freebsd_arm.c
@@ -53,7 +53,7 @@ _cgo_sys_thread_start(ThreadStart *ts)
 
 	// Not sure why the memset is necessary here,
 	// but without it, we get a bogus stack size
-	// out of pthread_attr_getstacksize.  C'est la Linux.
+	// out of pthread_attr_getstacksize. C'est la Linux.
 	memset(&attr, 0, sizeof attr);
 	pthread_attr_init(&attr);
 	size = 0;
diff --git a/src/runtime/cgo/gcc_linux_386.c b/src/runtime/cgo/gcc_linux_386.c
index 380441c0d4..15e0a8a302 100644
--- a/src/runtime/cgo/gcc_linux_386.c
+++ b/src/runtime/cgo/gcc_linux_386.c
@@ -48,7 +48,7 @@ _cgo_sys_thread_start(ThreadStart *ts)
 
 	// Not sure why the memset is necessary here,
 	// but without it, we get a bogus stack size
-	// out of pthread_attr_getstacksize.  C'est la Linux.
+	// out of pthread_attr_getstacksize. C'est la Linux.
 	memset(&attr, 0, sizeof attr);
 	pthread_attr_init(&attr);
 	size = 0;
diff --git a/src/runtime/cgo/gcc_linux_arm.c b/src/runtime/cgo/gcc_linux_arm.c
index fdcc343d19..f552421957 100644
--- a/src/runtime/cgo/gcc_linux_arm.c
+++ b/src/runtime/cgo/gcc_linux_arm.c
@@ -28,7 +28,7 @@ _cgo_sys_thread_start(ThreadStart *ts)
 
 	// Not sure why the memset is necessary here,
 	// but without it, we get a bogus stack size
-	// out of pthread_attr_getstacksize.  C'est la Linux.
+	// out of pthread_attr_getstacksize. C'est la Linux.
 	memset(&attr, 0, sizeof attr);
 	pthread_attr_init(&attr);
 	size = 0;
diff --git a/src/runtime/cgo/gcc_linux_arm64.c b/src/runtime/cgo/gcc_linux_arm64.c
index a7b5ddf5b6..84bd7c0b49 100644
--- a/src/runtime/cgo/gcc_linux_arm64.c
+++ b/src/runtime/cgo/gcc_linux_arm64.c
@@ -28,7 +28,7 @@ _cgo_sys_thread_start(ThreadStart *ts)
 
 	// Not sure why the memset is necessary here,
 	// but without it, we get a bogus stack size
-	// out of pthread_attr_getstacksize.  C'est la Linux.
+	// out of pthread_attr_getstacksize. C'est la Linux.
 	memset(&attr, 0, sizeof attr);
 	pthread_attr_init(&attr);
 	size = 0;
diff --git a/src/runtime/cgo/gcc_netbsd_386.c b/src/runtime/cgo/gcc_netbsd_386.c
index ba4fa6e425..32f2e15678 100644
--- a/src/runtime/cgo/gcc_netbsd_386.c
+++ b/src/runtime/cgo/gcc_netbsd_386.c
@@ -68,11 +68,11 @@ threadentry(void *v)
 	setg_gcc((void*)ts.g);
 
 	// On NetBSD, a new thread inherits the signal stack of the
-	// creating thread.  That confuses minit, so we remove that
-	// signal stack here before calling the regular mstart.  It's
+	// creating thread. That confuses minit, so we remove that
+	// signal stack here before calling the regular mstart. It's
 	// a bit baroque to remove a signal stack here only to add one
 	// in minit, but it's a simple change that keeps NetBSD
-	// working like other OS's.  At this point all signals are
+	// working like other OS's. At this point all signals are
 	// blocked, so there is no race.
 	memset(&ss, 0, sizeof ss);
 	ss.ss_flags = SS_DISABLE;
diff --git a/src/runtime/cgo/gcc_netbsd_amd64.c b/src/runtime/cgo/gcc_netbsd_amd64.c
index 035c4ff482..aa357459c7 100644
--- a/src/runtime/cgo/gcc_netbsd_amd64.c
+++ b/src/runtime/cgo/gcc_netbsd_amd64.c
@@ -69,11 +69,11 @@ threadentry(void *v)
 	setg_gcc((void*)ts.g);
 
 	// On NetBSD, a new thread inherits the signal stack of the
-	// creating thread.  That confuses minit, so we remove that
-	// signal stack here before calling the regular mstart.  It's
+	// creating thread. That confuses minit, so we remove that
+	// signal stack here before calling the regular mstart. It's
 	// a bit baroque to remove a signal stack here only to add one
 	// in minit, but it's a simple change that keeps NetBSD
-	// working like other OS's.  At this point all signals are
+	// working like other OS's. At this point all signals are
 	// blocked, so there is no race.
 	memset(&ss, 0, sizeof ss);
 	ss.ss_flags = SS_DISABLE;
diff --git a/src/runtime/cgo/gcc_netbsd_arm.c b/src/runtime/cgo/gcc_netbsd_arm.c
index 5b8553e830..9589780ac8 100644
--- a/src/runtime/cgo/gcc_netbsd_arm.c
+++ b/src/runtime/cgo/gcc_netbsd_arm.c
@@ -65,11 +65,11 @@ threadentry(void *v)
 	free(v);
 
 	// On NetBSD, a new thread inherits the signal stack of the
-	// creating thread.  That confuses minit, so we remove that
-	// signal stack here before calling the regular mstart.  It's
+	// creating thread. That confuses minit, so we remove that
+	// signal stack here before calling the regular mstart. It's
 	// a bit baroque to remove a signal stack here only to add one
 	// in minit, but it's a simple change that keeps NetBSD
-	// working like other OS's.  At this point all signals are
+	// working like other OS's. At this point all signals are
 	// blocked, so there is no race.
 	memset(&ss, 0, sizeof ss);
 	ss.ss_flags = SS_DISABLE;
diff --git a/src/runtime/cgo/iscgo.go b/src/runtime/cgo/iscgo.go
index 7604132170..e12d0f4b95 100644
--- a/src/runtime/cgo/iscgo.go
+++ b/src/runtime/cgo/iscgo.go
@@ -3,10 +3,10 @@
 // license that can be found in the LICENSE file.
 
 // The runtime package contains an uninitialized definition
-// for runtime·iscgo.  Override it to tell the runtime we're here.
+// for runtime·iscgo. Override it to tell the runtime we're here.
 // There are various function pointers that should be set too,
 // but those depend on dynamic linker magic to get initialized
-// correctly, and sometimes they break.  This variable is a
+// correctly, and sometimes they break. This variable is a
 // backup: it depends only on old C style static linking rules.
 
 package cgo
diff --git a/src/runtime/cgo/mmap.go b/src/runtime/cgo/mmap.go
index 6a4dc1562d..ff983599be 100644
--- a/src/runtime/cgo/mmap.go
+++ b/src/runtime/cgo/mmap.go
@@ -10,8 +10,8 @@ package cgo
 import _ "unsafe"
 
 // When using cgo, call the C library for mmap, so that we call into
-// any sanitizer interceptors.  This supports using the memory
-// sanitizer with Go programs.  The memory sanitizer only applies to
+// any sanitizer interceptors. This supports using the memory
+// sanitizer with Go programs. The memory sanitizer only applies to
 // C/C++ code; this permits that code to see the Go code as normal
 // program addresses that have been initialized.
 
diff --git a/src/runtime/cgo_mmap.go b/src/runtime/cgo_mmap.go
index dca1e22ad3..a23cc79b7e 100644
--- a/src/runtime/cgo_mmap.go
+++ b/src/runtime/cgo_mmap.go
@@ -2,7 +2,7 @@
 // Use of this source code is governed by a BSD-style
 // license that can be found in the LICENSE file.
 
-// Support for memory sanitizer.  See runtime/cgo/mmap.go.
+// Support for memory sanitizer. See runtime/cgo/mmap.go.
 
 // +build linux,amd64
 
@@ -32,10 +32,10 @@ func mmap(addr unsafe.Pointer, n uintptr, prot, flags, fd int32, off uint32) uns
 	return sysMmap(addr, n, prot, flags, fd, off)
 }
 
-// sysMmap calls the mmap system call.  It is implemented in assembly.
+// sysMmap calls the mmap system call. It is implemented in assembly.
 func sysMmap(addr unsafe.Pointer, n uintptr, prot, flags, fd int32, off uint32) unsafe.Pointer
 
 // cgoMmap calls the mmap function in the runtime/cgo package on the
 // callCgoMmap calls the mmap function in the runtime/cgo package
-// using the GCC calling convention.  It is implemented in assembly.
+// using the GCC calling convention. It is implemented in assembly.
 func callCgoMmap(addr unsafe.Pointer, n uintptr, prot, flags, fd int32, off uint32) uintptr
diff --git a/src/runtime/cgocall.go b/src/runtime/cgocall.go
index 5c9a73734c..9514c0ba9a 100644
--- a/src/runtime/cgocall.go
+++ b/src/runtime/cgocall.go
@@ -28,7 +28,7 @@
 // and then unlocks g from m.
 //
 // The above description skipped over the possibility of the gcc-compiled
-// function f calling back into Go.  If that happens, we continue down
+// function f calling back into Go. If that happens, we continue down
 // the rabbit hole during the execution of f.
 //
 // To make it possible for gcc-compiled C code to call a Go function p.GoF,
@@ -38,9 +38,9 @@
 // GoF calls crosscall2(_cgoexp_GoF, frame, framesize).  Crosscall2
 // (in cgo/gcc_$GOARCH.S, a gcc-compiled assembly file) is a two-argument
 // adapter from the gcc function call ABI to the 6c function call ABI.
-// It is called from gcc to call 6c functions.  In this case it calls
+// It is called from gcc to call 6c functions. In this case it calls
 // _cgoexp_GoF(frame, framesize), still running on m->g0's stack
-// and outside the $GOMAXPROCS limit.  Thus, this code cannot yet
+// and outside the $GOMAXPROCS limit. Thus, this code cannot yet
 // call arbitrary Go code directly and must be careful not to allocate
 // memory or use up m->g0's stack.
 //
@@ -317,8 +317,8 @@ var racecgosync uint64 // represents possible synchronization in C code
 
 // We want to detect all cases where a program that does not use
 // unsafe makes a cgo call passing a Go pointer to memory that
-// contains a Go pointer.  Here a Go pointer is defined as a pointer
-// to memory allocated by the Go runtime.  Programs that use unsafe
+// contains a Go pointer. Here a Go pointer is defined as a pointer
+// to memory allocated by the Go runtime. Programs that use unsafe
 // can evade this restriction easily, so we don't try to catch them.
 // The cgo program will rewrite all possibly bad pointer arguments to
 // call cgoCheckPointer, where we can catch cases of a Go pointer
@@ -326,14 +326,14 @@ var racecgosync uint64 // represents possible synchronization in C code
 
 // Complicating matters, taking the address of a slice or array
 // element permits the C program to access all elements of the slice
-// or array.  In that case we will see a pointer to a single element,
+// or array. In that case we will see a pointer to a single element,
 // but we need to check the entire data structure.
 
 // The cgoCheckPointer call takes additional arguments indicating that
-// it was called on an address expression.  An additional argument of
-// true means that it only needs to check a single element.  An
+// it was called on an address expression. An additional argument of
+// true means that it only needs to check a single element. An
 // additional argument of a slice or array means that it needs to
-// check the entire slice/array, but nothing else.  Otherwise, the
+// check the entire slice/array, but nothing else. Otherwise, the
 // pointer could be anything, and we check the entire heap object,
 // which is conservative but safe.
 
@@ -344,7 +344,7 @@ var racecgosync uint64 // represents possible synchronization in C code
 // pointers.)
 
 // cgoCheckPointer checks if the argument contains a Go pointer that
-// points to a Go pointer, and panics if it does.  It returns the pointer.
+// points to a Go pointer, and panics if it does. It returns the pointer.
 func cgoCheckPointer(ptr interface{}, args ...interface{}) interface{} {
 	if debug.cgocheck == 0 {
 		return ptr
@@ -395,9 +395,9 @@ func cgoCheckPointer(ptr interface{}, args ...interface{}) interface{} {
 const cgoCheckPointerFail = "cgo argument has Go pointer to Go pointer"
 const cgoResultFail = "cgo result has Go pointer"
 
-// cgoCheckArg is the real work of cgoCheckPointer.  The argument p
+// cgoCheckArg is the real work of cgoCheckPointer. The argument p
 // is either a pointer to the value (of type t), or the value itself,
-// depending on indir.  The top parameter is whether we are at the top
+// depending on indir. The top parameter is whether we are at the top
 // level, where Go pointers are allowed.
 func cgoCheckArg(t *_type, p unsafe.Pointer, indir, top bool, msg string) {
 	if t.kind&kindNoPointers != 0 {
@@ -423,7 +423,7 @@ func cgoCheckArg(t *_type, p unsafe.Pointer, indir, top bool, msg string) {
 		}
 	case kindChan, kindMap:
 		// These types contain internal pointers that will
-		// always be allocated in the Go heap.  It's never OK
+		// always be allocated in the Go heap. It's never OK
 		// to pass them to C.
 		panic(errorString(msg))
 	case kindFunc:
@@ -440,7 +440,7 @@ func cgoCheckArg(t *_type, p unsafe.Pointer, indir, top bool, msg string) {
 			return
 		}
 		// A type known at compile time is OK since it's
-		// constant.  A type not known at compile time will be
+		// constant. A type not known at compile time will be
 		// in the heap and will not be OK.
 		if inheap(uintptr(unsafe.Pointer(it))) {
 			panic(errorString(msg))
@@ -507,8 +507,8 @@ func cgoCheckArg(t *_type, p unsafe.Pointer, indir, top bool, msg string) {
 }
 
 // cgoCheckUnknownPointer is called for an arbitrary pointer into Go
-// memory.  It checks whether that Go memory contains any other
-// pointer into Go memory.  If it does, we panic.
+// memory. It checks whether that Go memory contains any other
+// pointer into Go memory. If it does, we panic.
 // The return values are unused but useful to see in panic tracebacks.
 func cgoCheckUnknownPointer(p unsafe.Pointer, msg string) (base, i uintptr) {
 	if cgoInRange(p, mheap_.arena_start, mheap_.arena_used) {
@@ -559,7 +559,7 @@ func cgoCheckUnknownPointer(p unsafe.Pointer, msg string) (base, i uintptr) {
 }
 
 // cgoIsGoPointer returns whether the pointer is a Go pointer--a
-// pointer to Go memory.  We only care about Go memory that might
+// pointer to Go memory. We only care about Go memory that might
 // contain pointers.
 //go:nosplit
 //go:nowritebarrierrec
@@ -589,7 +589,7 @@ func cgoInRange(p unsafe.Pointer, start, end uintptr) bool {
 }
 
 // cgoCheckResult is called to check the result parameter of an
-// exported Go function.  It panics if the result is or contains a Go
+// exported Go function. It panics if the result is or contains a Go
 // pointer.
 func cgoCheckResult(val interface{}) {
 	if debug.cgocheck == 0 {
diff --git a/src/runtime/cgocheck.go b/src/runtime/cgocheck.go
index 0d46dde59d..d85d5fe5a8 100644
--- a/src/runtime/cgocheck.go
+++ b/src/runtime/cgocheck.go
@@ -89,7 +89,7 @@ func cgoCheckSliceCopy(typ *_type, dst, src slice, n int) {
 }
 
 // cgoCheckTypedBlock checks the block of memory at src, for up to size bytes,
-// and throws if it finds a Go pointer.  The type of the memory is typ,
+// and throws if it finds a Go pointer. The type of the memory is typ,
 // and src is off bytes into that type.
 //go:nosplit
 //go:nowritebarrier
@@ -99,7 +99,7 @@ func cgoCheckTypedBlock(typ *_type, src unsafe.Pointer, off, size uintptr) {
 		return
 	}
 
-	// The type has a GC program.  Try to find GC bits somewhere else.
+	// The type has a GC program. Try to find GC bits somewhere else.
 	for datap := &firstmoduledata; datap != nil; datap = datap.next {
 		if cgoInRange(src, datap.data, datap.edata) {
 			doff := uintptr(src) - datap.data
@@ -148,8 +148,8 @@ func cgoCheckTypedBlock(typ *_type, src unsafe.Pointer, off, size uintptr) {
 }
 
 // cgoCheckBits checks the block of memory at src, for up to size
-// bytes, and throws if it finds a Go pointer.  The gcbits mark each
-// pointer value.  The src pointer is off bytes into the gcbits.
+// bytes, and throws if it finds a Go pointer. The gcbits mark each
+// pointer value. The src pointer is off bytes into the gcbits.
 //go:nosplit
 //go:nowritebarrier
 func cgoCheckBits(src unsafe.Pointer, gcbits *byte, off, size uintptr) {
@@ -186,7 +186,7 @@ func cgoCheckBits(src unsafe.Pointer, gcbits *byte, off, size uintptr) {
 // fall back to look for pointers in src using the type information.
 // We only this when looking at a value on the stack when the type
 // uses a GC program, because otherwise it's more efficient to use the
-// GC bits.  This is called on the system stack.
+// GC bits. This is called on the system stack.
 //go:nowritebarrier
 //go:systemstack
 func cgoCheckUsingType(typ *_type, src unsafe.Pointer, off, size uintptr) {
diff --git a/src/runtime/chan.go b/src/runtime/chan.go
index f6f3ce4d90..2fc0839600 100644
--- a/src/runtime/chan.go
+++ b/src/runtime/chan.go
@@ -175,7 +175,7 @@ func chansend(t *chantype, c *hchan, ep unsafe.Pointer, block bool, callerpc uin
 	}
 
 	if c.qcount < c.dataqsiz {
-		// Space is available in the channel buffer.  Enqueue the element to send.
+		// Space is available in the channel buffer. Enqueue the element to send.
 		qp := chanbuf(c, c.sendx)
 		if raceenabled {
 			raceacquire(qp)
@@ -196,7 +196,7 @@ func chansend(t *chantype, c *hchan, ep unsafe.Pointer, block bool, callerpc uin
 		return false
 	}
 
-	// Block on the channel.  Some receiver will complete our operation for us.
+	// Block on the channel. Some receiver will complete our operation for us.
 	gp := getg()
 	mysg := acquireSudog()
 	mysg.releasetime = 0
@@ -245,7 +245,7 @@ func send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func()) {
 			racesync(c, sg)
 		} else {
 			// Pretend we go through the buffer, even though
-			// we copy directly.  Note that we need to increment
+			// we copy directly. Note that we need to increment
 			// the head/tail locations only when raceenabled.
 			qp := chanbuf(c, c.recvx)
 			raceacquire(qp)
@@ -422,8 +422,8 @@ func chanrecv(t *chantype, c *hchan, ep unsafe.Pointer, block bool) (selected, r
 	}
 
 	if sg := c.sendq.dequeue(); sg != nil {
-		// Found a waiting sender.  If buffer is size 0, receive value
-		// directly from sender.  Otherwise, receive from head of queue
+		// Found a waiting sender. If buffer is size 0, receive value
+		// directly from sender. Otherwise, receive from head of queue
 		// and add sender's value to the tail of the queue (both map to
 		// the same buffer slot because the queue is full).
 		recv(c, sg, ep, func() { unlock(&c.lock) })
@@ -513,9 +513,9 @@ func recv(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func()) {
 			typedmemmove(c.elemtype, ep, sg.elem)
 		}
 	} else {
-		// Queue is full.  Take the item at the
-		// head of the queue.  Make the sender enqueue
-		// its item at the tail of the queue.  Since the
+		// Queue is full. Take the item at the
+		// head of the queue. Make the sender enqueue
+		// its item at the tail of the queue. Since the
 		// queue is full, those are both the same slot.
 		qp := chanbuf(c, c.recvx)
 		if raceenabled {
diff --git a/src/runtime/compiler.go b/src/runtime/compiler.go
index 47e80b15ff..1ebc62dea1 100644
--- a/src/runtime/compiler.go
+++ b/src/runtime/compiler.go
@@ -5,7 +5,7 @@
 package runtime
 
 // Compiler is the name of the compiler toolchain that built the
-// running binary.  Known toolchains are:
+// running binary. Known toolchains are:
 //
 //	gc      Also known as cmd/compile.
 //	gccgo   The gccgo front end, part of the GCC compiler suite.
diff --git a/src/runtime/cpuprof.go b/src/runtime/cpuprof.go
index 6334104003..4b9dfafb90 100644
--- a/src/runtime/cpuprof.go
+++ b/src/runtime/cpuprof.go
@@ -12,30 +12,30 @@
 // writes to an operating system file.
 //
 // The signal handler for the profiling clock tick adds a new stack trace
-// to a hash table tracking counts for recent traces.  Most clock ticks
-// hit in the cache.  In the event of a cache miss, an entry must be
+// to a hash table tracking counts for recent traces. Most clock ticks
+// hit in the cache. In the event of a cache miss, an entry must be
 // evicted from the hash table, copied to a log that will eventually be
-// written as profile data.  The google-perftools code flushed the
-// log itself during the signal handler.  This code cannot do that, because
+// written as profile data. The google-perftools code flushed the
+// log itself during the signal handler. This code cannot do that, because
 // the io.Writer might block or need system calls or locks that are not
-// safe to use from within the signal handler.  Instead, we split the log
+// safe to use from within the signal handler. Instead, we split the log
 // into two halves and let the signal handler fill one half while a goroutine
-// is writing out the other half.  When the signal handler fills its half, it
-// offers to swap with the goroutine.  If the writer is not done with its half,
+// is writing out the other half. When the signal handler fills its half, it
+// offers to swap with the goroutine. If the writer is not done with its half,
 // we lose the stack trace for this clock tick (and record that loss).
 // The goroutine interacts with the signal handler by calling getprofile() to
 // get the next log piece to write, implicitly handing back the last log
 // piece it obtained.
 //
 // The state of this dance between the signal handler and the goroutine
-// is encoded in the Profile.handoff field.  If handoff == 0, then the goroutine
+// is encoded in the Profile.handoff field. If handoff == 0, then the goroutine
 // is not using either log half and is waiting (or will soon be waiting) for
 // a new piece by calling notesleep(&p.wait).  If the signal handler
 // changes handoff from 0 to non-zero, it must call notewakeup(&p.wait)
-// to wake the goroutine.  The value indicates the number of entries in the
-// log half being handed off.  The goroutine leaves the non-zero value in
+// to wake the goroutine. The value indicates the number of entries in the
+// log half being handed off. The goroutine leaves the non-zero value in
 // place until it has finished processing the log half and then flips the number
-// back to zero.  Setting the high bit in handoff means that the profiling is over,
+// back to zero. Setting the high bit in handoff means that the profiling is over,
 // and the goroutine is now in charge of flushing the data left in the hash table
 // to the log and returning that data.
 //
@@ -44,7 +44,7 @@
 // then the signal handler owns it and can change it to non-zero.
 // If handoff != 0 then the goroutine owns it and can change it to zero.
 // If that were the end of the story then we would not need to manipulate
-// handoff using atomic operations.  The operations are needed, however,
+// handoff using atomic operations. The operations are needed, however,
 // in order to let the log closer set the high bit to indicate "EOF" safely
 // in the situation when normally the goroutine "owns" handoff.
 
@@ -192,7 +192,7 @@ func SetCPUProfileRate(hz int) {
 // It is called from signal handlers and other limited environments
 // and cannot allocate memory or acquire locks that might be
 // held at the time of the signal, nor can it use substantial amounts
-// of stack.  It is allowed to call evict.
+// of stack. It is allowed to call evict.
 func (p *cpuProfile) add(pc []uintptr) {
 	if len(pc) > maxCPUProfStack {
 		pc = pc[:maxCPUProfStack]
@@ -232,7 +232,7 @@ Assoc:
 	}
 	if e.count > 0 {
 		if !p.evict(e) {
-			// Could not evict entry.  Record lost stack.
+			// Could not evict entry. Record lost stack.
 			p.lost++
 			return
 		}
@@ -248,7 +248,7 @@ Assoc:
 // evict copies the given entry's data into the log, so that
 // the entry can be reused.  evict is called from add, which
 // is called from the profiling signal handler, so it must not
-// allocate memory or block.  It is safe to call flushlog.
+// allocate memory or block. It is safe to call flushlog.
 // evict returns true if the entry was copied to the log,
 // false if there was no room available.
 func (p *cpuProfile) evict(e *cpuprofEntry) bool {
@@ -276,7 +276,7 @@ func (p *cpuProfile) evict(e *cpuprofEntry) bool {
 
 // flushlog tries to flush the current log and switch to the other one.
 // flushlog is called from evict, called from add, called from the signal handler,
-// so it cannot allocate memory or block.  It can try to swap logs with
+// so it cannot allocate memory or block. It can try to swap logs with
 // the writing goroutine, as explained in the comment at the top of this file.
 func (p *cpuProfile) flushlog() bool {
 	if !atomic.Cas(&p.handoff, 0, uint32(p.nlog)) {
@@ -300,7 +300,7 @@ func (p *cpuProfile) flushlog() bool {
 }
 
 // getprofile blocks until the next block of profiling data is available
-// and returns it as a []byte.  It is called from the writing goroutine.
+// and returns it as a []byte. It is called from the writing goroutine.
 func (p *cpuProfile) getprofile() []byte {
 	if p == nil {
 		return nil
@@ -358,7 +358,7 @@ func (p *cpuProfile) getprofile() []byte {
 	}
 
 	// In flush mode.
-	// Add is no longer being called.  We own the log.
+	// Add is no longer being called. We own the log.
 	// Also, p.handoff is non-zero, so flushlog will return false.
 	// Evict the hash table into the log and return it.
 Flush:
@@ -367,7 +367,7 @@ Flush:
 		for j := range b.entry {
 			e := &b.entry[j]
 			if e.count > 0 && !p.evict(e) {
-				// Filled the log.  Stop the loop and return what we've got.
+				// Filled the log. Stop the loop and return what we've got.
 				break Flush
 			}
 		}
@@ -390,7 +390,7 @@ Flush:
 		return uintptrBytes(eod[:])
 	}
 
-	// Finally done.  Clean up and return nil.
+	// Finally done. Clean up and return nil.
 	p.flushing = false
 	if !atomic.Cas(&p.handoff, p.handoff, 0) {
 		print("runtime: profile flush racing with something\n")
@@ -410,7 +410,7 @@ func uintptrBytes(p []uintptr) (ret []byte) {
 }
 
 // CPUProfile returns the next chunk of binary CPU profiling stack trace data,
-// blocking until data is available.  If profiling is turned off and all the profile
+// blocking until data is available. If profiling is turned off and all the profile
 // data accumulated while it was on has been returned, CPUProfile returns nil.
 // The caller must save the returned data before calling CPUProfile again.
 //
diff --git a/src/runtime/cputicks.go b/src/runtime/cputicks.go
index 3c036df2bd..91627460c3 100644
--- a/src/runtime/cputicks.go
+++ b/src/runtime/cputicks.go
@@ -10,5 +10,5 @@
 package runtime
 
 // careful: cputicks is not guaranteed to be monotonic!  In particular, we have
-// noticed drift between cpus on certain os/arch combinations.  See issue 8976.
+// noticed drift between cpus on certain os/arch combinations. See issue 8976.
 func cputicks() int64
diff --git a/src/runtime/crash_test.go b/src/runtime/crash_test.go
index de45e832f8..85fcc69fed 100644
--- a/src/runtime/crash_test.go
+++ b/src/runtime/crash_test.go
@@ -294,9 +294,9 @@ func TestRecoverBeforePanicAfterGoexit(t *testing.T) {
 	// 1. defer a function that recovers
 	// 2. defer a function that panics
 	// 3. call goexit
-	// Goexit should run the #2 defer.  Its panic
+	// Goexit should run the #2 defer. Its panic
 	// should be caught by the #1 defer, and execution
-	// should resume in the caller.  Like the Goexit
+	// should resume in the caller. Like the Goexit
 	// never happened!
 	defer func() {
 		r := recover()
diff --git a/src/runtime/debug.go b/src/runtime/debug.go
index 0f5936566e..0e798fc6f5 100644
--- a/src/runtime/debug.go
+++ b/src/runtime/debug.go
@@ -10,7 +10,7 @@ import (
 )
 
 // GOMAXPROCS sets the maximum number of CPUs that can be executing
-// simultaneously and returns the previous setting.  If n < 1, it does not
+// simultaneously and returns the previous setting. If n < 1, it does not
 // change the current setting.
 // The number of logical CPUs on the local machine can be queried with NumCPU.
 // This call will go away when the scheduler improves.
diff --git a/src/runtime/defs2_linux.go b/src/runtime/defs2_linux.go
index 980df9ec31..9dea6a1f3a 100644
--- a/src/runtime/defs2_linux.go
+++ b/src/runtime/defs2_linux.go
@@ -32,7 +32,7 @@ package runtime
 #include <linux/eventpoll.h>
 
 // This is the sigaction structure from the Linux 2.1.68 kernel which
-//   is used with the rt_sigaction system call.  For 386 this is not
+//   is used with the rt_sigaction system call. For 386 this is not
 //   defined in any public header file.
 
 struct kernel_sigaction {
diff --git a/src/runtime/extern.go b/src/runtime/extern.go
index 9c1f9f5a03..984b0ca817 100644
--- a/src/runtime/extern.go
+++ b/src/runtime/extern.go
@@ -147,11 +147,11 @@ package runtime
 import "runtime/internal/sys"
 
 // Caller reports file and line number information about function invocations on
-// the calling goroutine's stack.  The argument skip is the number of stack frames
+// the calling goroutine's stack. The argument skip is the number of stack frames
 // to ascend, with 0 identifying the caller of Caller.  (For historical reasons the
 // meaning of skip differs between Caller and Callers.) The return values report the
 // program counter, file name, and line number within the file of the corresponding
-// call.  The boolean ok is false if it was not possible to recover the information.
+// call. The boolean ok is false if it was not possible to recover the information.
 func Caller(skip int) (pc uintptr, file string, line int, ok bool) {
 	// Ask for two PCs: the one we were asked for
 	// and what it called, so that we can see if it
@@ -184,7 +184,7 @@ func Caller(skip int) (pc uintptr, file string, line int, ok bool) {
 }
 
 // Callers fills the slice pc with the return program counters of function invocations
-// on the calling goroutine's stack.  The argument skip is the number of stack frames
+// on the calling goroutine's stack. The argument skip is the number of stack frames
 // to skip before recording in pc, with 0 identifying the frame for Callers itself and
 // 1 identifying the caller of Callers.
 // It returns the number of entries written to pc.
@@ -196,7 +196,7 @@ func Caller(skip int) (pc uintptr, file string, line int, ok bool) {
 // To easily look up file/line information for the call sequence, use Frames.
 func Callers(skip int, pc []uintptr) int {
 	// runtime.callers uses pc.array==nil as a signal
-	// to print a stack trace.  Pick off 0-length pc here
+	// to print a stack trace. Pick off 0-length pc here
 	// so that we don't let a nil pc slice get to it.
 	if len(pc) == 0 {
 		return 0
diff --git a/src/runtime/hash_test.go b/src/runtime/hash_test.go
index a787d8d367..7cceab86cc 100644
--- a/src/runtime/hash_test.go
+++ b/src/runtime/hash_test.go
@@ -17,7 +17,7 @@ import (
 // https://code.google.com/p/smhasher/
 // This code is a port of some of the Smhasher tests to Go.
 //
-// The current AES hash function passes Smhasher.  Our fallback
+// The current AES hash function passes Smhasher. Our fallback
 // hash functions don't, so we only enable the difficult tests when
 // we know the AES implementation is available.
 
@@ -349,7 +349,7 @@ func (k *EfaceKey) random(r *rand.Rand) {
 	k.i = uint64(r.Int63())
 }
 func (k *EfaceKey) bits() int {
-	// use 64 bits.  This tests inlined interfaces
+	// use 64 bits. This tests inlined interfaces
 	// on 64-bit targets and indirect interfaces on
 	// 32-bit targets.
 	return 64
@@ -381,7 +381,7 @@ func (k *IfaceKey) random(r *rand.Rand) {
 	k.i = fInter(r.Int63())
 }
 func (k *IfaceKey) bits() int {
-	// use 64 bits.  This tests inlined interfaces
+	// use 64 bits. This tests inlined interfaces
 	// on 64-bit targets and indirect interfaces on
 	// 32-bit targets.
 	return 64
@@ -443,7 +443,7 @@ func avalancheTest1(t *testing.T, k Key) {
 
 	// Each entry in the grid should be about REP/2.
 	// More precisely, we did N = k.bits() * hashSize experiments where
-	// each is the sum of REP coin flips.  We want to find bounds on the
+	// each is the sum of REP coin flips. We want to find bounds on the
 	// sum of coin flips such that a truly random experiment would have
 	// all sums inside those bounds with 99% probability.
 	N := n * hashSize
@@ -563,19 +563,19 @@ func BenchmarkHash1024(b *testing.B)  { benchmarkHash(b, 1024) }
 func BenchmarkHash65536(b *testing.B) { benchmarkHash(b, 65536) }
 
 func TestArrayHash(t *testing.T) {
-	// Make sure that "" in arrays hash correctly.  The hash
+	// Make sure that "" in arrays hash correctly. The hash
 	// should at least scramble the input seed so that, e.g.,
 	// {"","foo"} and {"foo",""} have different hashes.
 
 	// If the hash is bad, then all (8 choose 4) = 70 keys
 	// have the same hash. If so, we allocate 70/8 = 8
-	// overflow buckets.  If the hash is good we don't
+	// overflow buckets. If the hash is good we don't
 	// normally allocate any overflow buckets, and the
 	// probability of even one or two overflows goes down rapidly.
-	// (There is always 1 allocation of the bucket array.  The map
+	// (There is always 1 allocation of the bucket array. The map
 	// header is allocated on the stack.)
 	f := func() {
-		// Make the key type at most 128 bytes.  Otherwise,
+		// Make the key type at most 128 bytes. Otherwise,
 		// we get an allocation per key.
 		type key [8]string
 		m := make(map[key]bool, 70)
diff --git a/src/runtime/hashmap.go b/src/runtime/hashmap.go
index 892a79a914..6f7451e02c 100644
--- a/src/runtime/hashmap.go
+++ b/src/runtime/hashmap.go
@@ -6,10 +6,10 @@ package runtime
 
 // This file contains the implementation of Go's map type.
 //
-// A map is just a hash table.  The data is arranged
-// into an array of buckets.  Each bucket contains up to
-// 8 key/value pairs.  The low-order bits of the hash are
-// used to select a bucket.  Each bucket contains a few
+// A map is just a hash table. The data is arranged
+// into an array of buckets. Each bucket contains up to
+// 8 key/value pairs. The low-order bits of the hash are
+// used to select a bucket. Each bucket contains a few
 // high-order bits of each hash to distinguish the entries
 // within a single bucket.
 //
@@ -17,7 +17,7 @@ package runtime
 // extra buckets.
 //
 // When the hashtable grows, we allocate a new array
-// of buckets twice as big.  Buckets are incrementally
+// of buckets twice as big. Buckets are incrementally
 // copied from the old bucket array to the new bucket array.
 //
 // Map iterators walk through the array of buckets and
@@ -31,7 +31,7 @@ package runtime
 // to the new table.
 
 // Picking loadFactor: too large and we have lots of overflow
-// buckets, too small and we waste a lot of space.  I wrote
+// buckets, too small and we waste a lot of space. I wrote
 // a simple program to check some stats for different loads:
 // (64-bit, 8 byte keys and values)
 //  loadFactor    %overflow  bytes/entry     hitprobe    missprobe
@@ -51,7 +51,7 @@ package runtime
 // missprobe   = # of entries to check when looking up an absent key
 //
 // Keep in mind this data is for maximally loaded tables, i.e. just
-// before the table grows.  Typical tables will be somewhat less loaded.
+// before the table grows. Typical tables will be somewhat less loaded.
 
 import (
 	"runtime/internal/atomic"
@@ -75,14 +75,14 @@ const (
 	maxValueSize = 128
 
 	// data offset should be the size of the bmap struct, but needs to be
-	// aligned correctly.  For amd64p32 this means 64-bit alignment
+	// aligned correctly. For amd64p32 this means 64-bit alignment
 	// even though pointers are 32 bit.
 	dataOffset = unsafe.Offsetof(struct {
 		b bmap
 		v int64
 	}{}.v)
 
-	// Possible tophash values.  We reserve a few possibilities for special marks.
+	// Possible tophash values. We reserve a few possibilities for special marks.
 	// Each bucket (including its overflow buckets, if any) will have either all or none of its
 	// entries in the evacuated* states (except during the evacuate() method, which only happens
 	// during map writes and thus no one else can observe the map during that time).
@@ -104,7 +104,7 @@ const (
 // A header for a Go map.
 type hmap struct {
 	// Note: the format of the Hmap is encoded in ../../cmd/internal/gc/reflect.go and
-	// ../reflect/type.go.  Don't change this structure without also changing that code!
+	// ../reflect/type.go. Don't change this structure without also changing that code!
 	count int // # live cells == size of map.  Must be first (used by len() builtin)
 	flags uint8
 	B     uint8  // log_2 of # of buckets (can hold up to loadFactor * 2^B items)
@@ -212,7 +212,7 @@ func makemap(t *maptype, hint int64, h *hmap, bucket unsafe.Pointer) *hmap {
 		throw("value size wrong")
 	}
 
-	// invariants we depend on.  We should probably check these at compile time
+	// invariants we depend on. We should probably check these at compile time
 	// somewhere, but for now we'll do it here.
 	if t.key.align > bucketCnt {
 		throw("key align too big")
@@ -380,7 +380,7 @@ func mapaccess2(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, bool)
 	}
 }
 
-// returns both key and value.  Used by map iterator
+// returns both key and value. Used by map iterator
 func mapaccessK(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, unsafe.Pointer) {
 	if h == nil || h.count == 0 {
 		return nil, nil
@@ -485,7 +485,7 @@ again:
 			if !alg.equal(key, k2) {
 				continue
 			}
-			// already have a mapping for key.  Update it.
+			// already have a mapping for key. Update it.
 			if t.needkeyupdate {
 				typedmemmove(t.key, k2, key)
 			}
@@ -504,7 +504,7 @@ again:
 		b = ovf
 	}
 
-	// did not find mapping for key.  Allocate new cell & add entry.
+	// did not find mapping for key. Allocate new cell & add entry.
 	if float32(h.count) >= loadFactor*float32((uintptr(1)<<h.B)) && h.count >= bucketCnt {
 		hashGrow(t, h)
 		goto again // Growing the table invalidates everything, so try again
@@ -718,9 +718,9 @@ next:
 		if b.tophash[offi] != empty && b.tophash[offi] != evacuatedEmpty {
 			if checkBucket != noCheck {
 				// Special case: iterator was started during a grow and the
-				// grow is not done yet.  We're working on a bucket whose
-				// oldbucket has not been evacuated yet.  Or at least, it wasn't
-				// evacuated when we started the bucket.  So we're iterating
+				// grow is not done yet. We're working on a bucket whose
+				// oldbucket has not been evacuated yet. Or at least, it wasn't
+				// evacuated when we started the bucket. So we're iterating
 				// through the oldbucket, skipping any keys that will go
 				// to the other new bucket (each oldbucket expands to two
 				// buckets during a grow).
@@ -738,7 +738,7 @@ next:
 				} else {
 					// Hash isn't repeatable if k != k (NaNs).  We need a
 					// repeatable and randomish choice of which direction
-					// to send NaNs during evacuation.  We'll use the low
+					// to send NaNs during evacuation. We'll use the low
 					// bit of tophash to decide which way NaNs go.
 					// NOTE: this case is why we need two evacuate tophash
 					// values, evacuatedX and evacuatedY, that differ in
@@ -779,7 +779,7 @@ next:
 					it.value = rv
 				} else {
 					// if key!=key then the entry can't be deleted or
-					// updated, so we can just return it.  That's lucky for
+					// updated, so we can just return it. That's lucky for
 					// us because when key!=key we can't look it up
 					// successfully in the current table.
 					it.key = k2
@@ -882,12 +882,12 @@ func evacuate(t *maptype, h *hmap, oldbucket uintptr) {
 				if h.flags&iterator != 0 {
 					if !t.reflexivekey && !alg.equal(k2, k2) {
 						// If key != key (NaNs), then the hash could be (and probably
-						// will be) entirely different from the old hash.  Moreover,
-						// it isn't reproducible.  Reproducibility is required in the
+						// will be) entirely different from the old hash. Moreover,
+						// it isn't reproducible. Reproducibility is required in the
 						// presence of iterators, as our evacuation decision must
 						// match whatever decision the iterator made.
 						// Fortunately, we have the freedom to send these keys either
-						// way.  Also, tophash is meaningless for these kinds of keys.
+						// way. Also, tophash is meaningless for these kinds of keys.
 						// We let the low bit of tophash drive the evacuation decision.
 						// We recompute a new random tophash for the next level so
 						// these keys will get evenly distributed across all buckets
@@ -965,7 +965,7 @@ func evacuate(t *maptype, h *hmap, oldbucket uintptr) {
 	if oldbucket == h.nevacuate {
 		h.nevacuate = oldbucket + 1
 		if oldbucket+1 == newbit { // newbit == # of oldbuckets
-			// Growing is all done.  Free old main bucket array.
+			// Growing is all done. Free old main bucket array.
 			h.oldbuckets = nil
 			// Can discard old overflow buckets as well.
 			// If they are still referenced by an iterator,
@@ -981,7 +981,7 @@ func ismapkey(t *_type) bool {
 	return t.alg.hash != nil
 }
 
-// Reflect stubs.  Called from ../reflect/asm_*.s
+// Reflect stubs. Called from ../reflect/asm_*.s
 
 //go:linkname reflect_makemap reflect.makemap
 func reflect_makemap(t *maptype) *hmap {
diff --git a/src/runtime/hashmap_fast.go b/src/runtime/hashmap_fast.go
index f95ea3e1b7..6a5484edee 100644
--- a/src/runtime/hashmap_fast.go
+++ b/src/runtime/hashmap_fast.go
@@ -23,7 +23,7 @@ func mapaccess1_fast32(t *maptype, h *hmap, key uint32) unsafe.Pointer {
 	}
 	var b *bmap
 	if h.B == 0 {
-		// One-bucket table.  No need to hash.
+		// One-bucket table. No need to hash.
 		b = (*bmap)(h.buckets)
 	} else {
 		hash := t.key.alg.hash(noescape(unsafe.Pointer(&key)), uintptr(h.hash0))
@@ -68,7 +68,7 @@ func mapaccess2_fast32(t *maptype, h *hmap, key uint32) (unsafe.Pointer, bool) {
 	}
 	var b *bmap
 	if h.B == 0 {
-		// One-bucket table.  No need to hash.
+		// One-bucket table. No need to hash.
 		b = (*bmap)(h.buckets)
 	} else {
 		hash := t.key.alg.hash(noescape(unsafe.Pointer(&key)), uintptr(h.hash0))
@@ -113,7 +113,7 @@ func mapaccess1_fast64(t *maptype, h *hmap, key uint64) unsafe.Pointer {
 	}
 	var b *bmap
 	if h.B == 0 {
-		// One-bucket table.  No need to hash.
+		// One-bucket table. No need to hash.
 		b = (*bmap)(h.buckets)
 	} else {
 		hash := t.key.alg.hash(noescape(unsafe.Pointer(&key)), uintptr(h.hash0))
@@ -158,7 +158,7 @@ func mapaccess2_fast64(t *maptype, h *hmap, key uint64) (unsafe.Pointer, bool) {
 	}
 	var b *bmap
 	if h.B == 0 {
-		// One-bucket table.  No need to hash.
+		// One-bucket table. No need to hash.
 		b = (*bmap)(h.buckets)
 	} else {
 		hash := t.key.alg.hash(noescape(unsafe.Pointer(&key)), uintptr(h.hash0))
@@ -247,7 +247,7 @@ func mapaccess1_faststr(t *maptype, h *hmap, ky string) unsafe.Pointer {
 				continue
 			}
 			if keymaybe != bucketCnt {
-				// Two keys are potential matches.  Use hash to distinguish them.
+				// Two keys are potential matches. Use hash to distinguish them.
 				goto dohash
 			}
 			keymaybe = i
@@ -350,7 +350,7 @@ func mapaccess2_faststr(t *maptype, h *hmap, ky string) (unsafe.Pointer, bool) {
 				continue
 			}
 			if keymaybe != bucketCnt {
-				// Two keys are potential matches.  Use hash to distinguish them.
+				// Two keys are potential matches. Use hash to distinguish them.
 				goto dohash
 			}
 			keymaybe = i
diff --git a/src/runtime/heapdump.go b/src/runtime/heapdump.go
index 3bff36bd78..e4ec302a19 100644
--- a/src/runtime/heapdump.go
+++ b/src/runtime/heapdump.go
@@ -2,7 +2,7 @@
 // Use of this source code is governed by a BSD-style
 // license that can be found in the LICENSE file.
 
-// Implementation of runtime/debug.WriteHeapDump.  Writes all
+// Implementation of runtime/debug.WriteHeapDump. Writes all
 // objects in the heap plus additional info (roots, threads,
 // finalizers, etc.) to a file.
 
@@ -97,7 +97,7 @@ func flush() {
 // Inside a bucket, we keep a list of types that
 // have been serialized so far, most recently used first.
 // Note: when a bucket overflows we may end up
-// serializing a type more than once.  That's ok.
+// serializing a type more than once. That's ok.
 const (
 	typeCacheBuckets = 256
 	typeCacheAssoc   = 4
@@ -172,7 +172,7 @@ func dumptype(t *_type) {
 		}
 	}
 
-	// Might not have been dumped yet.  Dump it and
+	// Might not have been dumped yet. Dump it and
 	// remember we did so.
 	for j := typeCacheAssoc - 1; j > 0; j-- {
 		b.t[j] = b.t[j-1]
@@ -254,7 +254,7 @@ func dumpframe(s *stkframe, arg unsafe.Pointer) bool {
 	pcdata := pcdatavalue(f, _PCDATA_StackMapIndex, pc, nil)
 	if pcdata == -1 {
 		// We do not have a valid pcdata value but there might be a
-		// stackmap for this function.  It is likely that we are looking
+		// stackmap for this function. It is likely that we are looking
 		// at the function prologue, assume so and hope for the best.
 		pcdata = 0
 	}
@@ -679,8 +679,8 @@ func dumpfields(bv bitvector) {
 }
 
 // The heap dump reader needs to be able to disambiguate
-// Eface entries.  So it needs to know every type that might
-// appear in such an entry.  The following routine accomplishes that.
+// Eface entries. So it needs to know every type that might
+// appear in such an entry. The following routine accomplishes that.
 // TODO(rsc, khr): Delete - no longer possible.
 
 // Dump all the types that appear in the type field of
diff --git a/src/runtime/iface.go b/src/runtime/iface.go
index d980367866..bad0156e61 100644
--- a/src/runtime/iface.go
+++ b/src/runtime/iface.go
@@ -140,7 +140,7 @@ func convT2E(t *_type, elem unsafe.Pointer, x unsafe.Pointer) (e eface) {
 			x = newobject(t)
 		}
 		// TODO: We allocate a zeroed object only to overwrite it with
-		// actual data.  Figure out how to avoid zeroing.  Also below in convT2I.
+		// actual data. Figure out how to avoid zeroing. Also below in convT2I.
 		typedmemmove(t, x, elem)
 		e._type = t
 		e.data = x
diff --git a/src/runtime/internal/atomic/asm_mips64x.s b/src/runtime/internal/atomic/asm_mips64x.s
index 4cab4342f9..a454f284ab 100644
--- a/src/runtime/internal/atomic/asm_mips64x.s
+++ b/src/runtime/internal/atomic/asm_mips64x.s
@@ -189,7 +189,7 @@ TEXT ·Or8(SB), NOSPLIT, $0-9
 	// R4 = ((ptr & 3) * 8)
 	AND	$3, R1, R4
 	SLLV	$3, R4
-	// Shift val for aligned ptr.  R2 = val << R4
+	// Shift val for aligned ptr. R2 = val << R4
 	SLLV	R4, R2
 
 	SYNC
@@ -215,7 +215,7 @@ TEXT ·And8(SB), NOSPLIT, $0-9
 	// R4 = ((ptr & 3) * 8)
 	AND	$3, R1, R4
 	SLLV	$3, R4
-	// Shift val for aligned ptr.  R2 = val << R4 | ^(0xFF << R4)
+	// Shift val for aligned ptr. R2 = val << R4 | ^(0xFF << R4)
 	MOVV	$0xFF, R5
 	SLLV	R4, R2
 	SLLV	R4, R5
diff --git a/src/runtime/internal/atomic/asm_ppc64x.s b/src/runtime/internal/atomic/asm_ppc64x.s
index 87f7f5d892..45a48b6203 100644
--- a/src/runtime/internal/atomic/asm_ppc64x.s
+++ b/src/runtime/internal/atomic/asm_ppc64x.s
@@ -181,7 +181,7 @@ TEXT runtime∕internal∕atomic·Or8(SB), NOSPLIT, $0-9
 #endif
 	// R6 = ((ptr & 3) * 8) = (ptr << 3) & (3*8)
 	RLDC	$3, R3, $(3*8), R6
-	// Shift val for aligned ptr.  R4 = val << R6
+	// Shift val for aligned ptr. R4 = val << R6
 	SLD	R6, R4, R4
 
 again:
@@ -208,7 +208,7 @@ TEXT runtime∕internal∕atomic·And8(SB), NOSPLIT, $0-9
 #endif
 	// R6 = ((ptr & 3) * 8) = (ptr << 3) & (3*8)
 	RLDC	$3, R3, $(3*8), R6
-	// Shift val for aligned ptr.  R4 = val << R6 | ^(0xFF << R6)
+	// Shift val for aligned ptr. R4 = val << R6 | ^(0xFF << R6)
 	MOVD	$0xFF, R7
 	SLD	R6, R4
 	SLD	R6, R7
diff --git a/src/runtime/internal/atomic/atomic_test.go b/src/runtime/internal/atomic/atomic_test.go
index e8ec788d6a..d5dc552b95 100644
--- a/src/runtime/internal/atomic/atomic_test.go
+++ b/src/runtime/internal/atomic/atomic_test.go
@@ -48,7 +48,7 @@ func TestXadduintptr(t *testing.T) {
 	}
 }
 
-// Tests that xadduintptr correctly updates 64-bit values.  The place where
+// Tests that xadduintptr correctly updates 64-bit values. The place where
 // we actually do so is mstats.go, functions mSysStat{Inc,Dec}.
 func TestXadduintptrOnUint64(t *testing.T) {
 	/*	if runtime.BigEndian != 0 {
diff --git a/src/runtime/lock_futex.go b/src/runtime/lock_futex.go
index fc480290cf..d28fd92720 100644
--- a/src/runtime/lock_futex.go
+++ b/src/runtime/lock_futex.go
@@ -58,7 +58,7 @@ func lock(l *mutex) {
 
 	// wait is either MUTEX_LOCKED or MUTEX_SLEEPING
 	// depending on whether there is a thread sleeping
-	// on this mutex.  If we ever change l->key from
+	// on this mutex. If we ever change l->key from
 	// MUTEX_SLEEPING to some other value, we must be
 	// careful to change it back to MUTEX_SLEEPING before
 	// returning, to ensure that the sleeping thread gets
diff --git a/src/runtime/lock_sema.go b/src/runtime/lock_sema.go
index 1220674ab9..0fa0481733 100644
--- a/src/runtime/lock_sema.go
+++ b/src/runtime/lock_sema.go
@@ -81,7 +81,7 @@ Loop:
 				}
 			}
 			if v&locked != 0 {
-				// Queued.  Wait.
+				// Queued. Wait.
 				semasleep(-1)
 				i = 0
 			}
@@ -143,7 +143,7 @@ func notewakeup(n *note) {
 		// Two notewakeups!  Not allowed.
 		throw("notewakeup - double wakeup")
 	default:
-		// Must be the waiting m.  Wake it up.
+		// Must be the waiting m. Wake it up.
 		semawakeup((*m)(unsafe.Pointer(v)))
 	}
 }
@@ -161,7 +161,7 @@ func notesleep(n *note) {
 		}
 		return
 	}
-	// Queued.  Sleep.
+	// Queued. Sleep.
 	gp.m.blocked = true
 	semasleep(-1)
 	gp.m.blocked = false
@@ -184,7 +184,7 @@ func notetsleep_internal(n *note, ns int64, gp *g, deadline int64) bool {
 		return true
 	}
 	if ns < 0 {
-		// Queued.  Sleep.
+		// Queued. Sleep.
 		gp.m.blocked = true
 		semasleep(-1)
 		gp.m.blocked = false
@@ -193,7 +193,7 @@ func notetsleep_internal(n *note, ns int64, gp *g, deadline int64) bool {
 
 	deadline = nanotime() + ns
 	for {
-		// Registered.  Sleep.
+		// Registered. Sleep.
 		gp.m.blocked = true
 		if semasleep(ns) >= 0 {
 			gp.m.blocked = false
@@ -202,15 +202,15 @@ func notetsleep_internal(n *note, ns int64, gp *g, deadline int64) bool {
 			return true
 		}
 		gp.m.blocked = false
-		// Interrupted or timed out.  Still registered.  Semaphore not acquired.
+		// Interrupted or timed out. Still registered. Semaphore not acquired.
 		ns = deadline - nanotime()
 		if ns <= 0 {
 			break
 		}
-		// Deadline hasn't arrived.  Keep sleeping.
+		// Deadline hasn't arrived. Keep sleeping.
 	}
 
-	// Deadline arrived.  Still registered.  Semaphore not acquired.
+	// Deadline arrived. Still registered. Semaphore not acquired.
 	// Want to give up and return, but have to unregister first,
 	// so that any notewakeup racing with the return does not
 	// try to grant us the semaphore when we don't expect it.
diff --git a/src/runtime/malloc.go b/src/runtime/malloc.go
index b520c68df0..e5a5fe61d9 100644
--- a/src/runtime/malloc.go
+++ b/src/runtime/malloc.go
@@ -65,8 +65,8 @@
 // directly, bypassing the MCache and MCentral free lists.
 //
 // The small objects on the MCache and MCentral free lists
-// may or may not be zeroed.  They are zeroed if and only if
-// the second word of the object is zero.  A span in the
+// may or may not be zeroed. They are zeroed if and only if
+// the second word of the object is zero. A span in the
 // page heap is zeroed unless s->needzero is set. When a span
 // is allocated to break into small objects, it is zeroed if needed
 // and s->needzero is set. There are two main benefits to delaying the
@@ -113,9 +113,9 @@ const (
 	// _64bit = 1 on 64-bit systems, 0 on 32-bit systems
 	_64bit = 1 << (^uintptr(0) >> 63) / 2
 
-	// Computed constant.  The definition of MaxSmallSize and the
+	// Computed constant. The definition of MaxSmallSize and the
 	// algorithm in msize.go produces some number of different allocation
-	// size classes.  NumSizeClasses is that number.  It's needed here
+	// size classes. NumSizeClasses is that number. It's needed here
 	// because there are static arrays of this length; when msize runs its
 	// size choosing algorithm it double-checks that NumSizeClasses agrees.
 	_NumSizeClasses = 67
@@ -134,9 +134,9 @@ const (
 	// Per-P, per order stack segment cache size.
 	_StackCacheSize = 32 * 1024
 
-	// Number of orders that get caching.  Order 0 is FixedStack
+	// Number of orders that get caching. Order 0 is FixedStack
 	// and each successive order is twice as large.
-	// We want to cache 2KB, 4KB, 8KB, and 16KB stacks.  Larger stacks
+	// We want to cache 2KB, 4KB, 8KB, and 16KB stacks. Larger stacks
 	// will be allocated directly.
 	// Since FixedStack is different on different systems, we
 	// must vary NumStackOrders to keep the same maximum cached size.
@@ -165,7 +165,7 @@ const (
 
 	// Max number of threads to run garbage collection.
 	// 2, 3, and 4 are all plausible maximums depending
-	// on the hardware details of the machine.  The garbage
+	// on the hardware details of the machine. The garbage
 	// collector scales well to 32 cpus.
 	_MaxGcproc = 32
 )
@@ -192,14 +192,14 @@ const _MaxArena32 = 2 << 30
 //
 // SysFree returns it unconditionally; this is only used if
 // an out-of-memory error has been detected midway through
-// an allocation.  It is okay if SysFree is a no-op.
+// an allocation. It is okay if SysFree is a no-op.
 //
 // SysReserve reserves address space without allocating memory.
 // If the pointer passed to it is non-nil, the caller wants the
 // reservation there, but SysReserve can still choose another
-// location if that one is unavailable.  On some systems and in some
+// location if that one is unavailable. On some systems and in some
 // cases SysReserve will simply check that the address space is
-// available and not actually reserve it.  If SysReserve returns
+// available and not actually reserve it. If SysReserve returns
 // non-nil, it sets *reserved to true if the address space is
 // reserved, false if it has merely been checked.
 // NOTE: SysReserve returns OS-aligned memory, but the heap allocator
@@ -211,7 +211,7 @@ const _MaxArena32 = 2 << 30
 // reserved, not merely checked.
 //
 // SysFault marks a (already sysAlloc'd) region to fault
-// if accessed.  Used only for debugging the runtime.
+// if accessed. Used only for debugging the runtime.
 
 func mallocinit() {
 	initSizes()
@@ -229,7 +229,7 @@ func mallocinit() {
 	limit = 0
 
 	// Set up the allocation arena, a contiguous area of memory where
-	// allocated data will be found.  The arena begins with a bitmap large
+	// allocated data will be found. The arena begins with a bitmap large
 	// enough to hold 4 bits per allocated word.
 	if sys.PtrSize == 8 && (limit == 0 || limit > 1<<30) {
 		// On a 64-bit machine, allocate from a single contiguous reservation.
@@ -239,12 +239,12 @@ func mallocinit() {
 		// SysReserve to use 0x0000XXc000000000 if possible (XX=00...7f).
 		// Allocating a 512 GB region takes away 39 bits, and the amd64
 		// doesn't let us choose the top 17 bits, so that leaves the 9 bits
-		// in the middle of 0x00c0 for us to choose.  Choosing 0x00c0 means
+		// in the middle of 0x00c0 for us to choose. Choosing 0x00c0 means
 		// that the valid memory addresses will begin 0x00c0, 0x00c1, ..., 0x00df.
 		// In little-endian, that's c0 00, c1 00, ..., df 00. None of those are valid
 		// UTF-8 sequences, and they are otherwise as far away from
-		// ff (likely a common byte) as possible.  If that fails, we try other 0xXXc0
-		// addresses.  An earlier attempt to use 0x11f8 caused out of memory errors
+		// ff (likely a common byte) as possible. If that fails, we try other 0xXXc0
+		// addresses. An earlier attempt to use 0x11f8 caused out of memory errors
 		// on OS X during thread allocations.  0x00c0 causes conflicts with
 		// AddressSanitizer which reserves all memory up to 0x0100.
 		// These choices are both for debuggability and to reduce the
@@ -321,10 +321,10 @@ func mallocinit() {
 			spansSize = round(spansSize, _PageSize)
 
 			// SysReserve treats the address we ask for, end, as a hint,
-			// not as an absolute requirement.  If we ask for the end
+			// not as an absolute requirement. If we ask for the end
 			// of the data segment but the operating system requires
 			// a little more space before we can start allocating, it will
-			// give out a slightly higher pointer.  Except QEMU, which
+			// give out a slightly higher pointer. Except QEMU, which
 			// is buggy, as usual: it won't adjust the pointer upward.
 			// So adjust it upward a little bit ourselves: 1/4 MB to get
 			// away from the running binary image and then round up
@@ -803,7 +803,7 @@ func reflect_unsafe_NewArray(typ *_type, n uintptr) unsafe.Pointer {
 	return newarray(typ, n)
 }
 
-// rawmem returns a chunk of pointerless memory.  It is
+// rawmem returns a chunk of pointerless memory. It is
 // not zeroed.
 func rawmem(size uintptr) unsafe.Pointer {
 	return mallocgc(size, nil, flagNoScan|flagNoZero)
diff --git a/src/runtime/mcache.go b/src/runtime/mcache.go
index b06d354eb6..2230c5c200 100644
--- a/src/runtime/mcache.go
+++ b/src/runtime/mcache.go
@@ -101,7 +101,7 @@ func freemcache(c *mcache) {
 }
 
 // Gets a span that has a free object in it and assigns it
-// to be the cached span for the given sizeclass.  Returns this span.
+// to be the cached span for the given sizeclass. Returns this span.
 func (c *mcache) refill(sizeclass int32) *mspan {
 	_g_ := getg()
 
diff --git a/src/runtime/mcentral.go b/src/runtime/mcentral.go
index 8a2fbe98c9..4f0b86c228 100644
--- a/src/runtime/mcentral.go
+++ b/src/runtime/mcentral.go
@@ -146,7 +146,7 @@ func (c *mcentral) uncacheSpan(s *mspan) {
 
 // Free n objects from a span s back into the central free list c.
 // Called during sweep.
-// Returns true if the span was returned to heap.  Sets sweepgen to
+// Returns true if the span was returned to heap. Sets sweepgen to
 // the latest generation.
 // If preserve=true, don't return the span to heap nor relink in MCentral lists;
 // caller takes care of it.
@@ -179,7 +179,7 @@ func (c *mcentral) freeSpan(s *mspan, n int32, start gclinkptr, end gclinkptr, p
 		c.nonempty.insert(s)
 	}
 
-	// delay updating sweepgen until here.  This is the signal that
+	// delay updating sweepgen until here. This is the signal that
 	// the span may be used in an MCache, so it must come after the
 	// linked list operations above (actually, just after the
 	// lock of c above.)
diff --git a/src/runtime/mem_bsd.go b/src/runtime/mem_bsd.go
index 6c24137f3c..bf4f24426c 100644
--- a/src/runtime/mem_bsd.go
+++ b/src/runtime/mem_bsd.go
@@ -44,7 +44,7 @@ func sysFault(v unsafe.Pointer, n uintptr) {
 
 func sysReserve(v unsafe.Pointer, n uintptr, reserved *bool) unsafe.Pointer {
 	// On 64-bit, people with ulimit -v set complain if we reserve too
-	// much address space.  Instead, assume that the reservation is okay
+	// much address space. Instead, assume that the reservation is okay
 	// and check the assumption in SysMap.
 	if sys.PtrSize == 8 && uint64(n) > 1<<32 || sys.GoosNacl != 0 {
 		*reserved = false
diff --git a/src/runtime/mem_linux.go b/src/runtime/mem_linux.go
index 85a7f80efc..1ee13bd7e6 100644
--- a/src/runtime/mem_linux.go
+++ b/src/runtime/mem_linux.go
@@ -172,7 +172,7 @@ func sysFault(v unsafe.Pointer, n uintptr) {
 
 func sysReserve(v unsafe.Pointer, n uintptr, reserved *bool) unsafe.Pointer {
 	// On 64-bit, people with ulimit -v set complain if we reserve too
-	// much address space.  Instead, assume that the reservation is okay
+	// much address space. Instead, assume that the reservation is okay
 	// if we can reserve at least 64K and check the assumption in SysMap.
 	// Only user-mode Linux (UML) rejects these requests.
 	if sys.PtrSize == 8 && uint64(n) > 1<<32 {
diff --git a/src/runtime/memclr_arm.s b/src/runtime/memclr_arm.s
index 8b5fe31c51..c9b8586eae 100644
--- a/src/runtime/memclr_arm.s
+++ b/src/runtime/memclr_arm.s
@@ -1,7 +1,7 @@
 // Inferno's libkern/memset-arm.s
 // http://code.google.com/p/inferno-os/source/browse/libkern/memset-arm.s
 //
-//         Copyright © 1994-1999 Lucent Technologies Inc.  All rights reserved.
+//         Copyright © 1994-1999 Lucent Technologies Inc. All rights reserved.
 //         Revisions Copyright © 2000-2007 Vita Nuova Holdings Limited (www.vitanuova.com).  All rights reserved.
 //         Portions Copyright 2009 The Go Authors. All rights reserved.
 //
diff --git a/src/runtime/memmove_386.s b/src/runtime/memmove_386.s
index f72a73ae4f..9a21e84136 100644
--- a/src/runtime/memmove_386.s
+++ b/src/runtime/memmove_386.s
@@ -1,7 +1,7 @@
 // Inferno's libkern/memmove-386.s
 // http://code.google.com/p/inferno-os/source/browse/libkern/memmove-386.s
 //
-//         Copyright © 1994-1999 Lucent Technologies Inc.  All rights reserved.
+//         Copyright © 1994-1999 Lucent Technologies Inc. All rights reserved.
 //         Revisions Copyright © 2000-2007 Vita Nuova Holdings Limited (www.vitanuova.com).  All rights reserved.
 //         Portions Copyright 2009 The Go Authors. All rights reserved.
 //
@@ -33,8 +33,8 @@ TEXT runtime·memmove(SB), NOSPLIT, $0-12
 	MOVL	n+8(FP), BX
 
 	// REP instructions have a high startup cost, so we handle small sizes
-	// with some straightline code.  The REP MOVSL instruction is really fast
-	// for large sizes.  The cutover is approximately 1K.  We implement up to
+	// with some straightline code. The REP MOVSL instruction is really fast
+	// for large sizes. The cutover is approximately 1K.  We implement up to
 	// 128 because that is the maximum SSE register load (loading all data
 	// into registers lets us ignore copy direction).
 tail:
diff --git a/src/runtime/memmove_amd64.s b/src/runtime/memmove_amd64.s
index e14614d631..ae95b155be 100644
--- a/src/runtime/memmove_amd64.s
+++ b/src/runtime/memmove_amd64.s
@@ -1,7 +1,7 @@
 // Derived from Inferno's libkern/memmove-386.s (adapted for amd64)
 // http://code.google.com/p/inferno-os/source/browse/libkern/memmove-386.s
 //
-//         Copyright © 1994-1999 Lucent Technologies Inc.  All rights reserved.
+//         Copyright © 1994-1999 Lucent Technologies Inc. All rights reserved.
 //         Revisions Copyright © 2000-2007 Vita Nuova Holdings Limited (www.vitanuova.com).  All rights reserved.
 //         Portions Copyright 2009 The Go Authors. All rights reserved.
 //
@@ -35,8 +35,8 @@ TEXT runtime·memmove(SB), NOSPLIT, $0-24
 	MOVQ	n+16(FP), BX
 
 	// REP instructions have a high startup cost, so we handle small sizes
-	// with some straightline code.  The REP MOVSQ instruction is really fast
-	// for large sizes.  The cutover is approximately 2K.
+	// with some straightline code. The REP MOVSQ instruction is really fast
+	// for large sizes. The cutover is approximately 2K.
 tail:
 	// move_129through256 or smaller work whether or not the source and the
 	// destination memory regions overlap because they load all data into
diff --git a/src/runtime/memmove_arm.s b/src/runtime/memmove_arm.s
index 35f04a84bc..6b880d5e6d 100644
--- a/src/runtime/memmove_arm.s
+++ b/src/runtime/memmove_arm.s
@@ -1,7 +1,7 @@
 // Inferno's libkern/memmove-arm.s
 // http://code.google.com/p/inferno-os/source/browse/libkern/memmove-arm.s
 //
-//         Copyright © 1994-1999 Lucent Technologies Inc.  All rights reserved.
+//         Copyright © 1994-1999 Lucent Technologies Inc. All rights reserved.
 //         Revisions Copyright © 2000-2007 Vita Nuova Holdings Limited (www.vitanuova.com).  All rights reserved.
 //         Portions Copyright 2009 The Go Authors. All rights reserved.
 //
diff --git a/src/runtime/memmove_nacl_amd64p32.s b/src/runtime/memmove_nacl_amd64p32.s
index 64b732e777..13907a90b2 100644
--- a/src/runtime/memmove_nacl_amd64p32.s
+++ b/src/runtime/memmove_nacl_amd64p32.s
@@ -47,6 +47,6 @@ back:
 	CLD
 
 	// Note: we copy only 4 bytes at a time so that the tail is at most
-	// 3 bytes.  That guarantees that we aren't copying pointers with MOVSB.
+	// 3 bytes. That guarantees that we aren't copying pointers with MOVSB.
 	// See issue 13160.
 	RET
diff --git a/src/runtime/memmove_plan9_386.s b/src/runtime/memmove_plan9_386.s
index 3b492eb6cd..c4d62ec946 100644
--- a/src/runtime/memmove_plan9_386.s
+++ b/src/runtime/memmove_plan9_386.s
@@ -1,7 +1,7 @@
 // Inferno's libkern/memmove-386.s
 // http://code.google.com/p/inferno-os/source/browse/libkern/memmove-386.s
 //
-//         Copyright © 1994-1999 Lucent Technologies Inc.  All rights reserved.
+//         Copyright © 1994-1999 Lucent Technologies Inc. All rights reserved.
 //         Revisions Copyright © 2000-2007 Vita Nuova Holdings Limited (www.vitanuova.com).  All rights reserved.
 //         Portions Copyright 2009 The Go Authors. All rights reserved.
 //
@@ -31,8 +31,8 @@ TEXT runtime·memmove(SB), NOSPLIT, $0-12
 	MOVL	n+8(FP), BX
 
 	// REP instructions have a high startup cost, so we handle small sizes
-	// with some straightline code.  The REP MOVSL instruction is really fast
-	// for large sizes.  The cutover is approximately 1K.
+	// with some straightline code. The REP MOVSL instruction is really fast
+	// for large sizes. The cutover is approximately 1K.
 tail:
 	TESTL	BX, BX
 	JEQ	move_0
diff --git a/src/runtime/memmove_plan9_amd64.s b/src/runtime/memmove_plan9_amd64.s
index a1cc25567b..9bef31d43e 100644
--- a/src/runtime/memmove_plan9_amd64.s
+++ b/src/runtime/memmove_plan9_amd64.s
@@ -1,7 +1,7 @@
 // Derived from Inferno's libkern/memmove-386.s (adapted for amd64)
 // http://code.google.com/p/inferno-os/source/browse/libkern/memmove-386.s
 //
-//         Copyright © 1994-1999 Lucent Technologies Inc.  All rights reserved.
+//         Copyright © 1994-1999 Lucent Technologies Inc. All rights reserved.
 //         Revisions Copyright © 2000-2007 Vita Nuova Holdings Limited (www.vitanuova.com).  All rights reserved.
 //         Portions Copyright 2009 The Go Authors. All rights reserved.
 //
@@ -33,8 +33,8 @@ TEXT runtime·memmove(SB), NOSPLIT, $0-24
 	MOVQ	n+16(FP), BX
 
 	// REP instructions have a high startup cost, so we handle small sizes
-	// with some straightline code.  The REP MOVSQ instruction is really fast
-	// for large sizes.  The cutover is approximately 1K.
+	// with some straightline code. The REP MOVSQ instruction is really fast
+	// for large sizes. The cutover is approximately 1K.
 tail:
 	TESTQ	BX, BX
 	JEQ	move_0
diff --git a/src/runtime/mfinal.go b/src/runtime/mfinal.go
index 9418e147bc..6142c2d532 100644
--- a/src/runtime/mfinal.go
+++ b/src/runtime/mfinal.go
@@ -219,8 +219,8 @@ func runfinq() {
 // SetFinalizer sets the finalizer associated with x to f.
 // When the garbage collector finds an unreachable block
 // with an associated finalizer, it clears the association and runs
-// f(x) in a separate goroutine.  This makes x reachable again, but
-// now without an associated finalizer.  Assuming that SetFinalizer
+// f(x) in a separate goroutine. This makes x reachable again, but
+// now without an associated finalizer. Assuming that SetFinalizer
 // is not called again, the next time the garbage collector sees
 // that x is unreachable, it will free x.
 //
@@ -374,8 +374,8 @@ okarg:
 	})
 }
 
-// Look up pointer v in heap.  Return the span containing the object,
-// the start of the object, and the size of the object.  If the object
+// Look up pointer v in heap. Return the span containing the object,
+// the start of the object, and the size of the object. If the object
 // does not exist, return nil, nil, 0.
 func findObject(v unsafe.Pointer) (s *mspan, x unsafe.Pointer, n uintptr) {
 	c := gomcache()
diff --git a/src/runtime/mfixalloc.go b/src/runtime/mfixalloc.go
index 569a304cf4..c4ab6487a8 100644
--- a/src/runtime/mfixalloc.go
+++ b/src/runtime/mfixalloc.go
@@ -2,7 +2,7 @@
 // Use of this source code is governed by a BSD-style
 // license that can be found in the LICENSE file.
 
-// Fixed-size object allocator.  Returned memory is not zeroed.
+// Fixed-size object allocator. Returned memory is not zeroed.
 //
 // See malloc.go for overview.
 
diff --git a/src/runtime/mgc.go b/src/runtime/mgc.go
index 138a623ca5..52936cec2c 100644
--- a/src/runtime/mgc.go
+++ b/src/runtime/mgc.go
@@ -1165,8 +1165,8 @@ func gcMarkTermination() {
 	casgstatus(gp, _Grunning, _Gwaiting)
 	gp.waitreason = "garbage collection"
 
-	// Run gc on the g0 stack.  We do this so that the g stack
-	// we're currently running on will no longer change.  Cuts
+	// Run gc on the g0 stack. We do this so that the g stack
+	// we're currently running on will no longer change. Cuts
 	// the root set down a bit (g0 stacks are not scanned, and
 	// we don't need to scan gc's internal state).  We also
 	// need to switch to g0 so we can shrink the stack.
diff --git a/src/runtime/mgcmark.go b/src/runtime/mgcmark.go
index 0be908bfe8..241fbc8169 100644
--- a/src/runtime/mgcmark.go
+++ b/src/runtime/mgcmark.go
@@ -704,7 +704,7 @@ func scanframeworker(frame *stkframe, cache *pcvalueCache, gcw *gcWork) {
 	pcdata := pcdatavalue(f, _PCDATA_StackMapIndex, targetpc, cache)
 	if pcdata == -1 {
 		// We do not have a valid pcdata value but there might be a
-		// stackmap for this function.  It is likely that we are looking
+		// stackmap for this function. It is likely that we are looking
 		// at the function prologue, assume so and hope for the best.
 		pcdata = 0
 	}
diff --git a/src/runtime/mgcwork.go b/src/runtime/mgcwork.go
index 7bc4278195..63a3ade3a6 100644
--- a/src/runtime/mgcwork.go
+++ b/src/runtime/mgcwork.go
@@ -17,11 +17,11 @@ const (
 // Garbage collector work pool abstraction.
 //
 // This implements a producer/consumer model for pointers to grey
-// objects.  A grey object is one that is marked and on a work
-// queue.  A black object is marked and not on a work queue.
+// objects. A grey object is one that is marked and on a work
+// queue. A black object is marked and not on a work queue.
 //
 // Write barriers, root discovery, stack scanning, and object scanning
-// produce pointers to grey objects.  Scanning consumes pointers to
+// produce pointers to grey objects. Scanning consumes pointers to
 // grey objects, thus blackening them, and then scans them,
 // potentially producing new pointers to grey objects.
 
diff --git a/src/runtime/mheap.go b/src/runtime/mheap.go
index e8189547f8..06a7d88143 100644
--- a/src/runtime/mheap.go
+++ b/src/runtime/mheap.go
@@ -161,7 +161,7 @@ var h_allspans []*mspan // TODO: make this h.allspans once mheap can be defined
 
 // h_spans is a lookup table to map virtual address page IDs to *mspan.
 // For allocated spans, their pages map to the span itself.
-// For free spans, only the lowest and highest pages map to the span itself.  Internal
+// For free spans, only the lowest and highest pages map to the span itself. Internal
 // pages map to an arbitrary span.
 // For pages that have never been allocated, h_spans entries are nil.
 var h_spans []*mspan // TODO: make this h.spans once mheap can be defined in Go
@@ -689,7 +689,7 @@ func (h *mheap) lookup(v unsafe.Pointer) *mspan {
 // Address is *not* guaranteed to be in map
 // and may be anywhere in the span.
 // Map entries for the middle of a span are only
-// valid for allocated spans.  Free spans may have
+// valid for allocated spans. Free spans may have
 // other garbage in their middles, so we have to
 // check for that.
 func (h *mheap) lookupMaybe(v unsafe.Pointer) *mspan {
@@ -971,7 +971,7 @@ type special struct {
 }
 
 // Adds the special record s to the list of special records for
-// the object p.  All fields of s should be filled in except for
+// the object p. All fields of s should be filled in except for
 // offset & next, which this routine will fill in.
 // Returns true if the special was successfully added, false otherwise.
 // (The add will fail only if a record with the same p and s->kind
@@ -1069,7 +1069,7 @@ type specialfinalizer struct {
 	ot      *ptrtype
 }
 
-// Adds a finalizer to the object p.  Returns true if it succeeded.
+// Adds a finalizer to the object p. Returns true if it succeeded.
 func addfinalizer(p unsafe.Pointer, f *funcval, nret uintptr, fint *_type, ot *ptrtype) bool {
 	lock(&mheap_.speciallock)
 	s := (*specialfinalizer)(mheap_.specialfinalizeralloc.alloc())
@@ -1138,7 +1138,7 @@ func setprofilebucket(p unsafe.Pointer, b *bucket) {
 	}
 }
 
-// Do whatever cleanup needs to be done to deallocate s.  It has
+// Do whatever cleanup needs to be done to deallocate s. It has
 // already been unlinked from the MSpan specials list.
 func freespecial(s *special, p unsafe.Pointer, size uintptr) {
 	switch s.kind {
diff --git a/src/runtime/mmap.go b/src/runtime/mmap.go
index bcad065ea9..6363a90242 100644
--- a/src/runtime/mmap.go
+++ b/src/runtime/mmap.go
@@ -12,5 +12,5 @@ package runtime
 
 import "unsafe"
 
-// mmap calls the mmap system call.  It is implemented in assembly.
+// mmap calls the mmap system call. It is implemented in assembly.
 func mmap(addr unsafe.Pointer, n uintptr, prot, flags, fd int32, off uint32) unsafe.Pointer
diff --git a/src/runtime/mprof.go b/src/runtime/mprof.go
index d498a9328a..7be3ee9bf9 100644
--- a/src/runtime/mprof.go
+++ b/src/runtime/mprof.go
@@ -262,7 +262,7 @@ func mProf_Free(b *bucket, size uintptr) {
 var blockprofilerate uint64 // in CPU ticks
 
 // SetBlockProfileRate controls the fraction of goroutine blocking events
-// that are reported in the blocking profile.  The profiler aims to sample
+// that are reported in the blocking profile. The profiler aims to sample
 // an average of one blocking event per rate nanoseconds spent blocked.
 //
 // To include every blocking event in the profile, pass rate = 1.
@@ -335,7 +335,7 @@ func (r *StackRecord) Stack() []uintptr {
 //
 // The tools that process the memory profiles assume that the
 // profile rate is constant across the lifetime of the program
-// and equal to the current value.  Programs that change the
+// and equal to the current value. Programs that change the
 // memory profiling rate should do so just once, as early as
 // possible in the execution of the program (for example,
 // at the beginning of main).
diff --git a/src/runtime/msan.go b/src/runtime/msan.go
index 7eeeb30e6a..7177c8e611 100644
--- a/src/runtime/msan.go
+++ b/src/runtime/msan.go
@@ -24,10 +24,10 @@ func MSanWrite(addr unsafe.Pointer, len int) {
 const msanenabled = true
 
 // If we are running on the system stack, the C program may have
-// marked part of that stack as uninitialized.  We don't instrument
+// marked part of that stack as uninitialized. We don't instrument
 // the runtime, but operations like a slice copy can call msanread
-// anyhow for values on the stack.  Just ignore msanread when running
-// on the system stack.  The other msan functions are fine.
+// anyhow for values on the stack. Just ignore msanread when running
+// on the system stack. The other msan functions are fine.
 func msanread(addr unsafe.Pointer, sz uintptr) {
 	g := getg()
 	if g == g.m.g0 || g == g.m.gsignal {
diff --git a/src/runtime/msize.go b/src/runtime/msize.go
index bc735beb42..21fe2f4c61 100644
--- a/src/runtime/msize.go
+++ b/src/runtime/msize.go
@@ -13,7 +13,7 @@
 // and chopped up when new objects of the size class are needed.
 // That page count is chosen so that chopping up the run of
 // pages into objects of the given size wastes at most 12.5% (1.125x)
-// of the memory.  It is not necessary that the cutoff here be
+// of the memory. It is not necessary that the cutoff here be
 // the same as above.
 //
 // The two sources of waste multiply, so the worst possible case
@@ -27,7 +27,7 @@
 
 package runtime
 
-// Size classes.  Computed and initialized by InitSizes.
+// Size classes. Computed and initialized by InitSizes.
 //
 // SizeToClass(0 <= n <= MaxSmallSize) returns the size class,
 //	1 <= sizeclass < NumSizeClasses, for n.
diff --git a/src/runtime/mstats.go b/src/runtime/mstats.go
index 0f821b7e10..1d9b41ed20 100644
--- a/src/runtime/mstats.go
+++ b/src/runtime/mstats.go
@@ -371,7 +371,7 @@ func purgecachedstats(c *mcache) {
 	}
 }
 
-// Atomically increases a given *system* memory stat.  We are counting on this
+// Atomically increases a given *system* memory stat. We are counting on this
 // stat never overflowing a uintptr, so this function must only be used for
 // system memory stats.
 //
@@ -395,7 +395,7 @@ func mSysStatInc(sysStat *uint64, n uintptr) {
 	}
 }
 
-// Atomically decreases a given *system* memory stat.  Same comments as
+// Atomically decreases a given *system* memory stat. Same comments as
 // mSysStatInc apply.
 //go:nosplit
 func mSysStatDec(sysStat *uint64, n uintptr) {
diff --git a/src/runtime/netpoll_kqueue.go b/src/runtime/netpoll_kqueue.go
index 36956bae71..337377a95b 100644
--- a/src/runtime/netpoll_kqueue.go
+++ b/src/runtime/netpoll_kqueue.go
@@ -31,7 +31,7 @@ func netpollinit() {
 
 func netpollopen(fd uintptr, pd *pollDesc) int32 {
 	// Arm both EVFILT_READ and EVFILT_WRITE in edge-triggered mode (EV_CLEAR)
-	// for the whole fd lifetime.  The notifications are automatically unregistered
+	// for the whole fd lifetime. The notifications are automatically unregistered
 	// when fd is closed.
 	var ev [2]keventt
 	*(*uintptr)(unsafe.Pointer(&ev[0].ident)) = fd
diff --git a/src/runtime/os1_darwin.go b/src/runtime/os1_darwin.go
index 19bb0f16e0..01dc90f97c 100644
--- a/src/runtime/os1_darwin.go
+++ b/src/runtime/os1_darwin.go
@@ -66,7 +66,7 @@ func goenvs() {
 	goenvs_unix()
 
 	// Register our thread-creation callback (see sys_darwin_{amd64,386}.s)
-	// but only if we're not using cgo.  If we are using cgo we need
+	// but only if we're not using cgo. If we are using cgo we need
 	// to let the C pthread library install its own thread-creation callback.
 	if !iscgo {
 		if bsdthread_register() != 0 {
@@ -290,7 +290,7 @@ func machcall(h *machheader, maxsize int32, rxsize int32) int32 {
 	// Look for a response giving the return value.
 	// Any call can send this back with an error,
 	// and some calls only have return values so they
-	// send it back on success too.  I don't quite see how
+	// send it back on success too. I don't quite see how
 	// you know it's one of these and not the full response
 	// format, so just look if the message is right.
 	c := (*codemsg)(unsafe.Pointer(h))
diff --git a/src/runtime/os1_dragonfly.go b/src/runtime/os1_dragonfly.go
index 7e4f84e6a3..d7044ae4b0 100644
--- a/src/runtime/os1_dragonfly.go
+++ b/src/runtime/os1_dragonfly.go
@@ -143,9 +143,9 @@ func minit() {
 	// Initialize signal handling.
 
 	// On DragonFly a thread created by pthread_create inherits
-	// the signal stack of the creating thread.  We always create
+	// the signal stack of the creating thread. We always create
 	// a new signal stack here, to avoid having two Go threads
-	// using the same signal stack.  This breaks the case of a
+	// using the same signal stack. This breaks the case of a
 	// thread created in C that calls sigaltstack and then calls a
 	// Go function, because we will lose track of the C code's
 	// sigaltstack, but it's the best we can do.
@@ -191,7 +191,7 @@ func memlimit() uintptr {
 					return 0;
 
 				// If there's not at least 16 MB left, we're probably
-				// not going to be able to do much.  Treat as no limit.
+				// not going to be able to do much. Treat as no limit.
 				rl.rlim_cur -= used;
 				if(rl.rlim_cur < (16<<20))
 					return 0;
diff --git a/src/runtime/os1_freebsd.go b/src/runtime/os1_freebsd.go
index f00fdf4389..0dafe02325 100644
--- a/src/runtime/os1_freebsd.go
+++ b/src/runtime/os1_freebsd.go
@@ -201,7 +201,7 @@ func memlimit() uintptr {
 			return 0;
 
 		// If there's not at least 16 MB left, we're probably
-		// not going to be able to do much.  Treat as no limit.
+		// not going to be able to do much. Treat as no limit.
 		rl.rlim_cur -= used;
 		if(rl.rlim_cur < (16<<20))
 			return 0;
diff --git a/src/runtime/os1_linux.go b/src/runtime/os1_linux.go
index 2d53b934f5..1c1ead8790 100644
--- a/src/runtime/os1_linux.go
+++ b/src/runtime/os1_linux.go
@@ -33,7 +33,7 @@ func futexsleep(addr *uint32, val uint32, ns int64) {
 
 	// Some Linux kernels have a bug where futex of
 	// FUTEX_WAIT returns an internal error code
-	// as an errno.  Libpthread ignores the return value
+	// as an errno. Libpthread ignores the return value
 	// here, and so can we: as it says a few lines up,
 	// spurious wakeups are allowed.
 	if ns < 0 {
@@ -138,7 +138,7 @@ func newosproc(mp *m, stk unsafe.Pointer) {
 	}
 
 	// Disable signals during clone, so that the new thread starts
-	// with signals disabled.  It will enable them in minit.
+	// with signals disabled. It will enable them in minit.
 	var oset sigset
 	rtsigprocmask(_SIG_SETMASK, &sigset_all, &oset, int32(unsafe.Sizeof(oset)))
 	ret := clone(cloneFlags, stk, unsafe.Pointer(mp), unsafe.Pointer(mp.g0), unsafe.Pointer(funcPC(mstart)))
@@ -288,7 +288,7 @@ func memlimit() uintptr {
 			return 0;
 
 		// If there's not at least 16 MB left, we're probably
-		// not going to be able to do much.  Treat as no limit.
+		// not going to be able to do much. Treat as no limit.
 		rl.rlim_cur -= used;
 		if(rl.rlim_cur < (16<<20))
 			return 0;
diff --git a/src/runtime/os1_nacl.go b/src/runtime/os1_nacl.go
index 4cafaf2ebc..6fc2819cdd 100644
--- a/src/runtime/os1_nacl.go
+++ b/src/runtime/os1_nacl.go
@@ -172,7 +172,7 @@ func memlimit() uintptr {
 	return 0
 }
 
-// This runs on a foreign stack, without an m or a g.  No stack split.
+// This runs on a foreign stack, without an m or a g. No stack split.
 //go:nosplit
 func badsignal2() {
 	write(2, unsafe.Pointer(&badsignal1[0]), int32(len(badsignal1)))
diff --git a/src/runtime/os1_netbsd.go b/src/runtime/os1_netbsd.go
index e32df9585c..3c3b64186d 100644
--- a/src/runtime/os1_netbsd.go
+++ b/src/runtime/os1_netbsd.go
@@ -114,9 +114,9 @@ func newosproc(mp *m, stk unsafe.Pointer) {
 }
 
 // netbsdMStart is the function call that starts executing a newly
-// created thread.  On NetBSD, a new thread inherits the signal stack
-// of the creating thread.  That confuses minit, so we remove that
-// signal stack here before calling the regular mstart.  It's a bit
+// created thread. On NetBSD, a new thread inherits the signal stack
+// of the creating thread. That confuses minit, so we remove that
+// signal stack here before calling the regular mstart. It's a bit
 // baroque to remove a signal stack here only to add one in minit, but
 // it's a simple change that keeps NetBSD working like other OS's.
 // At this point all signals are blocked, so there is no race.
@@ -175,9 +175,9 @@ func minit() {
 	// Initialize signal handling.
 
 	// On NetBSD a thread created by pthread_create inherits the
-	// signal stack of the creating thread.  We always create a
+	// signal stack of the creating thread. We always create a
 	// new signal stack here, to avoid having two Go threads using
-	// the same signal stack.  This breaks the case of a thread
+	// the same signal stack. This breaks the case of a thread
 	// created in C that calls sigaltstack and then calls a Go
 	// function, because we will lose track of the C code's
 	// sigaltstack, but it's the best we can do.
diff --git a/src/runtime/os1_openbsd.go b/src/runtime/os1_openbsd.go
index a6cefa2039..447dff8193 100644
--- a/src/runtime/os1_openbsd.go
+++ b/src/runtime/os1_openbsd.go
@@ -80,7 +80,7 @@ func semasleep(ns int64) int32 {
 		//
 		// From OpenBSD's __thrsleep(2) manual:
 		// "The abort argument, if not NULL, points to an int that will
-		// be examined [...] immediately before blocking.  If that int
+		// be examined [...] immediately before blocking. If that int
 		// is non-zero then __thrsleep() will immediately return EINTR
 		// without blocking."
 		ret := thrsleep(uintptr(unsafe.Pointer(&_g_.m.waitsemacount)), _CLOCK_MONOTONIC, tsp, 0, &_g_.m.waitsemacount)
diff --git a/src/runtime/os1_plan9.go b/src/runtime/os1_plan9.go
index f35a39a418..c114b1db62 100644
--- a/src/runtime/os1_plan9.go
+++ b/src/runtime/os1_plan9.go
@@ -257,7 +257,7 @@ func memlimit() uint64 {
 
 var _badsignal = []byte("runtime: signal received on thread not created by Go.\n")
 
-// This runs on a foreign stack, without an m or a g.  No stack split.
+// This runs on a foreign stack, without an m or a g. No stack split.
 //go:nosplit
 func badsignal2() {
 	pwrite(2, unsafe.Pointer(&_badsignal[0]), int32(len(_badsignal)), -1)
diff --git a/src/runtime/os3_solaris.go b/src/runtime/os3_solaris.go
index fdc817d3f7..349f4abbcf 100644
--- a/src/runtime/os3_solaris.go
+++ b/src/runtime/os3_solaris.go
@@ -159,7 +159,7 @@ func newosproc(mp *m, _ unsafe.Pointer) {
 	}
 
 	// Disable signals during create, so that the new thread starts
-	// with signals disabled.  It will enable them in minit.
+	// with signals disabled. It will enable them in minit.
 	sigprocmask(_SIG_SETMASK, &sigset_all, &oset)
 	ret = pthread_create(&tid, &attr, funcPC(tstart_sysvicall), unsafe.Pointer(mp))
 	sigprocmask(_SIG_SETMASK, &oset, nil)
@@ -266,7 +266,7 @@ func memlimit() uintptr {
 			return 0;
 
 		// If there's not at least 16 MB left, we're probably
-		// not going to be able to do much.  Treat as no limit.
+		// not going to be able to do much. Treat as no limit.
 		rl.rlim_cur -= used;
 		if(rl.rlim_cur < (16<<20))
 			return 0;
@@ -357,8 +357,8 @@ func semacreate(mp *m) {
 	var sem *semt
 	_g_ := getg()
 
-	// Call libc's malloc rather than malloc.  This will
-	// allocate space on the C heap.  We can't call malloc
+	// Call libc's malloc rather than malloc. This will
+	// allocate space on the C heap. We can't call malloc
 	// here because it could cause a deadlock.
 	_g_.m.libcall.fn = uintptr(unsafe.Pointer(&libc_malloc))
 	_g_.m.libcall.n = 1
diff --git a/src/runtime/os_nacl.go b/src/runtime/os_nacl.go
index 402dfe9059..6f126b4770 100644
--- a/src/runtime/os_nacl.go
+++ b/src/runtime/os_nacl.go
@@ -63,7 +63,7 @@ func sigpanic() {
 func raiseproc(sig int32) {
 }
 
-// Stubs so tests can link correctly.  These should never be called.
+// Stubs so tests can link correctly. These should never be called.
 func open(name *byte, mode, perm int32) int32
 func closefd(fd int32) int32
 func read(fd int32, p unsafe.Pointer, n int32) int32
diff --git a/src/runtime/os_windows.go b/src/runtime/os_windows.go
index cab405e804..8bdf5a271f 100644
--- a/src/runtime/os_windows.go
+++ b/src/runtime/os_windows.go
@@ -17,7 +17,7 @@ func os_sigpipe() {
 	throw("too many writes on closed pipe")
 }
 
-// Stubs so tests can link correctly.  These should never be called.
+// Stubs so tests can link correctly. These should never be called.
 func open(name *byte, mode, perm int32) int32 {
 	throw("unimplemented")
 	return -1
diff --git a/src/runtime/panic.go b/src/runtime/panic.go
index 349e997395..10065c1803 100644
--- a/src/runtime/panic.go
+++ b/src/runtime/panic.go
@@ -62,10 +62,10 @@ func deferproc(siz int32, fn *funcval) { // arguments of fn follow fn
 		throw("defer on system stack")
 	}
 
-	// the arguments of fn are in a perilous state.  The stack map
-	// for deferproc does not describe them.  So we can't let garbage
+	// the arguments of fn are in a perilous state. The stack map
+	// for deferproc does not describe them. So we can't let garbage
 	// collection or stack copying trigger until we've copied them out
-	// to somewhere safe.  The memmove below does that.
+	// to somewhere safe. The memmove below does that.
 	// Until the copy completes, we can only call nosplit routines.
 	sp := getcallersp(unsafe.Pointer(&siz))
 	argp := uintptr(unsafe.Pointer(&fn)) + unsafe.Sizeof(fn)
@@ -255,7 +255,7 @@ func freedeferfn() {
 // If there is a deferred function, this will call runtime·jmpdefer,
 // which will jump to the deferred function such that it appears
 // to have been called by the caller of deferreturn at the point
-// just before deferreturn was called.  The effect is that deferreturn
+// just before deferreturn was called. The effect is that deferreturn
 // is called again and again until there are no more deferred functions.
 // Cannot split the stack because we reuse the caller's frame to
 // call the deferred function.
@@ -291,8 +291,8 @@ func deferreturn(arg0 uintptr) {
 	jmpdefer(fn, uintptr(unsafe.Pointer(&arg0)))
 }
 
-// Goexit terminates the goroutine that calls it.  No other goroutine is affected.
-// Goexit runs all deferred calls before terminating the goroutine.  Because Goexit
+// Goexit terminates the goroutine that calls it. No other goroutine is affected.
+// Goexit runs all deferred calls before terminating the goroutine. Because Goexit
 // is not panic, however, any recover calls in those deferred functions will return nil.
 //
 // Calling Goexit from the main goroutine terminates that goroutine
@@ -348,7 +348,7 @@ func preprintpanics(p *_panic) {
 	}
 }
 
-// Print all currently active panics.  Used when crashing.
+// Print all currently active panics. Used when crashing.
 func printpanics(p *_panic) {
 	if p.link != nil {
 		printpanics(p.link)
@@ -449,7 +449,7 @@ func gopanic(e interface{}) {
 		d.fn = nil
 		gp._defer = d.link
 
-		// trigger shrinkage to test stack copy.  See stack_test.go:TestStackPanic
+		// trigger shrinkage to test stack copy. See stack_test.go:TestStackPanic
 		//GC()
 
 		pc := d.pc
@@ -554,7 +554,7 @@ func throw(s string) {
 var paniclk mutex
 
 // Unwind the stack after a deferred function calls recover
-// after a panic.  Then arrange to continue running as though
+// after a panic. Then arrange to continue running as though
 // the caller of the deferred function returned normally.
 func recovery(gp *g) {
 	// Info about defer passed in G struct.
diff --git a/src/runtime/pprof/pprof.go b/src/runtime/pprof/pprof.go
index f4a4a90c84..b702fd345d 100644
--- a/src/runtime/pprof/pprof.go
+++ b/src/runtime/pprof/pprof.go
@@ -31,7 +31,7 @@ import (
 //
 // A Profile's methods can be called from multiple goroutines simultaneously.
 //
-// Each Profile has a unique name.  A few profiles are predefined:
+// Each Profile has a unique name. A few profiles are predefined:
 //
 //	goroutine    - stack traces of all current goroutines
 //	heap         - a sampling of all heap allocations
@@ -48,7 +48,7 @@ import (
 // all known allocations. This exception helps mainly in programs running
 // without garbage collection enabled, usually for debugging purposes.
 //
-// The CPU profile is not available as a Profile.  It has a special API,
+// The CPU profile is not available as a Profile. It has a special API,
 // the StartCPUProfile and StopCPUProfile functions, because it streams
 // output to a writer during profiling.
 //
@@ -173,11 +173,11 @@ func (p *Profile) Count() int {
 // Add adds the current execution stack to the profile, associated with value.
 // Add stores value in an internal map, so value must be suitable for use as
 // a map key and will not be garbage collected until the corresponding
-// call to Remove.  Add panics if the profile already contains a stack for value.
+// call to Remove. Add panics if the profile already contains a stack for value.
 //
 // The skip parameter has the same meaning as runtime.Caller's skip
-// and controls where the stack trace begins.  Passing skip=0 begins the
-// trace in the function calling Add.  For example, given this
+// and controls where the stack trace begins. Passing skip=0 begins the
+// trace in the function calling Add. For example, given this
 // execution stack:
 //
 //	Add
@@ -266,7 +266,7 @@ func (x stackProfile) Less(i, j int) bool {
 }
 
 // A countProfile is a set of stack traces to be printed as counts
-// grouped by stack trace.  There are multiple implementations:
+// grouped by stack trace. There are multiple implementations:
 // all that matters is that we can find out how many traces there are
 // and obtain each trace in turn.
 type countProfile interface {
@@ -500,7 +500,7 @@ func writeGoroutine(w io.Writer, debug int) error {
 
 func writeGoroutineStacks(w io.Writer) error {
 	// We don't know how big the buffer needs to be to collect
-	// all the goroutines.  Start with 1 MB and try a few times, doubling each time.
+	// all the goroutines. Start with 1 MB and try a few times, doubling each time.
 	// Give up and use a truncated trace if 64 MB is not enough.
 	buf := make([]byte, 1<<20)
 	for i := 0; ; i++ {
@@ -563,7 +563,7 @@ var cpu struct {
 // Go code built with -buildmode=c-archive or -buildmode=c-shared.
 // StartCPUProfile relies on the SIGPROF signal, but that signal will
 // be delivered to the main program's SIGPROF signal handler (if any)
-// not to the one used by Go.  To make it work, call os/signal.Notify
+// not to the one used by Go. To make it work, call os/signal.Notify
 // for syscall.SIGPROF, but note that doing so may break any profiling
 // being done by the main program.
 func StartCPUProfile(w io.Writer) error {
@@ -574,7 +574,7 @@ func StartCPUProfile(w io.Writer) error {
 	// 100 Hz is a reasonable choice: it is frequent enough to
 	// produce useful data, rare enough not to bog down the
 	// system, and a nice round number to make it easy to
-	// convert sample counts to seconds.  Instead of requiring
+	// convert sample counts to seconds. Instead of requiring
 	// each client to specify the frequency, we hard code it.
 	const hz = 100
 
diff --git a/src/runtime/proc.go b/src/runtime/proc.go
index 16237e98ec..4aa6b3600e 100644
--- a/src/runtime/proc.go
+++ b/src/runtime/proc.go
@@ -126,7 +126,7 @@ func main() {
 	})
 
 	// Lock the main goroutine onto this, the main OS thread,
-	// during initialization.  Most programs won't care, but a few
+	// during initialization. Most programs won't care, but a few
 	// do require certain calls to be made by the main thread.
 	// Those can arrange for main.main to run in the main thread
 	// by calling runtime.LockOSThread during initialization
@@ -237,7 +237,7 @@ func forcegchelper() {
 
 //go:nosplit
 
-// Gosched yields the processor, allowing other goroutines to run.  It does not
+// Gosched yields the processor, allowing other goroutines to run. It does not
 // suspend the current goroutine, so execution resumes automatically.
 func Gosched() {
 	mcall(gosched_m)
@@ -424,7 +424,7 @@ func schedinit() {
 
 	sched.maxmcount = 10000
 
-	// Cache the framepointer experiment.  This affects stack unwinding.
+	// Cache the framepointer experiment. This affects stack unwinding.
 	framepointer_enabled = haveexperiment("framepointer")
 
 	tracebackinit()
@@ -454,7 +454,7 @@ func schedinit() {
 	}
 
 	if buildVersion == "" {
-		// Condition should never trigger.  This code just serves
+		// Condition should never trigger. This code just serves
 		// to ensure runtime·buildVersion is kept in the resulting binary.
 		buildVersion = "unknown"
 	}
@@ -1014,7 +1014,7 @@ func startTheWorldWithSema() {
 		// in the hope that it will be available next time.
 		// It would have been even better to start it before the collection,
 		// but doing so requires allocating memory, so it's tricky to
-		// coordinate.  This lazy approach works out in practice:
+		// coordinate. This lazy approach works out in practice:
 		// we don't mind if the first couple gc rounds don't have quite
 		// the maximum number of procs.
 		newm(mhelpgc, nil)
@@ -1470,7 +1470,7 @@ func unlockextra(mp *m) {
 	atomic.Storeuintptr(&extram, uintptr(unsafe.Pointer(mp)))
 }
 
-// Create a new m.  It will start off with a call to fn, or else the scheduler.
+// Create a new m. It will start off with a call to fn, or else the scheduler.
 // fn needs to be static and not a heap allocated closure.
 // May run with m.p==nil, so write barriers are not allowed.
 //go:nowritebarrier
@@ -2641,7 +2641,7 @@ func newproc(siz int32, fn *funcval) {
 
 // Create a new g running fn with narg bytes of arguments starting
 // at argp and returning nret bytes of results.  callerpc is the
-// address of the go statement that created this.  The new g is put
+// address of the go statement that created this. The new g is put
 // on the queue of g's waiting to run.
 func newproc1(fn *funcval, argp *uint8, narg int32, nret int32, callerpc uintptr) *g {
 	_g_ := getg()
@@ -2792,7 +2792,7 @@ retry:
 		_p_.gfree = gp.schedlink.ptr()
 		_p_.gfreecnt--
 		if gp.stack.lo == 0 {
-			// Stack was deallocated in gfput.  Allocate a new one.
+			// Stack was deallocated in gfput. Allocate a new one.
 			systemstack(func() {
 				gp.stack, gp.stkbar = stackalloc(_FixedStack)
 			})
@@ -3128,7 +3128,7 @@ func setcpuprofilerate_m(hz int32) {
 	_g_.m.locks--
 }
 
-// Change number of processors.  The world is stopped, sched is locked.
+// Change number of processors. The world is stopped, sched is locked.
 // gcworkbufs are not being modified by either the GC or
 // the write barrier code.
 // Returns list of Ps with local work, they need to be scheduled by the caller.
@@ -3334,7 +3334,7 @@ func incidlelocked(v int32) {
 // The check is based on number of running M's, if 0 -> deadlock.
 func checkdead() {
 	// For -buildmode=c-shared or -buildmode=c-archive it's OK if
-	// there are no running goroutines.  The calling program is
+	// there are no running goroutines. The calling program is
 	// assumed to be running.
 	if islibrary || isarchive {
 		return
@@ -3579,7 +3579,7 @@ func retake(now int64) uint32 {
 }
 
 // Tell all goroutines that they have been preempted and they should stop.
-// This function is purely best-effort.  It can fail to inform a goroutine if a
+// This function is purely best-effort. It can fail to inform a goroutine if a
 // processor just started running it.
 // No locks need to be held.
 // Returns true if preemption request was issued to at least one goroutine.
@@ -3598,8 +3598,8 @@ func preemptall() bool {
 }
 
 // Tell the goroutine running on processor P to stop.
-// This function is purely best-effort.  It can incorrectly fail to inform the
-// goroutine.  It can send inform the wrong goroutine.  Even if it informs the
+// This function is purely best-effort. It can incorrectly fail to inform the
+// goroutine. It can send inform the wrong goroutine. Even if it informs the
 // correct goroutine, that goroutine might ignore the request if it is
 // simultaneously executing newstack.
 // No lock needs to be held.
diff --git a/src/runtime/rt0_linux_arm.s b/src/runtime/rt0_linux_arm.s
index d28c15a43a..a4419b898e 100644
--- a/src/runtime/rt0_linux_arm.s
+++ b/src/runtime/rt0_linux_arm.s
@@ -13,7 +13,7 @@ TEXT _rt0_arm_linux(SB),NOSPLIT,$-4
 // When building with -buildmode=c-shared, this symbol is called when the shared
 // library is loaded.
 TEXT _rt0_arm_linux_lib(SB),NOSPLIT,$32
-	// Preserve callee-save registers.  Raspberry Pi's dlopen(), for example,
+	// Preserve callee-save registers. Raspberry Pi's dlopen(), for example,
 	// actually cares that R11 is preserved.
 	MOVW	R4, 12(R13)
 	MOVW	R5, 16(R13)
diff --git a/src/runtime/runtime1.go b/src/runtime/runtime1.go
index 400ea296a9..0d539c829c 100644
--- a/src/runtime/runtime1.go
+++ b/src/runtime/runtime1.go
@@ -77,7 +77,7 @@ func goargs() {
 
 func goenvs_unix() {
 	// TODO(austin): ppc64 in dynamic linking mode doesn't
-	// guarantee env[] will immediately follow argv.  Might cause
+	// guarantee env[] will immediately follow argv. Might cause
 	// problems.
 	n := int32(0)
 	for argv_index(argv, argc+1+n) != nil {
diff --git a/src/runtime/runtime2.go b/src/runtime/runtime2.go
index 5f22afd863..6230b69e80 100644
--- a/src/runtime/runtime2.go
+++ b/src/runtime/runtime2.go
@@ -539,7 +539,7 @@ const (
 	_Structrnd = sys.RegSize
 )
 
-// startup_random_data holds random bytes initialized at startup.  These come from
+// startup_random_data holds random bytes initialized at startup. These come from
 // the ELF AT_RANDOM auxiliary vector (vdso_linux_amd64.go or os_linux_386.go).
 var startupRandomData []byte
 
diff --git a/src/runtime/runtime_test.go b/src/runtime/runtime_test.go
index f9d8f9dc9f..cd078c7eac 100644
--- a/src/runtime/runtime_test.go
+++ b/src/runtime/runtime_test.go
@@ -247,8 +247,8 @@ func TestBadOpen(t *testing.T) {
 	if GOOS == "windows" || GOOS == "nacl" {
 		t.Skip("skipping OS that doesn't have open/read/write/close")
 	}
-	// make sure we get the correct error code if open fails.  Same for
-	// read/write/close on the resulting -1 fd.  See issue 10052.
+	// make sure we get the correct error code if open fails. Same for
+	// read/write/close on the resulting -1 fd. See issue 10052.
 	nonfile := []byte("/notreallyafile")
 	fd := Open(&nonfile[0], 0, 0)
 	if fd != -1 {
diff --git a/src/runtime/select.go b/src/runtime/select.go
index b315dde6c6..4e87dba3e7 100644
--- a/src/runtime/select.go
+++ b/src/runtime/select.go
@@ -239,7 +239,7 @@ func selectgoImpl(sel *hselect) (uintptr, uint16) {
 	// only 0 or 1 cases plus default into simpler constructs.
 	// The only way we can end up with such small sel.ncase
 	// values here is for a larger select in which most channels
-	// have been nilled out.  The general code handles those
+	// have been nilled out. The general code handles those
 	// cases correctly, and they are rare enough not to bother
 	// optimizing (and needing to test).
 
@@ -649,8 +649,8 @@ func (q *waitq) dequeueSudoG(sgp *sudog) {
 		return
 	}
 
-	// x==y==nil.  Either sgp is the only element in the queue,
-	// or it has already been removed.  Use q.first to disambiguate.
+	// x==y==nil. Either sgp is the only element in the queue,
+	// or it has already been removed. Use q.first to disambiguate.
 	if q.first == sgp {
 		q.first = nil
 		q.last = nil
diff --git a/src/runtime/signal1_unix.go b/src/runtime/signal1_unix.go
index c848b129ce..8e4d425fde 100644
--- a/src/runtime/signal1_unix.go
+++ b/src/runtime/signal1_unix.go
@@ -212,11 +212,11 @@ func raisebadsignal(sig int32) {
 
 	// Reset the signal handler and raise the signal.
 	// We are currently running inside a signal handler, so the
-	// signal is blocked.  We need to unblock it before raising the
+	// signal is blocked. We need to unblock it before raising the
 	// signal, or the signal we raise will be ignored until we return
-	// from the signal handler.  We know that the signal was unblocked
+	// from the signal handler. We know that the signal was unblocked
 	// before entering the handler, or else we would not have received
-	// it.  That means that we don't have to worry about blocking it
+	// it. That means that we don't have to worry about blocking it
 	// again.
 	unblocksig(sig)
 	setsig(sig, handler, false)
@@ -294,14 +294,14 @@ func ensureSigM() {
 
 // This is called when we receive a signal when there is no signal stack.
 // This can only happen if non-Go code calls sigaltstack to disable the
-// signal stack.  This is called via cgocallback to establish a stack.
+// signal stack. This is called via cgocallback to establish a stack.
 func noSignalStack(sig uint32) {
 	println("signal", sig, "received on thread with no signal stack")
 	throw("non-Go code disabled sigaltstack")
 }
 
 // This is called if we receive a signal when there is a signal stack
-// but we are not on it.  This can only happen if non-Go code called
+// but we are not on it. This can only happen if non-Go code called
 // sigaction without setting the SS_ONSTACK flag.
 func sigNotOnStack(sig uint32) {
 	println("signal", sig, "received but handler not on signal stack")
diff --git a/src/runtime/signal2_unix.go b/src/runtime/signal2_unix.go
index e8c57b38ee..b137169940 100644
--- a/src/runtime/signal2_unix.go
+++ b/src/runtime/signal2_unix.go
@@ -12,7 +12,7 @@ import "unsafe"
 func sigfwd(fn uintptr, sig uint32, info *siginfo, ctx unsafe.Pointer)
 
 // Determines if the signal should be handled by Go and if not, forwards the
-// signal to the handler that was installed before Go's.  Returns whether the
+// signal to the handler that was installed before Go's. Returns whether the
 // signal was forwarded.
 // This is called by the signal handler, and the world may be stopped.
 //go:nosplit
@@ -54,7 +54,7 @@ func sigfwdgo(sig uint32, info *siginfo, ctx unsafe.Pointer) bool {
 	if c.sigcode() == _SI_USER || flags&_SigPanic == 0 {
 		return false
 	}
-	// Determine if the signal occurred inside Go code.  We test that:
+	// Determine if the signal occurred inside Go code. We test that:
 	//   (1) we were in a goroutine (i.e., m.curg != nil), and
 	//   (2) we weren't in CGO (i.e., m.curg.syscallsp == 0).
 	g := getg()
diff --git a/src/runtime/signal_386.go b/src/runtime/signal_386.go
index 967f2b5299..f27cf9d8e2 100644
--- a/src/runtime/signal_386.go
+++ b/src/runtime/signal_386.go
@@ -84,7 +84,7 @@ func sighandler(sig uint32, info *siginfo, ctxt unsafe.Pointer, gp *g) {
 
 		// Only push runtime.sigpanic if pc != 0.
 		// If pc == 0, probably panicked because of a
-		// call to a nil func.  Not pushing that onto sp will
+		// call to a nil func. Not pushing that onto sp will
 		// make the trace look like a call to runtime.sigpanic instead.
 		// (Otherwise the trace will end at runtime.sigpanic and we
 		// won't get to see who faulted.)
diff --git a/src/runtime/signal_amd64x.go b/src/runtime/signal_amd64x.go
index e5d4389d89..7b51fcc481 100644
--- a/src/runtime/signal_amd64x.go
+++ b/src/runtime/signal_amd64x.go
@@ -116,7 +116,7 @@ func sighandler(sig uint32, info *siginfo, ctxt unsafe.Pointer, gp *g) {
 
 		// Only push runtime.sigpanic if pc != 0.
 		// If pc == 0, probably panicked because of a
-		// call to a nil func.  Not pushing that onto sp will
+		// call to a nil func. Not pushing that onto sp will
 		// make the trace look like a call to runtime.sigpanic instead.
 		// (Otherwise the trace will end at runtime.sigpanic and we
 		// won't get to see who faulted.)
diff --git a/src/runtime/signal_windows.go b/src/runtime/signal_windows.go
index ab7183fe6b..6a53cf6452 100644
--- a/src/runtime/signal_windows.go
+++ b/src/runtime/signal_windows.go
@@ -82,7 +82,7 @@ func exceptionhandler(info *exceptionrecord, r *context, gp *g) int32 {
 
 	// Only push runtime·sigpanic if r.ip() != 0.
 	// If r.ip() == 0, probably panicked because of a
-	// call to a nil func.  Not pushing that onto sp will
+	// call to a nil func. Not pushing that onto sp will
 	// make the trace look like a call to runtime·sigpanic instead.
 	// (Otherwise the trace will end at runtime·sigpanic and we
 	// won't get to see who faulted.)
diff --git a/src/runtime/sigqueue.go b/src/runtime/sigqueue.go
index 546d3abb24..e86e6a5636 100644
--- a/src/runtime/sigqueue.go
+++ b/src/runtime/sigqueue.go
@@ -12,7 +12,7 @@
 // sigsend is called by the signal handler to queue a new signal.
 // signal_recv is called by the Go program to receive a newly queued signal.
 // Synchronization between sigsend and signal_recv is based on the sig.state
-// variable.  It can be in 3 states: sigIdle, sigReceiving and sigSending.
+// variable. It can be in 3 states: sigIdle, sigReceiving and sigSending.
 // sigReceiving means that signal_recv is blocked on sig.Note and there are no
 // new pending signals.
 // sigSending means that sig.mask *may* contain new pending signals,
@@ -136,7 +136,7 @@ func signal_recv() uint32 {
 func signal_enable(s uint32) {
 	if !sig.inuse {
 		// The first call to signal_enable is for us
-		// to use for initialization.  It does not pass
+		// to use for initialization. It does not pass
 		// signal information in m.
 		sig.inuse = true // enable reception of signals; cannot disable
 		noteclear(&sig.note)
@@ -177,7 +177,7 @@ func signal_ignored(s uint32) bool {
 	return sig.ignored[s/32]&(1<<(s&31)) != 0
 }
 
-// This runs on a foreign stack, without an m or a g.  No stack split.
+// This runs on a foreign stack, without an m or a g. No stack split.
 //go:nosplit
 //go:norace
 //go:nowritebarrierrec
diff --git a/src/runtime/sigqueue_plan9.go b/src/runtime/sigqueue_plan9.go
index 89f96be2e9..575d26afb4 100644
--- a/src/runtime/sigqueue_plan9.go
+++ b/src/runtime/sigqueue_plan9.go
@@ -115,7 +115,7 @@ func signal_recv() string {
 func signal_enable(s uint32) {
 	if !sig.inuse {
 		// The first call to signal_enable is for us
-		// to use for initialization.  It does not pass
+		// to use for initialization. It does not pass
 		// signal information in m.
 		sig.inuse = true // enable reception of signals; cannot disable
 		noteclear(&sig.note)
diff --git a/src/runtime/sqrt.go b/src/runtime/sqrt.go
index 1b130e3b01..d71a498c0a 100644
--- a/src/runtime/sqrt.go
+++ b/src/runtime/sqrt.go
@@ -11,7 +11,7 @@ package runtime
 
 // The original C code and the long comment below are
 // from FreeBSD's /usr/src/lib/msun/src/e_sqrt.c and
-// came with this notice.  The go code is a simplified
+// came with this notice. The go code is a simplified
 // version of the original C.
 //
 // ====================================================
diff --git a/src/runtime/stack.go b/src/runtime/stack.go
index d2466de653..f7865144d7 100644
--- a/src/runtime/stack.go
+++ b/src/runtime/stack.go
@@ -93,7 +93,7 @@ const (
 	_StackGuard = 720*sys.StackGuardMultiplier + _StackSystem
 
 	// After a stack split check the SP is allowed to be this
-	// many bytes below the stack guard.  This saves an instruction
+	// many bytes below the stack guard. This saves an instruction
 	// in the checking sequence for tiny frames.
 	_StackSmall = 128
 
@@ -180,13 +180,13 @@ func stacklog2(n uintptr) int {
 	return log2
 }
 
-// Allocates a stack from the free pool.  Must be called with
+// Allocates a stack from the free pool. Must be called with
 // stackpoolmu held.
 func stackpoolalloc(order uint8) gclinkptr {
 	list := &stackpool[order]
 	s := list.first
 	if s == nil {
-		// no free stacks.  Allocate another span worth.
+		// no free stacks. Allocate another span worth.
 		s = mheap_.allocStack(_StackCacheSize >> _PageShift)
 		if s == nil {
 			throw("out of memory")
@@ -217,7 +217,7 @@ func stackpoolalloc(order uint8) gclinkptr {
 	return x
 }
 
-// Adds stack x to the free pool.  Must be called with stackpoolmu held.
+// Adds stack x to the free pool. Must be called with stackpoolmu held.
 func stackpoolfree(x gclinkptr, order uint8) {
 	s := mheap_.lookup(unsafe.Pointer(x))
 	if s.state != _MSpanStack {
diff --git a/src/runtime/stack_test.go b/src/runtime/stack_test.go
index 9702e1e913..a32b68b630 100644
--- a/src/runtime/stack_test.go
+++ b/src/runtime/stack_test.go
@@ -416,9 +416,9 @@ func TestStackAllOutput(t *testing.T) {
 }
 
 func TestStackPanic(t *testing.T) {
-	// Test that stack copying copies panics correctly.  This is difficult
+	// Test that stack copying copies panics correctly. This is difficult
 	// to test because it is very unlikely that the stack will be copied
-	// in the middle of gopanic.  But it can happen.
+	// in the middle of gopanic. But it can happen.
 	// To make this test effective, edit panic.go:gopanic and uncomment
 	// the GC() call just before freedefer(d).
 	defer func() {
diff --git a/src/runtime/string_test.go b/src/runtime/string_test.go
index 37b75c1a89..292d5595e3 100644
--- a/src/runtime/string_test.go
+++ b/src/runtime/string_test.go
@@ -237,7 +237,7 @@ func TestRangeStringCast(t *testing.T) {
 func TestString2Slice(t *testing.T) {
 	// Make sure we don't return slices that expose
 	// an unzeroed section of stack-allocated temp buf
-	// between len and cap.  See issue 14232.
+	// between len and cap. See issue 14232.
 	s := "foož"
 	b := ([]byte)(s)
 	if cap(b) != 5 {
diff --git a/src/runtime/symtab.go b/src/runtime/symtab.go
index afea41448f..f1df93f9e4 100644
--- a/src/runtime/symtab.go
+++ b/src/runtime/symtab.go
@@ -163,8 +163,8 @@ const pcbucketsize = 256 * minfunc // size of bucket in the pc->func lookup tabl
 // Each bucket represents 4096 bytes of the text segment.
 // Each subbucket represents 256 bytes of the text segment.
 // To find a function given a pc, locate the bucket and subbucket for
-// that pc.  Add together the idx and subbucket value to obtain a
-// function index.  Then scan the functab array starting at that
+// that pc. Add together the idx and subbucket value to obtain a
+// function index. Then scan the functab array starting at that
 // index to find the target function.
 // This table uses 20 bytes for every 4096 bytes of code, or ~0.5% overhead.
 type findfuncbucket struct {
diff --git a/src/runtime/sys_darwin_386.s b/src/runtime/sys_darwin_386.s
index ad3dca444a..9e45f8a002 100644
--- a/src/runtime/sys_darwin_386.s
+++ b/src/runtime/sys_darwin_386.s
@@ -377,7 +377,7 @@ TEXT runtime·bsdthread_start(SB),NOSPLIT,$0
 	POPL	AX
 	POPAL
 
-	// Now segment is established.  Initialize m, g.
+	// Now segment is established. Initialize m, g.
 	get_tls(BP)
 	MOVL    m_g0(DX), AX
 	MOVL	AX, g(BP)
diff --git a/src/runtime/sys_dragonfly_amd64.s b/src/runtime/sys_dragonfly_amd64.s
index 4e4d793c43..be964cb3ec 100644
--- a/src/runtime/sys_dragonfly_amd64.s
+++ b/src/runtime/sys_dragonfly_amd64.s
@@ -52,11 +52,11 @@ TEXT runtime·lwp_start(SB),NOSPLIT,$0
 	MOVQ	DI, g(CX)
 
 	// On DragonFly, a new thread inherits the signal stack of the
-	// creating thread.  That confuses minit, so we remove that
-	// signal stack here before calling the regular mstart.  It's
+	// creating thread. That confuses minit, so we remove that
+	// signal stack here before calling the regular mstart. It's
 	// a bit baroque to remove a signal stack here only to add one
 	// in minit, but it's a simple change that keeps DragonFly
-	// working like other OS's.  At this point all signals are
+	// working like other OS's. At this point all signals are
 	// blocked, so there is no race.
 	SUBQ	$8, SP
 	MOVQ	$0, 0(SP)
diff --git a/src/runtime/sys_linux_386.s b/src/runtime/sys_linux_386.s
index 4a74196032..3c7b17f927 100644
--- a/src/runtime/sys_linux_386.s
+++ b/src/runtime/sys_linux_386.s
@@ -355,7 +355,7 @@ TEXT runtime·clone(SB),NOSPLIT,$0
 	POPL	AX
 	POPAL
 
-	// Now segment is established.  Initialize m, g.
+	// Now segment is established. Initialize m, g.
 	get_tls(AX)
 	MOVL	DX, g(AX)
 	MOVL	BX, g_m(DX)
diff --git a/src/runtime/sys_linux_amd64.s b/src/runtime/sys_linux_amd64.s
index f407078176..7cab649238 100644
--- a/src/runtime/sys_linux_amd64.s
+++ b/src/runtime/sys_linux_amd64.s
@@ -357,7 +357,7 @@ nog:
 	// Call fn
 	CALL	R12
 
-	// It shouldn't return.  If it does, exit that thread.
+	// It shouldn't return. If it does, exit that thread.
 	MOVL	$111, DI
 	MOVL	$60, AX
 	SYSCALL
diff --git a/src/runtime/sys_linux_arm.s b/src/runtime/sys_linux_arm.s
index 6a3b924330..50a551320a 100644
--- a/src/runtime/sys_linux_arm.s
+++ b/src/runtime/sys_linux_arm.s
@@ -313,7 +313,7 @@ nog:
 	MOVW	$16(R13), R13
 	BL	(R0)
 
-	// It shouldn't return.  If it does, exit that thread.
+	// It shouldn't return. If it does, exit that thread.
 	SUB	$16, R13 // restore the stack pointer to avoid memory corruption
 	MOVW	$0, R0
 	MOVW	R0, 4(R13)
diff --git a/src/runtime/sys_netbsd_386.s b/src/runtime/sys_netbsd_386.s
index 3b3c1095f0..0322c36d1c 100644
--- a/src/runtime/sys_netbsd_386.s
+++ b/src/runtime/sys_netbsd_386.s
@@ -262,7 +262,7 @@ TEXT runtime·lwp_tramp(SB),NOSPLIT,$0
 	POPL	AX
 	POPAL
 
-	// Now segment is established.  Initialize m, g.
+	// Now segment is established. Initialize m, g.
 	get_tls(AX)
 	MOVL	DX, g(AX)
 	MOVL	BX, g_m(DX)
diff --git a/src/runtime/sys_netbsd_amd64.s b/src/runtime/sys_netbsd_amd64.s
index fb21f1155a..d6b5d35232 100644
--- a/src/runtime/sys_netbsd_amd64.s
+++ b/src/runtime/sys_netbsd_amd64.s
@@ -37,7 +37,7 @@ TEXT runtime·lwp_tramp(SB),NOSPLIT,$0
 	// Call fn
 	CALL	R12
 
-	// It shouldn't return.  If it does, exit.
+	// It shouldn't return. If it does, exit.
 	MOVL	$310, AX		// sys__lwp_exit
 	SYSCALL
 	JMP	-3(PC)			// keep exiting
diff --git a/src/runtime/sys_openbsd_386.s b/src/runtime/sys_openbsd_386.s
index 769b2f9455..f80a85fb67 100644
--- a/src/runtime/sys_openbsd_386.s
+++ b/src/runtime/sys_openbsd_386.s
@@ -279,7 +279,7 @@ TEXT runtime·tfork(SB),NOSPLIT,$12
 	POPL	AX
 	POPAL
 	
-	// Now segment is established.  Initialize m, g.
+	// Now segment is established. Initialize m, g.
 	get_tls(AX)
 	MOVL	DX, g(AX)
 	MOVL	BX, g_m(DX)
diff --git a/src/runtime/sys_openbsd_amd64.s b/src/runtime/sys_openbsd_amd64.s
index ed368babc0..c9fb8322c5 100644
--- a/src/runtime/sys_openbsd_amd64.s
+++ b/src/runtime/sys_openbsd_amd64.s
@@ -50,7 +50,7 @@ TEXT runtime·tfork(SB),NOSPLIT,$32
 	// Call fn
 	CALL	R12
 
-	// It shouldn't return.  If it does, exit
+	// It shouldn't return. If it does, exit
 	MOVQ	$0, DI			// arg 1 - notdead
 	MOVL	$302, AX		// sys___threxit
 	SYSCALL
diff --git a/src/runtime/sys_x86.go b/src/runtime/sys_x86.go
index 9729671725..f6e45cc2dc 100644
--- a/src/runtime/sys_x86.go
+++ b/src/runtime/sys_x86.go
@@ -40,13 +40,13 @@ func rewindmorestack(buf *gobuf) {
 		return
 	}
 	if pc[0] == 0xcc {
-		// This is a breakpoint inserted by gdb.  We could use
-		// runtime·findfunc to find the function.  But if we
+		// This is a breakpoint inserted by gdb. We could use
+		// runtime·findfunc to find the function. But if we
 		// do that, then we will continue execution at the
 		// function entry point, and we will not hit the gdb
-		// breakpoint.  So for this case we don't change
+		// breakpoint. So for this case we don't change
 		// buf.pc, so that when we return we will execute
-		// the jump instruction and carry on.  This means that
+		// the jump instruction and carry on. This means that
 		// stack unwinding may not work entirely correctly
 		// (https://golang.org/issue/5723) but the user is
 		// running under gdb anyhow.
diff --git a/src/runtime/textflag.h b/src/runtime/textflag.h
index 4739781530..e11c5dc3a2 100644
--- a/src/runtime/textflag.h
+++ b/src/runtime/textflag.h
@@ -3,12 +3,12 @@
 // license that can be found in the LICENSE file.
 
 // This file defines flags attached to various functions
-// and data objects.  The compilers, assemblers, and linker must
+// and data objects. The compilers, assemblers, and linker must
 // all agree on these values.
 
-// Don't profile the marked routine.  This flag is deprecated.
+// Don't profile the marked routine. This flag is deprecated.
 #define NOPROF	1
-// It is ok for the linker to get multiple of these symbols.  It will
+// It is ok for the linker to get multiple of these symbols. It will
 // pick one of the duplicates to use.
 #define DUPOK	2
 // Don't insert stack check preamble.
diff --git a/src/runtime/time.go b/src/runtime/time.go
index 3f8f6968c2..8df185dc8f 100644
--- a/src/runtime/time.go
+++ b/src/runtime/time.go
@@ -202,7 +202,7 @@ func timerproc() {
 			goparkunlock(&timers.lock, "timer goroutine (idle)", traceEvGoBlock, 1)
 			continue
 		}
-		// At least one timer pending.  Sleep until then.
+		// At least one timer pending. Sleep until then.
 		timers.sleeping = true
 		noteclear(&timers.waitnote)
 		unlock(&timers.lock)
diff --git a/src/runtime/traceback.go b/src/runtime/traceback.go
index 1d76947380..1717624c1c 100644
--- a/src/runtime/traceback.go
+++ b/src/runtime/traceback.go
@@ -115,7 +115,7 @@ func tracebackdefers(gp *g, callback func(*stkframe, unsafe.Pointer) bool, v uns
 	}
 }
 
-// Generic traceback.  Handles runtime stack prints (pcbuf == nil),
+// Generic traceback. Handles runtime stack prints (pcbuf == nil),
 // the runtime.Callers function (pcbuf != nil), as well as the garbage
 // collector (callback != nil).  A little clunky to merge these, but avoids
 // duplicating the code and all its subtlety.
@@ -706,7 +706,7 @@ func tracebackothers(me *g) {
 		goroutineheader(gp)
 		// Note: gp.m == g.m occurs when tracebackothers is
 		// called from a signal handler initiated during a
-		// systemstack call.  The original G is still in the
+		// systemstack call. The original G is still in the
 		// running state, and we want to print its stack.
 		if gp.m != g.m && readgstatus(gp)&^_Gscan == _Grunning {
 			print("\tgoroutine running on other thread; stack unavailable\n")
diff --git a/src/runtime/vlop_386.s b/src/runtime/vlop_386.s
index ce8e7d0643..92232d57bc 100644
--- a/src/runtime/vlop_386.s
+++ b/src/runtime/vlop_386.s
@@ -1,7 +1,7 @@
 // Inferno's libkern/vlop-386.s
 // http://code.google.com/p/inferno-os/source/browse/libkern/vlop-386.s
 //
-//         Copyright © 1994-1999 Lucent Technologies Inc.  All rights reserved.
+//         Copyright © 1994-1999 Lucent Technologies Inc. All rights reserved.
 //         Revisions Copyright © 2000-2007 Vita Nuova Holdings Limited (www.vitanuova.com).  All rights reserved.
 //         Portions Copyright 2009 The Go Authors. All rights reserved.
 //
diff --git a/src/runtime/vlop_arm.s b/src/runtime/vlop_arm.s
index ae1f58254a..338d9d5d09 100644
--- a/src/runtime/vlop_arm.s
+++ b/src/runtime/vlop_arm.s
@@ -1,7 +1,7 @@
 // Inferno's libkern/vlop-arm.s
 // http://code.google.com/p/inferno-os/source/browse/libkern/vlop-arm.s
 //
-//         Copyright © 1994-1999 Lucent Technologies Inc.  All rights reserved.
+//         Copyright © 1994-1999 Lucent Technologies Inc. All rights reserved.
 //         Revisions Copyright © 2000-2007 Vita Nuova Holdings Limited (www.vitanuova.com).  All rights reserved.
 //         Portions Copyright 2009 The Go Authors. All rights reserved.
 //
diff --git a/src/runtime/vlrt.go b/src/runtime/vlrt.go
index 6370732ca0..2419f78ce2 100644
--- a/src/runtime/vlrt.go
+++ b/src/runtime/vlrt.go
@@ -1,7 +1,7 @@
 // Inferno's libkern/vlrt-arm.c
 // http://code.google.com/p/inferno-os/source/browse/libkern/vlrt-arm.c
 //
-//         Copyright © 1994-1999 Lucent Technologies Inc.  All rights reserved.
+//         Copyright © 1994-1999 Lucent Technologies Inc. All rights reserved.
 //         Revisions Copyright © 2000-2007 Vita Nuova Holdings Limited (www.vitanuova.com).  All rights reserved.
 //         Portions Copyright 2009 The Go Authors. All rights reserved.
 //
diff --git a/src/sort/search.go b/src/sort/search.go
index de8178ff48..b9640a40af 100644
--- a/src/sort/search.go
+++ b/src/sort/search.go
@@ -8,10 +8,10 @@ package sort
 
 // Search uses binary search to find and return the smallest index i
 // in [0, n) at which f(i) is true, assuming that on the range [0, n),
-// f(i) == true implies f(i+1) == true.  That is, Search requires that
+// f(i) == true implies f(i+1) == true. That is, Search requires that
 // f is false for some (possibly empty) prefix of the input range [0, n)
 // and then true for the (possibly empty) remainder; Search returns
-// the first true index.  If there is no such index, Search returns n.
+// the first true index. If there is no such index, Search returns n.
 // (Note that the "not found" return value is not -1 as in, for instance,
 // strings.Index.)
 // Search calls f(i) only for i in the range [0, n).
@@ -85,7 +85,7 @@ func SearchInts(a []int, x int) int {
 }
 
 // SearchFloat64s searches for x in a sorted slice of float64s and returns the index
-// as specified by Search.  The return value is the index to insert x if x is not
+// as specified by Search. The return value is the index to insert x if x is not
 // present (it could be len(a)).
 // The slice must be sorted in ascending order.
 //
@@ -94,7 +94,7 @@ func SearchFloat64s(a []float64, x float64) int {
 }
 
 // SearchStrings searches for x in a sorted slice of strings and returns the index
-// as specified by Search.  The return value is the index to insert x if x is not
+// as specified by Search. The return value is the index to insert x if x is not
 // present (it could be len(a)).
 // The slice must be sorted in ascending order.
 //
diff --git a/src/sort/search_test.go b/src/sort/search_test.go
index 29b8d62dfe..ded68ebde0 100644
--- a/src/sort/search_test.go
+++ b/src/sort/search_test.go
@@ -147,7 +147,7 @@ func BenchmarkSearchWrappers(b *testing.B) {
 }
 
 // Abstract exhaustive test: all sizes up to 100,
-// all possible return values.  If there are any small
+// all possible return values. If there are any small
 // corner cases, this test exercises them.
 func TestSearchExhaustive(t *testing.T) {
 	for size := 0; size <= 100; size++ {
diff --git a/src/sort/sort.go b/src/sort/sort.go
index ce3dc06f88..b322c0eddf 100644
--- a/src/sort/sort.go
+++ b/src/sort/sort.go
@@ -7,7 +7,7 @@
 package sort
 
 // A type, typically a collection, that satisfies sort.Interface can be
-// sorted by the routines in this package.  The methods require that the
+// sorted by the routines in this package. The methods require that the
 // elements of the collection be enumerated by an integer index.
 type Interface interface {
 	// Len is the number of elements in the collection.
@@ -315,7 +315,7 @@ func StringsAreSorted(a []string) bool { return IsSorted(StringSlice(a)) }
 
 // Notes on stable sorting:
 // The used algorithms are simple and provable correct on all input and use
-// only logarithmic additional stack space.  They perform well if compared
+// only logarithmic additional stack space. They perform well if compared
 // experimentally to other stable in-place sorting algorithms.
 //
 // Remarks on other algorithms evaluated:
diff --git a/src/strconv/atof_test.go b/src/strconv/atof_test.go
index ba4933218b..9f70cc1fd7 100644
--- a/src/strconv/atof_test.go
+++ b/src/strconv/atof_test.go
@@ -196,7 +196,7 @@ var (
 
 func init() {
 	// The atof routines return NumErrors wrapping
-	// the error and the string.  Convert the table above.
+	// the error and the string. Convert the table above.
 	for i := range atoftests {
 		test := &atoftests[i]
 		if test.err != nil {
diff --git a/src/strconv/atoi.go b/src/strconv/atoi.go
index e6febcb7d8..8fd966eaf8 100644
--- a/src/strconv/atoi.go
+++ b/src/strconv/atoi.go
@@ -138,16 +138,16 @@ Error:
 }
 
 // ParseInt interprets a string s in the given base (2 to 36) and
-// returns the corresponding value i.  If base == 0, the base is
+// returns the corresponding value i. If base == 0, the base is
 // implied by the string's prefix: base 16 for "0x", base 8 for
 // "0", and base 10 otherwise.
 //
 // The bitSize argument specifies the integer type
-// that the result must fit into.  Bit sizes 0, 8, 16, 32, and 64
+// that the result must fit into. Bit sizes 0, 8, 16, 32, and 64
 // correspond to int, int8, int16, int32, and int64.
 //
 // The errors that ParseInt returns have concrete type *NumError
-// and include err.Num = s.  If s is empty or contains invalid
+// and include err.Num = s. If s is empty or contains invalid
 // digits, err.Err = ErrSyntax and the returned value is 0;
 // if the value corresponding to s cannot be represented by a
 // signed integer of the given size, err.Err = ErrRange and the
diff --git a/src/strconv/atoi_test.go b/src/strconv/atoi_test.go
index bd6a6a01fa..d608505da2 100644
--- a/src/strconv/atoi_test.go
+++ b/src/strconv/atoi_test.go
@@ -196,7 +196,7 @@ var numErrorTests = []numErrorTest{
 
 func init() {
 	// The atoi routines return NumErrors wrapping
-	// the error and the string.  Convert the tables above.
+	// the error and the string. Convert the tables above.
 	for i := range atoui64tests {
 		test := &atoui64tests[i]
 		if test.err != nil {
diff --git a/src/strconv/fp_test.go b/src/strconv/fp_test.go
index 6de2f8bc6f..39dd9c4a58 100644
--- a/src/strconv/fp_test.go
+++ b/src/strconv/fp_test.go
@@ -41,7 +41,7 @@ func myatof64(s string) (f float64, ok bool) {
 		}
 		v := float64(n)
 		// We expect that v*pow2(e) fits in a float64,
-		// but pow2(e) by itself may not.  Be careful.
+		// but pow2(e) by itself may not. Be careful.
 		if e <= -1000 {
 			v *= pow2(-1000)
 			e += 1000
diff --git a/src/strconv/ftoa.go b/src/strconv/ftoa.go
index 9ff5d1056a..8b3d33e4e7 100644
--- a/src/strconv/ftoa.go
+++ b/src/strconv/ftoa.go
@@ -23,7 +23,7 @@ var float32info = floatInfo{23, 8, -127}
 var float64info = floatInfo{52, 11, -1023}
 
 // FormatFloat converts the floating-point number f to a string,
-// according to the format fmt and precision prec.  It rounds the
+// according to the format fmt and precision prec. It rounds the
 // result assuming that the original was obtained from a floating-point
 // value of bitSize bits (32 for float32, 64 for float64).
 //
diff --git a/src/strconv/quote.go b/src/strconv/quote.go
index 8a60159d41..becfe1df07 100644
--- a/src/strconv/quote.go
+++ b/src/strconv/quote.go
@@ -104,7 +104,7 @@ func appendEscapedRune(buf []byte, r rune, width int, quote byte, ASCIIonly, gra
 	return buf
 }
 
-// Quote returns a double-quoted Go string literal representing s.  The
+// Quote returns a double-quoted Go string literal representing s. The
 // returned string uses Go escape sequences (\t, \n, \xFF, \u0100) for
 // control characters and non-printable characters as defined by
 // IsPrint.
diff --git a/src/strings/compare_test.go b/src/strings/compare_test.go
index 68fc88e143..bc12e421b0 100644
--- a/src/strings/compare_test.go
+++ b/src/strings/compare_test.go
@@ -56,7 +56,7 @@ func TestCompareStrings(t *testing.T) {
 	a := make([]byte, n+1)
 	b := make([]byte, n+1)
 	for len := 0; len < 128; len++ {
-		// randomish but deterministic data.  No 0 or 255.
+		// randomish but deterministic data. No 0 or 255.
 		for i := 0; i < len; i++ {
 			a[i] = byte(1 + 31*i%254)
 			b[i] = byte(1 + 31*i%254)
diff --git a/src/strings/strings.go b/src/strings/strings.go
index 37d5647ffd..c24c77b9dd 100644
--- a/src/strings/strings.go
+++ b/src/strings/strings.go
@@ -346,7 +346,7 @@ func FieldsFunc(s string, f func(rune) bool) []string {
 	return a
 }
 
-// Join concatenates the elements of a to create a single string.   The separator string
+// Join concatenates the elements of a to create a single string. The separator string
 // sep is placed between elements in the resulting string.
 func Join(a []string, sep string) string {
 	if len(a) == 0 {
@@ -384,8 +384,8 @@ func HasSuffix(s, suffix string) bool {
 // dropped from the string with no replacement.
 func Map(mapping func(rune) rune, s string) string {
 	// In the worst case, the string can grow when mapped, making
-	// things unpleasant.  But it's so rare we barge in assuming it's
-	// fine.  It could also shrink but that falls out naturally.
+	// things unpleasant. But it's so rare we barge in assuming it's
+	// fine. It could also shrink but that falls out naturally.
 	maxbytes := len(s) // length of b
 	nbytes := 0        // number of bytes encoded in b
 	// The output buffer b is initialized on demand, the first
@@ -714,7 +714,7 @@ func EqualFold(s, t string) bool {
 			return false
 		}
 
-		// General case.  SimpleFold(x) returns the next equivalent rune > x
+		// General case. SimpleFold(x) returns the next equivalent rune > x
 		// or wraps around to smaller values.
 		r := unicode.SimpleFold(sr)
 		for r != sr && r < tr {
@@ -726,6 +726,6 @@ func EqualFold(s, t string) bool {
 		return false
 	}
 
-	// One string is empty.  Are both?
+	// One string is empty. Are both?
 	return s == t
 }
diff --git a/src/strings/strings_test.go b/src/strings/strings_test.go
index 49f55fe38c..0572adbdd9 100644
--- a/src/strings/strings_test.go
+++ b/src/strings/strings_test.go
@@ -492,7 +492,7 @@ func rot13(r rune) rune {
 func TestMap(t *testing.T) {
 	// Run a couple of awful growth/shrinkage tests
 	a := tenRunes('a')
-	// 1.  Grow.  This triggers two reallocations in Map.
+	// 1.  Grow. This triggers two reallocations in Map.
 	maxRune := func(rune) rune { return unicode.MaxRune }
 	m := Map(maxRune, a)
 	expect := tenRunes(unicode.MaxRune)
diff --git a/src/sync/atomic/asm_arm.s b/src/sync/atomic/asm_arm.s
index 6cdc8fbc36..d35ea2a4e0 100644
--- a/src/sync/atomic/asm_arm.s
+++ b/src/sync/atomic/asm_arm.s
@@ -208,7 +208,7 @@ loop:
 ok:
 	RET
 
-// Fast, cached version of check.  No frame, just MOVW CMP RET after first time.
+// Fast, cached version of check. No frame, just MOVW CMP RET after first time.
 TEXT	fastCheck64<>(SB),NOSPLIT,$-4
 	MOVW	ok64<>(SB), R0
 	CMP	$0, R0	// have we been here before?
diff --git a/src/sync/atomic/atomic_test.go b/src/sync/atomic/atomic_test.go
index 23650abae9..deb3ccb55b 100644
--- a/src/sync/atomic/atomic_test.go
+++ b/src/sync/atomic/atomic_test.go
@@ -747,7 +747,7 @@ func TestStorePointer(t *testing.T) {
 // (Is the function atomic?)
 //
 // For each function, we write a "hammer" function that repeatedly
-// uses the atomic operation to add 1 to a value.  After running
+// uses the atomic operation to add 1 to a value. After running
 // multiple hammers in parallel, check that we end with the correct
 // total.
 // Swap can't add 1, so it uses a different scheme.
diff --git a/src/sync/cond.go b/src/sync/cond.go
index 0aefcda908..273884767f 100644
--- a/src/sync/cond.go
+++ b/src/sync/cond.go
@@ -35,13 +35,13 @@ func NewCond(l Locker) *Cond {
 }
 
 // Wait atomically unlocks c.L and suspends execution
-// of the calling goroutine.  After later resuming execution,
-// Wait locks c.L before returning.  Unlike in other systems,
+// of the calling goroutine. After later resuming execution,
+// Wait locks c.L before returning. Unlike in other systems,
 // Wait cannot return unless awoken by Broadcast or Signal.
 //
 // Because c.L is not locked when Wait first resumes, the caller
 // typically cannot assume that the condition is true when
-// Wait returns.  Instead, the caller should Wait in a loop:
+// Wait returns. Instead, the caller should Wait in a loop:
 //
 //    c.L.Lock()
 //    for !condition() {
diff --git a/src/sync/mutex.go b/src/sync/mutex.go
index eb526144c5..78b115cf5a 100644
--- a/src/sync/mutex.go
+++ b/src/sync/mutex.go
@@ -3,8 +3,8 @@
 // license that can be found in the LICENSE file.
 
 // Package sync provides basic synchronization primitives such as mutual
-// exclusion locks.  Other than the Once and WaitGroup types, most are intended
-// for use by low-level library routines.  Higher-level synchronization is
+// exclusion locks. Other than the Once and WaitGroup types, most are intended
+// for use by low-level library routines. Higher-level synchronization is
 // better done via channels and communication.
 //
 // Values containing the types defined in this package should not be copied.
diff --git a/src/sync/once.go b/src/sync/once.go
index 10b42fddc2..d8ef952ea5 100644
--- a/src/sync/once.go
+++ b/src/sync/once.go
@@ -18,10 +18,10 @@ type Once struct {
 // first time for this instance of Once. In other words, given
 // 	var once Once
 // if once.Do(f) is called multiple times, only the first call will invoke f,
-// even if f has a different value in each invocation.  A new instance of
+// even if f has a different value in each invocation. A new instance of
 // Once is required for each function to execute.
 //
-// Do is intended for initialization that must be run exactly once.  Since f
+// Do is intended for initialization that must be run exactly once. Since f
 // is niladic, it may be necessary to use a function literal to capture the
 // arguments to a function to be invoked by Do:
 // 	config.once.Do(func() { config.init(filename) })
diff --git a/src/sync/rwmutex.go b/src/sync/rwmutex.go
index d438c93c88..9fc6e3bd2c 100644
--- a/src/sync/rwmutex.go
+++ b/src/sync/rwmutex.go
@@ -94,11 +94,11 @@ func (rw *RWMutex) Lock() {
 	}
 }
 
-// Unlock unlocks rw for writing.  It is a run-time error if rw is
+// Unlock unlocks rw for writing. It is a run-time error if rw is
 // not locked for writing on entry to Unlock.
 //
 // As with Mutexes, a locked RWMutex is not associated with a particular
-// goroutine.  One goroutine may RLock (Lock) an RWMutex and then
+// goroutine. One goroutine may RLock (Lock) an RWMutex and then
 // arrange for another goroutine to RUnlock (Unlock) it.
 func (rw *RWMutex) Unlock() {
 	if race.Enabled {
diff --git a/src/sync/waitgroup.go b/src/sync/waitgroup.go
index c77fec306c..029e6077cd 100644
--- a/src/sync/waitgroup.go
+++ b/src/sync/waitgroup.go
@@ -12,8 +12,8 @@ import (
 
 // A WaitGroup waits for a collection of goroutines to finish.
 // The main goroutine calls Add to set the number of
-// goroutines to wait for.  Then each of the goroutines
-// runs and calls Done when finished.  At the same time,
+// goroutines to wait for. Then each of the goroutines
+// runs and calls Done when finished. At the same time,
 // Wait can be used to block until all goroutines have finished.
 type WaitGroup struct {
 	// 64-bit value: high 32 bits are counter, low 32 bits are waiter count.
diff --git a/src/syscall/exec_bsd.go b/src/syscall/exec_bsd.go
index d182896a53..47adffd60c 100644
--- a/src/syscall/exec_bsd.go
+++ b/src/syscall/exec_bsd.go
@@ -32,7 +32,7 @@ func runtime_AfterFork()
 // If a dup or exec fails, write the errno error to pipe.
 // (Pipe is close-on-exec so if exec succeeds, it will be closed.)
 // In the child, this function must not acquire any locks, because
-// they might have been locked at the time of the fork.  This means
+// they might have been locked at the time of the fork. This means
 // no rescheduling, no malloc calls, and no new stack segments.
 // For the same reason compiler does not race instrument it.
 // The calls to RawSyscall are okay because they are assembly
diff --git a/src/syscall/exec_linux.go b/src/syscall/exec_linux.go
index 3e08d43bed..0ea9283bf6 100644
--- a/src/syscall/exec_linux.go
+++ b/src/syscall/exec_linux.go
@@ -48,7 +48,7 @@ func runtime_AfterFork()
 // If a dup or exec fails, write the errno error to pipe.
 // (Pipe is close-on-exec so if exec succeeds, it will be closed.)
 // In the child, this function must not acquire any locks, because
-// they might have been locked at the time of the fork.  This means
+// they might have been locked at the time of the fork. This means
 // no rescheduling, no malloc calls, and no new stack segments.
 // For the same reason compiler does not race instrument it.
 // The calls to RawSyscall are okay because they are assembly
diff --git a/src/syscall/exec_plan9.go b/src/syscall/exec_plan9.go
index d342cb02bc..b9e78c5ab4 100644
--- a/src/syscall/exec_plan9.go
+++ b/src/syscall/exec_plan9.go
@@ -15,31 +15,31 @@ import (
 // Lock synchronizing creation of new file descriptors with fork.
 //
 // We want the child in a fork/exec sequence to inherit only the
-// file descriptors we intend.  To do that, we mark all file
+// file descriptors we intend. To do that, we mark all file
 // descriptors close-on-exec and then, in the child, explicitly
 // unmark the ones we want the exec'ed program to keep.
 // Unix doesn't make this easy: there is, in general, no way to
-// allocate a new file descriptor close-on-exec.  Instead you
+// allocate a new file descriptor close-on-exec. Instead you
 // have to allocate the descriptor and then mark it close-on-exec.
 // If a fork happens between those two events, the child's exec
 // will inherit an unwanted file descriptor.
 //
 // This lock solves that race: the create new fd/mark close-on-exec
 // operation is done holding ForkLock for reading, and the fork itself
-// is done holding ForkLock for writing.  At least, that's the idea.
+// is done holding ForkLock for writing. At least, that's the idea.
 // There are some complications.
 //
 // Some system calls that create new file descriptors can block
 // for arbitrarily long times: open on a hung NFS server or named
-// pipe, accept on a socket, and so on.  We can't reasonably grab
+// pipe, accept on a socket, and so on. We can't reasonably grab
 // the lock across those operations.
 //
 // It is worse to inherit some file descriptors than others.
 // If a non-malicious child accidentally inherits an open ordinary file,
-// that's not a big deal.  On the other hand, if a long-lived child
+// that's not a big deal. On the other hand, if a long-lived child
 // accidentally inherits the write end of a pipe, then the reader
 // of that pipe will not see EOF until that child exits, potentially
-// causing the parent program to hang.  This is a common problem
+// causing the parent program to hang. This is a common problem
 // in threaded C programs that use popen.
 //
 // Luckily, the file descriptors that are most important not to
@@ -49,13 +49,13 @@ import (
 // The rules for which file descriptor-creating operations use the
 // ForkLock are as follows:
 //
-// 1) Pipe.    Does not block.  Use the ForkLock.
-// 2) Socket.  Does not block.  Use the ForkLock.
-// 3) Accept.  If using non-blocking mode, use the ForkLock.
+// 1) Pipe. Does not block. Use the ForkLock.
+// 2) Socket. Does not block. Use the ForkLock.
+// 3) Accept. If using non-blocking mode, use the ForkLock.
 //             Otherwise, live with the race.
-// 4) Open.    Can block.  Use O_CLOEXEC if available (Linux).
+// 4) Open. Can block. Use O_CLOEXEC if available (Linux).
 //             Otherwise, live with the race.
-// 5) Dup.     Does not block.  Use the ForkLock.
+// 5) Dup. Does not block. Use the ForkLock.
 //             On Linux, could use fcntl F_DUPFD_CLOEXEC
 //             instead of the ForkLock, but only for dup(fd, -1).
 
@@ -169,7 +169,7 @@ func init() {
 // (The pipe write end is close-on-exec so if exec succeeds, it will be closed.)
 //
 // In the child, this function must not acquire any locks, because
-// they might have been locked at the time of the fork.  This means
+// they might have been locked at the time of the fork. This means
 // no rescheduling, no malloc calls, and no new stack segments.
 // The calls to RawSyscall are okay because they are assembly
 // functions that do not grow the stack.
diff --git a/src/syscall/exec_solaris.go b/src/syscall/exec_solaris.go
index 63fa8482da..c2b2949462 100644
--- a/src/syscall/exec_solaris.go
+++ b/src/syscall/exec_solaris.go
@@ -44,7 +44,7 @@ func write1(fd uintptr, buf uintptr, nbyte uintptr) (n uintptr, err Errno)
 // If a dup or exec fails, write the errno error to pipe.
 // (Pipe is close-on-exec so if exec succeeds, it will be closed.)
 // In the child, this function must not acquire any locks, because
-// they might have been locked at the time of the fork.  This means
+// they might have been locked at the time of the fork. This means
 // no rescheduling, no malloc calls, and no new stack segments.
 //
 // We call hand-crafted syscalls, implemented in
diff --git a/src/syscall/exec_unix.go b/src/syscall/exec_unix.go
index 565252cb4a..82e33124e2 100644
--- a/src/syscall/exec_unix.go
+++ b/src/syscall/exec_unix.go
@@ -17,31 +17,31 @@ import (
 // Lock synchronizing creation of new file descriptors with fork.
 //
 // We want the child in a fork/exec sequence to inherit only the
-// file descriptors we intend.  To do that, we mark all file
+// file descriptors we intend. To do that, we mark all file
 // descriptors close-on-exec and then, in the child, explicitly
 // unmark the ones we want the exec'ed program to keep.
 // Unix doesn't make this easy: there is, in general, no way to
-// allocate a new file descriptor close-on-exec.  Instead you
+// allocate a new file descriptor close-on-exec. Instead you
 // have to allocate the descriptor and then mark it close-on-exec.
 // If a fork happens between those two events, the child's exec
 // will inherit an unwanted file descriptor.
 //
 // This lock solves that race: the create new fd/mark close-on-exec
 // operation is done holding ForkLock for reading, and the fork itself
-// is done holding ForkLock for writing.  At least, that's the idea.
+// is done holding ForkLock for writing. At least, that's the idea.
 // There are some complications.
 //
 // Some system calls that create new file descriptors can block
 // for arbitrarily long times: open on a hung NFS server or named
-// pipe, accept on a socket, and so on.  We can't reasonably grab
+// pipe, accept on a socket, and so on. We can't reasonably grab
 // the lock across those operations.
 //
 // It is worse to inherit some file descriptors than others.
 // If a non-malicious child accidentally inherits an open ordinary file,
-// that's not a big deal.  On the other hand, if a long-lived child
+// that's not a big deal. On the other hand, if a long-lived child
 // accidentally inherits the write end of a pipe, then the reader
 // of that pipe will not see EOF until that child exits, potentially
-// causing the parent program to hang.  This is a common problem
+// causing the parent program to hang. This is a common problem
 // in threaded C programs that use popen.
 //
 // Luckily, the file descriptors that are most important not to
@@ -51,13 +51,13 @@ import (
 // The rules for which file descriptor-creating operations use the
 // ForkLock are as follows:
 //
-// 1) Pipe.    Does not block.  Use the ForkLock.
-// 2) Socket.  Does not block.  Use the ForkLock.
-// 3) Accept.  If using non-blocking mode, use the ForkLock.
+// 1) Pipe. Does not block. Use the ForkLock.
+// 2) Socket. Does not block. Use the ForkLock.
+// 3) Accept. If using non-blocking mode, use the ForkLock.
 //             Otherwise, live with the race.
-// 4) Open.    Can block.  Use O_CLOEXEC if available (Linux).
+// 4) Open. Can block. Use O_CLOEXEC if available (Linux).
 //             Otherwise, live with the race.
-// 5) Dup.     Does not block.  Use the ForkLock.
+// 5) Dup. Does not block. Use the ForkLock.
 //             On Linux, could use fcntl F_DUPFD_CLOEXEC
 //             instead of the ForkLock, but only for dup(fd, -1).
 
diff --git a/src/syscall/syscall.go b/src/syscall/syscall.go
index 769e6b9fd5..bb102c6e13 100644
--- a/src/syscall/syscall.go
+++ b/src/syscall/syscall.go
@@ -3,10 +3,10 @@
 // license that can be found in the LICENSE file.
 
 // Package syscall contains an interface to the low-level operating system
-// primitives.  The details vary depending on the underlying system, and
+// primitives. The details vary depending on the underlying system, and
 // by default, godoc will display the syscall documentation for the current
-// system.  If you want godoc to display syscall documentation for another
-// system, set $GOOS and $GOARCH to the desired system.  For example, if
+// system. If you want godoc to display syscall documentation for another
+// system, set $GOOS and $GOARCH to the desired system. For example, if
 // you want to view documentation for freebsd/arm on linux/amd64, set $GOOS
 // to freebsd and $GOARCH to arm.
 // The primary use of syscall is inside other packages that provide a more
diff --git a/src/syscall/syscall_bsd.go b/src/syscall/syscall_bsd.go
index af563910b1..9370dd487e 100644
--- a/src/syscall/syscall_bsd.go
+++ b/src/syscall/syscall_bsd.go
@@ -33,7 +33,7 @@ func Getgroups() (gids []int, err error) {
 		return nil, nil
 	}
 
-	// Sanity check group count.  Max is 16 on BSD.
+	// Sanity check group count. Max is 16 on BSD.
 	if n < 0 || n > 1000 {
 		return nil, EINVAL
 	}
diff --git a/src/syscall/syscall_darwin.go b/src/syscall/syscall_darwin.go
index 52fd4e7094..1a3efd1e8f 100644
--- a/src/syscall/syscall_darwin.go
+++ b/src/syscall/syscall_darwin.go
@@ -53,7 +53,7 @@ func nametomib(name string) (mib []_C_int, err error) {
 
 	// NOTE(rsc): It seems strange to set the buffer to have
 	// size CTL_MAXNAME+2 but use only CTL_MAXNAME
-	// as the size.  I don't know why the +2 is here, but the
+	// as the size. I don't know why the +2 is here, but the
 	// kernel uses +2 for its own implementation of this function.
 	// I am scared that if we don't include the +2 here, the kernel
 	// will silently write 2 words farther than we specify
@@ -76,7 +76,7 @@ func nametomib(name string) (mib []_C_int, err error) {
 }
 
 // ParseDirent parses up to max directory entries in buf,
-// appending the names to names.  It returns the number
+// appending the names to names. It returns the number
 // bytes consumed from buf, the number of entries added
 // to names, and the new names slice.
 func ParseDirent(buf []byte, max int, names []string) (consumed int, count int, newnames []string) {
diff --git a/src/syscall/syscall_darwin_386.go b/src/syscall/syscall_darwin_386.go
index 2074e7ac2e..7dbb1c3d64 100644
--- a/src/syscall/syscall_darwin_386.go
+++ b/src/syscall/syscall_darwin_386.go
@@ -28,7 +28,7 @@ func NsecToTimeval(nsec int64) (tv Timeval) {
 //sysnb	gettimeofday(tp *Timeval) (sec int32, usec int32, err error)
 func Gettimeofday(tv *Timeval) (err error) {
 	// The tv passed to gettimeofday must be non-nil
-	// but is otherwise unused.  The answers come back
+	// but is otherwise unused. The answers come back
 	// in the two registers.
 	sec, usec, err := gettimeofday(tv)
 	tv.Sec = int32(sec)
diff --git a/src/syscall/syscall_darwin_amd64.go b/src/syscall/syscall_darwin_amd64.go
index 70b53b87f4..80e6024aeb 100644
--- a/src/syscall/syscall_darwin_amd64.go
+++ b/src/syscall/syscall_darwin_amd64.go
@@ -28,7 +28,7 @@ func NsecToTimeval(nsec int64) (tv Timeval) {
 //sysnb	gettimeofday(tp *Timeval) (sec int64, usec int32, err error)
 func Gettimeofday(tv *Timeval) (err error) {
 	// The tv passed to gettimeofday must be non-nil
-	// but is otherwise unused.  The answers come back
+	// but is otherwise unused. The answers come back
 	// in the two registers.
 	sec, usec, err := gettimeofday(tv)
 	tv.Sec = sec
diff --git a/src/syscall/syscall_darwin_arm.go b/src/syscall/syscall_darwin_arm.go
index 2a7d4f2db6..c302d83131 100644
--- a/src/syscall/syscall_darwin_arm.go
+++ b/src/syscall/syscall_darwin_arm.go
@@ -28,7 +28,7 @@ func NsecToTimeval(nsec int64) (tv Timeval) {
 //sysnb	gettimeofday(tp *Timeval) (sec int32, usec int32, err error)
 func Gettimeofday(tv *Timeval) (err error) {
 	// The tv passed to gettimeofday must be non-nil
-	// but is otherwise unused.  The answers come back
+	// but is otherwise unused. The answers come back
 	// in the two registers.
 	sec, usec, err := gettimeofday(tv)
 	tv.Sec = int32(sec)
diff --git a/src/syscall/syscall_darwin_arm64.go b/src/syscall/syscall_darwin_arm64.go
index de7a08bee0..29f40d4229 100644
--- a/src/syscall/syscall_darwin_arm64.go
+++ b/src/syscall/syscall_darwin_arm64.go
@@ -28,7 +28,7 @@ func NsecToTimeval(nsec int64) (tv Timeval) {
 //sysnb	gettimeofday(tp *Timeval) (sec int64, usec int32, err error)
 func Gettimeofday(tv *Timeval) (err error) {
 	// The tv passed to gettimeofday must be non-nil
-	// but is otherwise unused.  The answers come back
+	// but is otherwise unused. The answers come back
 	// in the two registers.
 	sec, usec, err := gettimeofday(tv)
 	tv.Sec = sec
diff --git a/src/syscall/syscall_dragonfly.go b/src/syscall/syscall_dragonfly.go
index c25963c437..7e693290a8 100644
--- a/src/syscall/syscall_dragonfly.go
+++ b/src/syscall/syscall_dragonfly.go
@@ -34,7 +34,7 @@ func nametomib(name string) (mib []_C_int, err error) {
 
 	// NOTE(rsc): It seems strange to set the buffer to have
 	// size CTL_MAXNAME+2 but use only CTL_MAXNAME
-	// as the size.  I don't know why the +2 is here, but the
+	// as the size. I don't know why the +2 is here, but the
 	// kernel uses +2 for its own implementation of this function.
 	// I am scared that if we don't include the +2 here, the kernel
 	// will silently write 2 words farther than we specify
@@ -57,7 +57,7 @@ func nametomib(name string) (mib []_C_int, err error) {
 }
 
 // ParseDirent parses up to max directory entries in buf,
-// appending the names to names.  It returns the number
+// appending the names to names. It returns the number
 // bytes consumed from buf, the number of entries added
 // to names, and the new names slice.
 func ParseDirent(buf []byte, max int, names []string) (consumed int, count int, newnames []string) {
diff --git a/src/syscall/syscall_freebsd.go b/src/syscall/syscall_freebsd.go
index 257d41960f..7bb163a53b 100644
--- a/src/syscall/syscall_freebsd.go
+++ b/src/syscall/syscall_freebsd.go
@@ -32,7 +32,7 @@ func nametomib(name string) (mib []_C_int, err error) {
 
 	// NOTE(rsc): It seems strange to set the buffer to have
 	// size CTL_MAXNAME+2 but use only CTL_MAXNAME
-	// as the size.  I don't know why the +2 is here, but the
+	// as the size. I don't know why the +2 is here, but the
 	// kernel uses +2 for its own implementation of this function.
 	// I am scared that if we don't include the +2 here, the kernel
 	// will silently write 2 words farther than we specify
@@ -55,7 +55,7 @@ func nametomib(name string) (mib []_C_int, err error) {
 }
 
 // ParseDirent parses up to max directory entries in buf,
-// appending the names to names.  It returns the number
+// appending the names to names. It returns the number
 // bytes consumed from buf, the number of entries added
 // to names, and the new names slice.
 func ParseDirent(buf []byte, max int, names []string) (consumed int, count int, newnames []string) {
diff --git a/src/syscall/syscall_linux.go b/src/syscall/syscall_linux.go
index 2875067df7..73a16f8959 100644
--- a/src/syscall/syscall_linux.go
+++ b/src/syscall/syscall_linux.go
@@ -163,7 +163,7 @@ func Getgroups() (gids []int, err error) {
 		return nil, nil
 	}
 
-	// Sanity check group count.  Max is 1<<16 on Linux.
+	// Sanity check group count. Max is 1<<16 on Linux.
 	if n < 0 || n > 1<<20 {
 		return nil, EINVAL
 	}
@@ -198,8 +198,8 @@ type WaitStatus uint32
 // 0x7F (stopped), or a signal number that caused an exit.
 // The 0x80 bit is whether there was a core dump.
 // An extra number (exit code, signal causing a stop)
-// is in the high bits.  At least that's the idea.
-// There are various irregularities.  For example, the
+// is in the high bits. At least that's the idea.
+// There are various irregularities. For example, the
 // "continued" status is 0xFFFF, distinguishing itself
 // from stopped via the core dump bit.
 
@@ -620,7 +620,7 @@ func ptracePeek(req int, pid int, addr uintptr, out []byte) (count int, err erro
 
 	var buf [sizeofPtr]byte
 
-	// Leading edge.  PEEKTEXT/PEEKDATA don't require aligned
+	// Leading edge. PEEKTEXT/PEEKDATA don't require aligned
 	// access (PEEKUSER warns that it might), but if we don't
 	// align our reads, we might straddle an unmapped page
 	// boundary and not get the bytes leading up to the page
diff --git a/src/syscall/syscall_linux_386.go b/src/syscall/syscall_linux_386.go
index 0e637b47d3..d9e0ed57ed 100644
--- a/src/syscall/syscall_linux_386.go
+++ b/src/syscall/syscall_linux_386.go
@@ -182,9 +182,9 @@ func Seek(fd int, offset int64, whence int) (newoffset int64, err error) {
 
 // On x86 Linux, all the socket calls go through an extra indirection,
 // I think because the 5-register system call interface can't handle
-// the 6-argument calls like sendto and recvfrom.  Instead the
+// the 6-argument calls like sendto and recvfrom. Instead the
 // arguments to the underlying system call are the number below
-// and a pointer to an array of uintptr.  We hide the pointer in the
+// and a pointer to an array of uintptr. We hide the pointer in the
 // socketcall assembly to avoid allocation on every system call.
 
 const (
diff --git a/src/syscall/syscall_nacl.go b/src/syscall/syscall_nacl.go
index bbeb22a66c..ba6eafed1c 100644
--- a/src/syscall/syscall_nacl.go
+++ b/src/syscall/syscall_nacl.go
@@ -59,7 +59,7 @@ func clen(n []byte) int {
 const PathMax = 256
 
 // An Errno is an unsigned number describing an error condition.
-// It implements the error interface.  The zero Errno is by convention
+// It implements the error interface. The zero Errno is by convention
 // a non-error, so code to convert from Errno to error should use:
 //	err = nil
 //	if errno != 0 {
diff --git a/src/syscall/syscall_solaris.go b/src/syscall/syscall_solaris.go
index 2f68760ed1..b307a80d28 100644
--- a/src/syscall/syscall_solaris.go
+++ b/src/syscall/syscall_solaris.go
@@ -39,7 +39,7 @@ func clen(n []byte) int {
 }
 
 // ParseDirent parses up to max directory entries in buf,
-// appending the names to names.  It returns the number
+// appending the names to names. It returns the number
 // bytes consumed from buf, the number of entries added
 // to names, and the new names slice.
 func ParseDirent(buf []byte, max int, names []string) (consumed int, count int, newnames []string) {
@@ -176,7 +176,7 @@ func Getgroups() (gids []int, err error) {
 		return nil, nil
 	}
 
-	// Sanity check group count.  Max is 16 on BSD.
+	// Sanity check group count. Max is 16 on BSD.
 	if n < 0 || n > 1000 {
 		return nil, EINVAL
 	}
diff --git a/src/syscall/syscall_unix.go b/src/syscall/syscall_unix.go
index 570313394c..4dae9d9b18 100644
--- a/src/syscall/syscall_unix.go
+++ b/src/syscall/syscall_unix.go
@@ -91,7 +91,7 @@ func (m *mmapper) Munmap(data []byte) (err error) {
 }
 
 // An Errno is an unsigned number describing an error condition.
-// It implements the error interface.  The zero Errno is by convention
+// It implements the error interface. The zero Errno is by convention
 // a non-error, so code to convert from Errno to error should use:
 //	err = nil
 //	if errno != 0 {
diff --git a/src/syscall/unzip_nacl.go b/src/syscall/unzip_nacl.go
index 5845e44f01..14b5bd154f 100644
--- a/src/syscall/unzip_nacl.go
+++ b/src/syscall/unzip_nacl.go
@@ -162,7 +162,7 @@ func (f *decompressor) readHuffman() {
 
 // Decode a single Huffman block from f.
 // hl and hd are the Huffman states for the lit/length values
-// and the distance values, respectively.  If hd == nil, using the
+// and the distance values, respectively. If hd == nil, using the
 // fixed distance encoding associated with fixed Huffman blocks.
 func (f *decompressor) huffmanBlock(hl, hd *huffmanDecoder) {
 	for {
diff --git a/src/testing/allocs.go b/src/testing/allocs.go
index 80c8658acf..1eeb2d4802 100644
--- a/src/testing/allocs.go
+++ b/src/testing/allocs.go
@@ -12,7 +12,7 @@ import (
 // Although the return value has type float64, it will always be an integral value.
 //
 // To compute the number of allocations, the function will first be run once as
-// a warm-up.  The average number of allocations over the specified number of
+// a warm-up. The average number of allocations over the specified number of
 // runs will then be measured and returned.
 //
 // AllocsPerRun sets GOMAXPROCS to 1 during its measurement and will restore
diff --git a/src/testing/benchmark.go b/src/testing/benchmark.go
index 39b8cff4d3..a5b163201e 100644
--- a/src/testing/benchmark.go
+++ b/src/testing/benchmark.go
@@ -63,7 +63,7 @@ type B struct {
 	netBytes  uint64
 }
 
-// StartTimer starts timing a test.  This function is called automatically
+// StartTimer starts timing a test. This function is called automatically
 // before a benchmark starts, but it can also used to resume timing after
 // a call to StopTimer.
 func (b *B) StartTimer() {
@@ -76,7 +76,7 @@ func (b *B) StartTimer() {
 	}
 }
 
-// StopTimer stops timing a test.  This can be used to pause the timer
+// StopTimer stops timing a test. This can be used to pause the timer
 // while performing complex initialization that you don't
 // want to measure.
 func (b *B) StopTimer() {
@@ -192,7 +192,7 @@ func (b *B) run() BenchmarkResult {
 	return b.result
 }
 
-// launch launches the benchmark function.  It gradually increases the number
+// launch launches the benchmark function. It gradually increases the number
 // of benchmark iterations until the benchmark runs for the requested benchtime.
 // It prints timing information in this form
 //		testing.BenchmarkHello	100000		19 ns/op
diff --git a/src/testing/iotest/reader.go b/src/testing/iotest/reader.go
index a5bccca906..8d82018fd6 100644
--- a/src/testing/iotest/reader.go
+++ b/src/testing/iotest/reader.go
@@ -71,7 +71,7 @@ func (r *dataErrReader) Read(p []byte) (n int, err error) {
 var ErrTimeout = errors.New("timeout")
 
 // TimeoutReader returns ErrTimeout on the second read
-// with no data.  Subsequent calls to read succeed.
+// with no data. Subsequent calls to read succeed.
 func TimeoutReader(r io.Reader) io.Reader { return &timeoutReader{r, 0} }
 
 type timeoutReader struct {
diff --git a/src/testing/quick/quick.go b/src/testing/quick/quick.go
index 1056aa2488..4bc8e3fc2e 100644
--- a/src/testing/quick/quick.go
+++ b/src/testing/quick/quick.go
@@ -248,8 +248,8 @@ func (s *CheckEqualError) Error() string {
 }
 
 // Check looks for an input to f, any function that returns bool,
-// such that f returns false.  It calls f repeatedly, with arbitrary
-// values for each argument.  If f returns false on a given input,
+// such that f returns false. It calls f repeatedly, with arbitrary
+// values for each argument. If f returns false on a given input,
 // Check returns that input as a *CheckError.
 // For example:
 //
diff --git a/src/testing/testing.go b/src/testing/testing.go
index 95182076ef..981883e07a 100644
--- a/src/testing/testing.go
+++ b/src/testing/testing.go
@@ -45,7 +45,7 @@
 //
 // The benchmark function must run the target code b.N times.
 // During benchmark execution, b.N is adjusted until the benchmark function lasts
-// long enough to be timed reliably.  The output
+// long enough to be timed reliably. The output
 //     BenchmarkHello    10000000    282 ns/op
 // means that the loop ran 10000000 times at a speed of 282 ns per loop.
 //
@@ -160,8 +160,8 @@ import (
 
 var (
 	// The short flag requests that tests run more quickly, but its functionality
-	// is provided by test writers themselves.  The testing package is just its
-	// home.  The all.bash installation script sets it to make installation more
+	// is provided by test writers themselves. The testing package is just its
+	// home. The all.bash installation script sets it to make installation more
 	// efficient, but by default the flag is off so a plain "go test" will do a
 	// full test of the package.
 	short = flag.Bool("test.short", false, "run smaller test suite to save time")
@@ -337,9 +337,9 @@ func (c *common) FailNow() {
 	// This previous version duplicated code (those lines are in
 	// tRunner no matter what), but worse the goroutine teardown
 	// implicit in runtime.Goexit was not guaranteed to complete
-	// before the test exited.  If a test deferred an important cleanup
+	// before the test exited. If a test deferred an important cleanup
 	// function (like removing temporary files), there was no guarantee
-	// it would run on a test failure.  Because we send on c.signal during
+	// it would run on a test failure. Because we send on c.signal during
 	// a top-of-stack deferred function now, we know that the send
 	// only happens after any other stacked defers have completed.
 	c.finished = true
diff --git a/src/text/scanner/scanner.go b/src/text/scanner/scanner.go
index dd87850fcd..a3da1fdabf 100644
--- a/src/text/scanner/scanner.go
+++ b/src/text/scanner/scanner.go
@@ -4,12 +4,12 @@
 
 // Package scanner provides a scanner and tokenizer for UTF-8-encoded text.
 // It takes an io.Reader providing the source, which then can be tokenized
-// through repeated calls to the Scan function.  For compatibility with
+// through repeated calls to the Scan function. For compatibility with
 // existing tools, the NUL character is not allowed. If the first character
 // in the source is a UTF-8 encoded byte order mark (BOM), it is discarded.
 //
 // By default, a Scanner skips white space and Go comments and recognizes all
-// literals as defined by the Go language specification.  It may be
+// literals as defined by the Go language specification. It may be
 // customized to recognize only a subset of those literals and to recognize
 // different identifier and white space characters.
 package scanner
diff --git a/src/text/template/exec.go b/src/text/template/exec.go
index e5be4fe7c7..a169e62ab0 100644
--- a/src/text/template/exec.go
+++ b/src/text/template/exec.go
@@ -440,7 +440,7 @@ func (s *state) evalCommand(dot reflect.Value, cmd *parse.CommandNode, final ref
 
 // idealConstant is called to return the value of a number in a context where
 // we don't know the type. In that case, the syntax of the number tells us
-// its type, and we use Go rules to resolve.  Note there is no such thing as
+// its type, and we use Go rules to resolve. Note there is no such thing as
 // a uint ideal constant in this situation - the value must be of int type.
 func (s *state) idealConstant(constant *parse.NumberNode) reflect.Value {
 	// These are ideal constants but we don't know the type
@@ -588,7 +588,7 @@ var (
 )
 
 // evalCall executes a function or method call. If it's a method, fun already has the receiver bound, so
-// it looks just like a function call.  The arg list, if non-nil, includes (in the manner of the shell), arg[0]
+// it looks just like a function call. The arg list, if non-nil, includes (in the manner of the shell), arg[0]
 // as the function itself.
 func (s *state) evalCall(dot, fun reflect.Value, node parse.Node, name string, args []parse.Node, final reflect.Value) reflect.Value {
 	if args != nil {
diff --git a/src/text/template/funcs.go b/src/text/template/funcs.go
index 58b8ea372d..0bfcffa795 100644
--- a/src/text/template/funcs.go
+++ b/src/text/template/funcs.go
@@ -142,7 +142,7 @@ func prepareArg(value reflect.Value, argType reflect.Type) (reflect.Value, error
 // Indexing.
 
 // index returns the result of indexing its first argument by the following
-// arguments.  Thus "index x 1 2 3" is, in Go syntax, x[1][2][3]. Each
+// arguments. Thus "index x 1 2 3" is, in Go syntax, x[1][2][3]. Each
 // indexed item must be a map, slice, or array.
 func index(item interface{}, indices ...interface{}) (interface{}, error) {
 	v := reflect.ValueOf(item)
diff --git a/src/text/template/parse/parse.go b/src/text/template/parse/parse.go
index a53e8ff771..86705e5a37 100644
--- a/src/text/template/parse/parse.go
+++ b/src/text/template/parse/parse.go
@@ -556,7 +556,7 @@ func (t *Tree) blockControl() Node {
 
 // Template:
 //	{{template stringValue pipeline}}
-// Template keyword is past.  The name must be something that can evaluate
+// Template keyword is past. The name must be something that can evaluate
 // to a string.
 func (t *Tree) templateControl() Node {
 	const context = "template clause"
diff --git a/src/text/template/parse/parse_test.go b/src/text/template/parse/parse_test.go
index b4512d3160..9d856bcb3d 100644
--- a/src/text/template/parse/parse_test.go
+++ b/src/text/template/parse/parse_test.go
@@ -76,7 +76,7 @@ var numberTests = []numberTest{
 
 func TestNumberParse(t *testing.T) {
 	for _, test := range numberTests {
-		// If fmt.Sscan thinks it's complex, it's complex.  We can't trust the output
+		// If fmt.Sscan thinks it's complex, it's complex. We can't trust the output
 		// because imaginary comes out as a number.
 		var c complex128
 		typ := itemNumber
diff --git a/src/time/format.go b/src/time/format.go
index e616feb048..13c2bb6e52 100644
--- a/src/time/format.go
+++ b/src/time/format.go
@@ -23,7 +23,7 @@ import "errors"
 // compatibility with fixed-width Unix time formats.
 //
 // A decimal point followed by one or more zeros represents a fractional
-// second, printed to the given number of decimal places.  A decimal point
+// second, printed to the given number of decimal places. A decimal point
 // followed by one or more nines represents a fractional second, printed to
 // the given number of decimal places, with trailing zeros removed.
 // When parsing (only), the input may contain a fractional second
@@ -37,7 +37,7 @@ import "errors"
 //	-07    ±hh
 // Replacing the sign in the format with a Z triggers
 // the ISO 8601 behavior of printing Z instead of an
-// offset for the UTC zone.  Thus:
+// offset for the UTC zone. Thus:
 //	Z0700  Z or ±hhmm
 //	Z07:00 Z or ±hh:mm
 //	Z07    Z or ±hh
@@ -551,7 +551,7 @@ func (t Time) AppendFormat(b []byte, layout string) []byte {
 				b = append(b, "am"...)
 			}
 		case stdISO8601TZ, stdISO8601ColonTZ, stdISO8601SecondsTZ, stdISO8601ShortTZ, stdISO8601ColonSecondsTZ, stdNumTZ, stdNumColonTZ, stdNumSecondsTz, stdNumShortTZ, stdNumColonSecondsTZ:
-			// Ugly special case.  We cheat and take the "Z" variants
+			// Ugly special case. We cheat and take the "Z" variants
 			// to mean "the time zone as formatted for ISO 8601".
 			if offset == 0 && (std == stdISO8601TZ || std == stdISO8601ColonTZ || std == stdISO8601SecondsTZ || std == stdISO8601ShortTZ || std == stdISO8601ColonSecondsTZ) {
 				b = append(b, 'Z')
diff --git a/src/time/sleep.go b/src/time/sleep.go
index e7a2ee2059..c348366604 100644
--- a/src/time/sleep.go
+++ b/src/time/sleep.go
@@ -24,7 +24,7 @@ type runtimeTimer struct {
 
 // when is a helper function for setting the 'when' field of a runtimeTimer.
 // It returns what the time will be, in nanoseconds, Duration d in the future.
-// If d is negative, it is ignored.  If the returned value would be less than
+// If d is negative, it is ignored. If the returned value would be less than
 // zero because of an overflow, MaxInt64 is returned.
 func when(d Duration) int64 {
 	if d <= 0 {
diff --git a/src/time/tick.go b/src/time/tick.go
index ccc2d9b479..3d693206a5 100644
--- a/src/time/tick.go
+++ b/src/time/tick.go
@@ -39,7 +39,7 @@ func NewTicker(d Duration) *Ticker {
 	return t
 }
 
-// Stop turns off a ticker.  After Stop, no more ticks will be sent.
+// Stop turns off a ticker. After Stop, no more ticks will be sent.
 // Stop does not close the channel, to prevent a read from the channel succeeding
 // incorrectly.
 func (t *Ticker) Stop() {
diff --git a/src/time/tick_test.go b/src/time/tick_test.go
index 32f4740ad9..2ab77f6025 100644
--- a/src/time/tick_test.go
+++ b/src/time/tick_test.go
@@ -35,7 +35,7 @@ func TestTicker(t *testing.T) {
 	}
 }
 
-// Test that a bug tearing down a ticker has been fixed.  This routine should not deadlock.
+// Test that a bug tearing down a ticker has been fixed. This routine should not deadlock.
 func TestTeardown(t *testing.T) {
 	Delta := 100 * Millisecond
 	if testing.Short() {
diff --git a/src/time/time.go b/src/time/time.go
index 5744200d8c..9693286fd5 100644
--- a/src/time/time.go
+++ b/src/time/time.go
@@ -12,8 +12,8 @@ import "errors"
 // A Time represents an instant in time with nanosecond precision.
 //
 // Programs using times should typically store and pass them as values,
-// not pointers.  That is, time variables and struct fields should be of
-// type time.Time, not *time.Time.  A Time value can be used by
+// not pointers. That is, time variables and struct fields should be of
+// type time.Time, not *time.Time. A Time value can be used by
 // multiple goroutines simultaneously.
 //
 // Time instants can be compared using the Before, After, and Equal methods.
@@ -146,7 +146,7 @@ func (d Weekday) String() string { return days[d] }
 // 00:00:00 UTC, which would be 12-31-(-1) 19:00:00 in New York.
 //
 // The zero Time value does not force a specific epoch for the time
-// representation.  For example, to use the Unix epoch internally, we
+// representation. For example, to use the Unix epoch internally, we
 // could define that to distinguish a zero value from Jan 1 1970, that
 // time would be represented by sec=-1, nsec=1e9.  However, it does
 // suggest a representation, namely using 1-1-1 00:00:00 UTC as the
@@ -155,17 +155,17 @@ func (d Weekday) String() string { return days[d] }
 // The Add and Sub computations are oblivious to the choice of epoch.
 //
 // The presentation computations - year, month, minute, and so on - all
-// rely heavily on division and modulus by positive constants.  For
+// rely heavily on division and modulus by positive constants. For
 // calendrical calculations we want these divisions to round down, even
 // for negative values, so that the remainder is always positive, but
 // Go's division (like most hardware division instructions) rounds to
-// zero.  We can still do those computations and then adjust the result
+// zero. We can still do those computations and then adjust the result
 // for a negative numerator, but it's annoying to write the adjustment
-// over and over.  Instead, we can change to a different epoch so long
+// over and over. Instead, we can change to a different epoch so long
 // ago that all the times we care about will be positive, and then round
-// to zero and round down coincide.  These presentation routines already
+// to zero and round down coincide. These presentation routines already
 // have to add the zone offset, so adding the translation to the
-// alternate epoch is cheap.  For example, having a non-negative time t
+// alternate epoch is cheap. For example, having a non-negative time t
 // means that we can write
 //
 //	sec = t % 60
@@ -181,9 +181,9 @@ func (d Weekday) String() string { return days[d] }
 //
 // The calendar runs on an exact 400 year cycle: a 400-year calendar
 // printed for 1970-2469 will apply as well to 2370-2769.  Even the days
-// of the week match up.  It simplifies the computations to choose the
+// of the week match up. It simplifies the computations to choose the
 // cycle boundaries so that the exceptional years are always delayed as
-// long as possible.  That means choosing a year equal to 1 mod 400, so
+// long as possible. That means choosing a year equal to 1 mod 400, so
 // that the first leap year is the 4th year, the first missed leap year
 // is the 100th year, and the missed missed leap year is the 400th year.
 // So we'd prefer instead to print a calendar for 2001-2400 and reuse it
@@ -209,7 +209,7 @@ func (d Weekday) String() string { return days[d] }
 // routines would then be invalid when displaying the epoch in time zones
 // west of UTC, since it is year 0.  It doesn't seem tenable to say that
 // printing the zero time correctly isn't supported in half the time
-// zones.  By comparison, it's reasonable to mishandle some times in
+// zones. By comparison, it's reasonable to mishandle some times in
 // the year -292277022399.
 //
 // All this is opaque to clients of the API and can be changed if a
@@ -425,7 +425,7 @@ func (t Time) YearDay() int {
 }
 
 // A Duration represents the elapsed time between two instants
-// as an int64 nanosecond count.  The representation limits the
+// as an int64 nanosecond count. The representation limits the
 // largest representable duration to approximately 290 years.
 type Duration int64
 
@@ -434,7 +434,7 @@ const (
 	maxDuration Duration = 1<<63 - 1
 )
 
-// Common durations.  There is no definition for units of Day or larger
+// Common durations. There is no definition for units of Day or larger
 // to avoid confusion across daylight savings time zone transitions.
 //
 // To count the number of units in a Duration, divide:
@@ -455,9 +455,9 @@ const (
 )
 
 // String returns a string representing the duration in the form "72h3m0.5s".
-// Leading zero units are omitted.  As a special case, durations less than one
+// Leading zero units are omitted. As a special case, durations less than one
 // second format use a smaller unit (milli-, micro-, or nanoseconds) to ensure
-// that the leading digit is non-zero.  The zero duration formats as 0,
+// that the leading digit is non-zero. The zero duration formats as 0,
 // with no unit.
 func (d Duration) String() string {
 	// Largest time is 2540400h10m10.000000000s
@@ -749,7 +749,7 @@ func absDate(abs uint64, full bool) (year int, month Month, day int, yday int) {
 }
 
 // daysBefore[m] counts the number of days in a non-leap year
-// before month m begins.  There is an entry for m=12, counting
+// before month m begins. There is an entry for m=12, counting
 // the number of days before January of next year (365).
 var daysBefore = [...]int32{
 	0,
@@ -1021,7 +1021,7 @@ func norm(hi, lo, base int) (nhi, nlo int) {
 //
 // A daylight savings time transition skips or repeats times.
 // For example, in the United States, March 13, 2011 2:15am never occurred,
-// while November 6, 2011 1:15am occurred twice.  In such cases, the
+// while November 6, 2011 1:15am occurred twice. In such cases, the
 // choice of time zone, and therefore the time, is not well-defined.
 // Date returns a time that is correct in one of the two zones involved
 // in the transition, but it does not guarantee which.
diff --git a/src/time/time_test.go b/src/time/time_test.go
index a925e98a83..5a5451b5b8 100644
--- a/src/time/time_test.go
+++ b/src/time/time_test.go
@@ -22,7 +22,7 @@ import (
 // the subsequent tests fail.
 func TestZoneData(t *testing.T) {
 	lt := Now()
-	// PST is 8 hours west, PDT is 7 hours west.  We could use the name but it's not unique.
+	// PST is 8 hours west, PDT is 7 hours west. We could use the name but it's not unique.
 	if name, off := lt.Zone(); off != -8*60*60 && off != -7*60*60 {
 		t.Errorf("Unable to find US Pacific time zone data for testing; time zone is %q offset %d", name, off)
 		t.Error("Likely problem: the time zone files have not been installed.")
diff --git a/src/time/zoneinfo_read.go b/src/time/zoneinfo_read.go
index de9ebb41c8..66777f6d73 100644
--- a/src/time/zoneinfo_read.go
+++ b/src/time/zoneinfo_read.go
@@ -210,10 +210,10 @@ func loadZoneFile(dir, name string) (l *Location, err error) {
 	return loadZoneData(buf)
 }
 
-// There are 500+ zoneinfo files.  Rather than distribute them all
+// There are 500+ zoneinfo files. Rather than distribute them all
 // individually, we ship them in an uncompressed zip file.
 // Used this way, the zip file format serves as a commonly readable
-// container for the individual small files.  We choose zip over tar
+// container for the individual small files. We choose zip over tar
 // because zip files have a contiguous table of contents, making
 // individual file lookups faster, and because the per-file overhead
 // in a zip file is considerably less than tar's 512 bytes.
diff --git a/src/time/zoneinfo_test.go b/src/time/zoneinfo_test.go
index 4ca7fad938..0b7584ab9c 100644
--- a/src/time/zoneinfo_test.go
+++ b/src/time/zoneinfo_test.go
@@ -19,7 +19,7 @@ func TestVersion3(t *testing.T) {
 }
 
 // Test that we get the correct results for times before the first
-// transition time.  To do this we explicitly check early dates in a
+// transition time. To do this we explicitly check early dates in a
 // couple of specific timezones.
 func TestFirstZone(t *testing.T) {
 	time.ForceZipFileForTesting(true)
diff --git a/src/unicode/graphic.go b/src/unicode/graphic.go
index 81eae3e762..ca6241949a 100644
--- a/src/unicode/graphic.go
+++ b/src/unicode/graphic.go
@@ -45,7 +45,7 @@ func IsGraphic(r rune) bool {
 // IsPrint reports whether the rune is defined as printable by Go. Such
 // characters include letters, marks, numbers, punctuation, symbols, and the
 // ASCII space character, from categories L, M, N, P, S and the ASCII space
-// character.  This categorization is the same as IsGraphic except that the
+// character. This categorization is the same as IsGraphic except that the
 // only spacing character is ASCII space, U+0020.
 func IsPrint(r rune) bool {
 	if uint32(r) <= MaxLatin1 {
diff --git a/src/unicode/letter.go b/src/unicode/letter.go
index 7fe4241edd..8443ee51a2 100644
--- a/src/unicode/letter.go
+++ b/src/unicode/letter.go
@@ -27,7 +27,7 @@ type RangeTable struct {
 	LatinOffset int // number of entries in R16 with Hi <= MaxLatin1
 }
 
-// Range16 represents of a range of 16-bit Unicode code points.  The range runs from Lo to Hi
+// Range16 represents of a range of 16-bit Unicode code points. The range runs from Lo to Hi
 // inclusive and has the specified stride.
 type Range16 struct {
 	Lo     uint16
@@ -36,7 +36,7 @@ type Range16 struct {
 }
 
 // Range32 represents of a range of Unicode code points and is used when one or
-// more of the values will not fit in 16 bits.  The range runs from Lo to Hi
+// more of the values will not fit in 16 bits. The range runs from Lo to Hi
 // inclusive and has the specified stride. Lo and Hi must always be >= 1<<16.
 type Range32 struct {
 	Lo     uint32
@@ -48,10 +48,10 @@ type Range32 struct {
 // code point to one code point) case conversion.
 // The range runs from Lo to Hi inclusive, with a fixed stride of 1.  Deltas
 // are the number to add to the code point to reach the code point for a
-// different case for that character.  They may be negative.  If zero, it
+// different case for that character. They may be negative. If zero, it
 // means the character is in the corresponding case. There is a special
 // case representing sequences of alternating corresponding Upper and Lower
-// pairs.  It appears with a fixed Delta of
+// pairs. It appears with a fixed Delta of
 //	{UpperLower, UpperLower, UpperLower}
 // The constant UpperLower has an otherwise impossible delta value.
 type CaseRange struct {
@@ -307,7 +307,7 @@ func (special SpecialCase) ToLower(r rune) rune {
 	return r1
 }
 
-// caseOrbit is defined in tables.go as []foldPair.  Right now all the
+// caseOrbit is defined in tables.go as []foldPair. Right now all the
 // entries fit in uint16, so use uint16.  If that changes, compilation
 // will fail (the constants in the composite literal will not fit in uint16)
 // and the types here can change to uint32.
@@ -317,7 +317,7 @@ type foldPair struct {
 }
 
 // SimpleFold iterates over Unicode code points equivalent under
-// the Unicode-defined simple case folding.  Among the code points
+// the Unicode-defined simple case folding. Among the code points
 // equivalent to rune (including rune itself), SimpleFold returns the
 // smallest rune > r if one exists, or else the smallest rune >= 0.
 //
@@ -347,7 +347,7 @@ func SimpleFold(r rune) rune {
 		return rune(caseOrbit[lo].To)
 	}
 
-	// No folding specified.  This is a one- or two-element
+	// No folding specified. This is a one- or two-element
 	// equivalence class containing rune and ToLower(rune)
 	// and ToUpper(rune) if they are different from rune.
 	if l := ToLower(r); l != r {
diff --git a/src/unicode/maketables.go b/src/unicode/maketables.go
index e0110c9536..328c75ed63 100644
--- a/src/unicode/maketables.go
+++ b/src/unicode/maketables.go
@@ -485,7 +485,7 @@ func printCategories() {
 			logger.Fatal("unknown category", name)
 		}
 		// We generate an UpperCase name to serve as concise documentation and an _UnderScored
-		// name to store the data.  This stops godoc dumping all the tables but keeps them
+		// name to store the data. This stops godoc dumping all the tables but keeps them
 		// available to clients.
 		// Cases deserving special comments
 		varDecl := ""
@@ -964,7 +964,7 @@ func getCaseState(i rune) (c *caseState) {
 		c._case = CaseTitle
 	}
 	// Some things such as roman numeral U+2161 don't describe themselves
-	// as upper case, but have a lower case.  Second-guess them.
+	// as upper case, but have a lower case. Second-guess them.
 	if c._case == CaseNone && ch.lowerCase != 0 {
 		c._case = CaseUpper
 	}
diff --git a/src/unicode/utf8/utf8.go b/src/unicode/utf8/utf8.go
index bbaf14aab8..9d35be6c06 100644
--- a/src/unicode/utf8/utf8.go
+++ b/src/unicode/utf8/utf8.go
@@ -341,7 +341,7 @@ func RuneLen(r rune) int {
 // EncodeRune writes into p (which must be large enough) the UTF-8 encoding of the rune.
 // It returns the number of bytes written.
 func EncodeRune(p []byte, r rune) int {
-	// Negative values are erroneous.  Making it unsigned addresses the problem.
+	// Negative values are erroneous. Making it unsigned addresses the problem.
 	switch i := uint32(r); {
 	case i <= rune1Max:
 		p[0] = byte(r)
@@ -367,7 +367,7 @@ func EncodeRune(p []byte, r rune) int {
 	}
 }
 
-// RuneCount returns the number of runes in p.  Erroneous and short
+// RuneCount returns the number of runes in p. Erroneous and short
 // encodings are treated as single runes of width 1 byte.
 func RuneCount(p []byte) int {
 	np := len(p)
@@ -441,7 +441,7 @@ func RuneCountInString(s string) (n int) {
 }
 
 // RuneStart reports whether the byte could be the first byte of an encoded,
-// possibly invalid rune.  Second and subsequent bytes always have the top two
+// possibly invalid rune. Second and subsequent bytes always have the top two
 // bits set to 10.
 func RuneStart(b byte) bool { return b&0xC0 != 0x80 }
 
diff --git a/src/unsafe/unsafe.go b/src/unsafe/unsafe.go
index 532fa4aa22..8f43e72775 100644
--- a/src/unsafe/unsafe.go
+++ b/src/unsafe/unsafe.go
@@ -11,10 +11,10 @@
 package unsafe
 
 // ArbitraryType is here for the purposes of documentation only and is not actually
-// part of the unsafe package.  It represents the type of an arbitrary Go expression.
+// part of the unsafe package. It represents the type of an arbitrary Go expression.
 type ArbitraryType int
 
-// Pointer represents a pointer to an arbitrary type.  There are four special operations
+// Pointer represents a pointer to an arbitrary type. There are four special operations
 // available for type Pointer that are not available for other types:
 //	- A pointer value of any type can be converted to a Pointer.
 //	- A Pointer can be converted to a pointer value of any type.
@@ -179,7 +179,7 @@ type Pointer *ArbitraryType
 func Sizeof(x ArbitraryType) uintptr
 
 // Offsetof returns the offset within the struct of the field represented by x,
-// which must be of the form structValue.field.  In other words, it returns the
+// which must be of the form structValue.field. In other words, it returns the
 // number of bytes between the start of the struct and the start of the field.
 func Offsetof(x ArbitraryType) uintptr
 
@@ -189,6 +189,6 @@ func Offsetof(x ArbitraryType) uintptr
 // It is the same as the value returned by reflect.TypeOf(x).Align().
 // As a special case, if a variable s is of struct type and f is a field
 // within that struct, then Alignof(s.f) will return the required alignment
-// of a field of that type within a struct.  This case is the same as the
+// of a field of that type within a struct. This case is the same as the
 // value returned by reflect.TypeOf(s.f).FieldAlign().
 func Alignof(x ArbitraryType) uintptr
