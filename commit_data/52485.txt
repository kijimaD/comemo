commit 68c2e9eedeaa2ad9d9528fbb58adffb0a48365c9
Author: Filippo Valsorda <filippo@golang.org>
Date:   Wed May 4 09:58:56 2022 -0400

    crypto/elliptic: replace generic P-256 with fiat-crypto
    
    For #52182
    
    Change-Id: I8d8b4c3d8299fbd59b0bf48e5c8b7b41c533a2cc
    Reviewed-on: https://go-review.googlesource.com/c/go/+/360114
    TryBot-Result: Gopher Robot <gobot@golang.org>
    Reviewed-by: Roland Shoemaker <roland@golang.org>
    Run-TryBot: Filippo Valsorda <filippo@golang.org>
    Reviewed-by: Fernando Lobato Meeser <felobato@google.com>
---
 src/crypto/elliptic/internal/fiat/generate.go      |   19 +-
 src/crypto/elliptic/internal/fiat/p256.go          |  135 ++
 src/crypto/elliptic/internal/fiat/p256_fiat64.go   | 1400 ++++++++++++++++++++
 src/crypto/elliptic/internal/fiat/p256_invert.go   |   84 ++
 src/crypto/elliptic/internal/nistec/generate.go    |    5 +
 src/crypto/elliptic/internal/nistec/nistec_test.go |   97 +-
 src/crypto/elliptic/internal/nistec/p256.go        |  288 ++++
 src/crypto/elliptic/nistec.go                      |   30 +
 src/crypto/elliptic/p256.go                        |   32 -
 src/crypto/elliptic/p256_asm.go                    |   20 +-
 src/crypto/elliptic/p256_generic.go                |  477 -------
 src/crypto/elliptic/p256_generic_field.go          |  705 ----------
 src/crypto/elliptic/p256_noasm.go                  |   15 -
 src/crypto/elliptic/p256_ppc64le.go                |   13 +-
 src/crypto/elliptic/p256_s390x.go                  |   17 +-
 15 files changed, 2045 insertions(+), 1292 deletions(-)

diff --git a/src/crypto/elliptic/internal/fiat/generate.go b/src/crypto/elliptic/internal/fiat/generate.go
index fd8509de45..3b97307ca3 100644
--- a/src/crypto/elliptic/internal/fiat/generate.go
+++ b/src/crypto/elliptic/internal/fiat/generate.go
@@ -30,15 +30,16 @@ var curves = []struct {
 		FiatType: "[4]uint64",
 		BytesLen: 28,
 	},
-	// The 32-bit pure Go P-256 in crypto/elliptic is still faster than the
-	// autogenerated code here, regrettably.
-	// {
-	//  Element:  "P256Element",
-	//  Prime:    "2^256 - 2^224 + 2^192 + 2^96 - 1",
-	//  Prefix:   "p256",
-	//  FiatType: "[4]uint64",
-	//  BytesLen: 32,
-	// },
+	// The P-256 fiat implementation is used only on 32-bit architectures, but
+	// the uint32 fiat code is for some reason slower than the uint64 one. That
+	// suggests there is a wide margin for improvement.
+	{
+		Element:  "P256Element",
+		Prime:    "2^256 - 2^224 + 2^192 + 2^96 - 1",
+		Prefix:   "p256",
+		FiatType: "[4]uint64",
+		BytesLen: 32,
+	},
 	{
 		Element:  "P384Element",
 		Prime:    "2^384 - 2^128 - 2^96 + 2^32 - 1",
diff --git a/src/crypto/elliptic/internal/fiat/p256.go b/src/crypto/elliptic/internal/fiat/p256.go
new file mode 100644
index 0000000000..dfdd0a7c69
--- /dev/null
+++ b/src/crypto/elliptic/internal/fiat/p256.go
@@ -0,0 +1,135 @@
+// Copyright 2021 The Go Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style
+// license that can be found in the LICENSE file.
+
+// Code generated by generate.go. DO NOT EDIT.
+
+package fiat
+
+import (
+	"crypto/subtle"
+	"errors"
+)
+
+// P256Element is an integer modulo 2^256 - 2^224 + 2^192 + 2^96 - 1.
+//
+// The zero value is a valid zero element.
+type P256Element struct {
+	// Values are represented internally always in the Montgomery domain, and
+	// converted in Bytes and SetBytes.
+	x p256MontgomeryDomainFieldElement
+}
+
+const p256ElementLen = 32
+
+type p256UntypedFieldElement = [4]uint64
+
+// One sets e = 1, and returns e.
+func (e *P256Element) One() *P256Element {
+	p256SetOne(&e.x)
+	return e
+}
+
+// Equal returns 1 if e == t, and zero otherwise.
+func (e *P256Element) Equal(t *P256Element) int {
+	eBytes := e.Bytes()
+	tBytes := t.Bytes()
+	return subtle.ConstantTimeCompare(eBytes, tBytes)
+}
+
+var p256ZeroEncoding = new(P256Element).Bytes()
+
+// IsZero returns 1 if e == 0, and zero otherwise.
+func (e *P256Element) IsZero() int {
+	eBytes := e.Bytes()
+	return subtle.ConstantTimeCompare(eBytes, p256ZeroEncoding)
+}
+
+// Set sets e = t, and returns e.
+func (e *P256Element) Set(t *P256Element) *P256Element {
+	e.x = t.x
+	return e
+}
+
+// Bytes returns the 32-byte big-endian encoding of e.
+func (e *P256Element) Bytes() []byte {
+	// This function is outlined to make the allocations inline in the caller
+	// rather than happen on the heap.
+	var out [p256ElementLen]byte
+	return e.bytes(&out)
+}
+
+func (e *P256Element) bytes(out *[p256ElementLen]byte) []byte {
+	var tmp p256NonMontgomeryDomainFieldElement
+	p256FromMontgomery(&tmp, &e.x)
+	p256ToBytes(out, (*p256UntypedFieldElement)(&tmp))
+	p256InvertEndianness(out[:])
+	return out[:]
+}
+
+// p256MinusOneEncoding is the encoding of -1 mod p, so p - 1, the
+// highest canonical encoding. It is used by SetBytes to check for non-canonical
+// encodings such as p + k, 2p + k, etc.
+var p256MinusOneEncoding = new(P256Element).Sub(
+	new(P256Element), new(P256Element).One()).Bytes()
+
+// SetBytes sets e = v, where v is a big-endian 32-byte encoding, and returns e.
+// If v is not 32 bytes or it encodes a value higher than 2^256 - 2^224 + 2^192 + 2^96 - 1,
+// SetBytes returns nil and an error, and e is unchanged.
+func (e *P256Element) SetBytes(v []byte) (*P256Element, error) {
+	if len(v) != p256ElementLen {
+		return nil, errors.New("invalid P256Element encoding")
+	}
+	for i := range v {
+		if v[i] < p256MinusOneEncoding[i] {
+			break
+		}
+		if v[i] > p256MinusOneEncoding[i] {
+			return nil, errors.New("invalid P256Element encoding")
+		}
+	}
+	var in [p256ElementLen]byte
+	copy(in[:], v)
+	p256InvertEndianness(in[:])
+	var tmp p256NonMontgomeryDomainFieldElement
+	p256FromBytes((*p256UntypedFieldElement)(&tmp), &in)
+	p256ToMontgomery(&e.x, &tmp)
+	return e, nil
+}
+
+// Add sets e = t1 + t2, and returns e.
+func (e *P256Element) Add(t1, t2 *P256Element) *P256Element {
+	p256Add(&e.x, &t1.x, &t2.x)
+	return e
+}
+
+// Sub sets e = t1 - t2, and returns e.
+func (e *P256Element) Sub(t1, t2 *P256Element) *P256Element {
+	p256Sub(&e.x, &t1.x, &t2.x)
+	return e
+}
+
+// Mul sets e = t1 * t2, and returns e.
+func (e *P256Element) Mul(t1, t2 *P256Element) *P256Element {
+	p256Mul(&e.x, &t1.x, &t2.x)
+	return e
+}
+
+// Square sets e = t * t, and returns e.
+func (e *P256Element) Square(t *P256Element) *P256Element {
+	p256Square(&e.x, &t.x)
+	return e
+}
+
+// Select sets v to a if cond == 1, and to b if cond == 0.
+func (v *P256Element) Select(a, b *P256Element, cond int) *P256Element {
+	p256Selectznz((*p256UntypedFieldElement)(&v.x), p256Uint1(cond),
+		(*p256UntypedFieldElement)(&b.x), (*p256UntypedFieldElement)(&a.x))
+	return v
+}
+
+func p256InvertEndianness(v []byte) {
+	for i := 0; i < len(v)/2; i++ {
+		v[i], v[len(v)-1-i] = v[len(v)-1-i], v[i]
+	}
+}
diff --git a/src/crypto/elliptic/internal/fiat/p256_fiat64.go b/src/crypto/elliptic/internal/fiat/p256_fiat64.go
new file mode 100644
index 0000000000..75352d5d26
--- /dev/null
+++ b/src/crypto/elliptic/internal/fiat/p256_fiat64.go
@@ -0,0 +1,1400 @@
+// Code generated by Fiat Cryptography. DO NOT EDIT.
+//
+// Autogenerated: word_by_word_montgomery --lang Go --no-wide-int --cmovznz-by-mul --relax-primitive-carry-to-bitwidth 32,64 --internal-static --public-function-case camelCase --public-type-case camelCase --private-function-case camelCase --private-type-case camelCase --doc-text-before-function-name '' --doc-newline-before-package-declaration --doc-prepend-header 'Code generated by Fiat Cryptography. DO NOT EDIT.' --package-name fiat --no-prefix-fiat p256 64 '2^256 - 2^224 + 2^192 + 2^96 - 1' mul square add sub one from_montgomery to_montgomery selectznz to_bytes from_bytes
+//
+// curve description: p256
+//
+// machine_wordsize = 64 (from "64")
+//
+// requested operations: mul, square, add, sub, one, from_montgomery, to_montgomery, selectznz, to_bytes, from_bytes
+//
+// m = 0xffffffff00000001000000000000000000000000ffffffffffffffffffffffff (from "2^256 - 2^224 + 2^192 + 2^96 - 1")
+//
+//
+//
+// NOTE: In addition to the bounds specified above each function, all
+//
+//   functions synthesized for this Montgomery arithmetic require the
+//
+//   input to be strictly less than the prime modulus (m), and also
+//
+//   require the input to be in the unique saturated representation.
+//
+//   All functions also ensure that these two properties are true of
+//
+//   return values.
+//
+//
+//
+// Computed values:
+//
+//   eval z = z[0] + (z[1] << 64) + (z[2] << 128) + (z[3] << 192)
+//
+//   bytes_eval z = z[0] + (z[1] << 8) + (z[2] << 16) + (z[3] << 24) + (z[4] << 32) + (z[5] << 40) + (z[6] << 48) + (z[7] << 56) + (z[8] << 64) + (z[9] << 72) + (z[10] << 80) + (z[11] << 88) + (z[12] << 96) + (z[13] << 104) + (z[14] << 112) + (z[15] << 120) + (z[16] << 128) + (z[17] << 136) + (z[18] << 144) + (z[19] << 152) + (z[20] << 160) + (z[21] << 168) + (z[22] << 176) + (z[23] << 184) + (z[24] << 192) + (z[25] << 200) + (z[26] << 208) + (z[27] << 216) + (z[28] << 224) + (z[29] << 232) + (z[30] << 240) + (z[31] << 248)
+//
+//   twos_complement_eval z = let x1 := z[0] + (z[1] << 64) + (z[2] << 128) + (z[3] << 192) in
+//
+//                            if x1 & (2^256-1) < 2^255 then x1 & (2^256-1) else (x1 & (2^256-1)) - 2^256
+
+package fiat
+
+import "math/bits"
+
+type p256Uint1 uint64 // We use uint64 instead of a more narrow type for performance reasons; see https://github.com/mit-plv/fiat-crypto/pull/1006#issuecomment-892625927
+type p256Int1 int64   // We use uint64 instead of a more narrow type for performance reasons; see https://github.com/mit-plv/fiat-crypto/pull/1006#issuecomment-892625927
+
+// The type p256MontgomeryDomainFieldElement is a field element in the Montgomery domain.
+//
+// Bounds: [[0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff]]
+type p256MontgomeryDomainFieldElement [4]uint64
+
+// The type p256NonMontgomeryDomainFieldElement is a field element NOT in the Montgomery domain.
+//
+// Bounds: [[0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff]]
+type p256NonMontgomeryDomainFieldElement [4]uint64
+
+// p256CmovznzU64 is a single-word conditional move.
+//
+// Postconditions:
+//
+//	out1 = (if arg1 = 0 then arg2 else arg3)
+//
+// Input Bounds:
+//
+//	arg1: [0x0 ~> 0x1]
+//	arg2: [0x0 ~> 0xffffffffffffffff]
+//	arg3: [0x0 ~> 0xffffffffffffffff]
+//
+// Output Bounds:
+//
+//	out1: [0x0 ~> 0xffffffffffffffff]
+func p256CmovznzU64(out1 *uint64, arg1 p256Uint1, arg2 uint64, arg3 uint64) {
+	x1 := (uint64(arg1) * 0xffffffffffffffff)
+	x2 := ((x1 & arg3) | ((^x1) & arg2))
+	*out1 = x2
+}
+
+// p256Mul multiplies two field elements in the Montgomery domain.
+//
+// Preconditions:
+//
+//	0 ≤ eval arg1 < m
+//	0 ≤ eval arg2 < m
+//
+// Postconditions:
+//
+//	eval (from_montgomery out1) mod m = (eval (from_montgomery arg1) * eval (from_montgomery arg2)) mod m
+//	0 ≤ eval out1 < m
+func p256Mul(out1 *p256MontgomeryDomainFieldElement, arg1 *p256MontgomeryDomainFieldElement, arg2 *p256MontgomeryDomainFieldElement) {
+	x1 := arg1[1]
+	x2 := arg1[2]
+	x3 := arg1[3]
+	x4 := arg1[0]
+	var x5 uint64
+	var x6 uint64
+	x6, x5 = bits.Mul64(x4, arg2[3])
+	var x7 uint64
+	var x8 uint64
+	x8, x7 = bits.Mul64(x4, arg2[2])
+	var x9 uint64
+	var x10 uint64
+	x10, x9 = bits.Mul64(x4, arg2[1])
+	var x11 uint64
+	var x12 uint64
+	x12, x11 = bits.Mul64(x4, arg2[0])
+	var x13 uint64
+	var x14 uint64
+	x13, x14 = bits.Add64(x12, x9, uint64(0x0))
+	var x15 uint64
+	var x16 uint64
+	x15, x16 = bits.Add64(x10, x7, uint64(p256Uint1(x14)))
+	var x17 uint64
+	var x18 uint64
+	x17, x18 = bits.Add64(x8, x5, uint64(p256Uint1(x16)))
+	x19 := (uint64(p256Uint1(x18)) + x6)
+	var x20 uint64
+	var x21 uint64
+	x21, x20 = bits.Mul64(x11, 0xffffffff00000001)
+	var x22 uint64
+	var x23 uint64
+	x23, x22 = bits.Mul64(x11, 0xffffffff)
+	var x24 uint64
+	var x25 uint64
+	x25, x24 = bits.Mul64(x11, 0xffffffffffffffff)
+	var x26 uint64
+	var x27 uint64
+	x26, x27 = bits.Add64(x25, x22, uint64(0x0))
+	x28 := (uint64(p256Uint1(x27)) + x23)
+	var x30 uint64
+	_, x30 = bits.Add64(x11, x24, uint64(0x0))
+	var x31 uint64
+	var x32 uint64
+	x31, x32 = bits.Add64(x13, x26, uint64(p256Uint1(x30)))
+	var x33 uint64
+	var x34 uint64
+	x33, x34 = bits.Add64(x15, x28, uint64(p256Uint1(x32)))
+	var x35 uint64
+	var x36 uint64
+	x35, x36 = bits.Add64(x17, x20, uint64(p256Uint1(x34)))
+	var x37 uint64
+	var x38 uint64
+	x37, x38 = bits.Add64(x19, x21, uint64(p256Uint1(x36)))
+	var x39 uint64
+	var x40 uint64
+	x40, x39 = bits.Mul64(x1, arg2[3])
+	var x41 uint64
+	var x42 uint64
+	x42, x41 = bits.Mul64(x1, arg2[2])
+	var x43 uint64
+	var x44 uint64
+	x44, x43 = bits.Mul64(x1, arg2[1])
+	var x45 uint64
+	var x46 uint64
+	x46, x45 = bits.Mul64(x1, arg2[0])
+	var x47 uint64
+	var x48 uint64
+	x47, x48 = bits.Add64(x46, x43, uint64(0x0))
+	var x49 uint64
+	var x50 uint64
+	x49, x50 = bits.Add64(x44, x41, uint64(p256Uint1(x48)))
+	var x51 uint64
+	var x52 uint64
+	x51, x52 = bits.Add64(x42, x39, uint64(p256Uint1(x50)))
+	x53 := (uint64(p256Uint1(x52)) + x40)
+	var x54 uint64
+	var x55 uint64
+	x54, x55 = bits.Add64(x31, x45, uint64(0x0))
+	var x56 uint64
+	var x57 uint64
+	x56, x57 = bits.Add64(x33, x47, uint64(p256Uint1(x55)))
+	var x58 uint64
+	var x59 uint64
+	x58, x59 = bits.Add64(x35, x49, uint64(p256Uint1(x57)))
+	var x60 uint64
+	var x61 uint64
+	x60, x61 = bits.Add64(x37, x51, uint64(p256Uint1(x59)))
+	var x62 uint64
+	var x63 uint64
+	x62, x63 = bits.Add64(uint64(p256Uint1(x38)), x53, uint64(p256Uint1(x61)))
+	var x64 uint64
+	var x65 uint64
+	x65, x64 = bits.Mul64(x54, 0xffffffff00000001)
+	var x66 uint64
+	var x67 uint64
+	x67, x66 = bits.Mul64(x54, 0xffffffff)
+	var x68 uint64
+	var x69 uint64
+	x69, x68 = bits.Mul64(x54, 0xffffffffffffffff)
+	var x70 uint64
+	var x71 uint64
+	x70, x71 = bits.Add64(x69, x66, uint64(0x0))
+	x72 := (uint64(p256Uint1(x71)) + x67)
+	var x74 uint64
+	_, x74 = bits.Add64(x54, x68, uint64(0x0))
+	var x75 uint64
+	var x76 uint64
+	x75, x76 = bits.Add64(x56, x70, uint64(p256Uint1(x74)))
+	var x77 uint64
+	var x78 uint64
+	x77, x78 = bits.Add64(x58, x72, uint64(p256Uint1(x76)))
+	var x79 uint64
+	var x80 uint64
+	x79, x80 = bits.Add64(x60, x64, uint64(p256Uint1(x78)))
+	var x81 uint64
+	var x82 uint64
+	x81, x82 = bits.Add64(x62, x65, uint64(p256Uint1(x80)))
+	x83 := (uint64(p256Uint1(x82)) + uint64(p256Uint1(x63)))
+	var x84 uint64
+	var x85 uint64
+	x85, x84 = bits.Mul64(x2, arg2[3])
+	var x86 uint64
+	var x87 uint64
+	x87, x86 = bits.Mul64(x2, arg2[2])
+	var x88 uint64
+	var x89 uint64
+	x89, x88 = bits.Mul64(x2, arg2[1])
+	var x90 uint64
+	var x91 uint64
+	x91, x90 = bits.Mul64(x2, arg2[0])
+	var x92 uint64
+	var x93 uint64
+	x92, x93 = bits.Add64(x91, x88, uint64(0x0))
+	var x94 uint64
+	var x95 uint64
+	x94, x95 = bits.Add64(x89, x86, uint64(p256Uint1(x93)))
+	var x96 uint64
+	var x97 uint64
+	x96, x97 = bits.Add64(x87, x84, uint64(p256Uint1(x95)))
+	x98 := (uint64(p256Uint1(x97)) + x85)
+	var x99 uint64
+	var x100 uint64
+	x99, x100 = bits.Add64(x75, x90, uint64(0x0))
+	var x101 uint64
+	var x102 uint64
+	x101, x102 = bits.Add64(x77, x92, uint64(p256Uint1(x100)))
+	var x103 uint64
+	var x104 uint64
+	x103, x104 = bits.Add64(x79, x94, uint64(p256Uint1(x102)))
+	var x105 uint64
+	var x106 uint64
+	x105, x106 = bits.Add64(x81, x96, uint64(p256Uint1(x104)))
+	var x107 uint64
+	var x108 uint64
+	x107, x108 = bits.Add64(x83, x98, uint64(p256Uint1(x106)))
+	var x109 uint64
+	var x110 uint64
+	x110, x109 = bits.Mul64(x99, 0xffffffff00000001)
+	var x111 uint64
+	var x112 uint64
+	x112, x111 = bits.Mul64(x99, 0xffffffff)
+	var x113 uint64
+	var x114 uint64
+	x114, x113 = bits.Mul64(x99, 0xffffffffffffffff)
+	var x115 uint64
+	var x116 uint64
+	x115, x116 = bits.Add64(x114, x111, uint64(0x0))
+	x117 := (uint64(p256Uint1(x116)) + x112)
+	var x119 uint64
+	_, x119 = bits.Add64(x99, x113, uint64(0x0))
+	var x120 uint64
+	var x121 uint64
+	x120, x121 = bits.Add64(x101, x115, uint64(p256Uint1(x119)))
+	var x122 uint64
+	var x123 uint64
+	x122, x123 = bits.Add64(x103, x117, uint64(p256Uint1(x121)))
+	var x124 uint64
+	var x125 uint64
+	x124, x125 = bits.Add64(x105, x109, uint64(p256Uint1(x123)))
+	var x126 uint64
+	var x127 uint64
+	x126, x127 = bits.Add64(x107, x110, uint64(p256Uint1(x125)))
+	x128 := (uint64(p256Uint1(x127)) + uint64(p256Uint1(x108)))
+	var x129 uint64
+	var x130 uint64
+	x130, x129 = bits.Mul64(x3, arg2[3])
+	var x131 uint64
+	var x132 uint64
+	x132, x131 = bits.Mul64(x3, arg2[2])
+	var x133 uint64
+	var x134 uint64
+	x134, x133 = bits.Mul64(x3, arg2[1])
+	var x135 uint64
+	var x136 uint64
+	x136, x135 = bits.Mul64(x3, arg2[0])
+	var x137 uint64
+	var x138 uint64
+	x137, x138 = bits.Add64(x136, x133, uint64(0x0))
+	var x139 uint64
+	var x140 uint64
+	x139, x140 = bits.Add64(x134, x131, uint64(p256Uint1(x138)))
+	var x141 uint64
+	var x142 uint64
+	x141, x142 = bits.Add64(x132, x129, uint64(p256Uint1(x140)))
+	x143 := (uint64(p256Uint1(x142)) + x130)
+	var x144 uint64
+	var x145 uint64
+	x144, x145 = bits.Add64(x120, x135, uint64(0x0))
+	var x146 uint64
+	var x147 uint64
+	x146, x147 = bits.Add64(x122, x137, uint64(p256Uint1(x145)))
+	var x148 uint64
+	var x149 uint64
+	x148, x149 = bits.Add64(x124, x139, uint64(p256Uint1(x147)))
+	var x150 uint64
+	var x151 uint64
+	x150, x151 = bits.Add64(x126, x141, uint64(p256Uint1(x149)))
+	var x152 uint64
+	var x153 uint64
+	x152, x153 = bits.Add64(x128, x143, uint64(p256Uint1(x151)))
+	var x154 uint64
+	var x155 uint64
+	x155, x154 = bits.Mul64(x144, 0xffffffff00000001)
+	var x156 uint64
+	var x157 uint64
+	x157, x156 = bits.Mul64(x144, 0xffffffff)
+	var x158 uint64
+	var x159 uint64
+	x159, x158 = bits.Mul64(x144, 0xffffffffffffffff)
+	var x160 uint64
+	var x161 uint64
+	x160, x161 = bits.Add64(x159, x156, uint64(0x0))
+	x162 := (uint64(p256Uint1(x161)) + x157)
+	var x164 uint64
+	_, x164 = bits.Add64(x144, x158, uint64(0x0))
+	var x165 uint64
+	var x166 uint64
+	x165, x166 = bits.Add64(x146, x160, uint64(p256Uint1(x164)))
+	var x167 uint64
+	var x168 uint64
+	x167, x168 = bits.Add64(x148, x162, uint64(p256Uint1(x166)))
+	var x169 uint64
+	var x170 uint64
+	x169, x170 = bits.Add64(x150, x154, uint64(p256Uint1(x168)))
+	var x171 uint64
+	var x172 uint64
+	x171, x172 = bits.Add64(x152, x155, uint64(p256Uint1(x170)))
+	x173 := (uint64(p256Uint1(x172)) + uint64(p256Uint1(x153)))
+	var x174 uint64
+	var x175 uint64
+	x174, x175 = bits.Sub64(x165, 0xffffffffffffffff, uint64(0x0))
+	var x176 uint64
+	var x177 uint64
+	x176, x177 = bits.Sub64(x167, 0xffffffff, uint64(p256Uint1(x175)))
+	var x178 uint64
+	var x179 uint64
+	x178, x179 = bits.Sub64(x169, uint64(0x0), uint64(p256Uint1(x177)))
+	var x180 uint64
+	var x181 uint64
+	x180, x181 = bits.Sub64(x171, 0xffffffff00000001, uint64(p256Uint1(x179)))
+	var x183 uint64
+	_, x183 = bits.Sub64(x173, uint64(0x0), uint64(p256Uint1(x181)))
+	var x184 uint64
+	p256CmovznzU64(&x184, p256Uint1(x183), x174, x165)
+	var x185 uint64
+	p256CmovznzU64(&x185, p256Uint1(x183), x176, x167)
+	var x186 uint64
+	p256CmovznzU64(&x186, p256Uint1(x183), x178, x169)
+	var x187 uint64
+	p256CmovznzU64(&x187, p256Uint1(x183), x180, x171)
+	out1[0] = x184
+	out1[1] = x185
+	out1[2] = x186
+	out1[3] = x187
+}
+
+// p256Square squares a field element in the Montgomery domain.
+//
+// Preconditions:
+//
+//	0 ≤ eval arg1 < m
+//
+// Postconditions:
+//
+//	eval (from_montgomery out1) mod m = (eval (from_montgomery arg1) * eval (from_montgomery arg1)) mod m
+//	0 ≤ eval out1 < m
+func p256Square(out1 *p256MontgomeryDomainFieldElement, arg1 *p256MontgomeryDomainFieldElement) {
+	x1 := arg1[1]
+	x2 := arg1[2]
+	x3 := arg1[3]
+	x4 := arg1[0]
+	var x5 uint64
+	var x6 uint64
+	x6, x5 = bits.Mul64(x4, arg1[3])
+	var x7 uint64
+	var x8 uint64
+	x8, x7 = bits.Mul64(x4, arg1[2])
+	var x9 uint64
+	var x10 uint64
+	x10, x9 = bits.Mul64(x4, arg1[1])
+	var x11 uint64
+	var x12 uint64
+	x12, x11 = bits.Mul64(x4, arg1[0])
+	var x13 uint64
+	var x14 uint64
+	x13, x14 = bits.Add64(x12, x9, uint64(0x0))
+	var x15 uint64
+	var x16 uint64
+	x15, x16 = bits.Add64(x10, x7, uint64(p256Uint1(x14)))
+	var x17 uint64
+	var x18 uint64
+	x17, x18 = bits.Add64(x8, x5, uint64(p256Uint1(x16)))
+	x19 := (uint64(p256Uint1(x18)) + x6)
+	var x20 uint64
+	var x21 uint64
+	x21, x20 = bits.Mul64(x11, 0xffffffff00000001)
+	var x22 uint64
+	var x23 uint64
+	x23, x22 = bits.Mul64(x11, 0xffffffff)
+	var x24 uint64
+	var x25 uint64
+	x25, x24 = bits.Mul64(x11, 0xffffffffffffffff)
+	var x26 uint64
+	var x27 uint64
+	x26, x27 = bits.Add64(x25, x22, uint64(0x0))
+	x28 := (uint64(p256Uint1(x27)) + x23)
+	var x30 uint64
+	_, x30 = bits.Add64(x11, x24, uint64(0x0))
+	var x31 uint64
+	var x32 uint64
+	x31, x32 = bits.Add64(x13, x26, uint64(p256Uint1(x30)))
+	var x33 uint64
+	var x34 uint64
+	x33, x34 = bits.Add64(x15, x28, uint64(p256Uint1(x32)))
+	var x35 uint64
+	var x36 uint64
+	x35, x36 = bits.Add64(x17, x20, uint64(p256Uint1(x34)))
+	var x37 uint64
+	var x38 uint64
+	x37, x38 = bits.Add64(x19, x21, uint64(p256Uint1(x36)))
+	var x39 uint64
+	var x40 uint64
+	x40, x39 = bits.Mul64(x1, arg1[3])
+	var x41 uint64
+	var x42 uint64
+	x42, x41 = bits.Mul64(x1, arg1[2])
+	var x43 uint64
+	var x44 uint64
+	x44, x43 = bits.Mul64(x1, arg1[1])
+	var x45 uint64
+	var x46 uint64
+	x46, x45 = bits.Mul64(x1, arg1[0])
+	var x47 uint64
+	var x48 uint64
+	x47, x48 = bits.Add64(x46, x43, uint64(0x0))
+	var x49 uint64
+	var x50 uint64
+	x49, x50 = bits.Add64(x44, x41, uint64(p256Uint1(x48)))
+	var x51 uint64
+	var x52 uint64
+	x51, x52 = bits.Add64(x42, x39, uint64(p256Uint1(x50)))
+	x53 := (uint64(p256Uint1(x52)) + x40)
+	var x54 uint64
+	var x55 uint64
+	x54, x55 = bits.Add64(x31, x45, uint64(0x0))
+	var x56 uint64
+	var x57 uint64
+	x56, x57 = bits.Add64(x33, x47, uint64(p256Uint1(x55)))
+	var x58 uint64
+	var x59 uint64
+	x58, x59 = bits.Add64(x35, x49, uint64(p256Uint1(x57)))
+	var x60 uint64
+	var x61 uint64
+	x60, x61 = bits.Add64(x37, x51, uint64(p256Uint1(x59)))
+	var x62 uint64
+	var x63 uint64
+	x62, x63 = bits.Add64(uint64(p256Uint1(x38)), x53, uint64(p256Uint1(x61)))
+	var x64 uint64
+	var x65 uint64
+	x65, x64 = bits.Mul64(x54, 0xffffffff00000001)
+	var x66 uint64
+	var x67 uint64
+	x67, x66 = bits.Mul64(x54, 0xffffffff)
+	var x68 uint64
+	var x69 uint64
+	x69, x68 = bits.Mul64(x54, 0xffffffffffffffff)
+	var x70 uint64
+	var x71 uint64
+	x70, x71 = bits.Add64(x69, x66, uint64(0x0))
+	x72 := (uint64(p256Uint1(x71)) + x67)
+	var x74 uint64
+	_, x74 = bits.Add64(x54, x68, uint64(0x0))
+	var x75 uint64
+	var x76 uint64
+	x75, x76 = bits.Add64(x56, x70, uint64(p256Uint1(x74)))
+	var x77 uint64
+	var x78 uint64
+	x77, x78 = bits.Add64(x58, x72, uint64(p256Uint1(x76)))
+	var x79 uint64
+	var x80 uint64
+	x79, x80 = bits.Add64(x60, x64, uint64(p256Uint1(x78)))
+	var x81 uint64
+	var x82 uint64
+	x81, x82 = bits.Add64(x62, x65, uint64(p256Uint1(x80)))
+	x83 := (uint64(p256Uint1(x82)) + uint64(p256Uint1(x63)))
+	var x84 uint64
+	var x85 uint64
+	x85, x84 = bits.Mul64(x2, arg1[3])
+	var x86 uint64
+	var x87 uint64
+	x87, x86 = bits.Mul64(x2, arg1[2])
+	var x88 uint64
+	var x89 uint64
+	x89, x88 = bits.Mul64(x2, arg1[1])
+	var x90 uint64
+	var x91 uint64
+	x91, x90 = bits.Mul64(x2, arg1[0])
+	var x92 uint64
+	var x93 uint64
+	x92, x93 = bits.Add64(x91, x88, uint64(0x0))
+	var x94 uint64
+	var x95 uint64
+	x94, x95 = bits.Add64(x89, x86, uint64(p256Uint1(x93)))
+	var x96 uint64
+	var x97 uint64
+	x96, x97 = bits.Add64(x87, x84, uint64(p256Uint1(x95)))
+	x98 := (uint64(p256Uint1(x97)) + x85)
+	var x99 uint64
+	var x100 uint64
+	x99, x100 = bits.Add64(x75, x90, uint64(0x0))
+	var x101 uint64
+	var x102 uint64
+	x101, x102 = bits.Add64(x77, x92, uint64(p256Uint1(x100)))
+	var x103 uint64
+	var x104 uint64
+	x103, x104 = bits.Add64(x79, x94, uint64(p256Uint1(x102)))
+	var x105 uint64
+	var x106 uint64
+	x105, x106 = bits.Add64(x81, x96, uint64(p256Uint1(x104)))
+	var x107 uint64
+	var x108 uint64
+	x107, x108 = bits.Add64(x83, x98, uint64(p256Uint1(x106)))
+	var x109 uint64
+	var x110 uint64
+	x110, x109 = bits.Mul64(x99, 0xffffffff00000001)
+	var x111 uint64
+	var x112 uint64
+	x112, x111 = bits.Mul64(x99, 0xffffffff)
+	var x113 uint64
+	var x114 uint64
+	x114, x113 = bits.Mul64(x99, 0xffffffffffffffff)
+	var x115 uint64
+	var x116 uint64
+	x115, x116 = bits.Add64(x114, x111, uint64(0x0))
+	x117 := (uint64(p256Uint1(x116)) + x112)
+	var x119 uint64
+	_, x119 = bits.Add64(x99, x113, uint64(0x0))
+	var x120 uint64
+	var x121 uint64
+	x120, x121 = bits.Add64(x101, x115, uint64(p256Uint1(x119)))
+	var x122 uint64
+	var x123 uint64
+	x122, x123 = bits.Add64(x103, x117, uint64(p256Uint1(x121)))
+	var x124 uint64
+	var x125 uint64
+	x124, x125 = bits.Add64(x105, x109, uint64(p256Uint1(x123)))
+	var x126 uint64
+	var x127 uint64
+	x126, x127 = bits.Add64(x107, x110, uint64(p256Uint1(x125)))
+	x128 := (uint64(p256Uint1(x127)) + uint64(p256Uint1(x108)))
+	var x129 uint64
+	var x130 uint64
+	x130, x129 = bits.Mul64(x3, arg1[3])
+	var x131 uint64
+	var x132 uint64
+	x132, x131 = bits.Mul64(x3, arg1[2])
+	var x133 uint64
+	var x134 uint64
+	x134, x133 = bits.Mul64(x3, arg1[1])
+	var x135 uint64
+	var x136 uint64
+	x136, x135 = bits.Mul64(x3, arg1[0])
+	var x137 uint64
+	var x138 uint64
+	x137, x138 = bits.Add64(x136, x133, uint64(0x0))
+	var x139 uint64
+	var x140 uint64
+	x139, x140 = bits.Add64(x134, x131, uint64(p256Uint1(x138)))
+	var x141 uint64
+	var x142 uint64
+	x141, x142 = bits.Add64(x132, x129, uint64(p256Uint1(x140)))
+	x143 := (uint64(p256Uint1(x142)) + x130)
+	var x144 uint64
+	var x145 uint64
+	x144, x145 = bits.Add64(x120, x135, uint64(0x0))
+	var x146 uint64
+	var x147 uint64
+	x146, x147 = bits.Add64(x122, x137, uint64(p256Uint1(x145)))
+	var x148 uint64
+	var x149 uint64
+	x148, x149 = bits.Add64(x124, x139, uint64(p256Uint1(x147)))
+	var x150 uint64
+	var x151 uint64
+	x150, x151 = bits.Add64(x126, x141, uint64(p256Uint1(x149)))
+	var x152 uint64
+	var x153 uint64
+	x152, x153 = bits.Add64(x128, x143, uint64(p256Uint1(x151)))
+	var x154 uint64
+	var x155 uint64
+	x155, x154 = bits.Mul64(x144, 0xffffffff00000001)
+	var x156 uint64
+	var x157 uint64
+	x157, x156 = bits.Mul64(x144, 0xffffffff)
+	var x158 uint64
+	var x159 uint64
+	x159, x158 = bits.Mul64(x144, 0xffffffffffffffff)
+	var x160 uint64
+	var x161 uint64
+	x160, x161 = bits.Add64(x159, x156, uint64(0x0))
+	x162 := (uint64(p256Uint1(x161)) + x157)
+	var x164 uint64
+	_, x164 = bits.Add64(x144, x158, uint64(0x0))
+	var x165 uint64
+	var x166 uint64
+	x165, x166 = bits.Add64(x146, x160, uint64(p256Uint1(x164)))
+	var x167 uint64
+	var x168 uint64
+	x167, x168 = bits.Add64(x148, x162, uint64(p256Uint1(x166)))
+	var x169 uint64
+	var x170 uint64
+	x169, x170 = bits.Add64(x150, x154, uint64(p256Uint1(x168)))
+	var x171 uint64
+	var x172 uint64
+	x171, x172 = bits.Add64(x152, x155, uint64(p256Uint1(x170)))
+	x173 := (uint64(p256Uint1(x172)) + uint64(p256Uint1(x153)))
+	var x174 uint64
+	var x175 uint64
+	x174, x175 = bits.Sub64(x165, 0xffffffffffffffff, uint64(0x0))
+	var x176 uint64
+	var x177 uint64
+	x176, x177 = bits.Sub64(x167, 0xffffffff, uint64(p256Uint1(x175)))
+	var x178 uint64
+	var x179 uint64
+	x178, x179 = bits.Sub64(x169, uint64(0x0), uint64(p256Uint1(x177)))
+	var x180 uint64
+	var x181 uint64
+	x180, x181 = bits.Sub64(x171, 0xffffffff00000001, uint64(p256Uint1(x179)))
+	var x183 uint64
+	_, x183 = bits.Sub64(x173, uint64(0x0), uint64(p256Uint1(x181)))
+	var x184 uint64
+	p256CmovznzU64(&x184, p256Uint1(x183), x174, x165)
+	var x185 uint64
+	p256CmovznzU64(&x185, p256Uint1(x183), x176, x167)
+	var x186 uint64
+	p256CmovznzU64(&x186, p256Uint1(x183), x178, x169)
+	var x187 uint64
+	p256CmovznzU64(&x187, p256Uint1(x183), x180, x171)
+	out1[0] = x184
+	out1[1] = x185
+	out1[2] = x186
+	out1[3] = x187
+}
+
+// p256Add adds two field elements in the Montgomery domain.
+//
+// Preconditions:
+//
+//	0 ≤ eval arg1 < m
+//	0 ≤ eval arg2 < m
+//
+// Postconditions:
+//
+//	eval (from_montgomery out1) mod m = (eval (from_montgomery arg1) + eval (from_montgomery arg2)) mod m
+//	0 ≤ eval out1 < m
+func p256Add(out1 *p256MontgomeryDomainFieldElement, arg1 *p256MontgomeryDomainFieldElement, arg2 *p256MontgomeryDomainFieldElement) {
+	var x1 uint64
+	var x2 uint64
+	x1, x2 = bits.Add64(arg1[0], arg2[0], uint64(0x0))
+	var x3 uint64
+	var x4 uint64
+	x3, x4 = bits.Add64(arg1[1], arg2[1], uint64(p256Uint1(x2)))
+	var x5 uint64
+	var x6 uint64
+	x5, x6 = bits.Add64(arg1[2], arg2[2], uint64(p256Uint1(x4)))
+	var x7 uint64
+	var x8 uint64
+	x7, x8 = bits.Add64(arg1[3], arg2[3], uint64(p256Uint1(x6)))
+	var x9 uint64
+	var x10 uint64
+	x9, x10 = bits.Sub64(x1, 0xffffffffffffffff, uint64(0x0))
+	var x11 uint64
+	var x12 uint64
+	x11, x12 = bits.Sub64(x3, 0xffffffff, uint64(p256Uint1(x10)))
+	var x13 uint64
+	var x14 uint64
+	x13, x14 = bits.Sub64(x5, uint64(0x0), uint64(p256Uint1(x12)))
+	var x15 uint64
+	var x16 uint64
+	x15, x16 = bits.Sub64(x7, 0xffffffff00000001, uint64(p256Uint1(x14)))
+	var x18 uint64
+	_, x18 = bits.Sub64(uint64(p256Uint1(x8)), uint64(0x0), uint64(p256Uint1(x16)))
+	var x19 uint64
+	p256CmovznzU64(&x19, p256Uint1(x18), x9, x1)
+	var x20 uint64
+	p256CmovznzU64(&x20, p256Uint1(x18), x11, x3)
+	var x21 uint64
+	p256CmovznzU64(&x21, p256Uint1(x18), x13, x5)
+	var x22 uint64
+	p256CmovznzU64(&x22, p256Uint1(x18), x15, x7)
+	out1[0] = x19
+	out1[1] = x20
+	out1[2] = x21
+	out1[3] = x22
+}
+
+// p256Sub subtracts two field elements in the Montgomery domain.
+//
+// Preconditions:
+//
+//	0 ≤ eval arg1 < m
+//	0 ≤ eval arg2 < m
+//
+// Postconditions:
+//
+//	eval (from_montgomery out1) mod m = (eval (from_montgomery arg1) - eval (from_montgomery arg2)) mod m
+//	0 ≤ eval out1 < m
+func p256Sub(out1 *p256MontgomeryDomainFieldElement, arg1 *p256MontgomeryDomainFieldElement, arg2 *p256MontgomeryDomainFieldElement) {
+	var x1 uint64
+	var x2 uint64
+	x1, x2 = bits.Sub64(arg1[0], arg2[0], uint64(0x0))
+	var x3 uint64
+	var x4 uint64
+	x3, x4 = bits.Sub64(arg1[1], arg2[1], uint64(p256Uint1(x2)))
+	var x5 uint64
+	var x6 uint64
+	x5, x6 = bits.Sub64(arg1[2], arg2[2], uint64(p256Uint1(x4)))
+	var x7 uint64
+	var x8 uint64
+	x7, x8 = bits.Sub64(arg1[3], arg2[3], uint64(p256Uint1(x6)))
+	var x9 uint64
+	p256CmovznzU64(&x9, p256Uint1(x8), uint64(0x0), 0xffffffffffffffff)
+	var x10 uint64
+	var x11 uint64
+	x10, x11 = bits.Add64(x1, x9, uint64(0x0))
+	var x12 uint64
+	var x13 uint64
+	x12, x13 = bits.Add64(x3, (x9 & 0xffffffff), uint64(p256Uint1(x11)))
+	var x14 uint64
+	var x15 uint64
+	x14, x15 = bits.Add64(x5, uint64(0x0), uint64(p256Uint1(x13)))
+	var x16 uint64
+	x16, _ = bits.Add64(x7, (x9 & 0xffffffff00000001), uint64(p256Uint1(x15)))
+	out1[0] = x10
+	out1[1] = x12
+	out1[2] = x14
+	out1[3] = x16
+}
+
+// p256SetOne returns the field element one in the Montgomery domain.
+//
+// Postconditions:
+//
+//	eval (from_montgomery out1) mod m = 1 mod m
+//	0 ≤ eval out1 < m
+func p256SetOne(out1 *p256MontgomeryDomainFieldElement) {
+	out1[0] = uint64(0x1)
+	out1[1] = 0xffffffff00000000
+	out1[2] = 0xffffffffffffffff
+	out1[3] = 0xfffffffe
+}
+
+// p256FromMontgomery translates a field element out of the Montgomery domain.
+//
+// Preconditions:
+//
+//	0 ≤ eval arg1 < m
+//
+// Postconditions:
+//
+//	eval out1 mod m = (eval arg1 * ((2^64)⁻¹ mod m)^4) mod m
+//	0 ≤ eval out1 < m
+func p256FromMontgomery(out1 *p256NonMontgomeryDomainFieldElement, arg1 *p256MontgomeryDomainFieldElement) {
+	x1 := arg1[0]
+	var x2 uint64
+	var x3 uint64
+	x3, x2 = bits.Mul64(x1, 0xffffffff00000001)
+	var x4 uint64
+	var x5 uint64
+	x5, x4 = bits.Mul64(x1, 0xffffffff)
+	var x6 uint64
+	var x7 uint64
+	x7, x6 = bits.Mul64(x1, 0xffffffffffffffff)
+	var x8 uint64
+	var x9 uint64
+	x8, x9 = bits.Add64(x7, x4, uint64(0x0))
+	var x11 uint64
+	_, x11 = bits.Add64(x1, x6, uint64(0x0))
+	var x12 uint64
+	var x13 uint64
+	x12, x13 = bits.Add64(uint64(0x0), x8, uint64(p256Uint1(x11)))
+	var x14 uint64
+	var x15 uint64
+	x14, x15 = bits.Add64(x12, arg1[1], uint64(0x0))
+	var x16 uint64
+	var x17 uint64
+	x17, x16 = bits.Mul64(x14, 0xffffffff00000001)
+	var x18 uint64
+	var x19 uint64
+	x19, x18 = bits.Mul64(x14, 0xffffffff)
+	var x20 uint64
+	var x21 uint64
+	x21, x20 = bits.Mul64(x14, 0xffffffffffffffff)
+	var x22 uint64
+	var x23 uint64
+	x22, x23 = bits.Add64(x21, x18, uint64(0x0))
+	var x25 uint64
+	_, x25 = bits.Add64(x14, x20, uint64(0x0))
+	var x26 uint64
+	var x27 uint64
+	x26, x27 = bits.Add64((uint64(p256Uint1(x15)) + (uint64(p256Uint1(x13)) + (uint64(p256Uint1(x9)) + x5))), x22, uint64(p256Uint1(x25)))
+	var x28 uint64
+	var x29 uint64
+	x28, x29 = bits.Add64(x2, (uint64(p256Uint1(x23)) + x19), uint64(p256Uint1(x27)))
+	var x30 uint64
+	var x31 uint64
+	x30, x31 = bits.Add64(x3, x16, uint64(p256Uint1(x29)))
+	var x32 uint64
+	var x33 uint64
+	x32, x33 = bits.Add64(x26, arg1[2], uint64(0x0))
+	var x34 uint64
+	var x35 uint64
+	x34, x35 = bits.Add64(x28, uint64(0x0), uint64(p256Uint1(x33)))
+	var x36 uint64
+	var x37 uint64
+	x36, x37 = bits.Add64(x30, uint64(0x0), uint64(p256Uint1(x35)))
+	var x38 uint64
+	var x39 uint64
+	x39, x38 = bits.Mul64(x32, 0xffffffff00000001)
+	var x40 uint64
+	var x41 uint64
+	x41, x40 = bits.Mul64(x32, 0xffffffff)
+	var x42 uint64
+	var x43 uint64
+	x43, x42 = bits.Mul64(x32, 0xffffffffffffffff)
+	var x44 uint64
+	var x45 uint64
+	x44, x45 = bits.Add64(x43, x40, uint64(0x0))
+	var x47 uint64
+	_, x47 = bits.Add64(x32, x42, uint64(0x0))
+	var x48 uint64
+	var x49 uint64
+	x48, x49 = bits.Add64(x34, x44, uint64(p256Uint1(x47)))
+	var x50 uint64
+	var x51 uint64
+	x50, x51 = bits.Add64(x36, (uint64(p256Uint1(x45)) + x41), uint64(p256Uint1(x49)))
+	var x52 uint64
+	var x53 uint64
+	x52, x53 = bits.Add64((uint64(p256Uint1(x37)) + (uint64(p256Uint1(x31)) + x17)), x38, uint64(p256Uint1(x51)))
+	var x54 uint64
+	var x55 uint64
+	x54, x55 = bits.Add64(x48, arg1[3], uint64(0x0))
+	var x56 uint64
+	var x57 uint64
+	x56, x57 = bits.Add64(x50, uint64(0x0), uint64(p256Uint1(x55)))
+	var x58 uint64
+	var x59 uint64
+	x58, x59 = bits.Add64(x52, uint64(0x0), uint64(p256Uint1(x57)))
+	var x60 uint64
+	var x61 uint64
+	x61, x60 = bits.Mul64(x54, 0xffffffff00000001)
+	var x62 uint64
+	var x63 uint64
+	x63, x62 = bits.Mul64(x54, 0xffffffff)
+	var x64 uint64
+	var x65 uint64
+	x65, x64 = bits.Mul64(x54, 0xffffffffffffffff)
+	var x66 uint64
+	var x67 uint64
+	x66, x67 = bits.Add64(x65, x62, uint64(0x0))
+	var x69 uint64
+	_, x69 = bits.Add64(x54, x64, uint64(0x0))
+	var x70 uint64
+	var x71 uint64
+	x70, x71 = bits.Add64(x56, x66, uint64(p256Uint1(x69)))
+	var x72 uint64
+	var x73 uint64
+	x72, x73 = bits.Add64(x58, (uint64(p256Uint1(x67)) + x63), uint64(p256Uint1(x71)))
+	var x74 uint64
+	var x75 uint64
+	x74, x75 = bits.Add64((uint64(p256Uint1(x59)) + (uint64(p256Uint1(x53)) + x39)), x60, uint64(p256Uint1(x73)))
+	x76 := (uint64(p256Uint1(x75)) + x61)
+	var x77 uint64
+	var x78 uint64
+	x77, x78 = bits.Sub64(x70, 0xffffffffffffffff, uint64(0x0))
+	var x79 uint64
+	var x80 uint64
+	x79, x80 = bits.Sub64(x72, 0xffffffff, uint64(p256Uint1(x78)))
+	var x81 uint64
+	var x82 uint64
+	x81, x82 = bits.Sub64(x74, uint64(0x0), uint64(p256Uint1(x80)))
+	var x83 uint64
+	var x84 uint64
+	x83, x84 = bits.Sub64(x76, 0xffffffff00000001, uint64(p256Uint1(x82)))
+	var x86 uint64
+	_, x86 = bits.Sub64(uint64(0x0), uint64(0x0), uint64(p256Uint1(x84)))
+	var x87 uint64
+	p256CmovznzU64(&x87, p256Uint1(x86), x77, x70)
+	var x88 uint64
+	p256CmovznzU64(&x88, p256Uint1(x86), x79, x72)
+	var x89 uint64
+	p256CmovznzU64(&x89, p256Uint1(x86), x81, x74)
+	var x90 uint64
+	p256CmovznzU64(&x90, p256Uint1(x86), x83, x76)
+	out1[0] = x87
+	out1[1] = x88
+	out1[2] = x89
+	out1[3] = x90
+}
+
+// p256ToMontgomery translates a field element into the Montgomery domain.
+//
+// Preconditions:
+//
+//	0 ≤ eval arg1 < m
+//
+// Postconditions:
+//
+//	eval (from_montgomery out1) mod m = eval arg1 mod m
+//	0 ≤ eval out1 < m
+func p256ToMontgomery(out1 *p256MontgomeryDomainFieldElement, arg1 *p256NonMontgomeryDomainFieldElement) {
+	x1 := arg1[1]
+	x2 := arg1[2]
+	x3 := arg1[3]
+	x4 := arg1[0]
+	var x5 uint64
+	var x6 uint64
+	x6, x5 = bits.Mul64(x4, 0x4fffffffd)
+	var x7 uint64
+	var x8 uint64
+	x8, x7 = bits.Mul64(x4, 0xfffffffffffffffe)
+	var x9 uint64
+	var x10 uint64
+	x10, x9 = bits.Mul64(x4, 0xfffffffbffffffff)
+	var x11 uint64
+	var x12 uint64
+	x12, x11 = bits.Mul64(x4, 0x3)
+	var x13 uint64
+	var x14 uint64
+	x13, x14 = bits.Add64(x12, x9, uint64(0x0))
+	var x15 uint64
+	var x16 uint64
+	x15, x16 = bits.Add64(x10, x7, uint64(p256Uint1(x14)))
+	var x17 uint64
+	var x18 uint64
+	x17, x18 = bits.Add64(x8, x5, uint64(p256Uint1(x16)))
+	var x19 uint64
+	var x20 uint64
+	x20, x19 = bits.Mul64(x11, 0xffffffff00000001)
+	var x21 uint64
+	var x22 uint64
+	x22, x21 = bits.Mul64(x11, 0xffffffff)
+	var x23 uint64
+	var x24 uint64
+	x24, x23 = bits.Mul64(x11, 0xffffffffffffffff)
+	var x25 uint64
+	var x26 uint64
+	x25, x26 = bits.Add64(x24, x21, uint64(0x0))
+	var x28 uint64
+	_, x28 = bits.Add64(x11, x23, uint64(0x0))
+	var x29 uint64
+	var x30 uint64
+	x29, x30 = bits.Add64(x13, x25, uint64(p256Uint1(x28)))
+	var x31 uint64
+	var x32 uint64
+	x31, x32 = bits.Add64(x15, (uint64(p256Uint1(x26)) + x22), uint64(p256Uint1(x30)))
+	var x33 uint64
+	var x34 uint64
+	x33, x34 = bits.Add64(x17, x19, uint64(p256Uint1(x32)))
+	var x35 uint64
+	var x36 uint64
+	x35, x36 = bits.Add64((uint64(p256Uint1(x18)) + x6), x20, uint64(p256Uint1(x34)))
+	var x37 uint64
+	var x38 uint64
+	x38, x37 = bits.Mul64(x1, 0x4fffffffd)
+	var x39 uint64
+	var x40 uint64
+	x40, x39 = bits.Mul64(x1, 0xfffffffffffffffe)
+	var x41 uint64
+	var x42 uint64
+	x42, x41 = bits.Mul64(x1, 0xfffffffbffffffff)
+	var x43 uint64
+	var x44 uint64
+	x44, x43 = bits.Mul64(x1, 0x3)
+	var x45 uint64
+	var x46 uint64
+	x45, x46 = bits.Add64(x44, x41, uint64(0x0))
+	var x47 uint64
+	var x48 uint64
+	x47, x48 = bits.Add64(x42, x39, uint64(p256Uint1(x46)))
+	var x49 uint64
+	var x50 uint64
+	x49, x50 = bits.Add64(x40, x37, uint64(p256Uint1(x48)))
+	var x51 uint64
+	var x52 uint64
+	x51, x52 = bits.Add64(x29, x43, uint64(0x0))
+	var x53 uint64
+	var x54 uint64
+	x53, x54 = bits.Add64(x31, x45, uint64(p256Uint1(x52)))
+	var x55 uint64
+	var x56 uint64
+	x55, x56 = bits.Add64(x33, x47, uint64(p256Uint1(x54)))
+	var x57 uint64
+	var x58 uint64
+	x57, x58 = bits.Add64(x35, x49, uint64(p256Uint1(x56)))
+	var x59 uint64
+	var x60 uint64
+	x60, x59 = bits.Mul64(x51, 0xffffffff00000001)
+	var x61 uint64
+	var x62 uint64
+	x62, x61 = bits.Mul64(x51, 0xffffffff)
+	var x63 uint64
+	var x64 uint64
+	x64, x63 = bits.Mul64(x51, 0xffffffffffffffff)
+	var x65 uint64
+	var x66 uint64
+	x65, x66 = bits.Add64(x64, x61, uint64(0x0))
+	var x68 uint64
+	_, x68 = bits.Add64(x51, x63, uint64(0x0))
+	var x69 uint64
+	var x70 uint64
+	x69, x70 = bits.Add64(x53, x65, uint64(p256Uint1(x68)))
+	var x71 uint64
+	var x72 uint64
+	x71, x72 = bits.Add64(x55, (uint64(p256Uint1(x66)) + x62), uint64(p256Uint1(x70)))
+	var x73 uint64
+	var x74 uint64
+	x73, x74 = bits.Add64(x57, x59, uint64(p256Uint1(x72)))
+	var x75 uint64
+	var x76 uint64
+	x75, x76 = bits.Add64(((uint64(p256Uint1(x58)) + uint64(p256Uint1(x36))) + (uint64(p256Uint1(x50)) + x38)), x60, uint64(p256Uint1(x74)))
+	var x77 uint64
+	var x78 uint64
+	x78, x77 = bits.Mul64(x2, 0x4fffffffd)
+	var x79 uint64
+	var x80 uint64
+	x80, x79 = bits.Mul64(x2, 0xfffffffffffffffe)
+	var x81 uint64
+	var x82 uint64
+	x82, x81 = bits.Mul64(x2, 0xfffffffbffffffff)
+	var x83 uint64
+	var x84 uint64
+	x84, x83 = bits.Mul64(x2, 0x3)
+	var x85 uint64
+	var x86 uint64
+	x85, x86 = bits.Add64(x84, x81, uint64(0x0))
+	var x87 uint64
+	var x88 uint64
+	x87, x88 = bits.Add64(x82, x79, uint64(p256Uint1(x86)))
+	var x89 uint64
+	var x90 uint64
+	x89, x90 = bits.Add64(x80, x77, uint64(p256Uint1(x88)))
+	var x91 uint64
+	var x92 uint64
+	x91, x92 = bits.Add64(x69, x83, uint64(0x0))
+	var x93 uint64
+	var x94 uint64
+	x93, x94 = bits.Add64(x71, x85, uint64(p256Uint1(x92)))
+	var x95 uint64
+	var x96 uint64
+	x95, x96 = bits.Add64(x73, x87, uint64(p256Uint1(x94)))
+	var x97 uint64
+	var x98 uint64
+	x97, x98 = bits.Add64(x75, x89, uint64(p256Uint1(x96)))
+	var x99 uint64
+	var x100 uint64
+	x100, x99 = bits.Mul64(x91, 0xffffffff00000001)
+	var x101 uint64
+	var x102 uint64
+	x102, x101 = bits.Mul64(x91, 0xffffffff)
+	var x103 uint64
+	var x104 uint64
+	x104, x103 = bits.Mul64(x91, 0xffffffffffffffff)
+	var x105 uint64
+	var x106 uint64
+	x105, x106 = bits.Add64(x104, x101, uint64(0x0))
+	var x108 uint64
+	_, x108 = bits.Add64(x91, x103, uint64(0x0))
+	var x109 uint64
+	var x110 uint64
+	x109, x110 = bits.Add64(x93, x105, uint64(p256Uint1(x108)))
+	var x111 uint64
+	var x112 uint64
+	x111, x112 = bits.Add64(x95, (uint64(p256Uint1(x106)) + x102), uint64(p256Uint1(x110)))
+	var x113 uint64
+	var x114 uint64
+	x113, x114 = bits.Add64(x97, x99, uint64(p256Uint1(x112)))
+	var x115 uint64
+	var x116 uint64
+	x115, x116 = bits.Add64(((uint64(p256Uint1(x98)) + uint64(p256Uint1(x76))) + (uint64(p256Uint1(x90)) + x78)), x100, uint64(p256Uint1(x114)))
+	var x117 uint64
+	var x118 uint64
+	x118, x117 = bits.Mul64(x3, 0x4fffffffd)
+	var x119 uint64
+	var x120 uint64
+	x120, x119 = bits.Mul64(x3, 0xfffffffffffffffe)
+	var x121 uint64
+	var x122 uint64
+	x122, x121 = bits.Mul64(x3, 0xfffffffbffffffff)
+	var x123 uint64
+	var x124 uint64
+	x124, x123 = bits.Mul64(x3, 0x3)
+	var x125 uint64
+	var x126 uint64
+	x125, x126 = bits.Add64(x124, x121, uint64(0x0))
+	var x127 uint64
+	var x128 uint64
+	x127, x128 = bits.Add64(x122, x119, uint64(p256Uint1(x126)))
+	var x129 uint64
+	var x130 uint64
+	x129, x130 = bits.Add64(x120, x117, uint64(p256Uint1(x128)))
+	var x131 uint64
+	var x132 uint64
+	x131, x132 = bits.Add64(x109, x123, uint64(0x0))
+	var x133 uint64
+	var x134 uint64
+	x133, x134 = bits.Add64(x111, x125, uint64(p256Uint1(x132)))
+	var x135 uint64
+	var x136 uint64
+	x135, x136 = bits.Add64(x113, x127, uint64(p256Uint1(x134)))
+	var x137 uint64
+	var x138 uint64
+	x137, x138 = bits.Add64(x115, x129, uint64(p256Uint1(x136)))
+	var x139 uint64
+	var x140 uint64
+	x140, x139 = bits.Mul64(x131, 0xffffffff00000001)
+	var x141 uint64
+	var x142 uint64
+	x142, x141 = bits.Mul64(x131, 0xffffffff)
+	var x143 uint64
+	var x144 uint64
+	x144, x143 = bits.Mul64(x131, 0xffffffffffffffff)
+	var x145 uint64
+	var x146 uint64
+	x145, x146 = bits.Add64(x144, x141, uint64(0x0))
+	var x148 uint64
+	_, x148 = bits.Add64(x131, x143, uint64(0x0))
+	var x149 uint64
+	var x150 uint64
+	x149, x150 = bits.Add64(x133, x145, uint64(p256Uint1(x148)))
+	var x151 uint64
+	var x152 uint64
+	x151, x152 = bits.Add64(x135, (uint64(p256Uint1(x146)) + x142), uint64(p256Uint1(x150)))
+	var x153 uint64
+	var x154 uint64
+	x153, x154 = bits.Add64(x137, x139, uint64(p256Uint1(x152)))
+	var x155 uint64
+	var x156 uint64
+	x155, x156 = bits.Add64(((uint64(p256Uint1(x138)) + uint64(p256Uint1(x116))) + (uint64(p256Uint1(x130)) + x118)), x140, uint64(p256Uint1(x154)))
+	var x157 uint64
+	var x158 uint64
+	x157, x158 = bits.Sub64(x149, 0xffffffffffffffff, uint64(0x0))
+	var x159 uint64
+	var x160 uint64
+	x159, x160 = bits.Sub64(x151, 0xffffffff, uint64(p256Uint1(x158)))
+	var x161 uint64
+	var x162 uint64
+	x161, x162 = bits.Sub64(x153, uint64(0x0), uint64(p256Uint1(x160)))
+	var x163 uint64
+	var x164 uint64
+	x163, x164 = bits.Sub64(x155, 0xffffffff00000001, uint64(p256Uint1(x162)))
+	var x166 uint64
+	_, x166 = bits.Sub64(uint64(p256Uint1(x156)), uint64(0x0), uint64(p256Uint1(x164)))
+	var x167 uint64
+	p256CmovznzU64(&x167, p256Uint1(x166), x157, x149)
+	var x168 uint64
+	p256CmovznzU64(&x168, p256Uint1(x166), x159, x151)
+	var x169 uint64
+	p256CmovznzU64(&x169, p256Uint1(x166), x161, x153)
+	var x170 uint64
+	p256CmovznzU64(&x170, p256Uint1(x166), x163, x155)
+	out1[0] = x167
+	out1[1] = x168
+	out1[2] = x169
+	out1[3] = x170
+}
+
+// p256Selectznz is a multi-limb conditional select.
+//
+// Postconditions:
+//
+//	eval out1 = (if arg1 = 0 then eval arg2 else eval arg3)
+//
+// Input Bounds:
+//
+//	arg1: [0x0 ~> 0x1]
+//	arg2: [[0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff]]
+//	arg3: [[0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff]]
+//
+// Output Bounds:
+//
+//	out1: [[0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff]]
+func p256Selectznz(out1 *[4]uint64, arg1 p256Uint1, arg2 *[4]uint64, arg3 *[4]uint64) {
+	var x1 uint64
+	p256CmovznzU64(&x1, arg1, arg2[0], arg3[0])
+	var x2 uint64
+	p256CmovznzU64(&x2, arg1, arg2[1], arg3[1])
+	var x3 uint64
+	p256CmovznzU64(&x3, arg1, arg2[2], arg3[2])
+	var x4 uint64
+	p256CmovznzU64(&x4, arg1, arg2[3], arg3[3])
+	out1[0] = x1
+	out1[1] = x2
+	out1[2] = x3
+	out1[3] = x4
+}
+
+// p256ToBytes serializes a field element NOT in the Montgomery domain to bytes in little-endian order.
+//
+// Preconditions:
+//
+//	0 ≤ eval arg1 < m
+//
+// Postconditions:
+//
+//	out1 = map (λ x, ⌊((eval arg1 mod m) mod 2^(8 * (x + 1))) / 2^(8 * x)⌋) [0..31]
+//
+// Input Bounds:
+//
+//	arg1: [[0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff]]
+//
+// Output Bounds:
+//
+//	out1: [[0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff]]
+func p256ToBytes(out1 *[32]uint8, arg1 *[4]uint64) {
+	x1 := arg1[3]
+	x2 := arg1[2]
+	x3 := arg1[1]
+	x4 := arg1[0]
+	x5 := (uint8(x4) & 0xff)
+	x6 := (x4 >> 8)
+	x7 := (uint8(x6) & 0xff)
+	x8 := (x6 >> 8)
+	x9 := (uint8(x8) & 0xff)
+	x10 := (x8 >> 8)
+	x11 := (uint8(x10) & 0xff)
+	x12 := (x10 >> 8)
+	x13 := (uint8(x12) & 0xff)
+	x14 := (x12 >> 8)
+	x15 := (uint8(x14) & 0xff)
+	x16 := (x14 >> 8)
+	x17 := (uint8(x16) & 0xff)
+	x18 := uint8((x16 >> 8))
+	x19 := (uint8(x3) & 0xff)
+	x20 := (x3 >> 8)
+	x21 := (uint8(x20) & 0xff)
+	x22 := (x20 >> 8)
+	x23 := (uint8(x22) & 0xff)
+	x24 := (x22 >> 8)
+	x25 := (uint8(x24) & 0xff)
+	x26 := (x24 >> 8)
+	x27 := (uint8(x26) & 0xff)
+	x28 := (x26 >> 8)
+	x29 := (uint8(x28) & 0xff)
+	x30 := (x28 >> 8)
+	x31 := (uint8(x30) & 0xff)
+	x32 := uint8((x30 >> 8))
+	x33 := (uint8(x2) & 0xff)
+	x34 := (x2 >> 8)
+	x35 := (uint8(x34) & 0xff)
+	x36 := (x34 >> 8)
+	x37 := (uint8(x36) & 0xff)
+	x38 := (x36 >> 8)
+	x39 := (uint8(x38) & 0xff)
+	x40 := (x38 >> 8)
+	x41 := (uint8(x40) & 0xff)
+	x42 := (x40 >> 8)
+	x43 := (uint8(x42) & 0xff)
+	x44 := (x42 >> 8)
+	x45 := (uint8(x44) & 0xff)
+	x46 := uint8((x44 >> 8))
+	x47 := (uint8(x1) & 0xff)
+	x48 := (x1 >> 8)
+	x49 := (uint8(x48) & 0xff)
+	x50 := (x48 >> 8)
+	x51 := (uint8(x50) & 0xff)
+	x52 := (x50 >> 8)
+	x53 := (uint8(x52) & 0xff)
+	x54 := (x52 >> 8)
+	x55 := (uint8(x54) & 0xff)
+	x56 := (x54 >> 8)
+	x57 := (uint8(x56) & 0xff)
+	x58 := (x56 >> 8)
+	x59 := (uint8(x58) & 0xff)
+	x60 := uint8((x58 >> 8))
+	out1[0] = x5
+	out1[1] = x7
+	out1[2] = x9
+	out1[3] = x11
+	out1[4] = x13
+	out1[5] = x15
+	out1[6] = x17
+	out1[7] = x18
+	out1[8] = x19
+	out1[9] = x21
+	out1[10] = x23
+	out1[11] = x25
+	out1[12] = x27
+	out1[13] = x29
+	out1[14] = x31
+	out1[15] = x32
+	out1[16] = x33
+	out1[17] = x35
+	out1[18] = x37
+	out1[19] = x39
+	out1[20] = x41
+	out1[21] = x43
+	out1[22] = x45
+	out1[23] = x46
+	out1[24] = x47
+	out1[25] = x49
+	out1[26] = x51
+	out1[27] = x53
+	out1[28] = x55
+	out1[29] = x57
+	out1[30] = x59
+	out1[31] = x60
+}
+
+// p256FromBytes deserializes a field element NOT in the Montgomery domain from bytes in little-endian order.
+//
+// Preconditions:
+//
+//	0 ≤ bytes_eval arg1 < m
+//
+// Postconditions:
+//
+//	eval out1 mod m = bytes_eval arg1 mod m
+//	0 ≤ eval out1 < m
+//
+// Input Bounds:
+//
+//	arg1: [[0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff], [0x0 ~> 0xff]]
+//
+// Output Bounds:
+//
+//	out1: [[0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff], [0x0 ~> 0xffffffffffffffff]]
+func p256FromBytes(out1 *[4]uint64, arg1 *[32]uint8) {
+	x1 := (uint64(arg1[31]) << 56)
+	x2 := (uint64(arg1[30]) << 48)
+	x3 := (uint64(arg1[29]) << 40)
+	x4 := (uint64(arg1[28]) << 32)
+	x5 := (uint64(arg1[27]) << 24)
+	x6 := (uint64(arg1[26]) << 16)
+	x7 := (uint64(arg1[25]) << 8)
+	x8 := arg1[24]
+	x9 := (uint64(arg1[23]) << 56)
+	x10 := (uint64(arg1[22]) << 48)
+	x11 := (uint64(arg1[21]) << 40)
+	x12 := (uint64(arg1[20]) << 32)
+	x13 := (uint64(arg1[19]) << 24)
+	x14 := (uint64(arg1[18]) << 16)
+	x15 := (uint64(arg1[17]) << 8)
+	x16 := arg1[16]
+	x17 := (uint64(arg1[15]) << 56)
+	x18 := (uint64(arg1[14]) << 48)
+	x19 := (uint64(arg1[13]) << 40)
+	x20 := (uint64(arg1[12]) << 32)
+	x21 := (uint64(arg1[11]) << 24)
+	x22 := (uint64(arg1[10]) << 16)
+	x23 := (uint64(arg1[9]) << 8)
+	x24 := arg1[8]
+	x25 := (uint64(arg1[7]) << 56)
+	x26 := (uint64(arg1[6]) << 48)
+	x27 := (uint64(arg1[5]) << 40)
+	x28 := (uint64(arg1[4]) << 32)
+	x29 := (uint64(arg1[3]) << 24)
+	x30 := (uint64(arg1[2]) << 16)
+	x31 := (uint64(arg1[1]) << 8)
+	x32 := arg1[0]
+	x33 := (x31 + uint64(x32))
+	x34 := (x30 + x33)
+	x35 := (x29 + x34)
+	x36 := (x28 + x35)
+	x37 := (x27 + x36)
+	x38 := (x26 + x37)
+	x39 := (x25 + x38)
+	x40 := (x23 + uint64(x24))
+	x41 := (x22 + x40)
+	x42 := (x21 + x41)
+	x43 := (x20 + x42)
+	x44 := (x19 + x43)
+	x45 := (x18 + x44)
+	x46 := (x17 + x45)
+	x47 := (x15 + uint64(x16))
+	x48 := (x14 + x47)
+	x49 := (x13 + x48)
+	x50 := (x12 + x49)
+	x51 := (x11 + x50)
+	x52 := (x10 + x51)
+	x53 := (x9 + x52)
+	x54 := (x7 + uint64(x8))
+	x55 := (x6 + x54)
+	x56 := (x5 + x55)
+	x57 := (x4 + x56)
+	x58 := (x3 + x57)
+	x59 := (x2 + x58)
+	x60 := (x1 + x59)
+	out1[0] = x39
+	out1[1] = x46
+	out1[2] = x53
+	out1[3] = x60
+}
diff --git a/src/crypto/elliptic/internal/fiat/p256_invert.go b/src/crypto/elliptic/internal/fiat/p256_invert.go
new file mode 100644
index 0000000000..d0101e1d4f
--- /dev/null
+++ b/src/crypto/elliptic/internal/fiat/p256_invert.go
@@ -0,0 +1,84 @@
+// Copyright 2021 The Go Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style
+// license that can be found in the LICENSE file.
+
+// Code generated by addchain. DO NOT EDIT.
+
+package fiat
+
+// Invert sets e = 1/x, and returns e.
+//
+// If x == 0, Invert returns e = 0.
+func (e *P256Element) Invert(x *P256Element) *P256Element {
+	// Inversion is implemented as exponentiation with exponent p − 2.
+	// The sequence of 12 multiplications and 255 squarings is derived from the
+	// following addition chain generated with github.com/mmcloughlin/addchain v0.4.0.
+	//
+	//	_10     = 2*1
+	//	_11     = 1 + _10
+	//	_110    = 2*_11
+	//	_111    = 1 + _110
+	//	_111000 = _111 << 3
+	//	_111111 = _111 + _111000
+	//	x12     = _111111 << 6 + _111111
+	//	x15     = x12 << 3 + _111
+	//	x16     = 2*x15 + 1
+	//	x32     = x16 << 16 + x16
+	//	i53     = x32 << 15
+	//	x47     = x15 + i53
+	//	i263    = ((i53 << 17 + 1) << 143 + x47) << 47
+	//	return    (x47 + i263) << 2 + 1
+	//
+
+	var z = new(P256Element).Set(e)
+	var t0 = new(P256Element)
+	var t1 = new(P256Element)
+
+	z.Square(x)
+	z.Mul(x, z)
+	z.Square(z)
+	z.Mul(x, z)
+	t0.Square(z)
+	for s := 1; s < 3; s++ {
+		t0.Square(t0)
+	}
+	t0.Mul(z, t0)
+	t1.Square(t0)
+	for s := 1; s < 6; s++ {
+		t1.Square(t1)
+	}
+	t0.Mul(t0, t1)
+	for s := 0; s < 3; s++ {
+		t0.Square(t0)
+	}
+	z.Mul(z, t0)
+	t0.Square(z)
+	t0.Mul(x, t0)
+	t1.Square(t0)
+	for s := 1; s < 16; s++ {
+		t1.Square(t1)
+	}
+	t0.Mul(t0, t1)
+	for s := 0; s < 15; s++ {
+		t0.Square(t0)
+	}
+	z.Mul(z, t0)
+	for s := 0; s < 17; s++ {
+		t0.Square(t0)
+	}
+	t0.Mul(x, t0)
+	for s := 0; s < 143; s++ {
+		t0.Square(t0)
+	}
+	t0.Mul(z, t0)
+	for s := 0; s < 47; s++ {
+		t0.Square(t0)
+	}
+	z.Mul(z, t0)
+	for s := 0; s < 2; s++ {
+		z.Square(z)
+	}
+	z.Mul(x, z)
+
+	return e.Set(z)
+}
diff --git a/src/crypto/elliptic/internal/nistec/generate.go b/src/crypto/elliptic/internal/nistec/generate.go
index 52b14f8424..a7c9d00db4 100644
--- a/src/crypto/elliptic/internal/nistec/generate.go
+++ b/src/crypto/elliptic/internal/nistec/generate.go
@@ -28,6 +28,11 @@ var curves = []struct {
 		Element: "fiat.P224Element",
 		Params:  elliptic.P224().Params(),
 	},
+	{
+		P:       "P256",
+		Element: "fiat.P256Element",
+		Params:  elliptic.P256().Params(),
+	},
 	{
 		P:       "P384",
 		Element: "fiat.P384Element",
diff --git a/src/crypto/elliptic/internal/nistec/nistec_test.go b/src/crypto/elliptic/internal/nistec/nistec_test.go
index 4eae998c5d..9fde2f4fa1 100644
--- a/src/crypto/elliptic/internal/nistec/nistec_test.go
+++ b/src/crypto/elliptic/internal/nistec/nistec_test.go
@@ -5,6 +5,7 @@
 package nistec_test
 
 import (
+	"bytes"
 	"crypto/elliptic/internal/nistec"
 	"math/rand"
 	"os"
@@ -19,7 +20,21 @@ func TestAllocations(t *testing.T) {
 	t.Run("P224", func(t *testing.T) {
 		if allocs := testing.AllocsPerRun(100, func() {
 			p := nistec.NewP224Generator()
-			scalar := make([]byte, 66)
+			scalar := make([]byte, 28)
+			rand.Read(scalar)
+			p.ScalarMult(p, scalar)
+			out := p.Bytes()
+			if _, err := p.SetBytes(out); err != nil {
+				t.Fatal(err)
+			}
+		}); allocs > 0 {
+			t.Errorf("expected zero allocations, got %0.1f", allocs)
+		}
+	})
+	t.Run("P256", func(t *testing.T) {
+		if allocs := testing.AllocsPerRun(100, func() {
+			p := nistec.NewP256Generator()
+			scalar := make([]byte, 32)
 			rand.Read(scalar)
 			p.ScalarMult(p, scalar)
 			out := p.Bytes()
@@ -33,7 +48,7 @@ func TestAllocations(t *testing.T) {
 	t.Run("P384", func(t *testing.T) {
 		if allocs := testing.AllocsPerRun(100, func() {
 			p := nistec.NewP384Generator()
-			scalar := make([]byte, 66)
+			scalar := make([]byte, 48)
 			rand.Read(scalar)
 			p.ScalarMult(p, scalar)
 			out := p.Bytes()
@@ -60,35 +75,65 @@ func TestAllocations(t *testing.T) {
 	})
 }
 
+type nistPoint[T any] interface {
+	Bytes() []byte
+	SetBytes([]byte) (T, error)
+	Add(T, T) T
+	Double(T) T
+	ScalarMult(T, []byte) T
+}
+
+func TestEquivalents(t *testing.T) {
+	t.Run("P224", func(t *testing.T) {
+		testEquivalents(t, nistec.NewP224Point, nistec.NewP224Generator)
+	})
+	t.Run("P256", func(t *testing.T) {
+		testEquivalents(t, nistec.NewP256Point, nistec.NewP256Generator)
+	})
+	t.Run("P384", func(t *testing.T) {
+		testEquivalents(t, nistec.NewP384Point, nistec.NewP384Generator)
+	})
+	t.Run("P521", func(t *testing.T) {
+		testEquivalents(t, nistec.NewP521Point, nistec.NewP521Generator)
+	})
+}
+
+func testEquivalents[P nistPoint[P]](t *testing.T, newPoint, newGenerator func() P) {
+	p := newGenerator()
+
+	p1 := newPoint().Double(p)
+	p2 := newPoint().Add(p, p)
+	p3 := newPoint().ScalarMult(p, []byte{2})
+
+	if !bytes.Equal(p1.Bytes(), p2.Bytes()) {
+		t.Error("P+P != 2*P")
+	}
+	if !bytes.Equal(p1.Bytes(), p3.Bytes()) {
+		t.Error("P+P != [2]P")
+	}
+}
+
 func BenchmarkScalarMult(b *testing.B) {
 	b.Run("P224", func(b *testing.B) {
-		scalar := make([]byte, 66)
-		rand.Read(scalar)
-		p := nistec.NewP224Generator()
-		b.ReportAllocs()
-		b.ResetTimer()
-		for i := 0; i < b.N; i++ {
-			p.ScalarMult(p, scalar)
-		}
+		benchmarkScalarMult(b, nistec.NewP224Generator(), 28)
+	})
+	b.Run("P256", func(b *testing.B) {
+		benchmarkScalarMult(b, nistec.NewP256Generator(), 32)
 	})
 	b.Run("P384", func(b *testing.B) {
-		scalar := make([]byte, 66)
-		rand.Read(scalar)
-		p := nistec.NewP384Generator()
-		b.ReportAllocs()
-		b.ResetTimer()
-		for i := 0; i < b.N; i++ {
-			p.ScalarMult(p, scalar)
-		}
+		benchmarkScalarMult(b, nistec.NewP384Generator(), 48)
 	})
 	b.Run("P521", func(b *testing.B) {
-		scalar := make([]byte, 66)
-		rand.Read(scalar)
-		p := nistec.NewP521Generator()
-		b.ReportAllocs()
-		b.ResetTimer()
-		for i := 0; i < b.N; i++ {
-			p.ScalarMult(p, scalar)
-		}
+		benchmarkScalarMult(b, nistec.NewP521Generator(), 66)
 	})
 }
+
+func benchmarkScalarMult[P nistPoint[P]](b *testing.B, p P, scalarSize int) {
+	scalar := make([]byte, scalarSize)
+	rand.Read(scalar)
+	b.ReportAllocs()
+	b.ResetTimer()
+	for i := 0; i < b.N; i++ {
+		p.ScalarMult(p, scalar)
+	}
+}
diff --git a/src/crypto/elliptic/internal/nistec/p256.go b/src/crypto/elliptic/internal/nistec/p256.go
new file mode 100644
index 0000000000..e3f172767b
--- /dev/null
+++ b/src/crypto/elliptic/internal/nistec/p256.go
@@ -0,0 +1,288 @@
+// Copyright 2022 The Go Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style
+// license that can be found in the LICENSE file.
+
+// Code generated by generate.go. DO NOT EDIT.
+
+package nistec
+
+import (
+	"crypto/elliptic/internal/fiat"
+	"crypto/subtle"
+	"errors"
+)
+
+var p256B, _ = new(fiat.P256Element).SetBytes([]byte{0x5a, 0xc6, 0x35, 0xd8, 0xaa, 0x3a, 0x93, 0xe7, 0xb3, 0xeb, 0xbd, 0x55, 0x76, 0x98, 0x86, 0xbc, 0x65, 0x1d, 0x6, 0xb0, 0xcc, 0x53, 0xb0, 0xf6, 0x3b, 0xce, 0x3c, 0x3e, 0x27, 0xd2, 0x60, 0x4b})
+
+var p256G, _ = NewP256Point().SetBytes([]byte{0x4, 0x6b, 0x17, 0xd1, 0xf2, 0xe1, 0x2c, 0x42, 0x47, 0xf8, 0xbc, 0xe6, 0xe5, 0x63, 0xa4, 0x40, 0xf2, 0x77, 0x3, 0x7d, 0x81, 0x2d, 0xeb, 0x33, 0xa0, 0xf4, 0xa1, 0x39, 0x45, 0xd8, 0x98, 0xc2, 0x96, 0x4f, 0xe3, 0x42, 0xe2, 0xfe, 0x1a, 0x7f, 0x9b, 0x8e, 0xe7, 0xeb, 0x4a, 0x7c, 0xf, 0x9e, 0x16, 0x2b, 0xce, 0x33, 0x57, 0x6b, 0x31, 0x5e, 0xce, 0xcb, 0xb6, 0x40, 0x68, 0x37, 0xbf, 0x51, 0xf5})
+
+const p256ElementLength = 32
+
+// P256Point is a P256 point. The zero value is NOT valid.
+type P256Point struct {
+	// The point is represented in projective coordinates (X:Y:Z),
+	// where x = X/Z and y = Y/Z.
+	x, y, z *fiat.P256Element
+}
+
+// NewP256Point returns a new P256Point representing the point at infinity point.
+func NewP256Point() *P256Point {
+	return &P256Point{
+		x: new(fiat.P256Element),
+		y: new(fiat.P256Element).One(),
+		z: new(fiat.P256Element),
+	}
+}
+
+// NewP256Generator returns a new P256Point set to the canonical generator.
+func NewP256Generator() *P256Point {
+	return (&P256Point{
+		x: new(fiat.P256Element),
+		y: new(fiat.P256Element),
+		z: new(fiat.P256Element),
+	}).Set(p256G)
+}
+
+// Set sets p = q and returns p.
+func (p *P256Point) Set(q *P256Point) *P256Point {
+	p.x.Set(q.x)
+	p.y.Set(q.y)
+	p.z.Set(q.z)
+	return p
+}
+
+// SetBytes sets p to the compressed, uncompressed, or infinity value encoded in
+// b, as specified in SEC 1, Version 2.0, Section 2.3.4. If the point is not on
+// the curve, it returns nil and an error, and the receiver is unchanged.
+// Otherwise, it returns p.
+func (p *P256Point) SetBytes(b []byte) (*P256Point, error) {
+	switch {
+	// Point at infinity.
+	case len(b) == 1 && b[0] == 0:
+		return p.Set(NewP256Point()), nil
+
+	// Uncompressed form.
+	case len(b) == 1+2*p256ElementLength && b[0] == 4:
+		x, err := new(fiat.P256Element).SetBytes(b[1 : 1+p256ElementLength])
+		if err != nil {
+			return nil, err
+		}
+		y, err := new(fiat.P256Element).SetBytes(b[1+p256ElementLength:])
+		if err != nil {
+			return nil, err
+		}
+		if err := p256CheckOnCurve(x, y); err != nil {
+			return nil, err
+		}
+		p.x.Set(x)
+		p.y.Set(y)
+		p.z.One()
+		return p, nil
+
+	// Compressed form
+	case len(b) == 1+p256ElementLength && b[0] == 0:
+		return nil, errors.New("unimplemented") // TODO(filippo)
+
+	default:
+		return nil, errors.New("invalid P256 point encoding")
+	}
+}
+
+func p256CheckOnCurve(x, y *fiat.P256Element) error {
+	// x³ - 3x + b.
+	x3 := new(fiat.P256Element).Square(x)
+	x3.Mul(x3, x)
+
+	threeX := new(fiat.P256Element).Add(x, x)
+	threeX.Add(threeX, x)
+
+	x3.Sub(x3, threeX)
+	x3.Add(x3, p256B)
+
+	// y² = x³ - 3x + b
+	y2 := new(fiat.P256Element).Square(y)
+
+	if x3.Equal(y2) != 1 {
+		return errors.New("P256 point not on curve")
+	}
+	return nil
+}
+
+// Bytes returns the uncompressed or infinity encoding of p, as specified in
+// SEC 1, Version 2.0, Section 2.3.3. Note that the encoding of the point at
+// infinity is shorter than all other encodings.
+func (p *P256Point) Bytes() []byte {
+	// This function is outlined to make the allocations inline in the caller
+	// rather than happen on the heap.
+	var out [133]byte
+	return p.bytes(&out)
+}
+
+func (p *P256Point) bytes(out *[133]byte) []byte {
+	if p.z.IsZero() == 1 {
+		return append(out[:0], 0)
+	}
+
+	zinv := new(fiat.P256Element).Invert(p.z)
+	xx := new(fiat.P256Element).Mul(p.x, zinv)
+	yy := new(fiat.P256Element).Mul(p.y, zinv)
+
+	buf := append(out[:0], 4)
+	buf = append(buf, xx.Bytes()...)
+	buf = append(buf, yy.Bytes()...)
+	return buf
+}
+
+// Add sets q = p1 + p2, and returns q. The points may overlap.
+func (q *P256Point) Add(p1, p2 *P256Point) *P256Point {
+	// Complete addition formula for a = -3 from "Complete addition formulas for
+	// prime order elliptic curves" (https://eprint.iacr.org/2015/1060), §A.2.
+
+	t0 := new(fiat.P256Element).Mul(p1.x, p2.x) // t0 := X1 * X2
+	t1 := new(fiat.P256Element).Mul(p1.y, p2.y) // t1 := Y1 * Y2
+	t2 := new(fiat.P256Element).Mul(p1.z, p2.z) // t2 := Z1 * Z2
+	t3 := new(fiat.P256Element).Add(p1.x, p1.y) // t3 := X1 + Y1
+	t4 := new(fiat.P256Element).Add(p2.x, p2.y) // t4 := X2 + Y2
+	t3.Mul(t3, t4)                              // t3 := t3 * t4
+	t4.Add(t0, t1)                              // t4 := t0 + t1
+	t3.Sub(t3, t4)                              // t3 := t3 - t4
+	t4.Add(p1.y, p1.z)                          // t4 := Y1 + Z1
+	x3 := new(fiat.P256Element).Add(p2.y, p2.z) // X3 := Y2 + Z2
+	t4.Mul(t4, x3)                              // t4 := t4 * X3
+	x3.Add(t1, t2)                              // X3 := t1 + t2
+	t4.Sub(t4, x3)                              // t4 := t4 - X3
+	x3.Add(p1.x, p1.z)                          // X3 := X1 + Z1
+	y3 := new(fiat.P256Element).Add(p2.x, p2.z) // Y3 := X2 + Z2
+	x3.Mul(x3, y3)                              // X3 := X3 * Y3
+	y3.Add(t0, t2)                              // Y3 := t0 + t2
+	y3.Sub(x3, y3)                              // Y3 := X3 - Y3
+	z3 := new(fiat.P256Element).Mul(p256B, t2)  // Z3 := b * t2
+	x3.Sub(y3, z3)                              // X3 := Y3 - Z3
+	z3.Add(x3, x3)                              // Z3 := X3 + X3
+	x3.Add(x3, z3)                              // X3 := X3 + Z3
+	z3.Sub(t1, x3)                              // Z3 := t1 - X3
+	x3.Add(t1, x3)                              // X3 := t1 + X3
+	y3.Mul(p256B, y3)                           // Y3 := b * Y3
+	t1.Add(t2, t2)                              // t1 := t2 + t2
+	t2.Add(t1, t2)                              // t2 := t1 + t2
+	y3.Sub(y3, t2)                              // Y3 := Y3 - t2
+	y3.Sub(y3, t0)                              // Y3 := Y3 - t0
+	t1.Add(y3, y3)                              // t1 := Y3 + Y3
+	y3.Add(t1, y3)                              // Y3 := t1 + Y3
+	t1.Add(t0, t0)                              // t1 := t0 + t0
+	t0.Add(t1, t0)                              // t0 := t1 + t0
+	t0.Sub(t0, t2)                              // t0 := t0 - t2
+	t1.Mul(t4, y3)                              // t1 := t4 * Y3
+	t2.Mul(t0, y3)                              // t2 := t0 * Y3
+	y3.Mul(x3, z3)                              // Y3 := X3 * Z3
+	y3.Add(y3, t2)                              // Y3 := Y3 + t2
+	x3.Mul(t3, x3)                              // X3 := t3 * X3
+	x3.Sub(x3, t1)                              // X3 := X3 - t1
+	z3.Mul(t4, z3)                              // Z3 := t4 * Z3
+	t1.Mul(t3, t0)                              // t1 := t3 * t0
+	z3.Add(z3, t1)                              // Z3 := Z3 + t1
+
+	q.x.Set(x3)
+	q.y.Set(y3)
+	q.z.Set(z3)
+	return q
+}
+
+// Double sets q = p + p, and returns q. The points may overlap.
+func (q *P256Point) Double(p *P256Point) *P256Point {
+	// Complete addition formula for a = -3 from "Complete addition formulas for
+	// prime order elliptic curves" (https://eprint.iacr.org/2015/1060), §A.2.
+
+	t0 := new(fiat.P256Element).Square(p.x)    // t0 := X ^ 2
+	t1 := new(fiat.P256Element).Square(p.y)    // t1 := Y ^ 2
+	t2 := new(fiat.P256Element).Square(p.z)    // t2 := Z ^ 2
+	t3 := new(fiat.P256Element).Mul(p.x, p.y)  // t3 := X * Y
+	t3.Add(t3, t3)                             // t3 := t3 + t3
+	z3 := new(fiat.P256Element).Mul(p.x, p.z)  // Z3 := X * Z
+	z3.Add(z3, z3)                             // Z3 := Z3 + Z3
+	y3 := new(fiat.P256Element).Mul(p256B, t2) // Y3 := b * t2
+	y3.Sub(y3, z3)                             // Y3 := Y3 - Z3
+	x3 := new(fiat.P256Element).Add(y3, y3)    // X3 := Y3 + Y3
+	y3.Add(x3, y3)                             // Y3 := X3 + Y3
+	x3.Sub(t1, y3)                             // X3 := t1 - Y3
+	y3.Add(t1, y3)                             // Y3 := t1 + Y3
+	y3.Mul(x3, y3)                             // Y3 := X3 * Y3
+	x3.Mul(x3, t3)                             // X3 := X3 * t3
+	t3.Add(t2, t2)                             // t3 := t2 + t2
+	t2.Add(t2, t3)                             // t2 := t2 + t3
+	z3.Mul(p256B, z3)                          // Z3 := b * Z3
+	z3.Sub(z3, t2)                             // Z3 := Z3 - t2
+	z3.Sub(z3, t0)                             // Z3 := Z3 - t0
+	t3.Add(z3, z3)                             // t3 := Z3 + Z3
+	z3.Add(z3, t3)                             // Z3 := Z3 + t3
+	t3.Add(t0, t0)                             // t3 := t0 + t0
+	t0.Add(t3, t0)                             // t0 := t3 + t0
+	t0.Sub(t0, t2)                             // t0 := t0 - t2
+	t0.Mul(t0, z3)                             // t0 := t0 * Z3
+	y3.Add(y3, t0)                             // Y3 := Y3 + t0
+	t0.Mul(p.y, p.z)                           // t0 := Y * Z
+	t0.Add(t0, t0)                             // t0 := t0 + t0
+	z3.Mul(t0, z3)                             // Z3 := t0 * Z3
+	x3.Sub(x3, z3)                             // X3 := X3 - Z3
+	z3.Mul(t0, t1)                             // Z3 := t0 * t1
+	z3.Add(z3, z3)                             // Z3 := Z3 + Z3
+	z3.Add(z3, z3)                             // Z3 := Z3 + Z3
+
+	q.x.Set(x3)
+	q.y.Set(y3)
+	q.z.Set(z3)
+	return q
+}
+
+// Select sets q to p1 if cond == 1, and to p2 if cond == 0.
+func (q *P256Point) Select(p1, p2 *P256Point, cond int) *P256Point {
+	q.x.Select(p1.x, p2.x, cond)
+	q.y.Select(p1.y, p2.y, cond)
+	q.z.Select(p1.z, p2.z, cond)
+	return q
+}
+
+// ScalarMult sets p = scalar * q, and returns p.
+func (p *P256Point) ScalarMult(q *P256Point, scalar []byte) *P256Point {
+	// table holds the first 16 multiples of q. The explicit newP256Point calls
+	// get inlined, letting the allocations live on the stack.
+	var table = [16]*P256Point{
+		NewP256Point(), NewP256Point(), NewP256Point(), NewP256Point(),
+		NewP256Point(), NewP256Point(), NewP256Point(), NewP256Point(),
+		NewP256Point(), NewP256Point(), NewP256Point(), NewP256Point(),
+		NewP256Point(), NewP256Point(), NewP256Point(), NewP256Point(),
+	}
+	for i := 1; i < 16; i++ {
+		table[i].Add(table[i-1], q)
+	}
+
+	// Instead of doing the classic double-and-add chain, we do it with a
+	// four-bit window: we double four times, and then add [0-15]P.
+	t := NewP256Point()
+	p.Set(NewP256Point())
+	for _, byte := range scalar {
+		p.Double(p)
+		p.Double(p)
+		p.Double(p)
+		p.Double(p)
+
+		for i := uint8(0); i < 16; i++ {
+			cond := subtle.ConstantTimeByteEq(byte>>4, i)
+			t.Select(table[i], t, cond)
+		}
+		p.Add(p, t)
+
+		p.Double(p)
+		p.Double(p)
+		p.Double(p)
+		p.Double(p)
+
+		for i := uint8(0); i < 16; i++ {
+			cond := subtle.ConstantTimeByteEq(byte&0b1111, i)
+			t.Select(table[i], t, cond)
+		}
+		p.Add(p, t)
+	}
+
+	return p
+}
diff --git a/src/crypto/elliptic/nistec.go b/src/crypto/elliptic/nistec.go
index c6f170b3f0..2a95380e06 100644
--- a/src/crypto/elliptic/nistec.go
+++ b/src/crypto/elliptic/nistec.go
@@ -29,6 +29,36 @@ func initP224() {
 	}
 }
 
+var p256Params CurveParams
+
+var p256 Curve = &nistCurve[*nistec.P256Point]{
+	params:       &p256Params,
+	newPoint:     nistec.NewP256Point,
+	newGenerator: nistec.NewP256Generator,
+}
+
+var initP256Arch func()
+
+func initP256() {
+	p256Params = CurveParams{
+		Name:    "P-256",
+		BitSize: 256,
+		// FIPS 186-4, section D.1.2.3
+		P:  bigFromDecimal("115792089210356248762697446949407573530086143415290314195533631308867097853951"),
+		N:  bigFromDecimal("115792089210356248762697446949407573529996955224135760342422259061068512044369"),
+		B:  bigFromHex("5ac635d8aa3a93e7b3ebbd55769886bc651d06b0cc53b0f63bce3c3e27d2604b"),
+		Gx: bigFromHex("6b17d1f2e12c4247f8bce6e563a440f277037d812deb33a0f4a13945d898c296"),
+		Gy: bigFromHex("4fe342e2fe1a7f9b8ee7eb4a7c0f9e162bce33576b315ececbb6406837bf51f5"),
+	}
+
+	// P-256 is implemented by various different backends, including a generic
+	// 32-bit constant-time one in internal/nistec, which is used when assembly
+	// implementations are not available, or not appropriate for the hardware.
+	if initP256Arch != nil {
+		initP256Arch()
+	}
+}
+
 var p384 = &nistCurve[*nistec.P384Point]{
 	newPoint:     nistec.NewP384Point,
 	newGenerator: nistec.NewP384Generator,
diff --git a/src/crypto/elliptic/p256.go b/src/crypto/elliptic/p256.go
deleted file mode 100644
index 97ecda5a8e..0000000000
--- a/src/crypto/elliptic/p256.go
+++ /dev/null
@@ -1,32 +0,0 @@
-// Copyright 2021 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-package elliptic
-
-// P-256 is implemented by various different backends, including a generic
-// 32-bit constant-time one in p256_generic.go, which is used when assembly
-// implementations are not available, or not appropriate for the hardware.
-
-import "math/big"
-
-var p256Params *CurveParams
-
-// RInverse contains 1/R mod p, the inverse of the Montgomery constant 2^257.
-var p256RInverse *big.Int
-
-func initP256() {
-	// See FIPS 186-3, section D.2.3
-	p256Params = &CurveParams{Name: "P-256"}
-	p256Params.P, _ = new(big.Int).SetString("115792089210356248762697446949407573530086143415290314195533631308867097853951", 10)
-	p256Params.N, _ = new(big.Int).SetString("115792089210356248762697446949407573529996955224135760342422259061068512044369", 10)
-	p256Params.B, _ = new(big.Int).SetString("5ac635d8aa3a93e7b3ebbd55769886bc651d06b0cc53b0f63bce3c3e27d2604b", 16)
-	p256Params.Gx, _ = new(big.Int).SetString("6b17d1f2e12c4247f8bce6e563a440f277037d812deb33a0f4a13945d898c296", 16)
-	p256Params.Gy, _ = new(big.Int).SetString("4fe342e2fe1a7f9b8ee7eb4a7c0f9e162bce33576b315ececbb6406837bf51f5", 16)
-	p256Params.BitSize = 256
-
-	p256RInverse, _ = new(big.Int).SetString("7fffffff00000001fffffffe8000000100000000ffffffff0000000180000000", 16)
-
-	// Arch-specific initialization, i.e. let a platform dynamically pick a P256 implementation
-	initP256Arch()
-}
diff --git a/src/crypto/elliptic/p256_asm.go b/src/crypto/elliptic/p256_asm.go
index ce80282ed6..f8335bc85c 100644
--- a/src/crypto/elliptic/p256_asm.go
+++ b/src/crypto/elliptic/p256_asm.go
@@ -32,10 +32,10 @@ type p256Point struct {
 	xyz [12]uint64
 }
 
-var p256 p256Curve
-
-func initP256Arch() {
-	p256 = p256Curve{p256Params}
+func init() {
+	initP256Arch = func() {
+		p256 = p256Curve{&p256Params}
+	}
 }
 
 func (curve p256Curve) Params() *CurveParams {
@@ -120,9 +120,9 @@ func (curve p256Curve) Inverse(k *big.Int) *big.Int {
 		k = new(big.Int).Neg(k)
 	}
 
-	if k.Cmp(p256.N) >= 0 {
+	if k.Cmp(p256Params.N) >= 0 {
 		// This should never happen.
-		k = new(big.Int).Mod(k, p256.N)
+		k = new(big.Int).Mod(k, p256Params.N)
 	}
 
 	// table will store precomputed powers of x.
@@ -218,8 +218,8 @@ func fromBig(out []uint64, big *big.Int) {
 func p256GetScalar(out []uint64, in []byte) {
 	n := new(big.Int).SetBytes(in)
 
-	if n.Cmp(p256.N) >= 0 {
-		n.Mod(n, p256.N)
+	if n.Cmp(p256Params.N) >= 0 {
+		n.Mod(n, p256Params.N)
 	}
 	fromBig(out, n)
 }
@@ -230,10 +230,10 @@ func p256GetScalar(out []uint64, in []byte) {
 var rr = []uint64{0x0000000000000003, 0xfffffffbffffffff, 0xfffffffffffffffe, 0x00000004fffffffd}
 
 func maybeReduceModP(in *big.Int) *big.Int {
-	if in.Cmp(p256.P) < 0 {
+	if in.Cmp(p256Params.P) < 0 {
 		return in
 	}
-	return new(big.Int).Mod(in, p256.P)
+	return new(big.Int).Mod(in, p256Params.P)
 }
 
 func (curve p256Curve) CombinedMult(bigX, bigY *big.Int, baseScalar, scalar []byte) (x, y *big.Int) {
diff --git a/src/crypto/elliptic/p256_generic.go b/src/crypto/elliptic/p256_generic.go
deleted file mode 100644
index 22dde23109..0000000000
--- a/src/crypto/elliptic/p256_generic.go
+++ /dev/null
@@ -1,477 +0,0 @@
-// Copyright 2013 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build !amd64 && !arm64
-
-package elliptic
-
-// This file contains a constant-time, 32-bit implementation of P256.
-
-import "math/big"
-
-type p256Curve struct {
-	*CurveParams
-}
-
-func (curve p256Curve) Params() *CurveParams {
-	return curve.CurveParams
-}
-
-// p256GetScalar endian-swaps the big-endian scalar value from in and writes it
-// to out. If the scalar is equal or greater than the order of the group, it's
-// reduced modulo that order.
-func p256GetScalar(out *[32]byte, in []byte) {
-	n := new(big.Int).SetBytes(in)
-	var scalarBytes []byte
-
-	if n.Cmp(p256Params.N) >= 0 || len(in) > len(out) {
-		n.Mod(n, p256Params.N)
-		scalarBytes = n.Bytes()
-	} else {
-		scalarBytes = in
-	}
-
-	for i, v := range scalarBytes {
-		out[len(scalarBytes)-(1+i)] = v
-	}
-}
-
-func (p256Curve) ScalarBaseMult(scalar []byte) (x, y *big.Int) {
-	var scalarReversed [32]byte
-	p256GetScalar(&scalarReversed, scalar)
-
-	var x1, y1, z1 [p256Limbs]uint32
-	p256ScalarBaseMult(&x1, &y1, &z1, &scalarReversed)
-	return p256ToAffine(&x1, &y1, &z1)
-}
-
-func (p256Curve) ScalarMult(bigX, bigY *big.Int, scalar []byte) (x, y *big.Int) {
-	var scalarReversed [32]byte
-	p256GetScalar(&scalarReversed, scalar)
-
-	var px, py, x1, y1, z1 [p256Limbs]uint32
-	p256FromBig(&px, bigX)
-	p256FromBig(&py, bigY)
-	p256ScalarMult(&x1, &y1, &z1, &px, &py, &scalarReversed)
-	return p256ToAffine(&x1, &y1, &z1)
-}
-
-// p256Precomputed contains precomputed values to aid the calculation of scalar
-// multiples of the base point, G. It's actually two, equal length, tables
-// concatenated.
-//
-// The first table contains (x,y) field element pairs for 16 multiples of the
-// base point, G.
-//
-//	Index  |  Index (binary) | Value
-//	    0  |           0000  | 0G (all zeros, omitted)
-//	    1  |           0001  | G
-//	    2  |           0010  | 2**64G
-//	    3  |           0011  | 2**64G + G
-//	    4  |           0100  | 2**128G
-//	    5  |           0101  | 2**128G + G
-//	    6  |           0110  | 2**128G + 2**64G
-//	    7  |           0111  | 2**128G + 2**64G + G
-//	    8  |           1000  | 2**192G
-//	    9  |           1001  | 2**192G + G
-//	   10  |           1010  | 2**192G + 2**64G
-//	   11  |           1011  | 2**192G + 2**64G + G
-//	   12  |           1100  | 2**192G + 2**128G
-//	   13  |           1101  | 2**192G + 2**128G + G
-//	   14  |           1110  | 2**192G + 2**128G + 2**64G
-//	   15  |           1111  | 2**192G + 2**128G + 2**64G + G
-//
-// The second table follows the same style, but the terms are 2**32G,
-// 2**96G, 2**160G, 2**224G.
-//
-// This is ~2KB of data.
-var p256Precomputed = [p256Limbs * 2 * 15 * 2]uint32{
-	0x11522878, 0xe730d41, 0xdb60179, 0x4afe2ff, 0x12883add, 0xcaddd88, 0x119e7edc, 0xd4a6eab, 0x3120bee,
-	0x1d2aac15, 0xf25357c, 0x19e45cdd, 0x5c721d0, 0x1992c5a5, 0xa237487, 0x154ba21, 0x14b10bb, 0xae3fe3,
-	0xd41a576, 0x922fc51, 0x234994f, 0x60b60d3, 0x164586ae, 0xce95f18, 0x1fe49073, 0x3fa36cc, 0x5ebcd2c,
-	0xb402f2f, 0x15c70bf, 0x1561925c, 0x5a26704, 0xda91e90, 0xcdc1c7f, 0x1ea12446, 0xe1ade1e, 0xec91f22,
-	0x26f7778, 0x566847e, 0xa0bec9e, 0x234f453, 0x1a31f21a, 0xd85e75c, 0x56c7109, 0xa267a00, 0xb57c050,
-	0x98fb57, 0xaa837cc, 0x60c0792, 0xcfa5e19, 0x61bab9e, 0x589e39b, 0xa324c5, 0x7d6dee7, 0x2976e4b,
-	0x1fc4124a, 0xa8c244b, 0x1ce86762, 0xcd61c7e, 0x1831c8e0, 0x75774e1, 0x1d96a5a9, 0x843a649, 0xc3ab0fa,
-	0x6e2e7d5, 0x7673a2a, 0x178b65e8, 0x4003e9b, 0x1a1f11c2, 0x7816ea, 0xf643e11, 0x58c43df, 0xf423fc2,
-	0x19633ffa, 0x891f2b2, 0x123c231c, 0x46add8c, 0x54700dd, 0x59e2b17, 0x172db40f, 0x83e277d, 0xb0dd609,
-	0xfd1da12, 0x35c6e52, 0x19ede20c, 0xd19e0c0, 0x97d0f40, 0xb015b19, 0x449e3f5, 0xe10c9e, 0x33ab581,
-	0x56a67ab, 0x577734d, 0x1dddc062, 0xc57b10d, 0x149b39d, 0x26a9e7b, 0xc35df9f, 0x48764cd, 0x76dbcca,
-	0xca4b366, 0xe9303ab, 0x1a7480e7, 0x57e9e81, 0x1e13eb50, 0xf466cf3, 0x6f16b20, 0x4ba3173, 0xc168c33,
-	0x15cb5439, 0x6a38e11, 0x73658bd, 0xb29564f, 0x3f6dc5b, 0x53b97e, 0x1322c4c0, 0x65dd7ff, 0x3a1e4f6,
-	0x14e614aa, 0x9246317, 0x1bc83aca, 0xad97eed, 0xd38ce4a, 0xf82b006, 0x341f077, 0xa6add89, 0x4894acd,
-	0x9f162d5, 0xf8410ef, 0x1b266a56, 0xd7f223, 0x3e0cb92, 0xe39b672, 0x6a2901a, 0x69a8556, 0x7e7c0,
-	0x9b7d8d3, 0x309a80, 0x1ad05f7f, 0xc2fb5dd, 0xcbfd41d, 0x9ceb638, 0x1051825c, 0xda0cf5b, 0x812e881,
-	0x6f35669, 0x6a56f2c, 0x1df8d184, 0x345820, 0x1477d477, 0x1645db1, 0xbe80c51, 0xc22be3e, 0xe35e65a,
-	0x1aeb7aa0, 0xc375315, 0xf67bc99, 0x7fdd7b9, 0x191fc1be, 0x61235d, 0x2c184e9, 0x1c5a839, 0x47a1e26,
-	0xb7cb456, 0x93e225d, 0x14f3c6ed, 0xccc1ac9, 0x17fe37f3, 0x4988989, 0x1a90c502, 0x2f32042, 0xa17769b,
-	0xafd8c7c, 0x8191c6e, 0x1dcdb237, 0x16200c0, 0x107b32a1, 0x66c08db, 0x10d06a02, 0x3fc93, 0x5620023,
-	0x16722b27, 0x68b5c59, 0x270fcfc, 0xfad0ecc, 0xe5de1c2, 0xeab466b, 0x2fc513c, 0x407f75c, 0xbaab133,
-	0x9705fe9, 0xb88b8e7, 0x734c993, 0x1e1ff8f, 0x19156970, 0xabd0f00, 0x10469ea7, 0x3293ac0, 0xcdc98aa,
-	0x1d843fd, 0xe14bfe8, 0x15be825f, 0x8b5212, 0xeb3fb67, 0x81cbd29, 0xbc62f16, 0x2b6fcc7, 0xf5a4e29,
-	0x13560b66, 0xc0b6ac2, 0x51ae690, 0xd41e271, 0xf3e9bd4, 0x1d70aab, 0x1029f72, 0x73e1c35, 0xee70fbc,
-	0xad81baf, 0x9ecc49a, 0x86c741e, 0xfe6be30, 0x176752e7, 0x23d416, 0x1f83de85, 0x27de188, 0x66f70b8,
-	0x181cd51f, 0x96b6e4c, 0x188f2335, 0xa5df759, 0x17a77eb6, 0xfeb0e73, 0x154ae914, 0x2f3ec51, 0x3826b59,
-	0xb91f17d, 0x1c72949, 0x1362bf0a, 0xe23fddf, 0xa5614b0, 0xf7d8f, 0x79061, 0x823d9d2, 0x8213f39,
-	0x1128ae0b, 0xd095d05, 0xb85c0c2, 0x1ecb2ef, 0x24ddc84, 0xe35e901, 0x18411a4a, 0xf5ddc3d, 0x3786689,
-	0x52260e8, 0x5ae3564, 0x542b10d, 0x8d93a45, 0x19952aa4, 0x996cc41, 0x1051a729, 0x4be3499, 0x52b23aa,
-	0x109f307e, 0x6f5b6bb, 0x1f84e1e7, 0x77a0cfa, 0x10c4df3f, 0x25a02ea, 0xb048035, 0xe31de66, 0xc6ecaa3,
-	0x28ea335, 0x2886024, 0x1372f020, 0xf55d35, 0x15e4684c, 0xf2a9e17, 0x1a4a7529, 0xcb7beb1, 0xb2a78a1,
-	0x1ab21f1f, 0x6361ccf, 0x6c9179d, 0xb135627, 0x1267b974, 0x4408bad, 0x1cbff658, 0xe3d6511, 0xc7d76f,
-	0x1cc7a69, 0xe7ee31b, 0x54fab4f, 0x2b914f, 0x1ad27a30, 0xcd3579e, 0xc50124c, 0x50daa90, 0xb13f72,
-	0xb06aa75, 0x70f5cc6, 0x1649e5aa, 0x84a5312, 0x329043c, 0x41c4011, 0x13d32411, 0xb04a838, 0xd760d2d,
-	0x1713b532, 0xbaa0c03, 0x84022ab, 0x6bcf5c1, 0x2f45379, 0x18ae070, 0x18c9e11e, 0x20bca9a, 0x66f496b,
-	0x3eef294, 0x67500d2, 0xd7f613c, 0x2dbbeb, 0xb741038, 0xe04133f, 0x1582968d, 0xbe985f7, 0x1acbc1a,
-	0x1a6a939f, 0x33e50f6, 0xd665ed4, 0xb4b7bd6, 0x1e5a3799, 0x6b33847, 0x17fa56ff, 0x65ef930, 0x21dc4a,
-	0x2b37659, 0x450fe17, 0xb357b65, 0xdf5efac, 0x15397bef, 0x9d35a7f, 0x112ac15f, 0x624e62e, 0xa90ae2f,
-	0x107eecd2, 0x1f69bbe, 0x77d6bce, 0x5741394, 0x13c684fc, 0x950c910, 0x725522b, 0xdc78583, 0x40eeabb,
-	0x1fde328a, 0xbd61d96, 0xd28c387, 0x9e77d89, 0x12550c40, 0x759cb7d, 0x367ef34, 0xae2a960, 0x91b8bdc,
-	0x93462a9, 0xf469ef, 0xb2e9aef, 0xd2ca771, 0x54e1f42, 0x7aaa49, 0x6316abb, 0x2413c8e, 0x5425bf9,
-	0x1bed3e3a, 0xf272274, 0x1f5e7326, 0x6416517, 0xea27072, 0x9cedea7, 0x6e7633, 0x7c91952, 0xd806dce,
-	0x8e2a7e1, 0xe421e1a, 0x418c9e1, 0x1dbc890, 0x1b395c36, 0xa1dc175, 0x1dc4ef73, 0x8956f34, 0xe4b5cf2,
-	0x1b0d3a18, 0x3194a36, 0x6c2641f, 0xe44124c, 0xa2f4eaa, 0xa8c25ba, 0xf927ed7, 0x627b614, 0x7371cca,
-	0xba16694, 0x417bc03, 0x7c0a7e3, 0x9c35c19, 0x1168a205, 0x8b6b00d, 0x10e3edc9, 0x9c19bf2, 0x5882229,
-	0x1b2b4162, 0xa5cef1a, 0x1543622b, 0x9bd433e, 0x364e04d, 0x7480792, 0x5c9b5b3, 0xe85ff25, 0x408ef57,
-	0x1814cfa4, 0x121b41b, 0xd248a0f, 0x3b05222, 0x39bb16a, 0xc75966d, 0xa038113, 0xa4a1769, 0x11fbc6c,
-	0x917e50e, 0xeec3da8, 0x169d6eac, 0x10c1699, 0xa416153, 0xf724912, 0x15cd60b7, 0x4acbad9, 0x5efc5fa,
-	0xf150ed7, 0x122b51, 0x1104b40a, 0xcb7f442, 0xfbb28ff, 0x6ac53ca, 0x196142cc, 0x7bf0fa9, 0x957651,
-	0x4e0f215, 0xed439f8, 0x3f46bd5, 0x5ace82f, 0x110916b6, 0x6db078, 0xffd7d57, 0xf2ecaac, 0xca86dec,
-	0x15d6b2da, 0x965ecc9, 0x1c92b4c2, 0x1f3811, 0x1cb080f5, 0x2d8b804, 0x19d1c12d, 0xf20bd46, 0x1951fa7,
-	0xa3656c3, 0x523a425, 0xfcd0692, 0xd44ddc8, 0x131f0f5b, 0xaf80e4a, 0xcd9fc74, 0x99bb618, 0x2db944c,
-	0xa673090, 0x1c210e1, 0x178c8d23, 0x1474383, 0x10b8743d, 0x985a55b, 0x2e74779, 0x576138, 0x9587927,
-	0x133130fa, 0xbe05516, 0x9f4d619, 0xbb62570, 0x99ec591, 0xd9468fe, 0x1d07782d, 0xfc72e0b, 0x701b298,
-	0x1863863b, 0x85954b8, 0x121a0c36, 0x9e7fedf, 0xf64b429, 0x9b9d71e, 0x14e2f5d8, 0xf858d3a, 0x942eea8,
-	0xda5b765, 0x6edafff, 0xa9d18cc, 0xc65e4ba, 0x1c747e86, 0xe4ea915, 0x1981d7a1, 0x8395659, 0x52ed4e2,
-	0x87d43b7, 0x37ab11b, 0x19d292ce, 0xf8d4692, 0x18c3053f, 0x8863e13, 0x4c146c0, 0x6bdf55a, 0x4e4457d,
-	0x16152289, 0xac78ec2, 0x1a59c5a2, 0x2028b97, 0x71c2d01, 0x295851f, 0x404747b, 0x878558d, 0x7d29aa4,
-	0x13d8341f, 0x8daefd7, 0x139c972d, 0x6b7ea75, 0xd4a9dde, 0xff163d8, 0x81d55d7, 0xa5bef68, 0xb7b30d8,
-	0xbe73d6f, 0xaa88141, 0xd976c81, 0x7e7a9cc, 0x18beb771, 0xd773cbd, 0x13f51951, 0x9d0c177, 0x1c49a78,
-}
-
-// Group operations:
-//
-// Elements of the elliptic curve group are represented in Jacobian
-// coordinates: (x, y, z). An affine point (x', y') is x'=x/z**2, y'=y/z**3 in
-// Jacobian form.
-
-// p256PointDouble sets {xOut,yOut,zOut} = 2*{x,y,z}.
-//
-// See https://www.hyperelliptic.org/EFD/g1p/auto-shortw-jacobian-0.html#doubling-dbl-2009-l
-func p256PointDouble(xOut, yOut, zOut, x, y, z *[p256Limbs]uint32) {
-	var delta, gamma, alpha, beta, tmp, tmp2 [p256Limbs]uint32
-
-	p256Square(&delta, z)
-	p256Square(&gamma, y)
-	p256Mul(&beta, x, &gamma)
-
-	p256Sum(&tmp, x, &delta)
-	p256Diff(&tmp2, x, &delta)
-	p256Mul(&alpha, &tmp, &tmp2)
-	p256Scalar3(&alpha)
-
-	p256Sum(&tmp, y, z)
-	p256Square(&tmp, &tmp)
-	p256Diff(&tmp, &tmp, &gamma)
-	p256Diff(zOut, &tmp, &delta)
-
-	p256Scalar4(&beta)
-	p256Square(xOut, &alpha)
-	p256Diff(xOut, xOut, &beta)
-	p256Diff(xOut, xOut, &beta)
-
-	p256Diff(&tmp, &beta, xOut)
-	p256Mul(&tmp, &alpha, &tmp)
-	p256Square(&tmp2, &gamma)
-	p256Scalar8(&tmp2)
-	p256Diff(yOut, &tmp, &tmp2)
-}
-
-// p256PointAddMixed sets {xOut,yOut,zOut} = {x1,y1,z1} + {x2,y2,1}.
-// (i.e. the second point is affine.)
-//
-// See https://www.hyperelliptic.org/EFD/g1p/auto-shortw-jacobian-0.html#addition-add-2007-bl
-//
-// Note that this function does not handle P+P, infinity+P nor P+infinity
-// correctly.
-func p256PointAddMixed(xOut, yOut, zOut, x1, y1, z1, x2, y2 *[p256Limbs]uint32) {
-	var z1z1, z1z1z1, s2, u2, h, i, j, r, rr, v, tmp [p256Limbs]uint32
-
-	p256Square(&z1z1, z1)
-	p256Sum(&tmp, z1, z1)
-
-	p256Mul(&u2, x2, &z1z1)
-	p256Mul(&z1z1z1, z1, &z1z1)
-	p256Mul(&s2, y2, &z1z1z1)
-	p256Diff(&h, &u2, x1)
-	p256Sum(&i, &h, &h)
-	p256Square(&i, &i)
-	p256Mul(&j, &h, &i)
-	p256Diff(&r, &s2, y1)
-	p256Sum(&r, &r, &r)
-	p256Mul(&v, x1, &i)
-
-	p256Mul(zOut, &tmp, &h)
-	p256Square(&rr, &r)
-	p256Diff(xOut, &rr, &j)
-	p256Diff(xOut, xOut, &v)
-	p256Diff(xOut, xOut, &v)
-
-	p256Diff(&tmp, &v, xOut)
-	p256Mul(yOut, &tmp, &r)
-	p256Mul(&tmp, y1, &j)
-	p256Diff(yOut, yOut, &tmp)
-	p256Diff(yOut, yOut, &tmp)
-}
-
-// p256PointAdd sets {xOut,yOut,zOut} = {x1,y1,z1} + {x2,y2,z2}.
-//
-// See https://www.hyperelliptic.org/EFD/g1p/auto-shortw-jacobian-0.html#addition-add-2007-bl
-//
-// Note that this function does not handle P+P, infinity+P nor P+infinity
-// correctly.
-func p256PointAdd(xOut, yOut, zOut, x1, y1, z1, x2, y2, z2 *[p256Limbs]uint32) {
-	var z1z1, z1z1z1, z2z2, z2z2z2, s1, s2, u1, u2, h, i, j, r, rr, v, tmp [p256Limbs]uint32
-
-	p256Square(&z1z1, z1)
-	p256Square(&z2z2, z2)
-	p256Mul(&u1, x1, &z2z2)
-
-	p256Sum(&tmp, z1, z2)
-	p256Square(&tmp, &tmp)
-	p256Diff(&tmp, &tmp, &z1z1)
-	p256Diff(&tmp, &tmp, &z2z2)
-
-	p256Mul(&z2z2z2, z2, &z2z2)
-	p256Mul(&s1, y1, &z2z2z2)
-
-	p256Mul(&u2, x2, &z1z1)
-	p256Mul(&z1z1z1, z1, &z1z1)
-	p256Mul(&s2, y2, &z1z1z1)
-	p256Diff(&h, &u2, &u1)
-	p256Sum(&i, &h, &h)
-	p256Square(&i, &i)
-	p256Mul(&j, &h, &i)
-	p256Diff(&r, &s2, &s1)
-	p256Sum(&r, &r, &r)
-	p256Mul(&v, &u1, &i)
-
-	p256Mul(zOut, &tmp, &h)
-	p256Square(&rr, &r)
-	p256Diff(xOut, &rr, &j)
-	p256Diff(xOut, xOut, &v)
-	p256Diff(xOut, xOut, &v)
-
-	p256Diff(&tmp, &v, xOut)
-	p256Mul(yOut, &tmp, &r)
-	p256Mul(&tmp, &s1, &j)
-	p256Diff(yOut, yOut, &tmp)
-	p256Diff(yOut, yOut, &tmp)
-}
-
-// p256SelectAffinePoint sets {out_x,out_y} to the index'th entry of table.
-//
-// On entry: index < 16, table[0] must be zero.
-func p256SelectAffinePoint(xOut, yOut *[p256Limbs]uint32, table []uint32, index uint32) {
-	for i := range xOut {
-		xOut[i] = 0
-	}
-	for i := range yOut {
-		yOut[i] = 0
-	}
-
-	for i := uint32(1); i < 16; i++ {
-		mask := i ^ index
-		mask |= mask >> 2
-		mask |= mask >> 1
-		mask &= 1
-		mask--
-		for j := range xOut {
-			xOut[j] |= table[0] & mask
-			table = table[1:]
-		}
-		for j := range yOut {
-			yOut[j] |= table[0] & mask
-			table = table[1:]
-		}
-	}
-}
-
-// p256SelectJacobianPoint sets {out_x,out_y,out_z} to the index'th entry of
-// table.
-//
-// On entry: index < 16, table[0] must be zero.
-func p256SelectJacobianPoint(xOut, yOut, zOut *[p256Limbs]uint32, table *[16][3][p256Limbs]uint32, index uint32) {
-	for i := range xOut {
-		xOut[i] = 0
-	}
-	for i := range yOut {
-		yOut[i] = 0
-	}
-	for i := range zOut {
-		zOut[i] = 0
-	}
-
-	// The implicit value at index 0 is all zero. We don't need to perform that
-	// iteration of the loop because we already set out_* to zero.
-	for i := uint32(1); i < 16; i++ {
-		mask := i ^ index
-		mask |= mask >> 2
-		mask |= mask >> 1
-		mask &= 1
-		mask--
-		for j := range xOut {
-			xOut[j] |= table[i][0][j] & mask
-		}
-		for j := range yOut {
-			yOut[j] |= table[i][1][j] & mask
-		}
-		for j := range zOut {
-			zOut[j] |= table[i][2][j] & mask
-		}
-	}
-}
-
-// p256GetBit returns the bit'th bit of scalar.
-func p256GetBit(scalar *[32]uint8, bit uint) uint32 {
-	return uint32(((scalar[bit>>3]) >> (bit & 7)) & 1)
-}
-
-// p256ScalarBaseMult sets {xOut,yOut,zOut} = scalar*G where scalar is a
-// little-endian number. Note that the value of scalar must be less than the
-// order of the group.
-func p256ScalarBaseMult(xOut, yOut, zOut *[p256Limbs]uint32, scalar *[32]uint8) {
-	nIsInfinityMask := ^uint32(0)
-	var pIsNoninfiniteMask, mask, tableOffset uint32
-	var px, py, tx, ty, tz [p256Limbs]uint32
-
-	for i := range xOut {
-		xOut[i] = 0
-	}
-	for i := range yOut {
-		yOut[i] = 0
-	}
-	for i := range zOut {
-		zOut[i] = 0
-	}
-
-	// The loop adds bits at positions 0, 64, 128 and 192, followed by
-	// positions 32,96,160 and 224 and does this 32 times.
-	for i := uint(0); i < 32; i++ {
-		if i != 0 {
-			p256PointDouble(xOut, yOut, zOut, xOut, yOut, zOut)
-		}
-		tableOffset = 0
-		for j := uint(0); j <= 32; j += 32 {
-			bit0 := p256GetBit(scalar, 31-i+j)
-			bit1 := p256GetBit(scalar, 95-i+j)
-			bit2 := p256GetBit(scalar, 159-i+j)
-			bit3 := p256GetBit(scalar, 223-i+j)
-			index := bit0 | (bit1 << 1) | (bit2 << 2) | (bit3 << 3)
-
-			p256SelectAffinePoint(&px, &py, p256Precomputed[tableOffset:], index)
-			tableOffset += 30 * p256Limbs
-
-			// Since scalar is less than the order of the group, we know that
-			// {xOut,yOut,zOut} != {px,py,1}, unless both are zero, which we handle
-			// below.
-			p256PointAddMixed(&tx, &ty, &tz, xOut, yOut, zOut, &px, &py)
-			// The result of pointAddMixed is incorrect if {xOut,yOut,zOut} is zero
-			// (a.k.a.  the point at infinity). We handle that situation by
-			// copying the point from the table.
-			p256CopyConditional(xOut, &px, nIsInfinityMask)
-			p256CopyConditional(yOut, &py, nIsInfinityMask)
-			p256CopyConditional(zOut, &p256One, nIsInfinityMask)
-
-			// Equally, the result is also wrong if the point from the table is
-			// zero, which happens when the index is zero. We handle that by
-			// only copying from {tx,ty,tz} to {xOut,yOut,zOut} if index != 0.
-			pIsNoninfiniteMask = nonZeroToAllOnes(index)
-			mask = pIsNoninfiniteMask & ^nIsInfinityMask
-			p256CopyConditional(xOut, &tx, mask)
-			p256CopyConditional(yOut, &ty, mask)
-			p256CopyConditional(zOut, &tz, mask)
-			// If p was not zero, then n is now non-zero.
-			nIsInfinityMask &^= pIsNoninfiniteMask
-		}
-	}
-}
-
-// p256PointToAffine converts a Jacobian point to an affine point. If the input
-// is the point at infinity then it returns (0, 0) in constant time.
-func p256PointToAffine(xOut, yOut, x, y, z *[p256Limbs]uint32) {
-	var zInv, zInvSq [p256Limbs]uint32
-
-	p256Invert(&zInv, z)
-	p256Square(&zInvSq, &zInv)
-	p256Mul(xOut, x, &zInvSq)
-	p256Mul(&zInv, &zInv, &zInvSq)
-	p256Mul(yOut, y, &zInv)
-}
-
-// p256ToAffine returns a pair of *big.Int containing the affine representation
-// of {x,y,z}.
-func p256ToAffine(x, y, z *[p256Limbs]uint32) (xOut, yOut *big.Int) {
-	var xx, yy [p256Limbs]uint32
-	p256PointToAffine(&xx, &yy, x, y, z)
-	return p256ToBig(&xx), p256ToBig(&yy)
-}
-
-// p256ScalarMult sets {xOut,yOut,zOut} = scalar*{x,y}.
-func p256ScalarMult(xOut, yOut, zOut, x, y *[p256Limbs]uint32, scalar *[32]uint8) {
-	var px, py, pz, tx, ty, tz [p256Limbs]uint32
-	var precomp [16][3][p256Limbs]uint32
-	var nIsInfinityMask, index, pIsNoninfiniteMask, mask uint32
-
-	// We precompute 0,1,2,... times {x,y}.
-	precomp[1][0] = *x
-	precomp[1][1] = *y
-	precomp[1][2] = p256One
-
-	for i := 2; i < 16; i += 2 {
-		p256PointDouble(&precomp[i][0], &precomp[i][1], &precomp[i][2], &precomp[i/2][0], &precomp[i/2][1], &precomp[i/2][2])
-		p256PointAddMixed(&precomp[i+1][0], &precomp[i+1][1], &precomp[i+1][2], &precomp[i][0], &precomp[i][1], &precomp[i][2], x, y)
-	}
-
-	for i := range xOut {
-		xOut[i] = 0
-	}
-	for i := range yOut {
-		yOut[i] = 0
-	}
-	for i := range zOut {
-		zOut[i] = 0
-	}
-	nIsInfinityMask = ^uint32(0)
-
-	// We add in a window of four bits each iteration and do this 64 times.
-	for i := 0; i < 64; i++ {
-		if i != 0 {
-			p256PointDouble(xOut, yOut, zOut, xOut, yOut, zOut)
-			p256PointDouble(xOut, yOut, zOut, xOut, yOut, zOut)
-			p256PointDouble(xOut, yOut, zOut, xOut, yOut, zOut)
-			p256PointDouble(xOut, yOut, zOut, xOut, yOut, zOut)
-		}
-
-		index = uint32(scalar[31-i/2])
-		if (i & 1) == 1 {
-			index &= 15
-		} else {
-			index >>= 4
-		}
-
-		// See the comments in scalarBaseMult about handling infinities.
-		p256SelectJacobianPoint(&px, &py, &pz, &precomp, index)
-		p256PointAdd(&tx, &ty, &tz, xOut, yOut, zOut, &px, &py, &pz)
-		p256CopyConditional(xOut, &px, nIsInfinityMask)
-		p256CopyConditional(yOut, &py, nIsInfinityMask)
-		p256CopyConditional(zOut, &pz, nIsInfinityMask)
-
-		pIsNoninfiniteMask = nonZeroToAllOnes(index)
-		mask = pIsNoninfiniteMask & ^nIsInfinityMask
-		p256CopyConditional(xOut, &tx, mask)
-		p256CopyConditional(yOut, &ty, mask)
-		p256CopyConditional(zOut, &tz, mask)
-		nIsInfinityMask &^= pIsNoninfiniteMask
-	}
-}
diff --git a/src/crypto/elliptic/p256_generic_field.go b/src/crypto/elliptic/p256_generic_field.go
deleted file mode 100644
index 5824946ba4..0000000000
--- a/src/crypto/elliptic/p256_generic_field.go
+++ /dev/null
@@ -1,705 +0,0 @@
-// Copyright 2013 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build !amd64 && !arm64
-
-package elliptic
-
-import "math/big"
-
-// Field elements are represented as nine, unsigned 32-bit words.
-//
-// The value of a field element is:
-//   x[0] + (x[1] * 2**29) + (x[2] * 2**57) + ... + (x[8] * 2**228)
-//
-// That is, each limb is alternately 29 or 28-bits wide in little-endian
-// order.
-//
-// This means that a field element hits 2**257, rather than 2**256 as we would
-// like. A 28, 29, ... pattern would cause us to hit 2**256, but that causes
-// problems when multiplying as terms end up one bit short of a limb which
-// would require much bit-shifting to correct.
-//
-// Finally, the values stored in a field element are in Montgomery form. So the
-// value |y| is stored as (y*R) mod p, where p is the P-256 prime and R is
-// 2**257.
-
-const (
-	p256Limbs    = 9
-	bottom29Bits = 0x1fffffff
-)
-
-var (
-	// p256One is the number 1 as a field element.
-	p256One  = [p256Limbs]uint32{2, 0, 0, 0xffff800, 0x1fffffff, 0xfffffff, 0x1fbfffff, 0x1ffffff, 0}
-	p256Zero = [p256Limbs]uint32{0, 0, 0, 0, 0, 0, 0, 0, 0}
-	// p256P is the prime modulus as a field element.
-	p256P = [p256Limbs]uint32{0x1fffffff, 0xfffffff, 0x1fffffff, 0x3ff, 0, 0, 0x200000, 0xf000000, 0xfffffff}
-	// p2562P is the twice prime modulus as a field element.
-	p2562P = [p256Limbs]uint32{0x1ffffffe, 0xfffffff, 0x1fffffff, 0x7ff, 0, 0, 0x400000, 0xe000000, 0x1fffffff}
-)
-
-// Field element operations:
-
-const bottom28Bits = 0xfffffff
-
-// nonZeroToAllOnes returns:
-//
-//	0xffffffff for 0 < x <= 2**31
-//	0 for x == 0 or x > 2**31.
-func nonZeroToAllOnes(x uint32) uint32 {
-	return ((x - 1) >> 31) - 1
-}
-
-// p256ReduceCarry adds a multiple of p in order to cancel |carry|,
-// which is a term at 2**257.
-//
-// On entry: carry < 2**3, inout[0,2,...] < 2**29, inout[1,3,...] < 2**28.
-// On exit: inout[0,2,..] < 2**30, inout[1,3,...] < 2**29.
-func p256ReduceCarry(inout *[p256Limbs]uint32, carry uint32) {
-	carry_mask := nonZeroToAllOnes(carry)
-
-	inout[0] += carry << 1
-	inout[3] += 0x10000000 & carry_mask
-	// carry < 2**3 thus (carry << 11) < 2**14 and we added 2**28 in the
-	// previous line therefore this doesn't underflow.
-	inout[3] -= carry << 11
-	inout[4] += (0x20000000 - 1) & carry_mask
-	inout[5] += (0x10000000 - 1) & carry_mask
-	inout[6] += (0x20000000 - 1) & carry_mask
-	inout[6] -= carry << 22
-	// This may underflow if carry is non-zero but, if so, we'll fix it in the
-	// next line.
-	inout[7] -= 1 & carry_mask
-	inout[7] += carry << 25
-}
-
-// p256Sum sets out = in+in2.
-//
-// On entry: in[i]+in2[i] must not overflow a 32-bit word.
-// On exit: out[0,2,...] < 2**30, out[1,3,...] < 2**29.
-func p256Sum(out, in, in2 *[p256Limbs]uint32) {
-	carry := uint32(0)
-	for i := 0; ; i++ {
-		out[i] = in[i] + in2[i]
-		out[i] += carry
-		carry = out[i] >> 29
-		out[i] &= bottom29Bits
-
-		i++
-		if i == p256Limbs {
-			break
-		}
-
-		out[i] = in[i] + in2[i]
-		out[i] += carry
-		carry = out[i] >> 28
-		out[i] &= bottom28Bits
-	}
-
-	p256ReduceCarry(out, carry)
-}
-
-const (
-	two30m2    = 1<<30 - 1<<2
-	two30p13m2 = 1<<30 + 1<<13 - 1<<2
-	two31m2    = 1<<31 - 1<<2
-	two31m3    = 1<<31 - 1<<3
-	two31p24m2 = 1<<31 + 1<<24 - 1<<2
-	two30m27m2 = 1<<30 - 1<<27 - 1<<2
-)
-
-// p256Zero31 is 0 mod p.
-var p256Zero31 = [p256Limbs]uint32{two31m3, two30m2, two31m2, two30p13m2, two31m2, two30m2, two31p24m2, two30m27m2, two31m2}
-
-// p256Diff sets out = in-in2.
-//
-// On entry: in[0,2,...] < 2**30, in[1,3,...] < 2**29 and
-// in2[0,2,...] < 2**30, in2[1,3,...] < 2**29.
-// On exit: out[0,2,...] < 2**30, out[1,3,...] < 2**29.
-func p256Diff(out, in, in2 *[p256Limbs]uint32) {
-	var carry uint32
-
-	for i := 0; ; i++ {
-		out[i] = in[i] - in2[i]
-		out[i] += p256Zero31[i]
-		out[i] += carry
-		carry = out[i] >> 29
-		out[i] &= bottom29Bits
-
-		i++
-		if i == p256Limbs {
-			break
-		}
-
-		out[i] = in[i] - in2[i]
-		out[i] += p256Zero31[i]
-		out[i] += carry
-		carry = out[i] >> 28
-		out[i] &= bottom28Bits
-	}
-
-	p256ReduceCarry(out, carry)
-}
-
-// p256ReduceDegree sets out = tmp/R mod p where tmp contains 64-bit words with
-// the same 29,28,... bit positions as a field element.
-//
-// The values in field elements are in Montgomery form: x*R mod p where R =
-// 2**257. Since we just multiplied two Montgomery values together, the result
-// is x*y*R*R mod p. We wish to divide by R in order for the result also to be
-// in Montgomery form.
-//
-// On entry: tmp[i] < 2**64.
-// On exit: out[0,2,...] < 2**30, out[1,3,...] < 2**29.
-func p256ReduceDegree(out *[p256Limbs]uint32, tmp [17]uint64) {
-	// The following table may be helpful when reading this code:
-	//
-	// Limb number:   0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10...
-	// Width (bits):  29| 28| 29| 28| 29| 28| 29| 28| 29| 28| 29
-	// Start bit:     0 | 29| 57| 86|114|143|171|200|228|257|285
-	//   (odd phase): 0 | 28| 57| 85|114|142|171|199|228|256|285
-	var tmp2 [18]uint32
-	var carry, x, xMask uint32
-
-	// tmp contains 64-bit words with the same 29,28,29-bit positions as a
-	// field element. So the top of an element of tmp might overlap with
-	// another element two positions down. The following loop eliminates
-	// this overlap.
-	tmp2[0] = uint32(tmp[0]) & bottom29Bits
-
-	tmp2[1] = uint32(tmp[0]) >> 29
-	tmp2[1] |= (uint32(tmp[0]>>32) << 3) & bottom28Bits
-	tmp2[1] += uint32(tmp[1]) & bottom28Bits
-	carry = tmp2[1] >> 28
-	tmp2[1] &= bottom28Bits
-
-	for i := 2; i < 17; i++ {
-		tmp2[i] = (uint32(tmp[i-2] >> 32)) >> 25
-		tmp2[i] += (uint32(tmp[i-1])) >> 28
-		tmp2[i] += (uint32(tmp[i-1]>>32) << 4) & bottom29Bits
-		tmp2[i] += uint32(tmp[i]) & bottom29Bits
-		tmp2[i] += carry
-		carry = tmp2[i] >> 29
-		tmp2[i] &= bottom29Bits
-
-		i++
-		if i == 17 {
-			break
-		}
-		tmp2[i] = uint32(tmp[i-2]>>32) >> 25
-		tmp2[i] += uint32(tmp[i-1]) >> 29
-		tmp2[i] += ((uint32(tmp[i-1] >> 32)) << 3) & bottom28Bits
-		tmp2[i] += uint32(tmp[i]) & bottom28Bits
-		tmp2[i] += carry
-		carry = tmp2[i] >> 28
-		tmp2[i] &= bottom28Bits
-	}
-
-	tmp2[17] = uint32(tmp[15]>>32) >> 25
-	tmp2[17] += uint32(tmp[16]) >> 29
-	tmp2[17] += uint32(tmp[16]>>32) << 3
-	tmp2[17] += carry
-
-	// Montgomery elimination of terms:
-	//
-	// Since R is 2**257, we can divide by R with a bitwise shift if we can
-	// ensure that the right-most 257 bits are all zero. We can make that true
-	// by adding multiplies of p without affecting the value.
-	//
-	// So we eliminate limbs from right to left. Since the bottom 29 bits of p
-	// are all ones, then by adding tmp2[0]*p to tmp2 we'll make tmp2[0] == 0.
-	// We can do that for 8 further limbs and then right shift to eliminate the
-	// extra factor of R.
-	for i := 0; ; i += 2 {
-		tmp2[i+1] += tmp2[i] >> 29
-		x = tmp2[i] & bottom29Bits
-		xMask = nonZeroToAllOnes(x)
-		tmp2[i] = 0
-
-		// The bounds calculations for this loop are tricky. Each iteration of
-		// the loop eliminates two words by adding values to words to their
-		// right.
-		//
-		// The following table contains the amounts added to each word (as an
-		// offset from the value of i at the top of the loop). The amounts are
-		// accounted for from the first and second half of the loop separately
-		// and are written as, for example, 28 to mean a value <2**28.
-		//
-		// Word:                   3   4   5   6   7   8   9   10
-		// Added in top half:     28  11      29  21  29  28
-		//                                        28  29
-		//                                            29
-		// Added in bottom half:      29  10      28  21  28   28
-		//                                            29
-		//
-		// The value that is currently offset 7 will be offset 5 for the next
-		// iteration and then offset 3 for the iteration after that. Therefore
-		// the total value added will be the values added at 7, 5 and 3.
-		//
-		// The following table accumulates these values. The sums at the bottom
-		// are written as, for example, 29+28, to mean a value < 2**29+2**28.
-		//
-		// Word:                   3   4   5   6   7   8   9  10  11  12  13
-		//                        28  11  10  29  21  29  28  28  28  28  28
-		//                            29  28  11  28  29  28  29  28  29  28
-		//                                    29  28  21  21  29  21  29  21
-		//                                        10  29  28  21  28  21  28
-		//                                        28  29  28  29  28  29  28
-		//                                            11  10  29  10  29  10
-		//                                            29  28  11  28  11
-		//                                                    29      29
-		//                        --------------------------------------------
-		//                                                30+ 31+ 30+ 31+ 30+
-		//                                                28+ 29+ 28+ 29+ 21+
-		//                                                21+ 28+ 21+ 28+ 10
-		//                                                10  21+ 10  21+
-		//                                                    11      11
-		//
-		// So the greatest amount is added to tmp2[10] and tmp2[12]. If
-		// tmp2[10/12] has an initial value of <2**29, then the maximum value
-		// will be < 2**31 + 2**30 + 2**28 + 2**21 + 2**11, which is < 2**32,
-		// as required.
-		tmp2[i+3] += (x << 10) & bottom28Bits
-		tmp2[i+4] += (x >> 18)
-
-		tmp2[i+6] += (x << 21) & bottom29Bits
-		tmp2[i+7] += x >> 8
-
-		// At position 200, which is the starting bit position for word 7, we
-		// have a factor of 0xf000000 = 2**28 - 2**24.
-		tmp2[i+7] += 0x10000000 & xMask
-		tmp2[i+8] += (x - 1) & xMask
-		tmp2[i+7] -= (x << 24) & bottom28Bits
-		tmp2[i+8] -= x >> 4
-
-		tmp2[i+8] += 0x20000000 & xMask
-		tmp2[i+8] -= x
-		tmp2[i+8] += (x << 28) & bottom29Bits
-		tmp2[i+9] += ((x >> 1) - 1) & xMask
-
-		if i+1 == p256Limbs {
-			break
-		}
-		tmp2[i+2] += tmp2[i+1] >> 28
-		x = tmp2[i+1] & bottom28Bits
-		xMask = nonZeroToAllOnes(x)
-		tmp2[i+1] = 0
-
-		tmp2[i+4] += (x << 11) & bottom29Bits
-		tmp2[i+5] += (x >> 18)
-
-		tmp2[i+7] += (x << 21) & bottom28Bits
-		tmp2[i+8] += x >> 7
-
-		// At position 199, which is the starting bit of the 8th word when
-		// dealing with a context starting on an odd word, we have a factor of
-		// 0x1e000000 = 2**29 - 2**25. Since we have not updated i, the 8th
-		// word from i+1 is i+8.
-		tmp2[i+8] += 0x20000000 & xMask
-		tmp2[i+9] += (x - 1) & xMask
-		tmp2[i+8] -= (x << 25) & bottom29Bits
-		tmp2[i+9] -= x >> 4
-
-		tmp2[i+9] += 0x10000000 & xMask
-		tmp2[i+9] -= x
-		tmp2[i+10] += (x - 1) & xMask
-	}
-
-	// We merge the right shift with a carry chain. The words above 2**257 have
-	// widths of 28,29,... which we need to correct when copying them down.
-	carry = 0
-	for i := 0; i < 8; i++ {
-		// The maximum value of tmp2[i + 9] occurs on the first iteration and
-		// is < 2**30+2**29+2**28. Adding 2**29 (from tmp2[i + 10]) is
-		// therefore safe.
-		out[i] = tmp2[i+9]
-		out[i] += carry
-		out[i] += (tmp2[i+10] << 28) & bottom29Bits
-		carry = out[i] >> 29
-		out[i] &= bottom29Bits
-
-		i++
-		out[i] = tmp2[i+9] >> 1
-		out[i] += carry
-		carry = out[i] >> 28
-		out[i] &= bottom28Bits
-	}
-
-	out[8] = tmp2[17]
-	out[8] += carry
-	carry = out[8] >> 29
-	out[8] &= bottom29Bits
-
-	p256ReduceCarry(out, carry)
-}
-
-// p256Square sets out=in*in.
-//
-// On entry: in[0,2,...] < 2**30, in[1,3,...] < 2**29.
-// On exit: out[0,2,...] < 2**30, out[1,3,...] < 2**29.
-func p256Square(out, in *[p256Limbs]uint32) {
-	var tmp [17]uint64
-
-	tmp[0] = uint64(in[0]) * uint64(in[0])
-	tmp[1] = uint64(in[0]) * (uint64(in[1]) << 1)
-	tmp[2] = uint64(in[0])*(uint64(in[2])<<1) +
-		uint64(in[1])*(uint64(in[1])<<1)
-	tmp[3] = uint64(in[0])*(uint64(in[3])<<1) +
-		uint64(in[1])*(uint64(in[2])<<1)
-	tmp[4] = uint64(in[0])*(uint64(in[4])<<1) +
-		uint64(in[1])*(uint64(in[3])<<2) +
-		uint64(in[2])*uint64(in[2])
-	tmp[5] = uint64(in[0])*(uint64(in[5])<<1) +
-		uint64(in[1])*(uint64(in[4])<<1) +
-		uint64(in[2])*(uint64(in[3])<<1)
-	tmp[6] = uint64(in[0])*(uint64(in[6])<<1) +
-		uint64(in[1])*(uint64(in[5])<<2) +
-		uint64(in[2])*(uint64(in[4])<<1) +
-		uint64(in[3])*(uint64(in[3])<<1)
-	tmp[7] = uint64(in[0])*(uint64(in[7])<<1) +
-		uint64(in[1])*(uint64(in[6])<<1) +
-		uint64(in[2])*(uint64(in[5])<<1) +
-		uint64(in[3])*(uint64(in[4])<<1)
-	// tmp[8] has the greatest value of 2**61 + 2**60 + 2**61 + 2**60 + 2**60,
-	// which is < 2**64 as required.
-	tmp[8] = uint64(in[0])*(uint64(in[8])<<1) +
-		uint64(in[1])*(uint64(in[7])<<2) +
-		uint64(in[2])*(uint64(in[6])<<1) +
-		uint64(in[3])*(uint64(in[5])<<2) +
-		uint64(in[4])*uint64(in[4])
-	tmp[9] = uint64(in[1])*(uint64(in[8])<<1) +
-		uint64(in[2])*(uint64(in[7])<<1) +
-		uint64(in[3])*(uint64(in[6])<<1) +
-		uint64(in[4])*(uint64(in[5])<<1)
-	tmp[10] = uint64(in[2])*(uint64(in[8])<<1) +
-		uint64(in[3])*(uint64(in[7])<<2) +
-		uint64(in[4])*(uint64(in[6])<<1) +
-		uint64(in[5])*(uint64(in[5])<<1)
-	tmp[11] = uint64(in[3])*(uint64(in[8])<<1) +
-		uint64(in[4])*(uint64(in[7])<<1) +
-		uint64(in[5])*(uint64(in[6])<<1)
-	tmp[12] = uint64(in[4])*(uint64(in[8])<<1) +
-		uint64(in[5])*(uint64(in[7])<<2) +
-		uint64(in[6])*uint64(in[6])
-	tmp[13] = uint64(in[5])*(uint64(in[8])<<1) +
-		uint64(in[6])*(uint64(in[7])<<1)
-	tmp[14] = uint64(in[6])*(uint64(in[8])<<1) +
-		uint64(in[7])*(uint64(in[7])<<1)
-	tmp[15] = uint64(in[7]) * (uint64(in[8]) << 1)
-	tmp[16] = uint64(in[8]) * uint64(in[8])
-
-	p256ReduceDegree(out, tmp)
-}
-
-// p256Mul sets out=in*in2.
-//
-// On entry: in[0,2,...] < 2**30, in[1,3,...] < 2**29 and
-// in2[0,2,...] < 2**30, in2[1,3,...] < 2**29.
-// On exit: out[0,2,...] < 2**30, out[1,3,...] < 2**29.
-func p256Mul(out, in, in2 *[p256Limbs]uint32) {
-	var tmp [17]uint64
-
-	tmp[0] = uint64(in[0]) * uint64(in2[0])
-	tmp[1] = uint64(in[0])*(uint64(in2[1])<<0) +
-		uint64(in[1])*(uint64(in2[0])<<0)
-	tmp[2] = uint64(in[0])*(uint64(in2[2])<<0) +
-		uint64(in[1])*(uint64(in2[1])<<1) +
-		uint64(in[2])*(uint64(in2[0])<<0)
-	tmp[3] = uint64(in[0])*(uint64(in2[3])<<0) +
-		uint64(in[1])*(uint64(in2[2])<<0) +
-		uint64(in[2])*(uint64(in2[1])<<0) +
-		uint64(in[3])*(uint64(in2[0])<<0)
-	tmp[4] = uint64(in[0])*(uint64(in2[4])<<0) +
-		uint64(in[1])*(uint64(in2[3])<<1) +
-		uint64(in[2])*(uint64(in2[2])<<0) +
-		uint64(in[3])*(uint64(in2[1])<<1) +
-		uint64(in[4])*(uint64(in2[0])<<0)
-	tmp[5] = uint64(in[0])*(uint64(in2[5])<<0) +
-		uint64(in[1])*(uint64(in2[4])<<0) +
-		uint64(in[2])*(uint64(in2[3])<<0) +
-		uint64(in[3])*(uint64(in2[2])<<0) +
-		uint64(in[4])*(uint64(in2[1])<<0) +
-		uint64(in[5])*(uint64(in2[0])<<0)
-	tmp[6] = uint64(in[0])*(uint64(in2[6])<<0) +
-		uint64(in[1])*(uint64(in2[5])<<1) +
-		uint64(in[2])*(uint64(in2[4])<<0) +
-		uint64(in[3])*(uint64(in2[3])<<1) +
-		uint64(in[4])*(uint64(in2[2])<<0) +
-		uint64(in[5])*(uint64(in2[1])<<1) +
-		uint64(in[6])*(uint64(in2[0])<<0)
-	tmp[7] = uint64(in[0])*(uint64(in2[7])<<0) +
-		uint64(in[1])*(uint64(in2[6])<<0) +
-		uint64(in[2])*(uint64(in2[5])<<0) +
-		uint64(in[3])*(uint64(in2[4])<<0) +
-		uint64(in[4])*(uint64(in2[3])<<0) +
-		uint64(in[5])*(uint64(in2[2])<<0) +
-		uint64(in[6])*(uint64(in2[1])<<0) +
-		uint64(in[7])*(uint64(in2[0])<<0)
-	// tmp[8] has the greatest value but doesn't overflow. See logic in
-	// p256Square.
-	tmp[8] = uint64(in[0])*(uint64(in2[8])<<0) +
-		uint64(in[1])*(uint64(in2[7])<<1) +
-		uint64(in[2])*(uint64(in2[6])<<0) +
-		uint64(in[3])*(uint64(in2[5])<<1) +
-		uint64(in[4])*(uint64(in2[4])<<0) +
-		uint64(in[5])*(uint64(in2[3])<<1) +
-		uint64(in[6])*(uint64(in2[2])<<0) +
-		uint64(in[7])*(uint64(in2[1])<<1) +
-		uint64(in[8])*(uint64(in2[0])<<0)
-	tmp[9] = uint64(in[1])*(uint64(in2[8])<<0) +
-		uint64(in[2])*(uint64(in2[7])<<0) +
-		uint64(in[3])*(uint64(in2[6])<<0) +
-		uint64(in[4])*(uint64(in2[5])<<0) +
-		uint64(in[5])*(uint64(in2[4])<<0) +
-		uint64(in[6])*(uint64(in2[3])<<0) +
-		uint64(in[7])*(uint64(in2[2])<<0) +
-		uint64(in[8])*(uint64(in2[1])<<0)
-	tmp[10] = uint64(in[2])*(uint64(in2[8])<<0) +
-		uint64(in[3])*(uint64(in2[7])<<1) +
-		uint64(in[4])*(uint64(in2[6])<<0) +
-		uint64(in[5])*(uint64(in2[5])<<1) +
-		uint64(in[6])*(uint64(in2[4])<<0) +
-		uint64(in[7])*(uint64(in2[3])<<1) +
-		uint64(in[8])*(uint64(in2[2])<<0)
-	tmp[11] = uint64(in[3])*(uint64(in2[8])<<0) +
-		uint64(in[4])*(uint64(in2[7])<<0) +
-		uint64(in[5])*(uint64(in2[6])<<0) +
-		uint64(in[6])*(uint64(in2[5])<<0) +
-		uint64(in[7])*(uint64(in2[4])<<0) +
-		uint64(in[8])*(uint64(in2[3])<<0)
-	tmp[12] = uint64(in[4])*(uint64(in2[8])<<0) +
-		uint64(in[5])*(uint64(in2[7])<<1) +
-		uint64(in[6])*(uint64(in2[6])<<0) +
-		uint64(in[7])*(uint64(in2[5])<<1) +
-		uint64(in[8])*(uint64(in2[4])<<0)
-	tmp[13] = uint64(in[5])*(uint64(in2[8])<<0) +
-		uint64(in[6])*(uint64(in2[7])<<0) +
-		uint64(in[7])*(uint64(in2[6])<<0) +
-		uint64(in[8])*(uint64(in2[5])<<0)
-	tmp[14] = uint64(in[6])*(uint64(in2[8])<<0) +
-		uint64(in[7])*(uint64(in2[7])<<1) +
-		uint64(in[8])*(uint64(in2[6])<<0)
-	tmp[15] = uint64(in[7])*(uint64(in2[8])<<0) +
-		uint64(in[8])*(uint64(in2[7])<<0)
-	tmp[16] = uint64(in[8]) * (uint64(in2[8]) << 0)
-
-	p256ReduceDegree(out, tmp)
-}
-
-func p256Assign(out, in *[p256Limbs]uint32) {
-	*out = *in
-}
-
-// p256Invert calculates |out| = |in|^{-1}
-//
-// Based on Fermat's Little Theorem:
-//
-//	a^p = a (mod p)
-//	a^{p-1} = 1 (mod p)
-//	a^{p-2} = a^{-1} (mod p)
-func p256Invert(out, in *[p256Limbs]uint32) {
-	var ftmp, ftmp2 [p256Limbs]uint32
-
-	// each e_I will hold |in|^{2^I - 1}
-	var e2, e4, e8, e16, e32, e64 [p256Limbs]uint32
-
-	p256Square(&ftmp, in)     // 2^1
-	p256Mul(&ftmp, in, &ftmp) // 2^2 - 2^0
-	p256Assign(&e2, &ftmp)
-	p256Square(&ftmp, &ftmp)   // 2^3 - 2^1
-	p256Square(&ftmp, &ftmp)   // 2^4 - 2^2
-	p256Mul(&ftmp, &ftmp, &e2) // 2^4 - 2^0
-	p256Assign(&e4, &ftmp)
-	p256Square(&ftmp, &ftmp)   // 2^5 - 2^1
-	p256Square(&ftmp, &ftmp)   // 2^6 - 2^2
-	p256Square(&ftmp, &ftmp)   // 2^7 - 2^3
-	p256Square(&ftmp, &ftmp)   // 2^8 - 2^4
-	p256Mul(&ftmp, &ftmp, &e4) // 2^8 - 2^0
-	p256Assign(&e8, &ftmp)
-	for i := 0; i < 8; i++ {
-		p256Square(&ftmp, &ftmp)
-	} // 2^16 - 2^8
-	p256Mul(&ftmp, &ftmp, &e8) // 2^16 - 2^0
-	p256Assign(&e16, &ftmp)
-	for i := 0; i < 16; i++ {
-		p256Square(&ftmp, &ftmp)
-	} // 2^32 - 2^16
-	p256Mul(&ftmp, &ftmp, &e16) // 2^32 - 2^0
-	p256Assign(&e32, &ftmp)
-	for i := 0; i < 32; i++ {
-		p256Square(&ftmp, &ftmp)
-	} // 2^64 - 2^32
-	p256Assign(&e64, &ftmp)
-	p256Mul(&ftmp, &ftmp, in) // 2^64 - 2^32 + 2^0
-	for i := 0; i < 192; i++ {
-		p256Square(&ftmp, &ftmp)
-	} // 2^256 - 2^224 + 2^192
-
-	p256Mul(&ftmp2, &e64, &e32) // 2^64 - 2^0
-	for i := 0; i < 16; i++ {
-		p256Square(&ftmp2, &ftmp2)
-	} // 2^80 - 2^16
-	p256Mul(&ftmp2, &ftmp2, &e16) // 2^80 - 2^0
-	for i := 0; i < 8; i++ {
-		p256Square(&ftmp2, &ftmp2)
-	} // 2^88 - 2^8
-	p256Mul(&ftmp2, &ftmp2, &e8) // 2^88 - 2^0
-	for i := 0; i < 4; i++ {
-		p256Square(&ftmp2, &ftmp2)
-	} // 2^92 - 2^4
-	p256Mul(&ftmp2, &ftmp2, &e4) // 2^92 - 2^0
-	p256Square(&ftmp2, &ftmp2)   // 2^93 - 2^1
-	p256Square(&ftmp2, &ftmp2)   // 2^94 - 2^2
-	p256Mul(&ftmp2, &ftmp2, &e2) // 2^94 - 2^0
-	p256Square(&ftmp2, &ftmp2)   // 2^95 - 2^1
-	p256Square(&ftmp2, &ftmp2)   // 2^96 - 2^2
-	p256Mul(&ftmp2, &ftmp2, in)  // 2^96 - 3
-
-	p256Mul(out, &ftmp2, &ftmp) // 2^256 - 2^224 + 2^192 + 2^96 - 3
-}
-
-// p256Scalar3 sets out=3*out.
-//
-// On entry: out[0,2,...] < 2**30, out[1,3,...] < 2**29.
-// On exit: out[0,2,...] < 2**30, out[1,3,...] < 2**29.
-func p256Scalar3(out *[p256Limbs]uint32) {
-	var carry uint32
-
-	for i := 0; ; i++ {
-		out[i] *= 3
-		out[i] += carry
-		carry = out[i] >> 29
-		out[i] &= bottom29Bits
-
-		i++
-		if i == p256Limbs {
-			break
-		}
-
-		out[i] *= 3
-		out[i] += carry
-		carry = out[i] >> 28
-		out[i] &= bottom28Bits
-	}
-
-	p256ReduceCarry(out, carry)
-}
-
-// p256Scalar4 sets out=4*out.
-//
-// On entry: out[0,2,...] < 2**30, out[1,3,...] < 2**29.
-// On exit: out[0,2,...] < 2**30, out[1,3,...] < 2**29.
-func p256Scalar4(out *[p256Limbs]uint32) {
-	var carry, nextCarry uint32
-
-	for i := 0; ; i++ {
-		nextCarry = out[i] >> 27
-		out[i] <<= 2
-		out[i] &= bottom29Bits
-		out[i] += carry
-		carry = nextCarry + (out[i] >> 29)
-		out[i] &= bottom29Bits
-
-		i++
-		if i == p256Limbs {
-			break
-		}
-		nextCarry = out[i] >> 26
-		out[i] <<= 2
-		out[i] &= bottom28Bits
-		out[i] += carry
-		carry = nextCarry + (out[i] >> 28)
-		out[i] &= bottom28Bits
-	}
-
-	p256ReduceCarry(out, carry)
-}
-
-// p256Scalar8 sets out=8*out.
-//
-// On entry: out[0,2,...] < 2**30, out[1,3,...] < 2**29.
-// On exit: out[0,2,...] < 2**30, out[1,3,...] < 2**29.
-func p256Scalar8(out *[p256Limbs]uint32) {
-	var carry, nextCarry uint32
-
-	for i := 0; ; i++ {
-		nextCarry = out[i] >> 26
-		out[i] <<= 3
-		out[i] &= bottom29Bits
-		out[i] += carry
-		carry = nextCarry + (out[i] >> 29)
-		out[i] &= bottom29Bits
-
-		i++
-		if i == p256Limbs {
-			break
-		}
-		nextCarry = out[i] >> 25
-		out[i] <<= 3
-		out[i] &= bottom28Bits
-		out[i] += carry
-		carry = nextCarry + (out[i] >> 28)
-		out[i] &= bottom28Bits
-	}
-
-	p256ReduceCarry(out, carry)
-}
-
-// p256CopyConditional sets out=in if mask = 0xffffffff in constant time.
-//
-// On entry: mask is either 0 or 0xffffffff.
-func p256CopyConditional(out, in *[p256Limbs]uint32, mask uint32) {
-	for i := 0; i < p256Limbs; i++ {
-		tmp := mask & (in[i] ^ out[i])
-		out[i] ^= tmp
-	}
-}
-
-// p256FromBig sets out = R*in.
-func p256FromBig(out *[p256Limbs]uint32, in *big.Int) {
-	tmp := new(big.Int).Lsh(in, 257)
-	tmp.Mod(tmp, p256Params.P)
-
-	for i := 0; i < p256Limbs; i++ {
-		if bits := tmp.Bits(); len(bits) > 0 {
-			out[i] = uint32(bits[0]) & bottom29Bits
-		} else {
-			out[i] = 0
-		}
-		tmp.Rsh(tmp, 29)
-
-		i++
-		if i == p256Limbs {
-			break
-		}
-
-		if bits := tmp.Bits(); len(bits) > 0 {
-			out[i] = uint32(bits[0]) & bottom28Bits
-		} else {
-			out[i] = 0
-		}
-		tmp.Rsh(tmp, 28)
-	}
-}
-
-// p256ToBig returns a *big.Int containing the value of in.
-func p256ToBig(in *[p256Limbs]uint32) *big.Int {
-	result, tmp := new(big.Int), new(big.Int)
-
-	result.SetInt64(int64(in[p256Limbs-1]))
-	for i := p256Limbs - 2; i >= 0; i-- {
-		if (i & 1) == 0 {
-			result.Lsh(result, 29)
-		} else {
-			result.Lsh(result, 28)
-		}
-		tmp.SetInt64(int64(in[i]))
-		result.Add(result, tmp)
-	}
-
-	result.Mul(result, p256RInverse)
-	result.Mod(result, p256Params.P)
-	return result
-}
diff --git a/src/crypto/elliptic/p256_noasm.go b/src/crypto/elliptic/p256_noasm.go
deleted file mode 100644
index 380ea66ac3..0000000000
--- a/src/crypto/elliptic/p256_noasm.go
+++ /dev/null
@@ -1,15 +0,0 @@
-// Copyright 2016 The Go Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style
-// license that can be found in the LICENSE file.
-
-//go:build !amd64 && !s390x && !arm64 && !ppc64le
-// +build !amd64,!s390x,!arm64,!ppc64le
-
-package elliptic
-
-var p256 p256Curve
-
-func initP256Arch() {
-	// Use pure Go constant-time implementation.
-	p256 = p256Curve{p256Params}
-}
diff --git a/src/crypto/elliptic/p256_ppc64le.go b/src/crypto/elliptic/p256_ppc64le.go
index 3867a87e1f..12021d038c 100644
--- a/src/crypto/elliptic/p256_ppc64le.go
+++ b/src/crypto/elliptic/p256_ppc64le.go
@@ -27,14 +27,13 @@ type p256Point struct {
 	z [32]byte
 }
 
-var (
-	p256        Curve
-	p256PreFast *[37][64]p256Point
-)
+var p256PreFast *[37][64]p256Point
 
-func initP256Arch() {
-	p256 = p256CurveFast{p256Params}
-	initTable()
+func init() {
+	initP256Arch = func() {
+		p256 = p256CurveFast{&p256Params}
+		initTable()
+	}
 }
 
 func (curve p256CurveFast) Params() *CurveParams {
diff --git a/src/crypto/elliptic/p256_s390x.go b/src/crypto/elliptic/p256_s390x.go
index b7331ebbfd..a8b2b07005 100644
--- a/src/crypto/elliptic/p256_s390x.go
+++ b/src/crypto/elliptic/p256_s390x.go
@@ -28,10 +28,7 @@ type p256Point struct {
 	z [32]byte
 }
 
-var (
-	p256        Curve
-	p256PreFast *[37][64]p256Point
-)
+var p256PreFast *[37][64]p256Point
 
 //go:noescape
 func p256MulInternalTrampolineSetup()
@@ -51,15 +48,13 @@ func p256SqrInternalVX()
 //go:noescape
 func p256SqrInternalVMSL()
 
-func initP256Arch() {
+func init() {
 	if cpu.S390X.HasVX {
-		p256 = p256CurveFast{p256Params}
-		initTable()
-		return
+		initP256Arch = func() {
+			p256 = p256CurveFast{&p256Params}
+			initTable()
+		}
 	}
-
-	// No vector support, use pure Go implementation.
-	p256 = p256Curve{p256Params}
 }
 
 func (curve p256CurveFast) Params() *CurveParams {
