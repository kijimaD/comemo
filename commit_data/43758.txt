commit bf5b83a835eb7be62abd6921590fedad24328343
Author: Josh Bleecher Snyder <josharian@gmail.com>
Date:   Thu Apr 23 09:56:55 2020 -0700

    cmd/compile: convert splitload rules to typed aux
    
    Passes toolstash-check -all.
    
    Change-Id: Ia441582f7f67184eb831e184f9c3c0e3c11001bd
    Reviewed-on: https://go-review.googlesource.com/c/go/+/229698
    Run-TryBot: Josh Bleecher Snyder <josharian@gmail.com>
    Reviewed-by: Keith Randall <khr@golang.org>
---
 .../compile/internal/ssa/gen/386splitload.rules    |   6 +-
 .../compile/internal/ssa/gen/AMD64splitload.rules  |  27 ++-
 src/cmd/compile/internal/ssa/op.go                 |  26 +--
 .../compile/internal/ssa/rewrite386splitload.go    |  60 +++---
 .../compile/internal/ssa/rewriteAMD64splitload.go  | 220 ++++++++++-----------
 5 files changed, 169 insertions(+), 170 deletions(-)

diff --git a/src/cmd/compile/internal/ssa/gen/386splitload.rules b/src/cmd/compile/internal/ssa/gen/386splitload.rules
index 7d24700750..ed93b90b73 100644
--- a/src/cmd/compile/internal/ssa/gen/386splitload.rules
+++ b/src/cmd/compile/internal/ssa/gen/386splitload.rules
@@ -4,6 +4,8 @@
 
 // See the top of AMD64splitload.rules for discussion of these rules.
 
-(CMP(L|W|B)load {sym} [off] ptr x mem) -> (CMP(L|W|B) (MOV(L|W|B)load {sym} [off] ptr mem) x)
+(CMP(L|W|B)load {sym} [off] ptr x mem) => (CMP(L|W|B) (MOV(L|W|B)load {sym} [off] ptr mem) x)
 
-(CMP(L|W|B)constload {sym} [vo] ptr mem) -> (CMP(L|W|B)const (MOV(L|W|B)load {sym} [offOnly(vo)] ptr mem) [valOnly(vo)])
+(CMPLconstload {sym} [vo] ptr mem) => (CMPLconst (MOVLload {sym} [vo.Off32()] ptr mem) [vo.Val32()])
+(CMPWconstload {sym} [vo] ptr mem) => (CMPWconst (MOVWload {sym} [vo.Off32()] ptr mem) [vo.Val16()])
+(CMPBconstload {sym} [vo] ptr mem) => (CMPBconst (MOVBload {sym} [vo.Off32()] ptr mem) [vo.Val8()])
diff --git a/src/cmd/compile/internal/ssa/gen/AMD64splitload.rules b/src/cmd/compile/internal/ssa/gen/AMD64splitload.rules
index 381feb662e..02265620b4 100644
--- a/src/cmd/compile/internal/ssa/gen/AMD64splitload.rules
+++ b/src/cmd/compile/internal/ssa/gen/AMD64splitload.rules
@@ -16,16 +16,23 @@
 // For example:
 // (CMPBconstload c (ADDQ x y)) -> (CMPBconstloadidx1 c x y) -> (CMPB c (MOVBloadidx1 x y))
 
-(CMP(Q|L|W|B)load {sym} [off] ptr x mem) -> (CMP(Q|L|W|B) (MOV(Q|L|W|B)load {sym} [off] ptr mem) x)
+(CMP(Q|L|W|B)load {sym} [off] ptr x mem) => (CMP(Q|L|W|B) (MOV(Q|L|W|B)load {sym} [off] ptr mem) x)
 
-(CMP(Q|L|W|B)constload {sym} [vo] ptr mem) -> (CMP(Q|L|W|B)const (MOV(Q|L|W|B)load {sym} [offOnly(vo)] ptr mem) [valOnly(vo)])
+(CMPQconstload {sym} [vo] ptr mem) => (CMPQconst (MOVQload {sym} [vo.Off32()] ptr mem) [vo.Val32()])
+(CMPLconstload {sym} [vo] ptr mem) => (CMPLconst (MOVLload {sym} [vo.Off32()] ptr mem) [vo.Val32()])
+(CMPWconstload {sym} [vo] ptr mem) => (CMPWconst (MOVWload {sym} [vo.Off32()] ptr mem) [vo.Val16()])
+(CMPBconstload {sym} [vo] ptr mem) => (CMPBconst (MOVBload {sym} [vo.Off32()] ptr mem) [vo.Val8()])
 
-(CMP(Q|L|W|B)loadidx1 {sym} [off] ptr idx x mem) -> (CMP(Q|L|W|B) (MOV(Q|L|W|B)loadidx1 {sym} [off] ptr idx mem) x)
-(CMPQloadidx8 {sym} [off] ptr idx x mem) -> (CMPQ (MOVQloadidx8 {sym} [off] ptr idx mem) x)
-(CMPLloadidx4 {sym} [off] ptr idx x mem) -> (CMPL (MOVLloadidx4 {sym} [off] ptr idx mem) x)
-(CMPWloadidx2 {sym} [off] ptr idx x mem) -> (CMPW (MOVWloadidx2 {sym} [off] ptr idx mem) x)
+(CMP(Q|L|W|B)loadidx1 {sym} [off] ptr idx x mem) => (CMP(Q|L|W|B) (MOV(Q|L|W|B)loadidx1 {sym} [off] ptr idx mem) x)
+(CMPQloadidx8 {sym} [off] ptr idx x mem) => (CMPQ (MOVQloadidx8 {sym} [off] ptr idx mem) x)
+(CMPLloadidx4 {sym} [off] ptr idx x mem) => (CMPL (MOVLloadidx4 {sym} [off] ptr idx mem) x)
+(CMPWloadidx2 {sym} [off] ptr idx x mem) => (CMPW (MOVWloadidx2 {sym} [off] ptr idx mem) x)
 
-(CMP(Q|L|W|B)constloadidx1 {sym} [vo] ptr idx mem) -> (CMP(Q|L|W|B)const (MOV(Q|L|W|B)loadidx1 {sym} [offOnly(vo)] ptr idx mem) [valOnly(vo)])
-(CMPQconstloadidx8 {sym} [vo] ptr idx mem) -> (CMPQconst (MOVQloadidx8 {sym} [offOnly(vo)] ptr idx mem) [valOnly(vo)])
-(CMPLconstloadidx4 {sym} [vo] ptr idx mem) -> (CMPLconst (MOVLloadidx4 {sym} [offOnly(vo)] ptr idx mem) [valOnly(vo)])
-(CMPWconstloadidx2 {sym} [vo] ptr idx mem) -> (CMPWconst (MOVWloadidx2 {sym} [offOnly(vo)] ptr idx mem) [valOnly(vo)])
+(CMPQconstloadidx1 {sym} [vo] ptr idx mem) => (CMPQconst (MOVQloadidx1 {sym} [vo.Off32()] ptr idx mem) [vo.Val32()])
+(CMPLconstloadidx1 {sym} [vo] ptr idx mem) => (CMPLconst (MOVLloadidx1 {sym} [vo.Off32()] ptr idx mem) [vo.Val32()])
+(CMPWconstloadidx1 {sym} [vo] ptr idx mem) => (CMPWconst (MOVWloadidx1 {sym} [vo.Off32()] ptr idx mem) [vo.Val16()])
+(CMPBconstloadidx1 {sym} [vo] ptr idx mem) => (CMPBconst (MOVBloadidx1 {sym} [vo.Off32()] ptr idx mem) [vo.Val8()])
+
+(CMPQconstloadidx8 {sym} [vo] ptr idx mem) => (CMPQconst (MOVQloadidx8 {sym} [vo.Off32()] ptr idx mem) [vo.Val32()])
+(CMPLconstloadidx4 {sym} [vo] ptr idx mem) => (CMPLconst (MOVLloadidx4 {sym} [vo.Off32()] ptr idx mem) [vo.Val32()])
+(CMPWconstloadidx2 {sym} [vo] ptr idx mem) => (CMPWconst (MOVWloadidx2 {sym} [vo.Off32()] ptr idx mem) [vo.Val16()])
diff --git a/src/cmd/compile/internal/ssa/op.go b/src/cmd/compile/internal/ssa/op.go
index 49e4fa5824..6f69570b52 100644
--- a/src/cmd/compile/internal/ssa/op.go
+++ b/src/cmd/compile/internal/ssa/op.go
@@ -125,12 +125,14 @@ type Sym interface {
 // The low 32 bits hold a pointer offset.
 type ValAndOff int64
 
-func (x ValAndOff) Val() int64 {
-	return int64(x) >> 32
-}
-func (x ValAndOff) Off() int64 {
-	return int64(int32(x))
-}
+func (x ValAndOff) Val() int64   { return int64(x) >> 32 }
+func (x ValAndOff) Val32() int32 { return int32(int64(x) >> 32) }
+func (x ValAndOff) Val16() int16 { return int16(int64(x) >> 32) }
+func (x ValAndOff) Val8() int8   { return int8(int64(x) >> 32) }
+
+func (x ValAndOff) Off() int64   { return int64(int32(x)) }
+func (x ValAndOff) Off32() int32 { return int32(x) }
+
 func (x ValAndOff) Int64() int64 {
 	return int64(x)
 }
@@ -173,18 +175,6 @@ func makeValAndOff32(val, off int32) ValAndOff {
 	return ValAndOff(int64(val)<<32 + int64(uint32(off)))
 }
 
-// offOnly returns the offset half of ValAndOff vo.
-// It is intended for use in rewrite rules.
-func offOnly(vo int64) int64 {
-	return ValAndOff(vo).Off()
-}
-
-// valOnly returns the value half of ValAndOff vo.
-// It is intended for use in rewrite rules.
-func valOnly(vo int64) int64 {
-	return ValAndOff(vo).Val()
-}
-
 func (x ValAndOff) canAdd(off int64) bool {
 	newoff := x.Off() + off
 	return newoff == int64(int32(newoff))
diff --git a/src/cmd/compile/internal/ssa/rewrite386splitload.go b/src/cmd/compile/internal/ssa/rewrite386splitload.go
index f82eae99ab..fff26fa77e 100644
--- a/src/cmd/compile/internal/ssa/rewrite386splitload.go
+++ b/src/cmd/compile/internal/ssa/rewrite386splitload.go
@@ -26,17 +26,17 @@ func rewriteValue386splitload_Op386CMPBconstload(v *Value) bool {
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (CMPBconstload {sym} [vo] ptr mem)
-	// result: (CMPBconst (MOVBload {sym} [offOnly(vo)] ptr mem) [valOnly(vo)])
+	// result: (CMPBconst (MOVBload {sym} [vo.Off32()] ptr mem) [vo.Val8()])
 	for {
-		vo := v.AuxInt
-		sym := v.Aux
+		vo := auxIntToValAndOff(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		mem := v_1
 		v.reset(Op386CMPBconst)
-		v.AuxInt = valOnly(vo)
+		v.AuxInt = int8ToAuxInt(vo.Val8())
 		v0 := b.NewValue0(v.Pos, Op386MOVBload, typ.UInt8)
-		v0.AuxInt = offOnly(vo)
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(vo.Off32())
+		v0.Aux = symToAux(sym)
 		v0.AddArg2(ptr, mem)
 		v.AddArg(v0)
 		return true
@@ -51,15 +51,15 @@ func rewriteValue386splitload_Op386CMPBload(v *Value) bool {
 	// match: (CMPBload {sym} [off] ptr x mem)
 	// result: (CMPB (MOVBload {sym} [off] ptr mem) x)
 	for {
-		off := v.AuxInt
-		sym := v.Aux
+		off := auxIntToInt32(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		x := v_1
 		mem := v_2
 		v.reset(Op386CMPB)
 		v0 := b.NewValue0(v.Pos, Op386MOVBload, typ.UInt8)
-		v0.AuxInt = off
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(off)
+		v0.Aux = symToAux(sym)
 		v0.AddArg2(ptr, mem)
 		v.AddArg2(v0, x)
 		return true
@@ -71,17 +71,17 @@ func rewriteValue386splitload_Op386CMPLconstload(v *Value) bool {
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (CMPLconstload {sym} [vo] ptr mem)
-	// result: (CMPLconst (MOVLload {sym} [offOnly(vo)] ptr mem) [valOnly(vo)])
+	// result: (CMPLconst (MOVLload {sym} [vo.Off32()] ptr mem) [vo.Val32()])
 	for {
-		vo := v.AuxInt
-		sym := v.Aux
+		vo := auxIntToValAndOff(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		mem := v_1
 		v.reset(Op386CMPLconst)
-		v.AuxInt = valOnly(vo)
+		v.AuxInt = int32ToAuxInt(vo.Val32())
 		v0 := b.NewValue0(v.Pos, Op386MOVLload, typ.UInt32)
-		v0.AuxInt = offOnly(vo)
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(vo.Off32())
+		v0.Aux = symToAux(sym)
 		v0.AddArg2(ptr, mem)
 		v.AddArg(v0)
 		return true
@@ -96,15 +96,15 @@ func rewriteValue386splitload_Op386CMPLload(v *Value) bool {
 	// match: (CMPLload {sym} [off] ptr x mem)
 	// result: (CMPL (MOVLload {sym} [off] ptr mem) x)
 	for {
-		off := v.AuxInt
-		sym := v.Aux
+		off := auxIntToInt32(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		x := v_1
 		mem := v_2
 		v.reset(Op386CMPL)
 		v0 := b.NewValue0(v.Pos, Op386MOVLload, typ.UInt32)
-		v0.AuxInt = off
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(off)
+		v0.Aux = symToAux(sym)
 		v0.AddArg2(ptr, mem)
 		v.AddArg2(v0, x)
 		return true
@@ -116,17 +116,17 @@ func rewriteValue386splitload_Op386CMPWconstload(v *Value) bool {
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (CMPWconstload {sym} [vo] ptr mem)
-	// result: (CMPWconst (MOVWload {sym} [offOnly(vo)] ptr mem) [valOnly(vo)])
+	// result: (CMPWconst (MOVWload {sym} [vo.Off32()] ptr mem) [vo.Val16()])
 	for {
-		vo := v.AuxInt
-		sym := v.Aux
+		vo := auxIntToValAndOff(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		mem := v_1
 		v.reset(Op386CMPWconst)
-		v.AuxInt = valOnly(vo)
+		v.AuxInt = int16ToAuxInt(vo.Val16())
 		v0 := b.NewValue0(v.Pos, Op386MOVWload, typ.UInt16)
-		v0.AuxInt = offOnly(vo)
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(vo.Off32())
+		v0.Aux = symToAux(sym)
 		v0.AddArg2(ptr, mem)
 		v.AddArg(v0)
 		return true
@@ -141,15 +141,15 @@ func rewriteValue386splitload_Op386CMPWload(v *Value) bool {
 	// match: (CMPWload {sym} [off] ptr x mem)
 	// result: (CMPW (MOVWload {sym} [off] ptr mem) x)
 	for {
-		off := v.AuxInt
-		sym := v.Aux
+		off := auxIntToInt32(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		x := v_1
 		mem := v_2
 		v.reset(Op386CMPW)
 		v0 := b.NewValue0(v.Pos, Op386MOVWload, typ.UInt16)
-		v0.AuxInt = off
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(off)
+		v0.Aux = symToAux(sym)
 		v0.AddArg2(ptr, mem)
 		v.AddArg2(v0, x)
 		return true
diff --git a/src/cmd/compile/internal/ssa/rewriteAMD64splitload.go b/src/cmd/compile/internal/ssa/rewriteAMD64splitload.go
index 6cdf8c89c2..b04dcaf7fb 100644
--- a/src/cmd/compile/internal/ssa/rewriteAMD64splitload.go
+++ b/src/cmd/compile/internal/ssa/rewriteAMD64splitload.go
@@ -58,17 +58,17 @@ func rewriteValueAMD64splitload_OpAMD64CMPBconstload(v *Value) bool {
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (CMPBconstload {sym} [vo] ptr mem)
-	// result: (CMPBconst (MOVBload {sym} [offOnly(vo)] ptr mem) [valOnly(vo)])
+	// result: (CMPBconst (MOVBload {sym} [vo.Off32()] ptr mem) [vo.Val8()])
 	for {
-		vo := v.AuxInt
-		sym := v.Aux
+		vo := auxIntToValAndOff(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		mem := v_1
 		v.reset(OpAMD64CMPBconst)
-		v.AuxInt = valOnly(vo)
+		v.AuxInt = int8ToAuxInt(vo.Val8())
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVBload, typ.UInt8)
-		v0.AuxInt = offOnly(vo)
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(vo.Off32())
+		v0.Aux = symToAux(sym)
 		v0.AddArg2(ptr, mem)
 		v.AddArg(v0)
 		return true
@@ -81,18 +81,18 @@ func rewriteValueAMD64splitload_OpAMD64CMPBconstloadidx1(v *Value) bool {
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (CMPBconstloadidx1 {sym} [vo] ptr idx mem)
-	// result: (CMPBconst (MOVBloadidx1 {sym} [offOnly(vo)] ptr idx mem) [valOnly(vo)])
+	// result: (CMPBconst (MOVBloadidx1 {sym} [vo.Off32()] ptr idx mem) [vo.Val8()])
 	for {
-		vo := v.AuxInt
-		sym := v.Aux
+		vo := auxIntToValAndOff(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		idx := v_1
 		mem := v_2
 		v.reset(OpAMD64CMPBconst)
-		v.AuxInt = valOnly(vo)
+		v.AuxInt = int8ToAuxInt(vo.Val8())
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVBloadidx1, typ.UInt8)
-		v0.AuxInt = offOnly(vo)
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(vo.Off32())
+		v0.Aux = symToAux(sym)
 		v0.AddArg3(ptr, idx, mem)
 		v.AddArg(v0)
 		return true
@@ -107,15 +107,15 @@ func rewriteValueAMD64splitload_OpAMD64CMPBload(v *Value) bool {
 	// match: (CMPBload {sym} [off] ptr x mem)
 	// result: (CMPB (MOVBload {sym} [off] ptr mem) x)
 	for {
-		off := v.AuxInt
-		sym := v.Aux
+		off := auxIntToInt32(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		x := v_1
 		mem := v_2
 		v.reset(OpAMD64CMPB)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVBload, typ.UInt8)
-		v0.AuxInt = off
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(off)
+		v0.Aux = symToAux(sym)
 		v0.AddArg2(ptr, mem)
 		v.AddArg2(v0, x)
 		return true
@@ -131,16 +131,16 @@ func rewriteValueAMD64splitload_OpAMD64CMPBloadidx1(v *Value) bool {
 	// match: (CMPBloadidx1 {sym} [off] ptr idx x mem)
 	// result: (CMPB (MOVBloadidx1 {sym} [off] ptr idx mem) x)
 	for {
-		off := v.AuxInt
-		sym := v.Aux
+		off := auxIntToInt32(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		idx := v_1
 		x := v_2
 		mem := v_3
 		v.reset(OpAMD64CMPB)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVBloadidx1, typ.UInt8)
-		v0.AuxInt = off
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(off)
+		v0.Aux = symToAux(sym)
 		v0.AddArg3(ptr, idx, mem)
 		v.AddArg2(v0, x)
 		return true
@@ -152,17 +152,17 @@ func rewriteValueAMD64splitload_OpAMD64CMPLconstload(v *Value) bool {
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (CMPLconstload {sym} [vo] ptr mem)
-	// result: (CMPLconst (MOVLload {sym} [offOnly(vo)] ptr mem) [valOnly(vo)])
+	// result: (CMPLconst (MOVLload {sym} [vo.Off32()] ptr mem) [vo.Val32()])
 	for {
-		vo := v.AuxInt
-		sym := v.Aux
+		vo := auxIntToValAndOff(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		mem := v_1
 		v.reset(OpAMD64CMPLconst)
-		v.AuxInt = valOnly(vo)
+		v.AuxInt = int32ToAuxInt(vo.Val32())
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLload, typ.UInt32)
-		v0.AuxInt = offOnly(vo)
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(vo.Off32())
+		v0.Aux = symToAux(sym)
 		v0.AddArg2(ptr, mem)
 		v.AddArg(v0)
 		return true
@@ -175,18 +175,18 @@ func rewriteValueAMD64splitload_OpAMD64CMPLconstloadidx1(v *Value) bool {
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (CMPLconstloadidx1 {sym} [vo] ptr idx mem)
-	// result: (CMPLconst (MOVLloadidx1 {sym} [offOnly(vo)] ptr idx mem) [valOnly(vo)])
+	// result: (CMPLconst (MOVLloadidx1 {sym} [vo.Off32()] ptr idx mem) [vo.Val32()])
 	for {
-		vo := v.AuxInt
-		sym := v.Aux
+		vo := auxIntToValAndOff(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		idx := v_1
 		mem := v_2
 		v.reset(OpAMD64CMPLconst)
-		v.AuxInt = valOnly(vo)
+		v.AuxInt = int32ToAuxInt(vo.Val32())
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx1, typ.UInt32)
-		v0.AuxInt = offOnly(vo)
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(vo.Off32())
+		v0.Aux = symToAux(sym)
 		v0.AddArg3(ptr, idx, mem)
 		v.AddArg(v0)
 		return true
@@ -199,18 +199,18 @@ func rewriteValueAMD64splitload_OpAMD64CMPLconstloadidx4(v *Value) bool {
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (CMPLconstloadidx4 {sym} [vo] ptr idx mem)
-	// result: (CMPLconst (MOVLloadidx4 {sym} [offOnly(vo)] ptr idx mem) [valOnly(vo)])
+	// result: (CMPLconst (MOVLloadidx4 {sym} [vo.Off32()] ptr idx mem) [vo.Val32()])
 	for {
-		vo := v.AuxInt
-		sym := v.Aux
+		vo := auxIntToValAndOff(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		idx := v_1
 		mem := v_2
 		v.reset(OpAMD64CMPLconst)
-		v.AuxInt = valOnly(vo)
+		v.AuxInt = int32ToAuxInt(vo.Val32())
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx4, typ.UInt32)
-		v0.AuxInt = offOnly(vo)
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(vo.Off32())
+		v0.Aux = symToAux(sym)
 		v0.AddArg3(ptr, idx, mem)
 		v.AddArg(v0)
 		return true
@@ -225,15 +225,15 @@ func rewriteValueAMD64splitload_OpAMD64CMPLload(v *Value) bool {
 	// match: (CMPLload {sym} [off] ptr x mem)
 	// result: (CMPL (MOVLload {sym} [off] ptr mem) x)
 	for {
-		off := v.AuxInt
-		sym := v.Aux
+		off := auxIntToInt32(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		x := v_1
 		mem := v_2
 		v.reset(OpAMD64CMPL)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLload, typ.UInt32)
-		v0.AuxInt = off
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(off)
+		v0.Aux = symToAux(sym)
 		v0.AddArg2(ptr, mem)
 		v.AddArg2(v0, x)
 		return true
@@ -249,16 +249,16 @@ func rewriteValueAMD64splitload_OpAMD64CMPLloadidx1(v *Value) bool {
 	// match: (CMPLloadidx1 {sym} [off] ptr idx x mem)
 	// result: (CMPL (MOVLloadidx1 {sym} [off] ptr idx mem) x)
 	for {
-		off := v.AuxInt
-		sym := v.Aux
+		off := auxIntToInt32(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		idx := v_1
 		x := v_2
 		mem := v_3
 		v.reset(OpAMD64CMPL)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx1, typ.UInt32)
-		v0.AuxInt = off
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(off)
+		v0.Aux = symToAux(sym)
 		v0.AddArg3(ptr, idx, mem)
 		v.AddArg2(v0, x)
 		return true
@@ -274,16 +274,16 @@ func rewriteValueAMD64splitload_OpAMD64CMPLloadidx4(v *Value) bool {
 	// match: (CMPLloadidx4 {sym} [off] ptr idx x mem)
 	// result: (CMPL (MOVLloadidx4 {sym} [off] ptr idx mem) x)
 	for {
-		off := v.AuxInt
-		sym := v.Aux
+		off := auxIntToInt32(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		idx := v_1
 		x := v_2
 		mem := v_3
 		v.reset(OpAMD64CMPL)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVLloadidx4, typ.UInt32)
-		v0.AuxInt = off
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(off)
+		v0.Aux = symToAux(sym)
 		v0.AddArg3(ptr, idx, mem)
 		v.AddArg2(v0, x)
 		return true
@@ -295,17 +295,17 @@ func rewriteValueAMD64splitload_OpAMD64CMPQconstload(v *Value) bool {
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (CMPQconstload {sym} [vo] ptr mem)
-	// result: (CMPQconst (MOVQload {sym} [offOnly(vo)] ptr mem) [valOnly(vo)])
+	// result: (CMPQconst (MOVQload {sym} [vo.Off32()] ptr mem) [vo.Val32()])
 	for {
-		vo := v.AuxInt
-		sym := v.Aux
+		vo := auxIntToValAndOff(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		mem := v_1
 		v.reset(OpAMD64CMPQconst)
-		v.AuxInt = valOnly(vo)
+		v.AuxInt = int32ToAuxInt(vo.Val32())
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVQload, typ.UInt64)
-		v0.AuxInt = offOnly(vo)
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(vo.Off32())
+		v0.Aux = symToAux(sym)
 		v0.AddArg2(ptr, mem)
 		v.AddArg(v0)
 		return true
@@ -318,18 +318,18 @@ func rewriteValueAMD64splitload_OpAMD64CMPQconstloadidx1(v *Value) bool {
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (CMPQconstloadidx1 {sym} [vo] ptr idx mem)
-	// result: (CMPQconst (MOVQloadidx1 {sym} [offOnly(vo)] ptr idx mem) [valOnly(vo)])
+	// result: (CMPQconst (MOVQloadidx1 {sym} [vo.Off32()] ptr idx mem) [vo.Val32()])
 	for {
-		vo := v.AuxInt
-		sym := v.Aux
+		vo := auxIntToValAndOff(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		idx := v_1
 		mem := v_2
 		v.reset(OpAMD64CMPQconst)
-		v.AuxInt = valOnly(vo)
+		v.AuxInt = int32ToAuxInt(vo.Val32())
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVQloadidx1, typ.UInt64)
-		v0.AuxInt = offOnly(vo)
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(vo.Off32())
+		v0.Aux = symToAux(sym)
 		v0.AddArg3(ptr, idx, mem)
 		v.AddArg(v0)
 		return true
@@ -342,18 +342,18 @@ func rewriteValueAMD64splitload_OpAMD64CMPQconstloadidx8(v *Value) bool {
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (CMPQconstloadidx8 {sym} [vo] ptr idx mem)
-	// result: (CMPQconst (MOVQloadidx8 {sym} [offOnly(vo)] ptr idx mem) [valOnly(vo)])
+	// result: (CMPQconst (MOVQloadidx8 {sym} [vo.Off32()] ptr idx mem) [vo.Val32()])
 	for {
-		vo := v.AuxInt
-		sym := v.Aux
+		vo := auxIntToValAndOff(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		idx := v_1
 		mem := v_2
 		v.reset(OpAMD64CMPQconst)
-		v.AuxInt = valOnly(vo)
+		v.AuxInt = int32ToAuxInt(vo.Val32())
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVQloadidx8, typ.UInt64)
-		v0.AuxInt = offOnly(vo)
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(vo.Off32())
+		v0.Aux = symToAux(sym)
 		v0.AddArg3(ptr, idx, mem)
 		v.AddArg(v0)
 		return true
@@ -368,15 +368,15 @@ func rewriteValueAMD64splitload_OpAMD64CMPQload(v *Value) bool {
 	// match: (CMPQload {sym} [off] ptr x mem)
 	// result: (CMPQ (MOVQload {sym} [off] ptr mem) x)
 	for {
-		off := v.AuxInt
-		sym := v.Aux
+		off := auxIntToInt32(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		x := v_1
 		mem := v_2
 		v.reset(OpAMD64CMPQ)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVQload, typ.UInt64)
-		v0.AuxInt = off
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(off)
+		v0.Aux = symToAux(sym)
 		v0.AddArg2(ptr, mem)
 		v.AddArg2(v0, x)
 		return true
@@ -392,16 +392,16 @@ func rewriteValueAMD64splitload_OpAMD64CMPQloadidx1(v *Value) bool {
 	// match: (CMPQloadidx1 {sym} [off] ptr idx x mem)
 	// result: (CMPQ (MOVQloadidx1 {sym} [off] ptr idx mem) x)
 	for {
-		off := v.AuxInt
-		sym := v.Aux
+		off := auxIntToInt32(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		idx := v_1
 		x := v_2
 		mem := v_3
 		v.reset(OpAMD64CMPQ)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVQloadidx1, typ.UInt64)
-		v0.AuxInt = off
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(off)
+		v0.Aux = symToAux(sym)
 		v0.AddArg3(ptr, idx, mem)
 		v.AddArg2(v0, x)
 		return true
@@ -417,16 +417,16 @@ func rewriteValueAMD64splitload_OpAMD64CMPQloadidx8(v *Value) bool {
 	// match: (CMPQloadidx8 {sym} [off] ptr idx x mem)
 	// result: (CMPQ (MOVQloadidx8 {sym} [off] ptr idx mem) x)
 	for {
-		off := v.AuxInt
-		sym := v.Aux
+		off := auxIntToInt32(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		idx := v_1
 		x := v_2
 		mem := v_3
 		v.reset(OpAMD64CMPQ)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVQloadidx8, typ.UInt64)
-		v0.AuxInt = off
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(off)
+		v0.Aux = symToAux(sym)
 		v0.AddArg3(ptr, idx, mem)
 		v.AddArg2(v0, x)
 		return true
@@ -438,17 +438,17 @@ func rewriteValueAMD64splitload_OpAMD64CMPWconstload(v *Value) bool {
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (CMPWconstload {sym} [vo] ptr mem)
-	// result: (CMPWconst (MOVWload {sym} [offOnly(vo)] ptr mem) [valOnly(vo)])
+	// result: (CMPWconst (MOVWload {sym} [vo.Off32()] ptr mem) [vo.Val16()])
 	for {
-		vo := v.AuxInt
-		sym := v.Aux
+		vo := auxIntToValAndOff(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		mem := v_1
 		v.reset(OpAMD64CMPWconst)
-		v.AuxInt = valOnly(vo)
+		v.AuxInt = int16ToAuxInt(vo.Val16())
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWload, typ.UInt16)
-		v0.AuxInt = offOnly(vo)
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(vo.Off32())
+		v0.Aux = symToAux(sym)
 		v0.AddArg2(ptr, mem)
 		v.AddArg(v0)
 		return true
@@ -461,18 +461,18 @@ func rewriteValueAMD64splitload_OpAMD64CMPWconstloadidx1(v *Value) bool {
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (CMPWconstloadidx1 {sym} [vo] ptr idx mem)
-	// result: (CMPWconst (MOVWloadidx1 {sym} [offOnly(vo)] ptr idx mem) [valOnly(vo)])
+	// result: (CMPWconst (MOVWloadidx1 {sym} [vo.Off32()] ptr idx mem) [vo.Val16()])
 	for {
-		vo := v.AuxInt
-		sym := v.Aux
+		vo := auxIntToValAndOff(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		idx := v_1
 		mem := v_2
 		v.reset(OpAMD64CMPWconst)
-		v.AuxInt = valOnly(vo)
+		v.AuxInt = int16ToAuxInt(vo.Val16())
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx1, typ.UInt16)
-		v0.AuxInt = offOnly(vo)
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(vo.Off32())
+		v0.Aux = symToAux(sym)
 		v0.AddArg3(ptr, idx, mem)
 		v.AddArg(v0)
 		return true
@@ -485,18 +485,18 @@ func rewriteValueAMD64splitload_OpAMD64CMPWconstloadidx2(v *Value) bool {
 	b := v.Block
 	typ := &b.Func.Config.Types
 	// match: (CMPWconstloadidx2 {sym} [vo] ptr idx mem)
-	// result: (CMPWconst (MOVWloadidx2 {sym} [offOnly(vo)] ptr idx mem) [valOnly(vo)])
+	// result: (CMPWconst (MOVWloadidx2 {sym} [vo.Off32()] ptr idx mem) [vo.Val16()])
 	for {
-		vo := v.AuxInt
-		sym := v.Aux
+		vo := auxIntToValAndOff(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		idx := v_1
 		mem := v_2
 		v.reset(OpAMD64CMPWconst)
-		v.AuxInt = valOnly(vo)
+		v.AuxInt = int16ToAuxInt(vo.Val16())
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx2, typ.UInt16)
-		v0.AuxInt = offOnly(vo)
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(vo.Off32())
+		v0.Aux = symToAux(sym)
 		v0.AddArg3(ptr, idx, mem)
 		v.AddArg(v0)
 		return true
@@ -511,15 +511,15 @@ func rewriteValueAMD64splitload_OpAMD64CMPWload(v *Value) bool {
 	// match: (CMPWload {sym} [off] ptr x mem)
 	// result: (CMPW (MOVWload {sym} [off] ptr mem) x)
 	for {
-		off := v.AuxInt
-		sym := v.Aux
+		off := auxIntToInt32(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		x := v_1
 		mem := v_2
 		v.reset(OpAMD64CMPW)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWload, typ.UInt16)
-		v0.AuxInt = off
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(off)
+		v0.Aux = symToAux(sym)
 		v0.AddArg2(ptr, mem)
 		v.AddArg2(v0, x)
 		return true
@@ -535,16 +535,16 @@ func rewriteValueAMD64splitload_OpAMD64CMPWloadidx1(v *Value) bool {
 	// match: (CMPWloadidx1 {sym} [off] ptr idx x mem)
 	// result: (CMPW (MOVWloadidx1 {sym} [off] ptr idx mem) x)
 	for {
-		off := v.AuxInt
-		sym := v.Aux
+		off := auxIntToInt32(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		idx := v_1
 		x := v_2
 		mem := v_3
 		v.reset(OpAMD64CMPW)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx1, typ.UInt16)
-		v0.AuxInt = off
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(off)
+		v0.Aux = symToAux(sym)
 		v0.AddArg3(ptr, idx, mem)
 		v.AddArg2(v0, x)
 		return true
@@ -560,16 +560,16 @@ func rewriteValueAMD64splitload_OpAMD64CMPWloadidx2(v *Value) bool {
 	// match: (CMPWloadidx2 {sym} [off] ptr idx x mem)
 	// result: (CMPW (MOVWloadidx2 {sym} [off] ptr idx mem) x)
 	for {
-		off := v.AuxInt
-		sym := v.Aux
+		off := auxIntToInt32(v.AuxInt)
+		sym := auxToSym(v.Aux)
 		ptr := v_0
 		idx := v_1
 		x := v_2
 		mem := v_3
 		v.reset(OpAMD64CMPW)
 		v0 := b.NewValue0(v.Pos, OpAMD64MOVWloadidx2, typ.UInt16)
-		v0.AuxInt = off
-		v0.Aux = sym
+		v0.AuxInt = int32ToAuxInt(off)
+		v0.Aux = symToAux(sym)
 		v0.AddArg3(ptr, idx, mem)
 		v.AddArg2(v0, x)
 		return true
